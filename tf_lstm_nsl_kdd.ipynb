{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Read Data Sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-06-01T14:19:48.677946Z",
     "start_time": "2017-06-01T14:19:48.284503Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import time\n",
    "from collections import namedtuple\n",
    "pd.set_option(\"display.max_rows\",35)\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-06-01T14:19:48.754464Z",
     "start_time": "2017-06-01T14:19:48.679349Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class dataset:\n",
    "    kdd_train_2labels = pd.read_pickle(\"dataset/kdd_train_2labels.pkl\")\n",
    "    kdd_test_2labels = pd.read_pickle(\"dataset/kdd_test_2labels.pkl\")\n",
    "    \n",
    "    kdd_train_5labels = pd.read_pickle(\"dataset/kdd_train_5labels.pkl\")\n",
    "    kdd_test_5labels = pd.read_pickle(\"dataset/kdd_test_5labels.pkl\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-06-01T14:19:48.763784Z",
     "start_time": "2017-06-01T14:19:48.756281Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(125973, 124)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.kdd_train_2labels.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-06-01T14:19:48.777520Z",
     "start_time": "2017-06-01T14:19:48.766066Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(22544, 124)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.kdd_test_2labels.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-06-01T14:19:49.517876Z",
     "start_time": "2017-06-01T14:19:48.779519Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.99589320646770185"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn import model_selection as ms\n",
    "from sklearn import preprocessing as pp\n",
    "\n",
    "class preprocess:\n",
    "    \n",
    "    output_columns_2labels = ['is_Attack','is_Normal']\n",
    "    \n",
    "    x_input = dataset.kdd_train_2labels.drop(output_columns_2labels, axis = 1)\n",
    "    y_output = dataset.kdd_train_2labels.loc[:,output_columns_2labels]\n",
    "\n",
    "    x_test_input = dataset.kdd_test_2labels.drop(output_columns_2labels, axis = 1)\n",
    "    y_test = dataset.kdd_test_2labels.loc[:,output_columns_2labels]\n",
    "\n",
    "    ss = pp.StandardScaler()\n",
    "\n",
    "    x_train = ss.fit_transform(x_input)\n",
    "    x_test = ss.transform(x_test_input)\n",
    "\n",
    "    y_train = y_output.values\n",
    "    y_test = y_test.values\n",
    "\n",
    "preprocess.x_train.std()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-06-01T14:19:51.245690Z",
     "start_time": "2017-06-01T14:19:49.520384Z"
    }
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.contrib.legacy_seq2seq.python.ops.seq2seq import basic_rnn_seq2seq\n",
    "from tensorflow.contrib.rnn import RNNCell, LSTMCell, MultiRNNCell\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-06-01T14:19:51.423358Z",
     "start_time": "2017-06-01T14:19:51.247438Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class network(object):\n",
    "    \n",
    "    input_dim = 122\n",
    "    classes = 2\n",
    "    hidden_encoder_dim = 122\n",
    "    hidden_layers = 1\n",
    "    latent_dim = 10\n",
    "\n",
    "    hidden_decoder_dim = 122\n",
    "    lam = 0.01\n",
    "    \n",
    "    def __init__(self, classes, hidden_layers, num_of_features):\n",
    "        self.classes = classes\n",
    "        self.hidden_layers = hidden_layers\n",
    "        self.latent_dim = num_of_features\n",
    "            \n",
    "    def build_layers(self):\n",
    "        tf.reset_default_graph()\n",
    "        #learning_rate = tf.Variable(initial_value=0.001)\n",
    "\n",
    "        input_dim = self.input_dim\n",
    "        classes = self.classes\n",
    "        hidden_encoder_dim = self.hidden_encoder_dim\n",
    "        hidden_layers = self.hidden_layers\n",
    "        latent_dim = self.latent_dim\n",
    "        hidden_decoder_dim = self.hidden_decoder_dim\n",
    "        lam = self.lam\n",
    "        \n",
    "        with tf.variable_scope(\"Input\"):\n",
    "            self.x_input = tf.placeholder(\"float\", shape=[None, 1, input_dim])\n",
    "            self.y_input_ = tf.placeholder(\"float\", shape=[None, 1, classes])\n",
    "            self.keep_prob = tf.placeholder(\"float\")\n",
    "            self.lr = tf.placeholder(\"float\")\n",
    "            self.x_list = tf.unstack(self.x_input, axis= 1)\n",
    "            self.y_list_ = tf.unstack(self.y_input_, axis = 1)\n",
    "            self.y_ = self.y_list_[0]\n",
    "            \n",
    "            #GO = tf.fill((tf.shape(self.x)[0], 1), 0.5)\n",
    "            \n",
    "            #y_with_GO = tf.stack([self.y_, GO])\n",
    "            \n",
    "        with tf.variable_scope(\"lstm\"):\n",
    "            multi_cell = MultiRNNCell([LSTMCell(input_dim) for i in range(hidden_layers)] )\n",
    "            \n",
    "            self.y, states = basic_rnn_seq2seq(self.x_list, self.y_list_, multi_cell)\n",
    "            #self.y = tf.slice(self.y, [0, 0], [-1,2])\n",
    "            \n",
    "            #self.out = tf.squeeze(self.y)\n",
    "            \n",
    "            self.y = tf.layers.dense(self.y[0], classes, activation = tf.nn.softmax)\n",
    "        with tf.variable_scope(\"Loss\"):\n",
    "            \n",
    "            self.regularized_loss = tf.losses.mean_squared_error(self.y_, self.y)\n",
    "            correct_prediction = tf.equal(tf.argmax(self.y_, 1), tf.argmax(self.y, 1))\n",
    "            self.tf_accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32), name = \"Accuracy\")\n",
    "\n",
    "        with tf.variable_scope(\"Optimizer\"):\n",
    "            learning_rate=self.lr\n",
    "            optimizer = tf.train.AdamOptimizer(learning_rate)\n",
    "            gradients, variables = zip(*optimizer.compute_gradients(self.regularized_loss))\n",
    "            gradients = [\n",
    "                None if gradient is None else tf.clip_by_value(gradient, -1, 1)\n",
    "                for gradient in gradients]\n",
    "            self.train_op = optimizer.apply_gradients(zip(gradients, variables))\n",
    "            #self.train_op = optimizer.minimize(self.regularized_loss)\n",
    "            \n",
    "        # add op for merging summary\n",
    "        #self.summary_op = tf.summary.merge_all()\n",
    "        self.pred = tf.argmax(self.y, axis = 1)\n",
    "        self.actual = tf.argmax(self.y_, axis = 1)\n",
    "\n",
    "        # add Saver ops\n",
    "        self.saver = tf.train.Saver()\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-06-01T00:59:00.684124Z",
     "start_time": "2017-06-01T00:58:59.843181Z"
    }
   },
   "source": [
    "batch_iterations = 200\n",
    "\n",
    "x_train, x_valid, y_train, y_valid, = ms.train_test_split(preprocess.x_train, \n",
    "                                                                          preprocess.y_train, \n",
    "                                                                          test_size=0.1)\n",
    "batch_indices = np.array_split(np.arange(x_train.shape[0]), \n",
    "                                           batch_iterations)\n",
    "                                                                          \n",
    "for i in batch_indices:\n",
    "    print(x_train[i,np.newaxis,:])\n",
    "    print(y_train[i,np.newaxis,:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-06-01T14:19:51.628743Z",
     "start_time": "2017-06-01T14:19:51.425432Z"
    },
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import collections\n",
    "\n",
    "class Train:    \n",
    "    \n",
    "    result = namedtuple(\"score\", ['epoch', 'no_of_features','hidden_layers','train_score', 'test_score', 'time_taken'])\n",
    "\n",
    "    predictions = {}\n",
    "\n",
    "    results = []\n",
    "    best_acc = 0\n",
    "    best_acc_global = 0\n",
    "\n",
    "    def train(epochs, net, h,f, lrs):\n",
    "        batch_iterations = 200\n",
    "        train_loss = None\n",
    "        Train.best_acc = 0\n",
    "        os.makedirs(\"dataset/tf_lstm_nsl_kdd/hidden layers_{}_features count_{}\".format(h,f),\n",
    "                    exist_ok = True)\n",
    "        with tf.Session() as sess:\n",
    "            #summary_writer_train = tf.summary.FileWriter('./logs/kdd/VAE/training', graph=sess.graph)\n",
    "            #summary_writer_valid = tf.summary.FileWriter('./logs/kdd/VAE/validation')\n",
    "\n",
    "            sess.run(tf.global_variables_initializer())\n",
    "            start_time = time.perf_counter()\n",
    "            for lr in lrs:\n",
    "                for epoch in range(1, (epochs+1)):\n",
    "                    x_train, x_valid, y_train, y_valid, = ms.train_test_split(preprocess.x_train, \n",
    "                                                                              preprocess.y_train, \n",
    "                                                                              test_size=0.1)\n",
    "                    batch_indices = np.array_split(np.arange(x_train.shape[0]), \n",
    "                                               batch_iterations)\n",
    "\n",
    "                    for i in batch_indices:\n",
    "\n",
    "                        _, train_loss = sess.run([net.train_op, net.regularized_loss], #net.summary_op\n",
    "                                                              feed_dict={net.x_input: x_train[i,np.newaxis,:], \n",
    "                                                                         net.y_input_: y_train[i,np.newaxis,:], \n",
    "                                                                         net.keep_prob:1, net.lr:lr})\n",
    "                        #summary_writer_train.add_summary(summary_str, epoch)\n",
    "                        if(train_loss > 1e9):\n",
    "                            print(\"Step {} | Training Loss: {:.6f}\".format(epoch, train_loss))\n",
    "\n",
    "\n",
    "                    valid_accuracy,valid_loss = sess.run([net.tf_accuracy, net.regularized_loss], #net.summary_op \n",
    "                                                          feed_dict={net.x_input: x_valid[:,np.newaxis,:], \n",
    "                                                                     net.y_input_: y_valid[:,np.newaxis,:], \n",
    "                                                                     net.keep_prob:1, net.lr:lr})\n",
    "                    #summary_writer_valid.add_summary(summary_str, epoch)\n",
    "\n",
    "\n",
    "\n",
    "                    accuracy, pred_value, actual_value, y_pred = sess.run([net.tf_accuracy, \n",
    "                                                                   net.pred, \n",
    "                                                                   net.actual, net.y], \n",
    "                                                                  feed_dict={net.x_input: preprocess.x_test[:,np.newaxis,:], \n",
    "                                                                             net.y_input_: preprocess.y_test[:,np.newaxis,:], \n",
    "                                                                             net.keep_prob:1, net.lr:lr})\n",
    "\n",
    "                    print(\"Step {} | Training Loss: {:.6f} | Train Accuracy: {:.6f} | Test Accuracy: {:.6f}\".format(epoch, train_loss, valid_accuracy, accuracy))\n",
    "\n",
    "                    if accuracy > Train.best_acc_global:\n",
    "                                Train.best_acc_global = accuracy\n",
    "                                Train.pred_value = pred_value\n",
    "                                Train.actual_value = actual_value\n",
    "                                Train.best_parameters = \"Hidden Layers:{}, Features Count:{}\".format(h, f)\n",
    "\n",
    "                    if accuracy > Train.best_acc:\n",
    "\n",
    "                        #net.saver.save(sess, \"dataset/tf_vae_only_nsl_kdd_hidden layers_{}_features count_{}\".format(epochs,h,f))\n",
    "                        #Train.results.append(Train.result(epochs, f, h,valid_accuracy, accuracy))\n",
    "                        #curr_pred = pd.DataFrame({\"Attack_prob\":y_pred[:,-2], \"Normal_prob\":y_pred[:, -1]})\n",
    "                        #Train.predictions.update({\"{}_{}_{}\".format(epochs,f,h):curr_pred})\n",
    "\n",
    "                        Train.best_acc = accuracy\n",
    "                        if not (np.isnan(train_loss)):\n",
    "                            net.saver.save(sess, \n",
    "                                       \"dataset/tf_lstm_nsl_kdd/hidden layers_{}_features count_{}/model\"\n",
    "                                       .format(h,f), \n",
    "                                       global_step = epoch, \n",
    "                                       write_meta_graph=False)\n",
    "\n",
    "                        curr_pred = pd.DataFrame({\"Attack_prob\":y_pred[:,-2], \"Normal_prob\":y_pred[:, -1], \"Prediction\":pred_value})\n",
    "                        Train.predictions.update({\"{}_{}_{}\".format(epochs*len(lrs),f,h):\n",
    "                                                  (curr_pred, \n",
    "                                                   Train.result(epochs*len(lrs), f, h,valid_accuracy, accuracy, time.perf_counter() - start_time))})\n",
    "\n",
    "\n",
    "\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-06-01T14:30:01.409982Z",
     "start_time": "2017-06-01T14:19:51.630248Z"
    },
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current Layer Attributes - epochs:5 hidden layers:2 features count:122\n",
      "Step 1 | Training Loss: 0.000002 | Train Accuracy: 0.999206 | Test Accuracy: 0.995830\n",
      "Step 2 | Training Loss: 0.000002 | Train Accuracy: 0.999524 | Test Accuracy: 0.995564\n",
      "Step 3 | Training Loss: 0.000000 | Train Accuracy: 0.999127 | Test Accuracy: 0.976757\n",
      "Step 4 | Training Loss: 0.000000 | Train Accuracy: 0.999444 | Test Accuracy: 0.976757\n",
      "Step 5 | Training Loss: 0.000000 | Train Accuracy: 0.999444 | Test Accuracy: 0.976934\n",
      "Step 1 | Training Loss: 0.000000 | Train Accuracy: 0.999682 | Test Accuracy: 0.976890\n",
      "Step 2 | Training Loss: 0.000000 | Train Accuracy: 0.999365 | Test Accuracy: 0.976890\n",
      "Step 3 | Training Loss: 0.000000 | Train Accuracy: 0.999524 | Test Accuracy: 0.976890\n",
      "Step 4 | Training Loss: 0.000000 | Train Accuracy: 0.999603 | Test Accuracy: 0.976934\n",
      "Step 5 | Training Loss: 0.000000 | Train Accuracy: 0.999603 | Test Accuracy: 0.976934\n",
      "Current Layer Attributes - epochs:5 hidden layers:4 features count:122\n",
      "Step 1 | Training Loss: 0.063477 | Train Accuracy: 0.945944 | Test Accuracy: 0.748669\n",
      "Step 2 | Training Loss: 0.027432 | Train Accuracy: 0.970630 | Test Accuracy: 0.791874\n",
      "Step 3 | Training Loss: 0.056552 | Train Accuracy: 0.943483 | Test Accuracy: 0.769473\n",
      "Step 4 | Training Loss: 0.030230 | Train Accuracy: 0.975949 | Test Accuracy: 0.826561\n",
      "Step 5 | Training Loss: 0.019433 | Train Accuracy: 0.977060 | Test Accuracy: 0.824521\n",
      "Step 1 | Training Loss: 0.031808 | Train Accuracy: 0.979917 | Test Accuracy: 0.836586\n",
      "Step 2 | Training Loss: 0.026526 | Train Accuracy: 0.980235 | Test Accuracy: 0.847897\n",
      "Step 3 | Training Loss: 0.015466 | Train Accuracy: 0.982140 | Test Accuracy: 0.918737\n",
      "Step 4 | Training Loss: 0.014970 | Train Accuracy: 0.988173 | Test Accuracy: 0.938121\n",
      "Step 5 | Training Loss: 0.005395 | Train Accuracy: 0.988093 | Test Accuracy: 0.941270\n",
      "Current Layer Attributes - epochs:5 hidden layers:6 features count:122\n",
      "Step 1 | Training Loss: 0.035111 | Train Accuracy: 0.971345 | Test Accuracy: 0.752750\n",
      "Step 2 | Training Loss: 0.034103 | Train Accuracy: 0.970075 | Test Accuracy: 0.754037\n",
      "Step 3 | Training Loss: 0.007049 | Train Accuracy: 0.989522 | Test Accuracy: 0.770671\n",
      "Step 4 | Training Loss: 0.004899 | Train Accuracy: 0.991427 | Test Accuracy: 0.769961\n",
      "Step 5 | Training Loss: 0.003432 | Train Accuracy: 0.990792 | Test Accuracy: 0.772401\n",
      "Step 1 | Training Loss: 0.004162 | Train Accuracy: 0.993332 | Test Accuracy: 0.777857\n",
      "Step 2 | Training Loss: 0.003847 | Train Accuracy: 0.995714 | Test Accuracy: 0.780296\n",
      "Step 3 | Training Loss: 0.005354 | Train Accuracy: 0.994364 | Test Accuracy: 0.778522\n",
      "Step 4 | Training Loss: 0.002995 | Train Accuracy: 0.994920 | Test Accuracy: 0.779454\n",
      "Step 5 | Training Loss: 0.003926 | Train Accuracy: 0.995555 | Test Accuracy: 0.777280\n"
     ]
    }
   ],
   "source": [
    "import itertools\n",
    "class Hyperparameters:\n",
    "#    features_arr = [2, 4, 8, 16, 32, 64, 128, 256]\n",
    "#    hidden_layers_arr = [2, 4, 6, 10]\n",
    "    features_arr = [122] #[4, 8, 16, 32]\n",
    "    hidden_layers_arr = [2, 4, 6]\n",
    "\n",
    "    epochs = [5]\n",
    "    lrs = [1e-2, 1e-4]\n",
    "    \n",
    "    for e, h, f in itertools.product(epochs, hidden_layers_arr, features_arr):\n",
    "        print(\"Current Layer Attributes - epochs:{} hidden layers:{} features count:{}\".format(e,h,f))\n",
    "        n = network(2,h,f)\n",
    "        n.build_layers()\n",
    "        Train.train(e, n, h,f, lrs)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-06-01T14:33:11.321709Z",
     "start_time": "2017-06-01T14:33:11.316912Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dict1 = {}\n",
    "dict2 = []\n",
    "for k, (v1, v2) in Train.predictions.items():\n",
    "    dict1.update({k: v1})\n",
    "    dict2.append(v2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-06-01T14:33:11.946279Z",
     "start_time": "2017-06-01T14:33:11.943196Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Train.predictions = dict1\n",
    "Train.results = dict2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-06-01T14:33:12.665651Z",
     "start_time": "2017-06-01T14:33:12.661661Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_results = pd.DataFrame(Train.results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-06-01T14:33:13.559787Z",
     "start_time": "2017-06-01T14:33:13.547893Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>epoch</th>\n",
       "      <th>no_of_features</th>\n",
       "      <th>hidden_layers</th>\n",
       "      <th>train_score</th>\n",
       "      <th>test_score</th>\n",
       "      <th>time_taken</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10</td>\n",
       "      <td>122</td>\n",
       "      <td>2</td>\n",
       "      <td>0.999206</td>\n",
       "      <td>0.995830</td>\n",
       "      <td>9.976430</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10</td>\n",
       "      <td>122</td>\n",
       "      <td>4</td>\n",
       "      <td>0.988093</td>\n",
       "      <td>0.941270</td>\n",
       "      <td>200.224591</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>10</td>\n",
       "      <td>122</td>\n",
       "      <td>6</td>\n",
       "      <td>0.995714</td>\n",
       "      <td>0.780296</td>\n",
       "      <td>210.623815</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   epoch  no_of_features  hidden_layers  train_score  test_score  time_taken\n",
       "0     10             122              2     0.999206    0.995830    9.976430\n",
       "1     10             122              4     0.988093    0.941270  200.224591\n",
       "2     10             122              6     0.995714    0.780296  210.623815"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_results.sort_values(by = 'test_score', ascending = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-06-01T14:33:21.949466Z",
     "start_time": "2017-06-01T14:33:21.942203Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pd.Panel(Train.predictions).to_pickle(\"dataset/tf_lstm_nsl_kdd_predictions.pkl\")\n",
    "df_results.to_pickle(\"dataset/tf_lstm_nsl_kdd_scores.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-06-01T14:33:43.666077Z",
     "start_time": "2017-06-01T14:33:43.605224Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import itertools\n",
    "\n",
    "def plot_confusion_matrix(cm, classes,\n",
    "                          normalize=False,\n",
    "                          title='Confusion matrix',\n",
    "                          cmap=plt.cm.Blues):\n",
    "    \"\"\"\n",
    "    This function prints and plots the confusion matrix.\n",
    "    Normalization can be applied by setting `normalize=True`.\n",
    "    \"\"\"\n",
    "    np.set_printoptions(precision=4)\n",
    "\n",
    "    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n",
    "    plt.title(title)\n",
    "    plt.colorbar()\n",
    "    tick_marks = np.arange(len(classes))\n",
    "    plt.xticks(tick_marks, classes, rotation=45)\n",
    "    plt.yticks(tick_marks, classes)\n",
    "\n",
    "    if normalize:\n",
    "        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "        print(\"Normalized confusion matrix\")\n",
    "    else:\n",
    "        print('Confusion matrix, without normalization')\n",
    "\n",
    "    print(cm)\n",
    "\n",
    "    thresh = cm.max() / 2.\n",
    "    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
    "        plt.text(j, i, cm[i, j].round(4),\n",
    "                 horizontalalignment=\"center\",\n",
    "                 color=\"white\" if cm[i, j] > thresh else \"black\")\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.ylabel('True label')\n",
    "    plt.xlabel('Predicted label')\n",
    "\n",
    "def plot(actual_value, pred_value):\n",
    "    from sklearn.metrics import confusion_matrix\n",
    "    cm_2labels = confusion_matrix(y_pred = pred_value, y_true = actual_value)\n",
    "    plt.figure(figsize=[6,6])\n",
    "    plot_confusion_matrix(cm_2labels, preprocess.output_columns_2labels, normalize = False,\n",
    "                         title = Train.best_parameters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-06-01T14:33:44.530473Z",
     "start_time": "2017-06-01T14:33:44.245695Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion matrix, without normalization\n",
      "[[12816    17]\n",
      " [   77  9634]]\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAbcAAAGeCAYAAAAXNE8VAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nWe78f/LYeaKEt8F8AAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7fcbbe48feb8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot(actual_value = Train.actual_value, pred_value = Train.pred_value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-06-01T14:33:45.460596Z",
     "start_time": "2017-06-01T14:33:45.422311Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#4.5 GB\n",
    "pd.Series(Train.pred_value).to_csv('LSTM_prediction_values.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "_draft": {
   "nbviewer_url": "https://gist.github.com/7d1ace18a82178e15ece8fc5252fce88"
  },
  "anaconda-cloud": {},
  "gist": {
   "data": {
    "description": "Hyper parameter tuning",
    "public": false
   },
   "id": "7d1ace18a82178e15ece8fc5252fce88"
  },
  "kernelspec": {
   "display_name": "Python [conda env:p3]",
   "language": "python",
   "name": "conda-env-p3-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
