{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Read Data Sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-10-17T22:27:42.097977Z",
     "start_time": "2017-10-17T22:27:41.692173Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "from collections import namedtuple\n",
    "pd.set_option(\"display.max_rows\",100)\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-10-17T22:27:42.109903Z",
     "start_time": "2017-10-17T22:27:42.099348Z"
    }
   },
   "outputs": [],
   "source": [
    "%%bash\n",
    "rm dataset/scores/tf_vae_only_vae_loss_nsl_kdd_scores_all.pkl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-10-17T22:27:42.120815Z",
     "start_time": "2017-10-17T22:27:42.111393Z"
    }
   },
   "outputs": [],
   "source": [
    "train_paths = {\"20150304\":\"dataset/preprocessed_train_data.pkl\"}\n",
    "test_paths = {\"20150604\":\"dataset/preprocessed_train_data.pkl\"}\n",
    "\n",
    "class preprocess:\n",
    "    \n",
    "    def get_data(paths):\n",
    "        \n",
    "        for key, value in paths.items():\n",
    "            sample_data = pd.read_pickle(value)\n",
    "            x = sample_data.iloc[:,:-2]\n",
    "            y = sample_data.iloc[:,-2:]\n",
    "            yield key, x.values, y.values\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-10-17T22:27:43.479222Z",
     "start_time": "2017-10-17T22:27:42.122057Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from sklearn import model_selection as ms\n",
    "from sklearn import metrics as me"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-10-17T22:27:43.873682Z",
     "start_time": "2017-10-17T22:27:43.480943Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class network(object):\n",
    "    \n",
    "    input_dim = 10\n",
    "    classes = 2\n",
    "    hidden_encoder_dim = 10\n",
    "    hidden_layers = 1\n",
    "    latent_dim = 5\n",
    "\n",
    "    hidden_decoder_dim = 10\n",
    "    lam = 0.01\n",
    "    \n",
    "    def __init__(self, classes, hidden_layers, num_of_features):\n",
    "        self.classes = classes\n",
    "        self.hidden_layers = hidden_layers\n",
    "        self.latent_dim = num_of_features\n",
    "            \n",
    "    def build_layers(self):\n",
    "        tf.reset_default_graph()\n",
    "        #learning_rate = tf.Variable(initial_value=0.001)\n",
    "\n",
    "        input_dim = self.input_dim\n",
    "        classes = self.classes\n",
    "        hidden_encoder_dim = self.hidden_encoder_dim\n",
    "        hidden_layers = self.hidden_layers\n",
    "        latent_dim = self.latent_dim\n",
    "        hidden_decoder_dim = self.hidden_decoder_dim\n",
    "        lam = self.lam\n",
    "        \n",
    "        with tf.variable_scope(\"Input\"):\n",
    "            self.x = tf.placeholder(\"float\", shape=[None, input_dim])\n",
    "            self.y_ = tf.placeholder(\"float\", shape=[None, classes])\n",
    "            self.keep_prob = tf.placeholder(\"float\")\n",
    "            self.lr = tf.placeholder(\"float\")\n",
    "        \n",
    "        with tf.variable_scope(\"Layer_Encoder\"):\n",
    "\n",
    "            hidden_encoder = tf.layers.dense(self.x, hidden_encoder_dim, activation = tf.nn.relu, kernel_regularizer=tf.nn.l2_loss)\n",
    "            hidden_encoder = tf.nn.dropout(hidden_encoder, self.keep_prob)\n",
    "            for h in range(hidden_layers - 1):\n",
    "                hidden_encoder = tf.layers.dense(hidden_encoder, hidden_encoder_dim, activation = tf.nn.relu, kernel_regularizer=tf.nn.l2_loss)\n",
    "                hidden_encoder = tf.nn.dropout(hidden_encoder, self.keep_prob)\n",
    "                \n",
    "        with tf.variable_scope(\"Layer_Mean\"):\n",
    "            mu_encoder = tf.layers.dense(hidden_encoder, latent_dim, activation = None, kernel_regularizer=tf.nn.l2_loss)\n",
    "\n",
    "        with tf.variable_scope(\"Layer_Variance\"):\n",
    "            logvar_encoder = tf.layers.dense(hidden_encoder, latent_dim, activation = None, kernel_regularizer=tf.nn.l2_loss)\n",
    "\n",
    "        with tf.variable_scope(\"Sampling_Distribution\"):\n",
    "            # Sample epsilon\n",
    "            epsilon = tf.random_normal(tf.shape(logvar_encoder), mean=0, stddev=1, name='epsilon')\n",
    "\n",
    "            # Sample latent variable\n",
    "            std_encoder = tf.exp(0.5 * logvar_encoder)\n",
    "            z = mu_encoder + tf.multiply(std_encoder, epsilon)\n",
    "            \n",
    "            #tf.summary.histogram(\"Sample_Distribution\", z)\n",
    "\n",
    "        with tf.variable_scope(\"Layer_Decoder\"):\n",
    "            hidden_decoder = tf.layers.dense(z, hidden_decoder_dim, activation = tf.nn.relu, kernel_regularizer=tf.nn.l2_loss)\n",
    "            hidden_decoder = tf.nn.dropout(hidden_decoder, self.keep_prob)\n",
    "            for h in range(hidden_layers - 1):\n",
    "                hidden_decoder = tf.layers.dense(hidden_decoder, hidden_decoder_dim, activation = tf.nn.relu, kernel_regularizer=tf.nn.l2_loss)\n",
    "                hidden_decoder = tf.nn.dropout(hidden_decoder, self.keep_prob)\n",
    "                \n",
    "        with tf.variable_scope(\"Layer_Reconstruction\"):\n",
    "            self.x_hat = tf.layers.dense(hidden_decoder, input_dim, activation = None)\n",
    "            \n",
    "            self.y = tf.slice(self.x_hat, [0,input_dim-2], [-1,-1])\n",
    "\n",
    "        with tf.variable_scope(\"Loss\"):\n",
    "            \n",
    "            BCE = tf.reduce_mean(tf.nn.sigmoid_cross_entropy_with_logits(logits=self.x_hat, labels=self.x), reduction_indices=1)\n",
    "            KLD = -0.5 * tf.reduce_mean(1 + logvar_encoder - tf.pow(mu_encoder, 2) - tf.exp(logvar_encoder), reduction_indices=1)\n",
    "            softmax_loss = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(labels = self.y_, logits = self.y))\n",
    "\n",
    "            loss = tf.reduce_mean((BCE + KLD + softmax_loss) * lam)\n",
    "\n",
    "            #loss = tf.clip_by_value(loss, -1e-2, 1e-2)\n",
    "            #loss = tf.where(tf.is_nan(loss), 1e-2, loss)\n",
    "            #loss = tf.where(tf.equal(loss, -1e-2), tf.random_normal(loss.shape), loss)\n",
    "            #loss = tf.where(tf.equal(loss, 1e-2), tf.random_normal(loss.shape), loss)\n",
    "            \n",
    "            self.regularized_loss = tf.abs(loss, name = \"Regularized_loss\")\n",
    "            correct_prediction = tf.equal(tf.argmax(self.y_, 1), tf.argmax(self.y, 1))\n",
    "            self.tf_accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32), name = \"Accuracy\")\n",
    "\n",
    "        with tf.variable_scope(\"Optimizer\"):\n",
    "            learning_rate=self.lr\n",
    "            optimizer = tf.train.AdamOptimizer(learning_rate)\n",
    "            gradients, variables = zip(*optimizer.compute_gradients(self.regularized_loss))\n",
    "            gradients = [\n",
    "                None if gradient is None else tf.clip_by_value(gradient, -1, 1)\n",
    "                for gradient in gradients]\n",
    "            self.train_op = optimizer.apply_gradients(zip(gradients, variables))\n",
    "            #self.train_op = optimizer.minimize(self.regularized_loss)\n",
    "            \n",
    "            \n",
    "        # add op for merging summary\n",
    "        #self.summary_op = tf.summary.merge_all()\n",
    "        self.pred = tf.argmax(self.y, axis = 1)\n",
    "        self.actual = tf.argmax(self.y_, axis = 1)\n",
    "\n",
    "        # add Saver ops\n",
    "        self.saver = tf.train.Saver()\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-10-17T22:27:44.105100Z",
     "start_time": "2017-10-17T22:27:43.875347Z"
    },
    "collapsed": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import collections\n",
    "import time\n",
    "\n",
    "class Train:    \n",
    "    \n",
    "    result = namedtuple(\"score\", ['key', 'no_of_features','hidden_layers','train_score', 'test_score', 'quality_score', 'time_taken'])\n",
    "\n",
    "    predictions = {}\n",
    "\n",
    "    results = []\n",
    "    best_acc = 0\n",
    "    best_acc_global = 0\n",
    "\n",
    "    def train(epochs, net, h,f, lrs):\n",
    "        batch_iterations = 200\n",
    "        train_loss = None\n",
    "        Train.best_acc = 0\n",
    "        os.makedirs(\"dataset/tf_vae_only_vae_loss_nsl_kdd/hidden layers_{}_features count_{}\".format(epochs,h,f),\n",
    "                    exist_ok = True)\n",
    "        with tf.Session() as sess:\n",
    "            #summary_writer_train = tf.summary.FileWriter('./logs/kdd/VAE/training', graph=sess.graph)\n",
    "            #summary_writer_valid = tf.summary.FileWriter('./logs/kdd/VAE/validation')\n",
    "\n",
    "            sess.run(tf.global_variables_initializer())\n",
    "            start_time = time.perf_counter()\n",
    "            for lr in lrs:\n",
    "                for epoch in range(1, (epochs+1)):\n",
    "                    #print(\"Step {} | Training Loss:\".format(epoch), end = \" \" )\n",
    "                    for key, x_train, y_train in preprocess.get_data(train_paths):\n",
    "                        x_train, x_valid, y_train, y_valid, = ms.train_test_split(x_train, \n",
    "                                                                                  y_train, \n",
    "                                                                                  test_size=0.1)\n",
    "                        batch_indices = np.array_split(np.arange(x_train.shape[0]), \n",
    "                                                   batch_iterations)\n",
    "\n",
    "                        for i in batch_indices:\n",
    "\n",
    "                            def train_batch():\n",
    "                                nonlocal train_loss\n",
    "                                _, train_loss = sess.run([net.train_op, \n",
    "                                                           net.regularized_loss, \n",
    "                                                           ], #net.summary_op\n",
    "                                                          feed_dict={net.x: x_train[i,:], \n",
    "                                                                     net.y_: y_train[i,:], \n",
    "                                                                     net.keep_prob:1, net.lr:lr})\n",
    "                            train_batch()\n",
    "\n",
    "                            count = 10\n",
    "                            while((train_loss > 1e4 or np.isnan(train_loss)) and epoch > 1 and count > 1):\n",
    "                                print(\"Step {} | High Training Loss: {:.6f} ... Restoring Net\".format(epoch, train_loss))\n",
    "                                net.saver.restore(sess, \n",
    "                                                  tf.train.latest_checkpoint('dataset/tf_vae_only_vae_loss_nsl_kdd/hidden layers_{}_features count_{}'\n",
    "                                                                             .format(epochs,h,f)))\n",
    "                                train_batch()\n",
    "                                count -=1\n",
    "\n",
    "                            #summary_writer_train.add_summary(summary_str, epoch)\n",
    "                            #if(train_loss > 1e9):\n",
    "\n",
    "                            #print(\"{:.6f}\".format(train_loss), end = \", \" )\n",
    "\n",
    "                        #print(\"\")\n",
    "                        valid_loss, valid_accuracy = sess.run([net.regularized_loss, net.tf_accuracy], feed_dict={net.x: x_valid, \n",
    "                                                                             net.y_: y_valid, \n",
    "                                                                             net.keep_prob:1, net.lr:lr})\n",
    "                    end_time = time.perf_counter()\n",
    "                    for key, x_test, y_test in preprocess.get_data(test_paths):\n",
    "\n",
    "                        accuracy, test_loss, pred_value, actual_value, y_pred = sess.run([net.tf_accuracy, net.regularized_loss, \n",
    "                                                                       net.pred, \n",
    "                                                                       net.actual, net.y], \n",
    "                                                                      feed_dict={net.x: x_test, \n",
    "                                                                                 net.y_: y_test, \n",
    "                                                                                 net.keep_prob:1, net.lr:lr})\n",
    "                        \n",
    "                        quality_score = me.matthews_corrcoef(actual_value, pred_value)\n",
    "                        recall = me.recall_score(actual_value, pred_value)\n",
    "                        prec = me.precision_score(actual_value, pred_value)\n",
    "                        accuracy = me.roc_auc_score(actual_value, pred_value)\n",
    "                        \n",
    "                        print(\"Key {} | Training Loss: {:.6f} | Train Accuracy: {:.6f} | Test Accuracy: {:.6f}, quality_score: {}\".format(key, train_loss, valid_accuracy, accuracy, quality_score))\n",
    "                       \n",
    "\n",
    "                        if accuracy > Train.best_acc_global:\n",
    "                            Train.best_acc_global = accuracy\n",
    "\n",
    "                            Train.pred_value = pred_value\n",
    "                            Train.actual_value = actual_value\n",
    "\n",
    "                            Train.best_parameters = \"Hidden Layers:{}, Features Count:{}\".format(h, f)\n",
    "\n",
    "\n",
    "                        curr_pred = pd.DataFrame({\"Attack_prob\":y_pred[:,-2], \"Normal_prob\":y_pred[:, -1], \"Prediction\":pred_value, \"Actual\":actual_value})\n",
    "                        Train.predictions.update({\"{}_{}_{}\".format(key,f,h):\n",
    "                                                  (curr_pred, \n",
    "                                                   Train.result(key, f, h,valid_accuracy, accuracy, quality_score, end_time - start_time))})\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-10-17T22:27:44.163303Z",
     "start_time": "2017-10-17T22:27:44.106729Z"
    },
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import itertools\n",
    "\n",
    "df_results = []\n",
    "past_scores = []\n",
    "\n",
    "class Hyperparameters:\n",
    "#    features_arr = [2, 4, 8, 16, 32, 64, 128, 256]\n",
    "#    hidden_layers_arr = [2, 4, 6, 10]\n",
    "\n",
    "    def start_training():\n",
    "        global df_results\n",
    "        global past_scores\n",
    "        print(\"********************************** Training ******************************\")\n",
    "        Train.predictions = {}\n",
    "        Train.results = []\n",
    "    \n",
    "        \n",
    "        features_arr = [1, 4, 10]\n",
    "        hidden_layers_arr = [1, 3]\n",
    "\n",
    "        epochs = [1]\n",
    "        lrs = [1e-5]\n",
    "        print(\"***************************** Entering Loop **********************\")\n",
    "        for e, h, f in itertools.product(epochs, hidden_layers_arr, features_arr):\n",
    "            print(\"Current Layer Attributes - hidden layers:{} features count:{}\".format(h,f))\n",
    "            n = network(2,h,f)\n",
    "            n.build_layers()\n",
    "            Train.train(e, n, h,f, lrs)\n",
    "            \n",
    "        dict1 = {}\n",
    "        dict2 = []\n",
    "        for k, (v1, v2) in Train.predictions.items():\n",
    "            dict1.update({k: v1})\n",
    "            dict2.append(v2)\n",
    "        Train.predictions = dict1\n",
    "        Train.results = dict2\n",
    "        df_results = pd.DataFrame(Train.results)\n",
    "\n",
    "        #temp = df_results.set_index(['no_of_features', 'hidden_layers'])\n",
    "\n",
    "        if not os.path.isfile('dataset/scores/tf_vae_only_vae_loss_nsl_kdd_scores_all.pkl'):\n",
    "            past_scores = df_results#temp\n",
    "        else:\n",
    "            past_scores = pd.read_pickle(\"dataset/scores/tf_vae_only_vae_loss_nsl_kdd_scores_all.pkl\")\n",
    "\n",
    "        past_scores.append(df_results, ignore_index=True).to_pickle(\"dataset/scores/tf_vae_only_vae_loss_nsl_kdd_scores_all.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-10-17T22:28:06.046136Z",
     "start_time": "2017-10-17T22:27:44.164897Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "********************************** Training ******************************\n",
      "***************************** Entering Loop **********************\n",
      "Current Layer Attributes - hidden layers:1 features count:1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ritesh_malaiya/anaconda3/envs/p3/lib/python3.6/site-packages/sklearn/metrics/classification.py:516: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  mcc = cov_ytyp / np.sqrt(var_yt * var_yp)\n",
      "/home/ritesh_malaiya/anaconda3/envs/p3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1113: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Key 20150604 | Training Loss: nan | Train Accuracy: 0.861450 | Test Accuracy: 0.500000, quality_score: 0.0\n",
      "Current Layer Attributes - hidden layers:1 features count:4\n",
      "Key 20150604 | Training Loss: nan | Train Accuracy: 0.862420 | Test Accuracy: 0.500000, quality_score: 0.0\n",
      "Current Layer Attributes - hidden layers:1 features count:10\n",
      "Key 20150604 | Training Loss: nan | Train Accuracy: 0.862299 | Test Accuracy: 0.500000, quality_score: 0.0\n",
      "Current Layer Attributes - hidden layers:3 features count:1\n",
      "Key 20150604 | Training Loss: nan | Train Accuracy: 0.862572 | Test Accuracy: 0.500000, quality_score: 0.0\n",
      "Current Layer Attributes - hidden layers:3 features count:4\n",
      "Key 20150604 | Training Loss: nan | Train Accuracy: 0.865087 | Test Accuracy: 0.500000, quality_score: 0.0\n",
      "Current Layer Attributes - hidden layers:3 features count:10\n",
      "Key 20150604 | Training Loss: nan | Train Accuracy: 0.861966 | Test Accuracy: 0.500000, quality_score: 0.0\n"
     ]
    }
   ],
   "source": [
    "#%%timeit\n",
    "Hyperparameters.start_training()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-10-17T22:28:06.378903Z",
     "start_time": "2017-10-17T22:28:06.049197Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pd.Panel(Train.predictions).to_pickle(\"dataset/tf_vae_only_vae_loss_nsl_kdd_predictions.pkl\")\n",
    "df_results.to_pickle(\"dataset/tf_vae_only_vae_loss_nsl_kdd_scores.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-10-17T22:28:06.481074Z",
     "start_time": "2017-10-17T22:28:06.381039Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import itertools\n",
    "\n",
    "def plot_confusion_matrix(cm, classes,\n",
    "                          normalize=False,\n",
    "                          title='Confusion matrix',\n",
    "                          cmap=plt.cm.Blues):\n",
    "    \"\"\"\n",
    "    This function prints and plots the confusion matrix.\n",
    "    Normalization can be applied by setting `normalize=True`.\n",
    "    \"\"\"\n",
    "    np.set_printoptions(precision=4)\n",
    "\n",
    "    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n",
    "    plt.title(title)\n",
    "    plt.colorbar()\n",
    "    tick_marks = np.arange(len(classes))\n",
    "    plt.xticks(tick_marks, classes, rotation=45)\n",
    "    plt.yticks(tick_marks, classes)\n",
    "\n",
    "    if normalize:\n",
    "        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "        #print(\"Normalized confusion matrix\")\n",
    "    else:\n",
    "        #print('Confusion matrix, without normalization')\n",
    "        pass\n",
    "    \n",
    "    #print(cm)\n",
    "\n",
    "    label = [[\"\\n True Positive\", \"\\n False Negative \\n Type II Error\"],\n",
    "             [\"\\n False Positive \\n Type I Error\", \"\\n True Negative\"]\n",
    "            ]\n",
    "    \n",
    "    thresh = cm.max() / 2.\n",
    "    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
    "        \n",
    "        plt.text(j, i, \"{} {}\".format(cm[i, j].round(4), label[i][j]),\n",
    "                 horizontalalignment=\"center\",\n",
    "                 color=\"white\" if cm[i, j] > thresh else \"black\")\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.ylabel('True label')\n",
    "    plt.xlabel('Predicted label')\n",
    "\n",
    "def plot(actual_value, pred_value):\n",
    "    from sklearn.metrics import confusion_matrix\n",
    "\n",
    "    cm_2labels = confusion_matrix(y_pred = pred_value, y_true = actual_value)\n",
    "    plt.figure(figsize=[6,6])\n",
    "    plot_confusion_matrix(cm_2labels, ['Normal', 'Attack'], normalize = False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-10-17T22:28:06.686037Z",
     "start_time": "2017-10-17T22:28:06.483195Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "past_scores = pd.read_pickle(\"dataset/scores/tf_vae_only_vae_loss_nsl_kdd_scores_all.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-10-17T22:28:06.715198Z",
     "start_time": "2017-10-17T22:28:06.688095Z"
    },
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>key</th>\n",
       "      <th>no_of_features</th>\n",
       "      <th>hidden_layers</th>\n",
       "      <th>train_score</th>\n",
       "      <th>test_score</th>\n",
       "      <th>quality_score</th>\n",
       "      <th>time_taken</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>20150604</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.861450</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.804789</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>20150604</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>0.862420</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.004063</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>20150604</td>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "      <td>0.862299</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.126698</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>20150604</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0.862572</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.597457</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>20150604</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>0.865087</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.663030</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>20150604</td>\n",
       "      <td>10</td>\n",
       "      <td>3</td>\n",
       "      <td>0.861966</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.976961</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>20150604</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.861450</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.804789</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>20150604</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>0.862420</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.004063</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>20150604</td>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "      <td>0.862299</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.126698</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>20150604</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0.862572</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.597457</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>20150604</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>0.865087</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.663030</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>20150604</td>\n",
       "      <td>10</td>\n",
       "      <td>3</td>\n",
       "      <td>0.861966</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.976961</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         key  no_of_features  hidden_layers  train_score  test_score  \\\n",
       "0   20150604               1              1     0.861450         0.5   \n",
       "1   20150604               4              1     0.862420         0.5   \n",
       "2   20150604              10              1     0.862299         0.5   \n",
       "3   20150604               1              3     0.862572         0.5   \n",
       "4   20150604               4              3     0.865087         0.5   \n",
       "5   20150604              10              3     0.861966         0.5   \n",
       "6   20150604               1              1     0.861450         0.5   \n",
       "7   20150604               4              1     0.862420         0.5   \n",
       "8   20150604              10              1     0.862299         0.5   \n",
       "9   20150604               1              3     0.862572         0.5   \n",
       "10  20150604               4              3     0.865087         0.5   \n",
       "11  20150604              10              3     0.861966         0.5   \n",
       "\n",
       "    quality_score  time_taken  \n",
       "0             0.0    0.804789  \n",
       "1             0.0    1.004063  \n",
       "2             0.0    1.126698  \n",
       "3             0.0    1.597457  \n",
       "4             0.0    1.663030  \n",
       "5             0.0    1.976961  \n",
       "6             0.0    0.804789  \n",
       "7             0.0    1.004063  \n",
       "8             0.0    1.126698  \n",
       "9             0.0    1.597457  \n",
       "10            0.0    1.663030  \n",
       "11            0.0    1.976961  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "past_scores.sort_values(by='quality_score', ascending = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-10-17T22:28:06.746981Z",
     "start_time": "2017-10-17T22:28:06.716645Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>key</th>\n",
       "      <th>train_score</th>\n",
       "      <th>test_score</th>\n",
       "      <th>quality_score</th>\n",
       "      <th>time_taken</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>no_of_features</th>\n",
       "      <th>hidden_layers</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">1</th>\n",
       "      <th>1</th>\n",
       "      <td>20150604</td>\n",
       "      <td>0.861450</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.804789</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>20150604</td>\n",
       "      <td>0.862572</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.597457</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">4</th>\n",
       "      <th>1</th>\n",
       "      <td>20150604</td>\n",
       "      <td>0.862420</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.004063</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>20150604</td>\n",
       "      <td>0.865087</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.663030</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">10</th>\n",
       "      <th>1</th>\n",
       "      <td>20150604</td>\n",
       "      <td>0.862299</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.126698</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>20150604</td>\n",
       "      <td>0.861966</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.976961</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                   key  train_score  test_score  \\\n",
       "no_of_features hidden_layers                                      \n",
       "1              1              20150604     0.861450         0.5   \n",
       "               3              20150604     0.862572         0.5   \n",
       "4              1              20150604     0.862420         0.5   \n",
       "               3              20150604     0.865087         0.5   \n",
       "10             1              20150604     0.862299         0.5   \n",
       "               3              20150604     0.861966         0.5   \n",
       "\n",
       "                              quality_score  time_taken  \n",
       "no_of_features hidden_layers                             \n",
       "1              1                        0.0    0.804789  \n",
       "               3                        0.0    1.597457  \n",
       "4              1                        0.0    1.004063  \n",
       "               3                        0.0    1.663030  \n",
       "10             1                        0.0    1.126698  \n",
       "               3                        0.0    1.976961  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "psg = past_scores.sort_values(by='quality_score', ascending=False).groupby(by=['no_of_features', 'hidden_layers'])\n",
    "psg.first().sort_values(by='quality_score', ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-10-17T22:28:06.868414Z",
     "start_time": "2017-10-17T22:28:06.748400Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#key_nof_hidden '20151201_16_1'\n",
    "Train.predictions = pd.read_pickle(\"dataset/tf_vae_only_vae_loss_nsl_kdd_predictions.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-10-17T22:28:53.774219Z",
     "start_time": "2017-10-17T22:28:53.760484Z"
    }
   },
   "outputs": [],
   "source": [
    "df = Train.predictions['20150604_1_1'].dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-10-17T22:28:54.669630Z",
     "start_time": "2017-10-17T22:28:54.665160Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([], dtype=int64)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Train.predictions['20151219_42_1'].loc[:,'Prediction']\n",
    "df.loc[:,'Prediction'].values.astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-10-17T22:28:54.870084Z",
     "start_time": "2017-10-17T22:28:54.864352Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn import metrics as me\n",
    "me.f1_score(df.loc[:,'Actual'].values.astype(int),\n",
    "            df.loc[:,'Prediction'].values.astype(int) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-10-17T22:28:55.061430Z",
     "start_time": "2017-10-17T22:28:55.055846Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Series([], Name: Actual, dtype: int64)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.groupby(by=\"Actual\").Actual.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-10-17T22:28:55.478320Z",
     "start_time": "2017-10-17T22:28:55.257512Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ritesh_malaiya/anaconda3/envs/p3/lib/python3.6/site-packages/matplotlib/axes/_base.py:2917: UserWarning: Attempting to set identical left==right results\n",
      "in singular transformations; automatically expanding.\n",
      "left=-0.5, right=-0.5\n",
      "  'left=%s, right=%s') % (left, right))\n",
      "/home/ritesh_malaiya/anaconda3/envs/p3/lib/python3.6/site-packages/matplotlib/axes/_base.py:3193: UserWarning: Attempting to set identical bottom==top results\n",
      "in singular transformations; automatically expanding.\n",
      "bottom=-0.5, top=-0.5\n",
      "  'bottom=%s, top=%s') % (bottom, top))\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "zero-size array to reduction operation maximum which has no identity",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-20-c901c718f014>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m plot(actual_value = df.loc[:,'Actual'].values.astype(int),\n\u001b[0;32m----> 2\u001b[0;31m      pred_value = df.loc[:,'Prediction'].values.astype(int))\n\u001b[0m",
      "\u001b[0;32m<ipython-input-10-3b88dbe6a537>\u001b[0m in \u001b[0;36mplot\u001b[0;34m(actual_value, pred_value)\u001b[0m\n\u001b[1;32m     49\u001b[0m     \u001b[0mcm_2labels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconfusion_matrix\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpred_value\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_true\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mactual_value\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     50\u001b[0m     \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfigure\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfigsize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m6\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m6\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 51\u001b[0;31m     \u001b[0mplot_confusion_matrix\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcm_2labels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m'Normal'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'Attack'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnormalize\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-10-3b88dbe6a537>\u001b[0m in \u001b[0;36mplot_confusion_matrix\u001b[0;34m(cm, classes, normalize, title, cmap)\u001b[0m\n\u001b[1;32m     33\u001b[0m             ]\n\u001b[1;32m     34\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 35\u001b[0;31m     \u001b[0mthresh\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0;36m2.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     36\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mj\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mitertools\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mproduct\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     37\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/p3/lib/python3.6/site-packages/numpy/core/_methods.py\u001b[0m in \u001b[0;36m_amax\u001b[0;34m(a, axis, out, keepdims)\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[0;31m# small reductions\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0m_amax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkeepdims\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 26\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mumr_maximum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkeepdims\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     27\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0m_amin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkeepdims\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: zero-size array to reduction operation maximum which has no identity"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAX0AAAFjCAYAAADRpdu6AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nwS5rAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7efdae59e8d0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot(actual_value = df.loc[:,'Actual'].values.astype(int),\n",
    "     pred_value = df.loc[:,'Prediction'].values.astype(int))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-10-17T22:28:55.478924Z",
     "start_time": "2017-10-17T22:28:54.362Z"
    }
   },
   "outputs": [],
   "source": [
    "psg.mean().sort_values(by='quality_score', ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-10-17T22:28:56.300588Z",
     "start_time": "2017-10-17T22:28:56.288671Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>train_score</th>\n",
       "      <th>test_score</th>\n",
       "      <th>quality_score</th>\n",
       "      <th>time_taken</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>no_of_features</th>\n",
       "      <th>hidden_layers</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">1</th>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">4</th>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">10</th>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                              train_score  test_score  quality_score  \\\n",
       "no_of_features hidden_layers                                           \n",
       "1              1                      0.0         0.0            0.0   \n",
       "               3                      0.0         0.0            0.0   \n",
       "4              1                      0.0         0.0            0.0   \n",
       "               3                      0.0         0.0            0.0   \n",
       "10             1                      0.0         0.0            0.0   \n",
       "               3                      0.0         0.0            0.0   \n",
       "\n",
       "                              time_taken  \n",
       "no_of_features hidden_layers              \n",
       "1              1                     0.0  \n",
       "               3                     0.0  \n",
       "4              1                     0.0  \n",
       "               3                     0.0  \n",
       "10             1                     0.0  \n",
       "               3                     0.0  "
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "psg.std()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-10-17T22:28:57.946470Z",
     "start_time": "2017-10-17T22:28:57.928818Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ritesh_malaiya/anaconda3/envs/p3/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:1907: RuntimeWarning: invalid value encountered in multiply\n",
      "  lower_bound = self.a * scale + loc\n",
      "/home/ritesh_malaiya/anaconda3/envs/p3/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:1908: RuntimeWarning: invalid value encountered in multiply\n",
      "  upper_bound = self.b * scale + loc\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "no_of_features  hidden_layers\n",
       "1               1                (nan, nan)\n",
       "                3                (nan, nan)\n",
       "4               1                (nan, nan)\n",
       "                3                (nan, nan)\n",
       "10              1                (nan, nan)\n",
       "                3                (nan, nan)\n",
       "dtype: object"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from scipy import stats\n",
    "\n",
    "def fn(x):\n",
    "    #print(x)\n",
    "    return stats.norm.interval(0.95, loc=x.quality_score.mean(), scale=x.quality_score.std())\n",
    "psg.apply(fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "_draft": {
   "nbviewer_url": "https://gist.github.com/7d1ace18a82178e15ece8fc5252fce88"
  },
  "anaconda-cloud": {},
  "gist": {
   "data": {
    "description": "Hyper parameter tuning",
    "public": false
   },
   "id": "7d1ace18a82178e15ece8fc5252fce88"
  },
  "kernelspec": {
   "display_name": "Python [conda env:p3]",
   "language": "python",
   "name": "conda-env-p3-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
