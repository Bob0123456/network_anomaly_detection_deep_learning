{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Read Data Sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-06-01T13:32:55.377514Z",
     "start_time": "2017-06-01T13:32:53.895683Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "from collections import namedtuple\n",
    "pd.set_option(\"display.max_rows\",35)\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-06-01T13:32:55.561259Z",
     "start_time": "2017-06-01T13:32:55.380221Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class dataset:\n",
    "    kdd_train_2labels = pd.read_pickle(\"dataset/kdd_train_2labels_20percent.pkl\")\n",
    "    kdd_test_2labels = pd.read_pickle(\"dataset/kdd_test_2labels_20percent.pkl\")\n",
    "    \n",
    "    kdd_train_5labels = pd.read_pickle(\"dataset/kdd_train_5labels.pkl\")\n",
    "    kdd_test_5labels = pd.read_pickle(\"dataset/kdd_test_5labels.pkl\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-06-01T13:32:55.589935Z",
     "start_time": "2017-06-01T13:32:55.564252Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(25192, 120)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.kdd_train_2labels.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-06-01T13:32:55.603586Z",
     "start_time": "2017-06-01T13:32:55.593256Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(11850, 120)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.kdd_test_2labels.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-06-01T13:32:56.761238Z",
     "start_time": "2017-06-01T13:32:55.611758Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(25192, 118)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn import model_selection as ms\n",
    "from sklearn import preprocessing as pp\n",
    "\n",
    "class preprocess:\n",
    "    \n",
    "    output_columns_2labels = ['is_Attack','is_Normal']\n",
    "    \n",
    "    x_input = dataset.kdd_train_2labels.drop(output_columns_2labels, axis = 1)\n",
    "    y_output = dataset.kdd_train_2labels.loc[:,output_columns_2labels]\n",
    "\n",
    "    x_test_input = dataset.kdd_test_2labels.drop(output_columns_2labels, axis = 1)\n",
    "    y_test = dataset.kdd_test_2labels.loc[:,output_columns_2labels]\n",
    "\n",
    "    ss = pp.StandardScaler()\n",
    "\n",
    "    x_train = ss.fit_transform(x_input)\n",
    "    x_test = ss.transform(x_test_input)\n",
    "\n",
    "    y_train = y_output.values\n",
    "    y_test = y_test.values\n",
    "\n",
    "preprocess.x_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-06-01T13:32:59.286072Z",
     "start_time": "2017-06-01T13:32:56.769393Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-06-01T13:32:59.757059Z",
     "start_time": "2017-06-01T13:32:59.298413Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class network(object):\n",
    "    \n",
    "    input_dim = 118\n",
    "    classes = 2\n",
    "    hidden_encoder_dim = 118\n",
    "    hidden_layers = 1\n",
    "    latent_dim = 18\n",
    "\n",
    "    def __init__(self, classes, hidden_layers, num_of_features):\n",
    "        self.classes = classes\n",
    "        self.hidden_layers = hidden_layers\n",
    "        self.latent_dim = num_of_features\n",
    "            \n",
    "    def build_layers(self):\n",
    "        tf.reset_default_graph()\n",
    "        #learning_rate = tf.Variable(initial_value=0.001)\n",
    "\n",
    "        input_dim = self.input_dim\n",
    "        classes = self.classes\n",
    "        hidden_encoder_dim = self.hidden_encoder_dim\n",
    "        hidden_layers = self.hidden_layers\n",
    "        latent_dim = self.latent_dim\n",
    "        \n",
    "        with tf.variable_scope(\"Input\"):\n",
    "            self.x = tf.placeholder(\"float\", shape=[None, input_dim])\n",
    "            self.y_ = tf.placeholder(\"float\", shape=[None, classes])\n",
    "            self.keep_prob = tf.placeholder(\"float\")\n",
    "            self.lr = tf.placeholder(\"float\")\n",
    "        \n",
    "        with tf.variable_scope(\"Layer_Encoder\"):\n",
    "\n",
    "            hidden_encoder = tf.layers.dense(self.x, hidden_encoder_dim, activation = tf.nn.relu, kernel_regularizer=tf.nn.l2_loss)\n",
    "            hidden_encoder = tf.nn.dropout(hidden_encoder, self.keep_prob)\n",
    "            for h in range(hidden_layers - 1):\n",
    "                hidden_encoder = tf.layers.dense(hidden_encoder, latent_dim, activation = tf.nn.relu, kernel_regularizer=tf.nn.l2_loss)\n",
    "                hidden_encoder = tf.nn.dropout(hidden_encoder, self.keep_prob)\n",
    "            \n",
    "            #hidden_encoder = tf.layers.dense(self.x, latent_dim, activation = tf.nn.relu, kernel_regularizer=tf.nn.l2_loss)\n",
    "            #hidden_encoder = tf.nn.dropout(hidden_encoder, self.keep_prob)\n",
    "            \n",
    "        with tf.variable_scope(\"Layer_Dense_Softmax\"):\n",
    "            self.y = tf.layers.dense(hidden_encoder, classes, activation=tf.nn.softmax)\n",
    "            \n",
    "        with tf.variable_scope(\"Loss\"):\n",
    "            \n",
    "            loss = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(labels = self.y_, logits = self.y))\n",
    "\n",
    "            #loss = tf.clip_by_value(loss, -1e-1, 1e-1)\n",
    "            #loss = tf.where(tf.is_nan(loss), 1e-1, loss)\n",
    "            #loss = tf.where(tf.equal(loss, -1e-1), tf.random_normal(loss.shape), loss)\n",
    "            #loss = tf.where(tf.equal(loss, 1e-1), tf.random_normal(loss.shape), loss)\n",
    "            \n",
    "            self.regularized_loss = loss\n",
    "            correct_prediction = tf.equal(tf.argmax(self.y_, 1), tf.argmax(self.y, 1))\n",
    "            self.tf_accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32), name = \"Accuracy\")\n",
    "\n",
    "        with tf.variable_scope(\"Optimizer\"):\n",
    "            learning_rate=self.lr\n",
    "            optimizer = tf.train.AdamOptimizer(learning_rate)\n",
    "            #gradients, variables = zip(*optimizer.compute_gradients(self.regularized_loss))\n",
    "            #gradients = [\n",
    "            #    None if gradient is None else tf.clip_by_value(gradient, -1, 1)\n",
    "            #    for gradient in gradients]\n",
    "            #self.train_op = optimizer.apply_gradients(zip(gradients, variables))\n",
    "            self.train_op = optimizer.minimize(self.regularized_loss)\n",
    "            \n",
    "        # add op for merging summary\n",
    "        #self.summary_op = tf.summary.merge_all()\n",
    "        self.pred = tf.argmax(self.y, axis = 1)\n",
    "        self.actual = tf.argmax(self.y_, axis = 1)\n",
    "\n",
    "        # add Saver ops\n",
    "        self.saver = tf.train.Saver()\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-06-01T13:33:00.464659Z",
     "start_time": "2017-06-01T13:32:59.771246Z"
    },
    "collapsed": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import collections\n",
    "import time\n",
    "\n",
    "class Train:    \n",
    "    \n",
    "    result = namedtuple(\"score\", ['epoch', 'no_of_features','hidden_layers','train_score', 'test_score', 'time_taken'])\n",
    "\n",
    "    predictions = {}\n",
    "\n",
    "    results = []\n",
    "    best_acc = 0\n",
    "    best_acc_global = 0\n",
    "    \n",
    "    def train(epochs, net, h,f, lrs):\n",
    "        batch_iterations = 200\n",
    "        train_loss = None\n",
    "        Train.best_acc = 0\n",
    "        os.makedirs(\"dataset/tf_dense_only_nsl_kdd-/hidden layers_{}_features count_{}\".format(epochs,h,f),\n",
    "                    exist_ok = True)\n",
    "        with tf.Session() as sess:\n",
    "            #summary_writer_train = tf.summary.FileWriter('./logs/kdd/VAE/training', graph=sess.graph)\n",
    "            #summary_writer_valid = tf.summary.FileWriter('./logs/kdd/VAE/validation')\n",
    "\n",
    "            sess.run(tf.global_variables_initializer())\n",
    "            start_time = time.perf_counter()\n",
    "            for lr in lrs:\n",
    "                for epoch in range(1, (epochs+1)):\n",
    "                    x_train, x_valid, y_train, y_valid, = ms.train_test_split(preprocess.x_train, \n",
    "                                                                              preprocess.y_train, \n",
    "                                                                              test_size=0.1)\n",
    "                    batch_indices = np.array_split(np.arange(x_train.shape[0]), \n",
    "                                               batch_iterations)\n",
    "\n",
    "                    for i in batch_indices:\n",
    "\n",
    "                        def train_batch():\n",
    "                            nonlocal train_loss\n",
    "                            _, train_loss = sess.run([net.train_op, \n",
    "                                                               net.regularized_loss, \n",
    "                                                               ], #net.summary_op\n",
    "                                                              feed_dict={net.x: x_train[i,:], \n",
    "                                                                         net.y_: y_train[i,:], \n",
    "                                                                         net.keep_prob:0.5, net.lr:lr})\n",
    "\n",
    "                        train_batch()\n",
    "                        #summary_writer_train.add_summary(summary_str, epoch)\n",
    "                        while((train_loss > 1e4 or np.isnan(train_loss)) and epoch > 1):\n",
    "                            print(\"Step {} | Training Loss: {:.6f}\".format(epoch, train_loss))\n",
    "                            net.saver.restore(sess, \n",
    "                                              tf.train.latest_checkpoint('dataset/tf_dense_only_nsl_kdd/hidden_layers_{}_features_count_{}'\n",
    "                                                                         .format(epochs,h,f)))\n",
    "                            train_batch()\n",
    "\n",
    "\n",
    "                    valid_accuracy = sess.run(net.tf_accuracy, #net.summary_op \n",
    "                                                          feed_dict={net.x: x_valid, \n",
    "                                                                     net.y_: y_valid, \n",
    "                                                                     net.keep_prob:1, net.lr:lr})\n",
    "                    #summary_writer_valid.add_summary(summary_str, epoch)\n",
    "\n",
    "\n",
    "                    accuracy, pred_value, actual_value, y_pred = sess.run([net.tf_accuracy, \n",
    "                                                                   net.pred, \n",
    "                                                                   net.actual, net.y], \n",
    "                                                                  feed_dict={net.x: preprocess.x_test, \n",
    "                                                                             net.y_: preprocess.y_test, \n",
    "                                                                             net.keep_prob:1, net.lr:lr})\n",
    "\n",
    "                    print(\"Step {} | Training Loss: {:.6f} | Validation Accuracy: {:.6f} | Test Accuracy: {:.6f}\".format(epoch, train_loss, valid_accuracy, accuracy))\n",
    "                   \n",
    "                    if accuracy > Train.best_acc_global:\n",
    "                        Train.best_acc_global = accuracy\n",
    "                        Train.pred_value = pred_value\n",
    "                        Train.actual_value = actual_value\n",
    "                        Train.best_parameters = \"Hidden Layers:{}, Features Count:{}\".format(h, f)\n",
    "\n",
    "                    if accuracy > Train.best_acc:\n",
    "                        Train.best_acc = accuracy\n",
    "\n",
    "                        if not (np.isnan(train_loss)):\n",
    "                            net.saver.save(sess, \n",
    "                                       \"dataset/tf_dense_only_nsl_kdd-/hidden_layers_{}_features_count_{}\".format(h,f),\n",
    "                                        global_step = epochs)\n",
    "                        curr_pred = pd.DataFrame({\"Attack_prob\":y_pred[:,-2], \"Normal_prob\":y_pred[:, -1], \"Prediction\":pred_value})\n",
    "                        Train.predictions.update({\"{}_{}_{}\".format(epochs*len(lrs),f,h):(curr_pred, \n",
    "                                                   Train.result(epochs*len(lrs), f, h,valid_accuracy, accuracy, time.perf_counter() - start_time))})\n",
    "\n",
    "                        #Train.results.append(Train.result(epochs, f, h,valid_accuracy, accuracy))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-06-01T13:36:26.743164Z",
     "start_time": "2017-06-01T13:33:00.477248Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current Layer Attributes - epochs:30 hidden layers:2 features count:4\n",
      "Step 1 | Training Loss: 0.705521 | Validation Accuracy: 0.309921 | Test Accuracy: 0.557721\n",
      "Step 2 | Training Loss: 0.717314 | Validation Accuracy: 0.312698 | Test Accuracy: 0.557721\n",
      "Step 3 | Training Loss: 0.739341 | Validation Accuracy: 0.297222 | Test Accuracy: 0.557721\n",
      "Step 4 | Training Loss: 0.738374 | Validation Accuracy: 0.303968 | Test Accuracy: 0.557721\n",
      "Step 5 | Training Loss: 0.724478 | Validation Accuracy: 0.305556 | Test Accuracy: 0.557721\n",
      "Step 6 | Training Loss: 0.717527 | Validation Accuracy: 0.303175 | Test Accuracy: 0.557721\n",
      "Step 7 | Training Loss: 0.745040 | Validation Accuracy: 0.300000 | Test Accuracy: 0.557721\n",
      "Step 8 | Training Loss: 0.699986 | Validation Accuracy: 0.306349 | Test Accuracy: 0.557721\n",
      "Step 9 | Training Loss: 0.719989 | Validation Accuracy: 0.301190 | Test Accuracy: 0.557721\n",
      "Step 10 | Training Loss: 0.719669 | Validation Accuracy: 0.296032 | Test Accuracy: 0.557806\n",
      "Step 11 | Training Loss: 0.701244 | Validation Accuracy: 0.303175 | Test Accuracy: 0.557806\n",
      "Step 12 | Training Loss: 0.712253 | Validation Accuracy: 0.303968 | Test Accuracy: 0.557806\n",
      "Step 13 | Training Loss: 0.702843 | Validation Accuracy: 0.300397 | Test Accuracy: 0.557806\n",
      "Step 14 | Training Loss: 0.716689 | Validation Accuracy: 0.303571 | Test Accuracy: 0.557806\n",
      "Step 15 | Training Loss: 0.731727 | Validation Accuracy: 0.302381 | Test Accuracy: 0.557806\n",
      "Step 16 | Training Loss: 0.710706 | Validation Accuracy: 0.303968 | Test Accuracy: 0.557806\n",
      "Step 17 | Training Loss: 0.687105 | Validation Accuracy: 0.300794 | Test Accuracy: 0.557806\n",
      "Step 18 | Training Loss: 0.725226 | Validation Accuracy: 0.313889 | Test Accuracy: 0.557806\n",
      "Step 19 | Training Loss: 0.734180 | Validation Accuracy: 0.284127 | Test Accuracy: 0.557806\n",
      "Step 20 | Training Loss: 0.712383 | Validation Accuracy: 0.300397 | Test Accuracy: 0.557806\n",
      "Step 21 | Training Loss: 0.712208 | Validation Accuracy: 0.298413 | Test Accuracy: 0.557806\n",
      "Step 22 | Training Loss: 0.717895 | Validation Accuracy: 0.307937 | Test Accuracy: 0.557806\n",
      "Step 23 | Training Loss: 0.710478 | Validation Accuracy: 0.294841 | Test Accuracy: 0.557806\n",
      "Step 24 | Training Loss: 0.704078 | Validation Accuracy: 0.300794 | Test Accuracy: 0.557806\n",
      "Step 25 | Training Loss: 0.741890 | Validation Accuracy: 0.304365 | Test Accuracy: 0.557806\n",
      "Step 26 | Training Loss: 0.718301 | Validation Accuracy: 0.312302 | Test Accuracy: 0.557806\n",
      "Step 27 | Training Loss: 0.718942 | Validation Accuracy: 0.290079 | Test Accuracy: 0.557806\n",
      "Step 28 | Training Loss: 0.715478 | Validation Accuracy: 0.300794 | Test Accuracy: 0.557806\n",
      "Step 29 | Training Loss: 0.705388 | Validation Accuracy: 0.303968 | Test Accuracy: 0.557806\n",
      "Step 30 | Training Loss: 0.741148 | Validation Accuracy: 0.325794 | Test Accuracy: 0.557806\n",
      "Step 1 | Training Loss: 0.716319 | Validation Accuracy: 0.309921 | Test Accuracy: 0.557806\n",
      "Step 2 | Training Loss: 0.712845 | Validation Accuracy: 0.306349 | Test Accuracy: 0.557806\n",
      "Step 3 | Training Loss: 0.722741 | Validation Accuracy: 0.299603 | Test Accuracy: 0.557806\n",
      "Step 4 | Training Loss: 0.720677 | Validation Accuracy: 0.301984 | Test Accuracy: 0.557806\n",
      "Step 5 | Training Loss: 0.717702 | Validation Accuracy: 0.307143 | Test Accuracy: 0.557806\n",
      "Step 6 | Training Loss: 0.728833 | Validation Accuracy: 0.288095 | Test Accuracy: 0.557806\n",
      "Step 7 | Training Loss: 0.712519 | Validation Accuracy: 0.305556 | Test Accuracy: 0.557806\n",
      "Step 8 | Training Loss: 0.705880 | Validation Accuracy: 0.309127 | Test Accuracy: 0.557806\n",
      "Step 9 | Training Loss: 0.714977 | Validation Accuracy: 0.308333 | Test Accuracy: 0.557806\n",
      "Step 10 | Training Loss: 0.720283 | Validation Accuracy: 0.288889 | Test Accuracy: 0.557806\n",
      "Step 11 | Training Loss: 0.727270 | Validation Accuracy: 0.308333 | Test Accuracy: 0.557806\n",
      "Step 12 | Training Loss: 0.727863 | Validation Accuracy: 0.304762 | Test Accuracy: 0.557806\n",
      "Step 13 | Training Loss: 0.699529 | Validation Accuracy: 0.303571 | Test Accuracy: 0.557806\n",
      "Step 14 | Training Loss: 0.725567 | Validation Accuracy: 0.296825 | Test Accuracy: 0.557806\n",
      "Step 15 | Training Loss: 0.728247 | Validation Accuracy: 0.280952 | Test Accuracy: 0.557806\n",
      "Step 16 | Training Loss: 0.739164 | Validation Accuracy: 0.307143 | Test Accuracy: 0.557806\n",
      "Step 17 | Training Loss: 0.697470 | Validation Accuracy: 0.315873 | Test Accuracy: 0.557806\n",
      "Step 18 | Training Loss: 0.732656 | Validation Accuracy: 0.317460 | Test Accuracy: 0.557806\n",
      "Step 19 | Training Loss: 0.718534 | Validation Accuracy: 0.300000 | Test Accuracy: 0.557806\n",
      "Step 20 | Training Loss: 0.727441 | Validation Accuracy: 0.307143 | Test Accuracy: 0.557806\n",
      "Step 21 | Training Loss: 0.713849 | Validation Accuracy: 0.303175 | Test Accuracy: 0.557806\n",
      "Step 22 | Training Loss: 0.727616 | Validation Accuracy: 0.301984 | Test Accuracy: 0.557806\n",
      "Step 23 | Training Loss: 0.704861 | Validation Accuracy: 0.291667 | Test Accuracy: 0.557806\n",
      "Step 24 | Training Loss: 0.710225 | Validation Accuracy: 0.295238 | Test Accuracy: 0.557806\n",
      "Step 25 | Training Loss: 0.721098 | Validation Accuracy: 0.292857 | Test Accuracy: 0.557806\n",
      "Step 26 | Training Loss: 0.706421 | Validation Accuracy: 0.306349 | Test Accuracy: 0.557806\n",
      "Step 27 | Training Loss: 0.713371 | Validation Accuracy: 0.315079 | Test Accuracy: 0.557806\n",
      "Step 28 | Training Loss: 0.707998 | Validation Accuracy: 0.297619 | Test Accuracy: 0.557806\n",
      "Step 29 | Training Loss: 0.724170 | Validation Accuracy: 0.303968 | Test Accuracy: 0.557806\n",
      "Step 30 | Training Loss: 0.712361 | Validation Accuracy: 0.309127 | Test Accuracy: 0.557806\n",
      "Current Layer Attributes - epochs:30 hidden layers:2 features count:8\n",
      "Step 1 | Training Loss: 0.680379 | Validation Accuracy: 0.597619 | Test Accuracy: 0.334937\n",
      "Step 2 | Training Loss: 0.677110 | Validation Accuracy: 0.602778 | Test Accuracy: 0.334937\n",
      "Step 3 | Training Loss: 0.674406 | Validation Accuracy: 0.594444 | Test Accuracy: 0.334937\n",
      "Step 4 | Training Loss: 0.681868 | Validation Accuracy: 0.592063 | Test Accuracy: 0.334937\n",
      "Step 5 | Training Loss: 0.658168 | Validation Accuracy: 0.599603 | Test Accuracy: 0.334937\n",
      "Step 6 | Training Loss: 0.699047 | Validation Accuracy: 0.617857 | Test Accuracy: 0.334937\n",
      "Step 7 | Training Loss: 0.690357 | Validation Accuracy: 0.585317 | Test Accuracy: 0.334937\n",
      "Step 8 | Training Loss: 0.678515 | Validation Accuracy: 0.596032 | Test Accuracy: 0.334937\n",
      "Step 9 | Training Loss: 0.687099 | Validation Accuracy: 0.601587 | Test Accuracy: 0.334937\n",
      "Step 10 | Training Loss: 0.679511 | Validation Accuracy: 0.620238 | Test Accuracy: 0.334937\n",
      "Step 11 | Training Loss: 0.647864 | Validation Accuracy: 0.600000 | Test Accuracy: 0.334937\n",
      "Step 12 | Training Loss: 0.700212 | Validation Accuracy: 0.598016 | Test Accuracy: 0.334937\n",
      "Step 13 | Training Loss: 0.708673 | Validation Accuracy: 0.609524 | Test Accuracy: 0.334937\n",
      "Step 14 | Training Loss: 0.684285 | Validation Accuracy: 0.590873 | Test Accuracy: 0.334937\n",
      "Step 15 | Training Loss: 0.667770 | Validation Accuracy: 0.588492 | Test Accuracy: 0.334937\n",
      "Step 16 | Training Loss: 0.753635 | Validation Accuracy: 0.613095 | Test Accuracy: 0.334937\n",
      "Step 17 | Training Loss: 0.705056 | Validation Accuracy: 0.599206 | Test Accuracy: 0.334937\n",
      "Step 18 | Training Loss: 0.716746 | Validation Accuracy: 0.597222 | Test Accuracy: 0.334937\n",
      "Step 19 | Training Loss: 0.700260 | Validation Accuracy: 0.581349 | Test Accuracy: 0.334937\n",
      "Step 20 | Training Loss: 0.652545 | Validation Accuracy: 0.611905 | Test Accuracy: 0.334937\n",
      "Step 21 | Training Loss: 0.711209 | Validation Accuracy: 0.608333 | Test Accuracy: 0.334937\n",
      "Step 22 | Training Loss: 0.698243 | Validation Accuracy: 0.604365 | Test Accuracy: 0.334937\n",
      "Step 23 | Training Loss: 0.706534 | Validation Accuracy: 0.606746 | Test Accuracy: 0.334937\n",
      "Step 24 | Training Loss: 0.702563 | Validation Accuracy: 0.590079 | Test Accuracy: 0.334937\n",
      "Step 25 | Training Loss: 0.687249 | Validation Accuracy: 0.584921 | Test Accuracy: 0.334937\n",
      "Step 26 | Training Loss: 0.653130 | Validation Accuracy: 0.613492 | Test Accuracy: 0.334937\n",
      "Step 27 | Training Loss: 0.660089 | Validation Accuracy: 0.601587 | Test Accuracy: 0.334937\n",
      "Step 28 | Training Loss: 0.688512 | Validation Accuracy: 0.586508 | Test Accuracy: 0.334937\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 29 | Training Loss: 0.667182 | Validation Accuracy: 0.592460 | Test Accuracy: 0.334937\n",
      "Step 30 | Training Loss: 0.713776 | Validation Accuracy: 0.613095 | Test Accuracy: 0.334937\n",
      "Step 1 | Training Loss: 0.664446 | Validation Accuracy: 0.606349 | Test Accuracy: 0.334937\n",
      "Step 2 | Training Loss: 0.718031 | Validation Accuracy: 0.589286 | Test Accuracy: 0.334937\n",
      "Step 3 | Training Loss: 0.713202 | Validation Accuracy: 0.593254 | Test Accuracy: 0.334937\n",
      "Step 4 | Training Loss: 0.712298 | Validation Accuracy: 0.605556 | Test Accuracy: 0.334937\n",
      "Step 5 | Training Loss: 0.671211 | Validation Accuracy: 0.586508 | Test Accuracy: 0.334937\n",
      "Step 6 | Training Loss: 0.664492 | Validation Accuracy: 0.592460 | Test Accuracy: 0.334937\n",
      "Step 7 | Training Loss: 0.665787 | Validation Accuracy: 0.589286 | Test Accuracy: 0.334937\n",
      "Step 8 | Training Loss: 0.720985 | Validation Accuracy: 0.612698 | Test Accuracy: 0.334937\n",
      "Step 9 | Training Loss: 0.677641 | Validation Accuracy: 0.593254 | Test Accuracy: 0.334937\n",
      "Step 10 | Training Loss: 0.706031 | Validation Accuracy: 0.576587 | Test Accuracy: 0.334937\n",
      "Step 11 | Training Loss: 0.681298 | Validation Accuracy: 0.610714 | Test Accuracy: 0.334937\n",
      "Step 12 | Training Loss: 0.700304 | Validation Accuracy: 0.589683 | Test Accuracy: 0.334937\n",
      "Step 13 | Training Loss: 0.697074 | Validation Accuracy: 0.605952 | Test Accuracy: 0.334937\n",
      "Step 14 | Training Loss: 0.724547 | Validation Accuracy: 0.580159 | Test Accuracy: 0.334937\n",
      "Step 15 | Training Loss: 0.658933 | Validation Accuracy: 0.601587 | Test Accuracy: 0.334937\n",
      "Step 16 | Training Loss: 0.681380 | Validation Accuracy: 0.584127 | Test Accuracy: 0.334937\n",
      "Step 17 | Training Loss: 0.686303 | Validation Accuracy: 0.602381 | Test Accuracy: 0.334937\n",
      "Step 18 | Training Loss: 0.713825 | Validation Accuracy: 0.621032 | Test Accuracy: 0.334937\n",
      "Step 19 | Training Loss: 0.666234 | Validation Accuracy: 0.599206 | Test Accuracy: 0.334937\n",
      "Step 20 | Training Loss: 0.693244 | Validation Accuracy: 0.583333 | Test Accuracy: 0.334937\n",
      "Step 21 | Training Loss: 0.668524 | Validation Accuracy: 0.603571 | Test Accuracy: 0.334937\n",
      "Step 22 | Training Loss: 0.691956 | Validation Accuracy: 0.603175 | Test Accuracy: 0.334937\n",
      "Step 23 | Training Loss: 0.691297 | Validation Accuracy: 0.588889 | Test Accuracy: 0.334937\n",
      "Step 24 | Training Loss: 0.662092 | Validation Accuracy: 0.593651 | Test Accuracy: 0.334937\n",
      "Step 25 | Training Loss: 0.673785 | Validation Accuracy: 0.601190 | Test Accuracy: 0.334937\n",
      "Step 26 | Training Loss: 0.695259 | Validation Accuracy: 0.581349 | Test Accuracy: 0.334937\n",
      "Step 27 | Training Loss: 0.679060 | Validation Accuracy: 0.605952 | Test Accuracy: 0.334937\n",
      "Step 28 | Training Loss: 0.696087 | Validation Accuracy: 0.608730 | Test Accuracy: 0.334937\n",
      "Step 29 | Training Loss: 0.690270 | Validation Accuracy: 0.598016 | Test Accuracy: 0.334937\n",
      "Step 30 | Training Loss: 0.707914 | Validation Accuracy: 0.598016 | Test Accuracy: 0.334937\n",
      "Current Layer Attributes - epochs:30 hidden layers:2 features count:16\n",
      "Step 1 | Training Loss: 0.770248 | Validation Accuracy: 0.364286 | Test Accuracy: 0.466245\n",
      "Step 2 | Training Loss: 0.689037 | Validation Accuracy: 0.354762 | Test Accuracy: 0.466245\n",
      "Step 3 | Training Loss: 0.730942 | Validation Accuracy: 0.353968 | Test Accuracy: 0.466245\n",
      "Step 4 | Training Loss: 0.734824 | Validation Accuracy: 0.367063 | Test Accuracy: 0.466245\n",
      "Step 5 | Training Loss: 0.761115 | Validation Accuracy: 0.353175 | Test Accuracy: 0.466245\n",
      "Step 6 | Training Loss: 0.722867 | Validation Accuracy: 0.355159 | Test Accuracy: 0.466245\n",
      "Step 7 | Training Loss: 0.753862 | Validation Accuracy: 0.370635 | Test Accuracy: 0.466245\n",
      "Step 8 | Training Loss: 0.758333 | Validation Accuracy: 0.376984 | Test Accuracy: 0.466245\n",
      "Step 9 | Training Loss: 0.746254 | Validation Accuracy: 0.351190 | Test Accuracy: 0.466245\n",
      "Step 10 | Training Loss: 0.702712 | Validation Accuracy: 0.348810 | Test Accuracy: 0.466245\n",
      "Step 11 | Training Loss: 0.714787 | Validation Accuracy: 0.358730 | Test Accuracy: 0.466245\n",
      "Step 12 | Training Loss: 0.717236 | Validation Accuracy: 0.363889 | Test Accuracy: 0.466245\n",
      "Step 13 | Training Loss: 0.752144 | Validation Accuracy: 0.356746 | Test Accuracy: 0.466245\n",
      "Step 14 | Training Loss: 0.705938 | Validation Accuracy: 0.361508 | Test Accuracy: 0.466245\n",
      "Step 15 | Training Loss: 0.713850 | Validation Accuracy: 0.344444 | Test Accuracy: 0.466245\n",
      "Step 16 | Training Loss: 0.722328 | Validation Accuracy: 0.346825 | Test Accuracy: 0.466245\n",
      "Step 17 | Training Loss: 0.684336 | Validation Accuracy: 0.364286 | Test Accuracy: 0.466245\n",
      "Step 18 | Training Loss: 0.711358 | Validation Accuracy: 0.355159 | Test Accuracy: 0.466245\n",
      "Step 19 | Training Loss: 0.717843 | Validation Accuracy: 0.360714 | Test Accuracy: 0.466245\n",
      "Step 20 | Training Loss: 0.682086 | Validation Accuracy: 0.358730 | Test Accuracy: 0.466245\n",
      "Step 21 | Training Loss: 0.777404 | Validation Accuracy: 0.342460 | Test Accuracy: 0.466160\n",
      "Step 22 | Training Loss: 0.735981 | Validation Accuracy: 0.364286 | Test Accuracy: 0.466160\n",
      "Step 23 | Training Loss: 0.762073 | Validation Accuracy: 0.360317 | Test Accuracy: 0.466160\n",
      "Step 24 | Training Loss: 0.733326 | Validation Accuracy: 0.350794 | Test Accuracy: 0.466160\n",
      "Step 25 | Training Loss: 0.725251 | Validation Accuracy: 0.377381 | Test Accuracy: 0.466160\n",
      "Step 26 | Training Loss: 0.761078 | Validation Accuracy: 0.360317 | Test Accuracy: 0.466160\n",
      "Step 27 | Training Loss: 0.732346 | Validation Accuracy: 0.358333 | Test Accuracy: 0.466160\n",
      "Step 28 | Training Loss: 0.723699 | Validation Accuracy: 0.358730 | Test Accuracy: 0.466160\n",
      "Step 29 | Training Loss: 0.741931 | Validation Accuracy: 0.352778 | Test Accuracy: 0.466160\n",
      "Step 30 | Training Loss: 0.699653 | Validation Accuracy: 0.346429 | Test Accuracy: 0.466160\n",
      "Step 1 | Training Loss: 0.721219 | Validation Accuracy: 0.346032 | Test Accuracy: 0.466160\n",
      "Step 2 | Training Loss: 0.769969 | Validation Accuracy: 0.357143 | Test Accuracy: 0.466160\n",
      "Step 3 | Training Loss: 0.710971 | Validation Accuracy: 0.350000 | Test Accuracy: 0.466160\n",
      "Step 4 | Training Loss: 0.718010 | Validation Accuracy: 0.352778 | Test Accuracy: 0.466160\n",
      "Step 5 | Training Loss: 0.719278 | Validation Accuracy: 0.349603 | Test Accuracy: 0.466160\n",
      "Step 6 | Training Loss: 0.722688 | Validation Accuracy: 0.362698 | Test Accuracy: 0.466160\n",
      "Step 7 | Training Loss: 0.755090 | Validation Accuracy: 0.361905 | Test Accuracy: 0.466160\n",
      "Step 8 | Training Loss: 0.721903 | Validation Accuracy: 0.352778 | Test Accuracy: 0.466160\n",
      "Step 9 | Training Loss: 0.744346 | Validation Accuracy: 0.360317 | Test Accuracy: 0.466160\n",
      "Step 10 | Training Loss: 0.696238 | Validation Accuracy: 0.362302 | Test Accuracy: 0.466160\n",
      "Step 11 | Training Loss: 0.755090 | Validation Accuracy: 0.367857 | Test Accuracy: 0.466160\n",
      "Step 12 | Training Loss: 0.729070 | Validation Accuracy: 0.351190 | Test Accuracy: 0.466160\n",
      "Step 13 | Training Loss: 0.705571 | Validation Accuracy: 0.369444 | Test Accuracy: 0.466160\n",
      "Step 14 | Training Loss: 0.711437 | Validation Accuracy: 0.363095 | Test Accuracy: 0.466160\n",
      "Step 15 | Training Loss: 0.735807 | Validation Accuracy: 0.378571 | Test Accuracy: 0.466160\n",
      "Step 16 | Training Loss: 0.727875 | Validation Accuracy: 0.354762 | Test Accuracy: 0.466160\n",
      "Step 17 | Training Loss: 0.722448 | Validation Accuracy: 0.352381 | Test Accuracy: 0.466160\n",
      "Step 18 | Training Loss: 0.711883 | Validation Accuracy: 0.351984 | Test Accuracy: 0.466160\n",
      "Step 19 | Training Loss: 0.685935 | Validation Accuracy: 0.357143 | Test Accuracy: 0.466160\n",
      "Step 20 | Training Loss: 0.719284 | Validation Accuracy: 0.347222 | Test Accuracy: 0.466160\n",
      "Step 21 | Training Loss: 0.720808 | Validation Accuracy: 0.356746 | Test Accuracy: 0.466160\n",
      "Step 22 | Training Loss: 0.722322 | Validation Accuracy: 0.348016 | Test Accuracy: 0.466160\n",
      "Step 23 | Training Loss: 0.705951 | Validation Accuracy: 0.358730 | Test Accuracy: 0.466160\n",
      "Step 24 | Training Loss: 0.724839 | Validation Accuracy: 0.365873 | Test Accuracy: 0.466160\n",
      "Step 25 | Training Loss: 0.722173 | Validation Accuracy: 0.341667 | Test Accuracy: 0.466160\n",
      "Step 26 | Training Loss: 0.713955 | Validation Accuracy: 0.363889 | Test Accuracy: 0.466160\n",
      "Step 27 | Training Loss: 0.707061 | Validation Accuracy: 0.368254 | Test Accuracy: 0.466160\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 28 | Training Loss: 0.733594 | Validation Accuracy: 0.366270 | Test Accuracy: 0.466160\n",
      "Step 29 | Training Loss: 0.729061 | Validation Accuracy: 0.349206 | Test Accuracy: 0.466160\n",
      "Step 30 | Training Loss: 0.725310 | Validation Accuracy: 0.354762 | Test Accuracy: 0.466160\n",
      "Current Layer Attributes - epochs:30 hidden layers:2 features count:32\n",
      "Step 1 | Training Loss: 0.699856 | Validation Accuracy: 0.488492 | Test Accuracy: 0.666076\n",
      "Step 2 | Training Loss: 0.732773 | Validation Accuracy: 0.474603 | Test Accuracy: 0.666076\n",
      "Step 3 | Training Loss: 0.782051 | Validation Accuracy: 0.475000 | Test Accuracy: 0.666076\n",
      "Step 4 | Training Loss: 0.721465 | Validation Accuracy: 0.471429 | Test Accuracy: 0.666076\n",
      "Step 5 | Training Loss: 0.767225 | Validation Accuracy: 0.482540 | Test Accuracy: 0.666076\n",
      "Step 6 | Training Loss: 0.711371 | Validation Accuracy: 0.473016 | Test Accuracy: 0.666076\n",
      "Step 7 | Training Loss: 0.740298 | Validation Accuracy: 0.484524 | Test Accuracy: 0.666076\n",
      "Step 8 | Training Loss: 0.733971 | Validation Accuracy: 0.472619 | Test Accuracy: 0.666076\n",
      "Step 9 | Training Loss: 0.716273 | Validation Accuracy: 0.478968 | Test Accuracy: 0.666076\n",
      "Step 10 | Training Loss: 0.741531 | Validation Accuracy: 0.473016 | Test Accuracy: 0.666076\n",
      "Step 11 | Training Loss: 0.692504 | Validation Accuracy: 0.485317 | Test Accuracy: 0.666076\n",
      "Step 12 | Training Loss: 0.761700 | Validation Accuracy: 0.486905 | Test Accuracy: 0.666076\n",
      "Step 13 | Training Loss: 0.743621 | Validation Accuracy: 0.486508 | Test Accuracy: 0.666076\n",
      "Step 14 | Training Loss: 0.683472 | Validation Accuracy: 0.469841 | Test Accuracy: 0.666076\n",
      "Step 15 | Training Loss: 0.691045 | Validation Accuracy: 0.467063 | Test Accuracy: 0.666076\n",
      "Step 16 | Training Loss: 0.693362 | Validation Accuracy: 0.481746 | Test Accuracy: 0.666076\n",
      "Step 17 | Training Loss: 0.713316 | Validation Accuracy: 0.479762 | Test Accuracy: 0.666076\n",
      "Step 18 | Training Loss: 0.642952 | Validation Accuracy: 0.479365 | Test Accuracy: 0.666076\n",
      "Step 19 | Training Loss: 0.691736 | Validation Accuracy: 0.469444 | Test Accuracy: 0.666076\n",
      "Step 20 | Training Loss: 0.698547 | Validation Accuracy: 0.461508 | Test Accuracy: 0.666076\n",
      "Step 21 | Training Loss: 0.703979 | Validation Accuracy: 0.471825 | Test Accuracy: 0.666076\n",
      "Step 22 | Training Loss: 0.708644 | Validation Accuracy: 0.475397 | Test Accuracy: 0.666076\n",
      "Step 23 | Training Loss: 0.702277 | Validation Accuracy: 0.495635 | Test Accuracy: 0.666076\n",
      "Step 24 | Training Loss: 0.733888 | Validation Accuracy: 0.485317 | Test Accuracy: 0.666076\n",
      "Step 25 | Training Loss: 0.703516 | Validation Accuracy: 0.471429 | Test Accuracy: 0.666076\n",
      "Step 26 | Training Loss: 0.698575 | Validation Accuracy: 0.488889 | Test Accuracy: 0.666076\n",
      "Step 27 | Training Loss: 0.688455 | Validation Accuracy: 0.492460 | Test Accuracy: 0.666076\n",
      "Step 28 | Training Loss: 0.757684 | Validation Accuracy: 0.489683 | Test Accuracy: 0.666076\n",
      "Step 29 | Training Loss: 0.710952 | Validation Accuracy: 0.471429 | Test Accuracy: 0.666076\n",
      "Step 30 | Training Loss: 0.720882 | Validation Accuracy: 0.489683 | Test Accuracy: 0.666076\n",
      "Step 1 | Training Loss: 0.720770 | Validation Accuracy: 0.473016 | Test Accuracy: 0.666076\n",
      "Step 2 | Training Loss: 0.685722 | Validation Accuracy: 0.481349 | Test Accuracy: 0.666076\n",
      "Step 3 | Training Loss: 0.679112 | Validation Accuracy: 0.480952 | Test Accuracy: 0.666076\n",
      "Step 4 | Training Loss: 0.725252 | Validation Accuracy: 0.462698 | Test Accuracy: 0.666076\n",
      "Step 5 | Training Loss: 0.696035 | Validation Accuracy: 0.500000 | Test Accuracy: 0.666076\n",
      "Step 6 | Training Loss: 0.722036 | Validation Accuracy: 0.486111 | Test Accuracy: 0.666076\n",
      "Step 7 | Training Loss: 0.709866 | Validation Accuracy: 0.474603 | Test Accuracy: 0.666076\n",
      "Step 8 | Training Loss: 0.746697 | Validation Accuracy: 0.457143 | Test Accuracy: 0.666076\n",
      "Step 9 | Training Loss: 0.711461 | Validation Accuracy: 0.492460 | Test Accuracy: 0.666076\n",
      "Step 10 | Training Loss: 0.676038 | Validation Accuracy: 0.491270 | Test Accuracy: 0.666076\n",
      "Step 11 | Training Loss: 0.719023 | Validation Accuracy: 0.469444 | Test Accuracy: 0.666076\n",
      "Step 12 | Training Loss: 0.729370 | Validation Accuracy: 0.484524 | Test Accuracy: 0.666076\n",
      "Step 13 | Training Loss: 0.681157 | Validation Accuracy: 0.483730 | Test Accuracy: 0.666076\n",
      "Step 14 | Training Loss: 0.738205 | Validation Accuracy: 0.473413 | Test Accuracy: 0.666076\n",
      "Step 15 | Training Loss: 0.666839 | Validation Accuracy: 0.465476 | Test Accuracy: 0.666076\n",
      "Step 16 | Training Loss: 0.728852 | Validation Accuracy: 0.487302 | Test Accuracy: 0.666076\n",
      "Step 17 | Training Loss: 0.677293 | Validation Accuracy: 0.478571 | Test Accuracy: 0.666076\n",
      "Step 18 | Training Loss: 0.705492 | Validation Accuracy: 0.493651 | Test Accuracy: 0.666076\n",
      "Step 19 | Training Loss: 0.724904 | Validation Accuracy: 0.480159 | Test Accuracy: 0.666076\n",
      "Step 20 | Training Loss: 0.681348 | Validation Accuracy: 0.457936 | Test Accuracy: 0.666076\n",
      "Step 21 | Training Loss: 0.709647 | Validation Accuracy: 0.480159 | Test Accuracy: 0.666076\n",
      "Step 22 | Training Loss: 0.708711 | Validation Accuracy: 0.508333 | Test Accuracy: 0.666076\n",
      "Step 23 | Training Loss: 0.714812 | Validation Accuracy: 0.489286 | Test Accuracy: 0.666076\n",
      "Step 24 | Training Loss: 0.658696 | Validation Accuracy: 0.485317 | Test Accuracy: 0.666076\n",
      "Step 25 | Training Loss: 0.699027 | Validation Accuracy: 0.491270 | Test Accuracy: 0.666076\n",
      "Step 26 | Training Loss: 0.714637 | Validation Accuracy: 0.466667 | Test Accuracy: 0.666076\n",
      "Step 27 | Training Loss: 0.659682 | Validation Accuracy: 0.484524 | Test Accuracy: 0.666076\n",
      "Step 28 | Training Loss: 0.745020 | Validation Accuracy: 0.472619 | Test Accuracy: 0.666076\n",
      "Step 29 | Training Loss: 0.704855 | Validation Accuracy: 0.486905 | Test Accuracy: 0.666076\n",
      "Step 30 | Training Loss: 0.691598 | Validation Accuracy: 0.509127 | Test Accuracy: 0.666076\n",
      "Current Layer Attributes - epochs:30 hidden layers:4 features count:4\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-9-5e78639ac371>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mitertools\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0;32mclass\u001b[0m \u001b[0mHyperparameters\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;31m#    features_arr = [2, 4, 8, 16, 32, 64, 128, 256]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;31m#    hidden_layers_arr = [2, 4, 6, 10]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mfeatures_arr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m8\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m16\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m32\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-9-5e78639ac371>\u001b[0m in \u001b[0;36mHyperparameters\u001b[0;34m()\u001b[0m\n\u001b[1;32m     11\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Current Layer Attributes - epochs:{} hidden layers:{} features count:{}\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mh\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m         \u001b[0mn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnetwork\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mh\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m         \u001b[0mn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuild_layers\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     14\u001b[0m         \u001b[0mTrain\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mh\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlrs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-7-280776bc8c1f>\u001b[0m in \u001b[0;36mbuild_layers\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     34\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mh\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhidden_layers\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     35\u001b[0m                 \u001b[0mhidden_encoder\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdense\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhidden_encoder\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlatent_dim\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mactivation\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrelu\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkernel_regularizer\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0ml2_loss\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 36\u001b[0;31m                 \u001b[0mhidden_encoder\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdropout\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhidden_encoder\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeep_prob\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     37\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     38\u001b[0m             \u001b[0;31m#hidden_encoder = tf.layers.dense(self.x, latent_dim, activation = tf.nn.relu, kernel_regularizer=tf.nn.l2_loss)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/ritesh_malaiya/anaconda3/envs/p3/lib/python3.6/site-packages/tensorflow/python/ops/nn_ops.py\u001b[0m in \u001b[0;36mdropout\u001b[0;34m(x, keep_prob, noise_shape, seed, name)\u001b[0m\n\u001b[1;32m   1962\u001b[0m     random_tensor += random_ops.random_uniform(noise_shape,\n\u001b[1;32m   1963\u001b[0m                                                \u001b[0mseed\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mseed\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1964\u001b[0;31m                                                dtype=x.dtype)\n\u001b[0m\u001b[1;32m   1965\u001b[0m     \u001b[0;31m# 0. if [keep_prob, 1.0) and 1. if [1.0, 1.0 + keep_prob)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1966\u001b[0m     \u001b[0mbinary_tensor\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmath_ops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrandom_tensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/ritesh_malaiya/anaconda3/envs/p3/lib/python3.6/site-packages/tensorflow/python/ops/random_ops.py\u001b[0m in \u001b[0;36mrandom_uniform\u001b[0;34m(shape, minval, maxval, dtype, seed, name)\u001b[0m\n\u001b[1;32m    234\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    235\u001b[0m       rnd = gen_random_ops._random_uniform(\n\u001b[0;32m--> 236\u001b[0;31m           shape, dtype, seed=seed1, seed2=seed2)\n\u001b[0m\u001b[1;32m    237\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mmath_ops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrnd\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mmaxval\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mminval\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mminval\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    238\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/ritesh_malaiya/anaconda3/envs/p3/lib/python3.6/site-packages/tensorflow/python/ops/gen_random_ops.py\u001b[0m in \u001b[0;36m_random_uniform\u001b[0;34m(shape, dtype, seed, seed2, name)\u001b[0m\n\u001b[1;32m    261\u001b[0m   \"\"\"\n\u001b[1;32m    262\u001b[0m   result = _op_def_lib.apply_op(\"RandomUniform\", shape=shape, dtype=dtype,\n\u001b[0;32m--> 263\u001b[0;31m                                 seed=seed, seed2=seed2, name=name)\n\u001b[0m\u001b[1;32m    264\u001b[0m   \u001b[0;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    265\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/ritesh_malaiya/anaconda3/envs/p3/lib/python3.6/site-packages/tensorflow/python/framework/op_def_library.py\u001b[0m in \u001b[0;36mapply_op\u001b[0;34m(self, op_type_name, name, **keywords)\u001b[0m\n\u001b[1;32m    766\u001b[0m         op = g.create_op(op_type_name, inputs, output_types, name=scope,\n\u001b[1;32m    767\u001b[0m                          \u001b[0minput_types\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minput_types\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattrs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mattr_protos\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 768\u001b[0;31m                          op_def=op_def)\n\u001b[0m\u001b[1;32m    769\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0moutput_structure\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    770\u001b[0m           \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mop\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/ritesh_malaiya/anaconda3/envs/p3/lib/python3.6/site-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36mcreate_op\u001b[0;34m(self, op_type, inputs, dtypes, input_types, name, attrs, op_def, compute_shapes, compute_device)\u001b[0m\n\u001b[1;32m   2336\u001b[0m                     original_op=self._default_original_op, op_def=op_def)\n\u001b[1;32m   2337\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mcompute_shapes\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2338\u001b[0;31m       \u001b[0mset_shapes_for_outputs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mret\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2339\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_add_op\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mret\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2340\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_record_op_seen_by_control_dependencies\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mret\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/ritesh_malaiya/anaconda3/envs/p3/lib/python3.6/site-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36mset_shapes_for_outputs\u001b[0;34m(op)\u001b[0m\n\u001b[1;32m   1717\u001b[0m       \u001b[0mshape_func\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_call_cpp_shape_fn_and_require_op\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1718\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1719\u001b[0;31m   \u001b[0mshapes\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mshape_func\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mop\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1720\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0mshapes\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1721\u001b[0m     raise RuntimeError(\n",
      "\u001b[0;32m/home/ritesh_malaiya/anaconda3/envs/p3/lib/python3.6/site-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36mcall_with_requiring\u001b[0;34m(op)\u001b[0m\n\u001b[1;32m   1667\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1668\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mcall_with_requiring\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mop\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1669\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mcall_cpp_shape_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mop\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrequire_shape_fn\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1670\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1671\u001b[0m   \u001b[0m_call_cpp_shape_fn_and_require_op\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcall_with_requiring\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/ritesh_malaiya/anaconda3/envs/p3/lib/python3.6/site-packages/tensorflow/python/framework/common_shapes.py\u001b[0m in \u001b[0;36mcall_cpp_shape_fn\u001b[0;34m(op, input_tensors_needed, input_tensors_as_shapes_needed, debug_python_shape_fn, require_shape_fn)\u001b[0m\n\u001b[1;32m    608\u001b[0m     res = _call_cpp_shape_fn_impl(op, input_tensors_needed,\n\u001b[1;32m    609\u001b[0m                                   \u001b[0minput_tensors_as_shapes_needed\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 610\u001b[0;31m                                   debug_python_shape_fn, require_shape_fn)\n\u001b[0m\u001b[1;32m    611\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mres\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    612\u001b[0m       \u001b[0;31m# Handles the case where _call_cpp_shape_fn_impl calls unknown_shape(op).\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/ritesh_malaiya/anaconda3/envs/p3/lib/python3.6/site-packages/tensorflow/python/framework/common_shapes.py\u001b[0m in \u001b[0;36m_call_cpp_shape_fn_impl\u001b[0;34m(op, input_tensors_needed, input_tensors_as_shapes_needed, debug_python_shape_fn, require_shape_fn)\u001b[0m\n\u001b[1;32m    687\u001b[0m   result_protos = [\n\u001b[1;32m    688\u001b[0m       \u001b[0mcpp_shape_inference_pb2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mCppShapeInferenceResult\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mFromString\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 689\u001b[0;31m       \u001b[0;32mfor\u001b[0m \u001b[0ms\u001b[0m \u001b[0;32min\u001b[0m \u001b[0moutput_shapes\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    690\u001b[0m   ]\n\u001b[1;32m    691\u001b[0m   \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mr\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mresult_protos\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/ritesh_malaiya/anaconda3/envs/p3/lib/python3.6/site-packages/tensorflow/python/framework/common_shapes.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    687\u001b[0m   result_protos = [\n\u001b[1;32m    688\u001b[0m       \u001b[0mcpp_shape_inference_pb2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mCppShapeInferenceResult\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mFromString\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 689\u001b[0;31m       \u001b[0;32mfor\u001b[0m \u001b[0ms\u001b[0m \u001b[0;32min\u001b[0m \u001b[0moutput_shapes\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    690\u001b[0m   ]\n\u001b[1;32m    691\u001b[0m   \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mr\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mresult_protos\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/ritesh_malaiya/anaconda3/envs/p3/lib/python3.6/site-packages/google/protobuf/internal/python_message.py\u001b[0m in \u001b[0;36mFromString\u001b[0;34m(s)\u001b[0m\n\u001b[1;32m    753\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mFromString\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    754\u001b[0m     \u001b[0mmessage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcls\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 755\u001b[0;31m     \u001b[0mmessage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mMergeFromString\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    756\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mmessage\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    757\u001b[0m   \u001b[0mcls\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mFromString\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstaticmethod\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mFromString\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/ritesh_malaiya/anaconda3/envs/p3/lib/python3.6/site-packages/google/protobuf/internal/python_message.py\u001b[0m in \u001b[0;36mMergeFromString\u001b[0;34m(self, serialized)\u001b[0m\n\u001b[1;32m   1060\u001b[0m     \u001b[0mlength\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mserialized\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1061\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1062\u001b[0;31m       \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_InternalParse\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mserialized\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlength\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mlength\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1063\u001b[0m         \u001b[0;31m# The only reason _InternalParse would return early is if it\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1064\u001b[0m         \u001b[0;31m# encountered an end-group tag.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/ritesh_malaiya/anaconda3/envs/p3/lib/python3.6/site-packages/google/protobuf/internal/python_message.py\u001b[0m in \u001b[0;36mInternalParse\u001b[0;34m(self, buffer, pos, end)\u001b[0m\n\u001b[1;32m   1096\u001b[0m         \u001b[0mpos\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnew_pos\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1097\u001b[0m       \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1098\u001b[0;31m         \u001b[0mpos\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfield_decoder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbuffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnew_pos\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mend\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfield_dict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1099\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mfield_desc\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1100\u001b[0m           \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_UpdateOneofState\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfield_desc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/ritesh_malaiya/anaconda3/envs/p3/lib/python3.6/site-packages/google/protobuf/internal/decoder.py\u001b[0m in \u001b[0;36mDecodeField\u001b[0;34m(buffer, pos, end, message, field_dict)\u001b[0m\n\u001b[1;32m    624\u001b[0m       \u001b[0mvalue\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfield_dict\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    625\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mvalue\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 626\u001b[0;31m         \u001b[0mvalue\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfield_dict\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msetdefault\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnew_default\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    627\u001b[0m       \u001b[0;31m# Read length.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    628\u001b[0m       \u001b[0;34m(\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpos\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlocal_DecodeVarint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbuffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpos\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/ritesh_malaiya/anaconda3/envs/p3/lib/python3.6/site-packages/google/protobuf/internal/python_message.py\u001b[0m in \u001b[0;36mMakeSubMessageDefault\u001b[0;34m(message)\u001b[0m\n\u001b[1;32m    421\u001b[0m     \u001b[0mmessage_type\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfield\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage_type\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    422\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mMakeSubMessageDefault\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 423\u001b[0;31m       \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmessage_type\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_concrete_class\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    424\u001b[0m       result._SetListener(\n\u001b[1;32m    425\u001b[0m           \u001b[0m_OneofListener\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfield\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/ritesh_malaiya/anaconda3/envs/p3/lib/python3.6/site-packages/google/protobuf/internal/python_message.py\u001b[0m in \u001b[0;36minit\u001b[0;34m(self, **kwargs)\u001b[0m\n\u001b[1;32m    467\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0minit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    468\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_cached_byte_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 469\u001b[0;31m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_cached_byte_size_dirty\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    470\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fields\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    471\u001b[0m     \u001b[0;31m# Contains a mapping from oneof field descriptors to the descriptor\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import itertools\n",
    "class Hyperparameters:\n",
    "#    features_arr = [2, 4, 8, 16, 32, 64, 128, 256]\n",
    "#    hidden_layers_arr = [2, 4, 6, 10]\n",
    "    features_arr = [4, 8, 16, 32]\n",
    "    hidden_layers_arr = [2, 4, 6]\n",
    "    \n",
    "    epochs = [30]\n",
    "    lrs = [1e-9, 1e-10]\n",
    "    for e, h, f in itertools.product(epochs, hidden_layers_arr, features_arr):\n",
    "        print(\"Current Layer Attributes - epochs:{} hidden layers:{} features count:{}\".format(e,h,f))\n",
    "        n = network(2,h,f)\n",
    "        n.build_layers()\n",
    "        Train.train(e, n, h,f, lrs)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-06-01T13:36:26.744287Z",
     "start_time": "2017-06-01T13:32:51.986Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dict1 = {}\n",
    "dict2 = []\n",
    "for k, (v1, v2) in Train.predictions.items():\n",
    "    dict1.update({k: v1})\n",
    "    dict2.append(v2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-06-01T13:36:26.745397Z",
     "start_time": "2017-06-01T13:32:51.988Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Train.predictions = dict1\n",
    "Train.results = dict2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-06-01T13:36:26.746484Z",
     "start_time": "2017-06-01T13:32:51.991Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_results = pd.DataFrame(Train.results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-06-01T13:36:26.749323Z",
     "start_time": "2017-06-01T13:32:51.993Z"
    }
   },
   "outputs": [],
   "source": [
    "df_results.sort_values(by = 'test_score', ascending = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-06-01T13:36:26.761195Z",
     "start_time": "2017-06-01T13:32:51.996Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pd.Panel(Train.predictions).to_pickle(\"dataset/tf_dense_only_nsl_kdd_predictions-.pkl\")\n",
    "df_results.to_pickle(\"dataset/tf_dense_only_nsl_kdd_scores-.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-06-01T13:36:26.762436Z",
     "start_time": "2017-06-01T13:32:51.999Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import itertools\n",
    "\n",
    "def plot_confusion_matrix(cm, classes,\n",
    "                          normalize=False,\n",
    "                          title='Confusion matrix',\n",
    "                          cmap=plt.cm.Blues):\n",
    "    \"\"\"\n",
    "    This function prints and plots the confusion matrix.\n",
    "    Normalization can be applied by setting `normalize=True`.\n",
    "    \"\"\"\n",
    "    np.set_printoptions(precision=4)\n",
    "\n",
    "    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n",
    "    plt.title(title)\n",
    "    plt.colorbar()\n",
    "    tick_marks = np.arange(len(classes))\n",
    "    plt.xticks(tick_marks, classes, rotation=45)\n",
    "    plt.yticks(tick_marks, classes)\n",
    "\n",
    "    if normalize:\n",
    "        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "        print(\"Normalized confusion matrix\")\n",
    "    else:\n",
    "        print('Confusion matrix, without normalization')\n",
    "\n",
    "    print(cm)\n",
    "\n",
    "    thresh = cm.max() / 2.\n",
    "    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
    "        plt.text(j, i, cm[i, j].round(4),\n",
    "                 horizontalalignment=\"center\",\n",
    "                 color=\"white\" if cm[i, j] > thresh else \"black\")\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.ylabel('True label')\n",
    "    plt.xlabel('Predicted label')\n",
    "\n",
    "def plot(actual_value, pred_value):\n",
    "    from sklearn.metrics import confusion_matrix\n",
    "    cm_2labels = confusion_matrix(y_pred = pred_value, y_true = actual_value)\n",
    "    plt.figure(figsize=[6,6])\n",
    "    plot_confusion_matrix(cm_2labels, preprocess.output_columns_2labels, normalize = True,\n",
    "                         title = Train.best_parameters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-06-01T13:36:26.763547Z",
     "start_time": "2017-06-01T13:32:52.002Z"
    }
   },
   "outputs": [],
   "source": [
    "plot(actual_value = Train.actual_value, pred_value = Train.pred_value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "_draft": {
   "nbviewer_url": "https://gist.github.com/7d1ace18a82178e15ece8fc5252fce88"
  },
  "anaconda-cloud": {},
  "gist": {
   "data": {
    "description": "Hyper parameter tuning",
    "public": false
   },
   "id": "7d1ace18a82178e15ece8fc5252fce88"
  },
  "kernelspec": {
   "display_name": "Python [conda env:p3]",
   "language": "python",
   "name": "conda-env-p3-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
