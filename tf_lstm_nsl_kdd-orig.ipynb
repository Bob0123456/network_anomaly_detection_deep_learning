{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Read Data Sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-06-30T21:19:56.543863Z",
     "start_time": "2017-06-30T21:19:56.139823Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import time\n",
    "from collections import namedtuple\n",
    "pd.set_option(\"display.max_rows\",35)\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-06-30T21:19:56.705830Z",
     "start_time": "2017-06-30T21:19:56.545516Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class dataset:\n",
    "    kdd_train = pd.read_pickle(\"dataset/kdd_train.pkl\")\n",
    "    kdd_test = pd.read_pickle(\"dataset/kdd_test.pkl\")\n",
    "\n",
    "    kdd_train_label = pd.read_pickle(\"dataset/kdd_train_label.pkl\")\n",
    "    kdd_test_label = pd.read_pickle(\"dataset/kdd_test_label.pkl\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-06-30T21:19:56.713295Z",
     "start_time": "2017-06-30T21:19:56.707553Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(381105, 161)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.kdd_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-06-30T21:19:56.726152Z",
     "start_time": "2017-06-30T21:19:56.715043Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(381105, 2)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.kdd_train_label.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-06-30T21:19:56.731796Z",
     "start_time": "2017-06-30T21:19:56.727718Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(350596, 161)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.kdd_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-06-30T21:19:59.348620Z",
     "start_time": "2017-06-30T21:19:56.733377Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0000000000000331"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn import model_selection as ms\n",
    "from sklearn import preprocessing as pp\n",
    "\n",
    "class preprocess:\n",
    "    \n",
    "    output_columns_2labels = ['label']\n",
    "    \n",
    "    x_input = dataset.kdd_train\n",
    "    y_output = dataset.kdd_train_label\n",
    "\n",
    "    x_test_input = dataset.kdd_test\n",
    "    y_test = dataset.kdd_test_label\n",
    "    \n",
    "    ss = pp.StandardScaler()\n",
    "\n",
    "    x_train = ss.fit_transform(x_input)\n",
    "    x_test = ss.transform(x_test_input)\n",
    "    \n",
    "    y_train = y_output.values\n",
    "    y_test = y_test.values\n",
    "    \n",
    "preprocess.x_train.std()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-06-30T21:20:01.143060Z",
     "start_time": "2017-06-30T21:19:59.350086Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.contrib.legacy_seq2seq.python.ops.seq2seq import basic_rnn_seq2seq\n",
    "from tensorflow.contrib.rnn import RNNCell, LSTMCell, MultiRNNCell\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-06-30T21:20:01.390090Z",
     "start_time": "2017-06-30T21:20:01.144588Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class network(object):\n",
    "    \n",
    "    input_dim = 161\n",
    "    classes = 2\n",
    "    hidden_encoder_dim = 161\n",
    "    hidden_layers = 1\n",
    "    latent_dim = 40\n",
    "\n",
    "    hidden_decoder_dim = 161\n",
    "    lam = 0.01\n",
    "    \n",
    "    def __init__(self, classes, hidden_layers, num_of_features):\n",
    "        self.classes = classes\n",
    "        self.hidden_layers = hidden_layers\n",
    "        self.latent_dim = num_of_features\n",
    "            \n",
    "    def build_layers(self):\n",
    "        tf.reset_default_graph()\n",
    "        #learning_rate = tf.Variable(initial_value=0.001)\n",
    "\n",
    "        input_dim = self.input_dim\n",
    "        classes = self.classes\n",
    "        hidden_encoder_dim = self.hidden_encoder_dim\n",
    "        hidden_layers = self.hidden_layers\n",
    "        latent_dim = self.latent_dim\n",
    "        hidden_decoder_dim = self.hidden_decoder_dim\n",
    "        lam = self.lam\n",
    "        \n",
    "        with tf.variable_scope(\"Input\"):\n",
    "            self.x_input = tf.placeholder(\"float\", shape=[None, 1, input_dim])\n",
    "            self.y_input_ = tf.placeholder(\"float\", shape=[None, 1, classes])\n",
    "            self.keep_prob = tf.placeholder(\"float\")\n",
    "            self.lr = tf.placeholder(\"float\")\n",
    "            self.x_list = tf.unstack(self.x_input, axis= 1)\n",
    "            self.y_list_ = tf.unstack(self.y_input_, axis = 1)\n",
    "            self.y_ = self.y_list_[0]\n",
    "            \n",
    "            #GO = tf.fill((tf.shape(self.x)[0], 1), 0.5)\n",
    "            \n",
    "            #y_with_GO = tf.stack([self.y_, GO])\n",
    "            \n",
    "        with tf.variable_scope(\"lstm\"):\n",
    "            multi_cell = MultiRNNCell([LSTMCell(input_dim) for i in range(hidden_layers)] )\n",
    "            \n",
    "            self.y, states = basic_rnn_seq2seq(self.x_list, self.y_list_, multi_cell)\n",
    "            #self.y = tf.slice(self.y, [0, 0], [-1,2])\n",
    "            \n",
    "            #self.out = tf.squeeze(self.y)\n",
    "            \n",
    "            #self.y = tf.layers.dense(self.y[0], classes, activation = None)\n",
    "            \n",
    "            self.y = tf.slice(self.y[0], [0, 0], [-1,2])\n",
    "            \n",
    "        with tf.variable_scope(\"Loss\"):\n",
    "            \n",
    "            self.regularized_loss = tf.losses.mean_squared_error(self.y_, self.y)\n",
    "            correct_prediction = tf.equal(tf.argmax(self.y_, 1), tf.argmax(self.y, 1))\n",
    "            self.tf_accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32), name = \"Accuracy\")\n",
    "\n",
    "        with tf.variable_scope(\"Optimizer\"):\n",
    "            learning_rate=self.lr\n",
    "            optimizer = tf.train.AdamOptimizer(learning_rate)\n",
    "            gradients, variables = zip(*optimizer.compute_gradients(self.regularized_loss))\n",
    "            gradients = [\n",
    "                None if gradient is None else tf.clip_by_value(gradient, -1, 1)\n",
    "                for gradient in gradients]\n",
    "            self.train_op = optimizer.apply_gradients(zip(gradients, variables))\n",
    "            #self.train_op = optimizer.minimize(self.regularized_loss)\n",
    "            \n",
    "        # add op for merging summary\n",
    "        #self.summary_op = tf.summary.merge_all()\n",
    "        self.pred = tf.argmax(self.y, axis = 1)\n",
    "        self.actual = tf.argmax(self.y_, axis = 1)\n",
    "\n",
    "        # add Saver ops\n",
    "        self.saver = tf.train.Saver()\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-06-01T00:59:00.684124Z",
     "start_time": "2017-06-01T00:58:59.843181Z"
    }
   },
   "source": [
    "batch_iterations = 200\n",
    "\n",
    "x_train, x_valid, y_train, y_valid, = ms.train_test_split(preprocess.x_train, \n",
    "                                                                          preprocess.y_train, \n",
    "                                                                          test_size=0.1)\n",
    "batch_indices = np.array_split(np.arange(x_train.shape[0]), \n",
    "                                           batch_iterations)\n",
    "                                                                          \n",
    "for i in batch_indices:\n",
    "    print(x_train[i,np.newaxis,:])\n",
    "    print(y_train[i,np.newaxis,:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-06-30T21:20:01.639914Z",
     "start_time": "2017-06-30T21:20:01.391959Z"
    },
    "collapsed": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import collections\n",
    "\n",
    "class Train:    \n",
    "    \n",
    "    result = namedtuple(\"score\", ['epoch', 'no_of_features','hidden_layers','train_score', 'test_score', 'time_taken'])\n",
    "\n",
    "    predictions = {}\n",
    "\n",
    "    results = []\n",
    "    best_acc = 0\n",
    "    best_acc_global = 0\n",
    "\n",
    "    def train(epochs, net, h,f, lrs):\n",
    "        batch_iterations = 1000\n",
    "        train_loss = None\n",
    "        Train.best_acc = 0\n",
    "        os.makedirs(\"dataset/tf_lstm_nsl_kdd-orig/hidden layers_{}_features count_{}\".format(h,f),\n",
    "                    exist_ok = True)\n",
    "        with tf.Session() as sess:\n",
    "            #summary_writer_train = tf.summary.FileWriter('./logs/kdd/VAE/training', graph=sess.graph)\n",
    "            #summary_writer_valid = tf.summary.FileWriter('./logs/kdd/VAE/validation')\n",
    "\n",
    "            sess.run(tf.global_variables_initializer())\n",
    "            start_time = time.perf_counter()\n",
    "            \n",
    "            accuracy, pred_value, actual_value, y_pred = sess.run([net.tf_accuracy, \n",
    "                                                                   net.pred, \n",
    "                                                                   net.actual, net.y], \n",
    "                                                                  feed_dict={net.x_input: preprocess.x_test[:,np.newaxis,:], \n",
    "                                                                             net.y_input_: preprocess.y_test[:,np.newaxis,:], \n",
    "                                                                             net.keep_prob:1})\n",
    "            \n",
    "            print(\"Initial Accuracy, before training: {}\".format(accuracy))\n",
    "            \n",
    "            for c, lr in enumerate(lrs):\n",
    "                for epoch in range(1, (epochs+1)):\n",
    "                    x_train, x_valid, y_train, y_valid, = ms.train_test_split(preprocess.x_train, \n",
    "                                                                              preprocess.y_train, \n",
    "                                                                              test_size=0.1)\n",
    "                    batch_indices = np.array_split(np.arange(x_train.shape[0]), \n",
    "                                               batch_iterations)\n",
    "\n",
    "                    for i in batch_indices:\n",
    "\n",
    "                        _, train_loss = sess.run([net.train_op, net.regularized_loss], #net.summary_op\n",
    "                                                  feed_dict={net.x_input: x_train[i,np.newaxis,:], \n",
    "                                                             net.y_input_: y_train[i,np.newaxis,:], \n",
    "                                                             net.keep_prob:1, net.lr:lr})\n",
    "                        #summary_writer_train.add_summary(summary_str, epoch)\n",
    "                        if(train_loss > 1e9):\n",
    "                            print(\"Step {} | Training Loss: {:.6f}\".format(epoch, train_loss))\n",
    "\n",
    "\n",
    "                    valid_accuracy,valid_loss = sess.run([net.tf_accuracy, net.regularized_loss], #net.summary_op \n",
    "                                                          feed_dict={net.x_input: x_valid[:,np.newaxis,:], \n",
    "                                                                     net.y_input_: y_valid[:,np.newaxis,:], \n",
    "                                                                     net.keep_prob:1, net.lr:lr})\n",
    "                    #summary_writer_valid.add_summary(summary_str, epoch)\n",
    "\n",
    "\n",
    "                    accuracy, pred_value, actual_value, y_pred = sess.run([net.tf_accuracy, \n",
    "                                                                           net.pred, \n",
    "                                                                           net.actual, net.y], \n",
    "                                                                          feed_dict={net.x_input: preprocess.x_test[:,np.newaxis,:], \n",
    "                                                                                     net.y_input_: preprocess.y_test[:,np.newaxis,:], \n",
    "                                                                                     net.keep_prob:1, net.lr:lr})\n",
    "\n",
    "                    print(\"Step {} | Training Loss: {:.6f} | Train Accuracy: {:.6f} | Test Accuracy: {:.6f}\".format(epoch, train_loss, valid_accuracy, accuracy))\n",
    "\n",
    "                    if accuracy > Train.best_acc_global:\n",
    "                                Train.best_acc_global = accuracy\n",
    "                                Train.pred_value = pred_value\n",
    "                                Train.actual_value = actual_value\n",
    "                                \n",
    "                                Train.best_parameters = \"Hidden Layers:{}, Features Count:{}\".format(h, f)\n",
    "\n",
    "                    if accuracy > Train.best_acc:\n",
    "\n",
    "                        #net.saver.save(sess, \"dataset/tf_vae_only_nsl_kdd_hidden layers_{}_features count_{}\".format(epochs,h,f))\n",
    "                        #Train.results.append(Train.result(epochs, f, h,valid_accuracy, accuracy))\n",
    "                        #curr_pred = pd.DataFrame({\"Attack_prob\":y_pred[:,-2], \"Normal_prob\":y_pred[:, -1]})\n",
    "                        #Train.predictions.update({\"{}_{}_{}\".format(epochs,f,h):curr_pred})\n",
    "\n",
    "                        Train.best_acc = accuracy\n",
    "                        if not (np.isnan(train_loss)):\n",
    "                            net.saver.save(sess, \n",
    "                                       \"dataset/tf_lstm_nsl_kdd-orig/hidden layers_{}_features count_{}/model\"\n",
    "                                       .format(h,f), \n",
    "                                       global_step = epoch, \n",
    "                                       write_meta_graph=False)\n",
    "\n",
    "                        curr_pred = pd.DataFrame({\"Attack_prob\":y_pred[:,-2], \"Normal_prob\":y_pred[:, -1], \"Prediction\":pred_value})\n",
    "                        Train.predictions.update({\"{}_{}_{}\".format((epochs+1)* (c+1),f,h):\n",
    "                                                  (curr_pred, \n",
    "                                                   Train.result((epochs+1)*(c+1), f, h,valid_accuracy, accuracy, time.perf_counter() - start_time))})\n",
    "\n",
    "\n",
    "\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-06-30T21:20:01.701176Z",
     "start_time": "2017-06-30T21:20:01.641471Z"
    },
    "collapsed": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import itertools\n",
    "\n",
    "df_results = []\n",
    "past_scores = []\n",
    "\n",
    "class Hyperparameters:\n",
    "#    features_arr = [2, 4, 8, 16, 32, 64, 128, 256]\n",
    "#    hidden_layers_arr = [2, 4, 6, 10]\n",
    "\n",
    "    def start_training():\n",
    "\n",
    "        global df_results\n",
    "        global past_scores\n",
    "        \n",
    "        Train.predictions = {}\n",
    "        Train.results = []\n",
    "        \n",
    "        features_arr = [1] #[4, 8, 16, 32]\n",
    "        hidden_layers_arr = [1, 3, 5]\n",
    "\n",
    "        epochs = [1]\n",
    "        lrs = [1e-2, 1e-2/2, 1e-2/4]\n",
    "\n",
    "        for e, h, f in itertools.product(epochs, hidden_layers_arr, features_arr):\n",
    "            print(\"Current Layer Attributes - epochs:{} hidden layers:{} features count:{}\".format(e,h,f))\n",
    "            n = network(2,h,f)\n",
    "            n.build_layers()\n",
    "            Train.train(e, n, h,f, lrs)\n",
    "            \n",
    "        dict1 = {}\n",
    "        dict2 = []\n",
    "        for k, (v1, v2) in Train.predictions.items():\n",
    "            dict1.update({k: v1})\n",
    "            dict2.append(v2)\n",
    "            \n",
    "        Train.predictions = dict1\n",
    "        Train.results = dict2\n",
    "        df_results = pd.DataFrame(Train.results)\n",
    "        temp = df_results.set_index(['no_of_features', 'hidden_layers'])\n",
    "\n",
    "        if not os.path.isfile('dataset/tf_lstm_nsl_kdd-orig_all.pkl'):\n",
    "            past_scores = temp\n",
    "        else:\n",
    "            past_scores = pd.read_pickle(\"dataset/tf_lstm_nsl_kdd-orig_all.pkl\")\n",
    "\n",
    "        past_scores.append(temp).to_pickle(\"dataset/tf_lstm_nsl_kdd-orig_all.pkl\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-06-30T21:48:15.857614Z",
     "start_time": "2017-06-30T21:20:01.702556Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current Layer Attributes - epochs:1 hidden layers:1 features count:1\n",
      "Initial Accuracy, before training: 0.4154781997203827\n",
      "Step 1 | Training Loss: 0.005654 | Train Accuracy: 0.999711 | Test Accuracy: 1.000000\n",
      "Step 1 | Training Loss: 0.005184 | Train Accuracy: 1.000000 | Test Accuracy: 1.000000\n",
      "Step 1 | Training Loss: 0.005964 | Train Accuracy: 1.000000 | Test Accuracy: 1.000000\n",
      "Current Layer Attributes - epochs:1 hidden layers:3 features count:1\n",
      "Initial Accuracy, before training: 0.06588780134916306\n",
      "Step 1 | Training Loss: 0.000649 | Train Accuracy: 0.998872 | Test Accuracy: 0.942509\n",
      "Step 1 | Training Loss: 0.000648 | Train Accuracy: 0.999790 | Test Accuracy: 0.942392\n",
      "Step 1 | Training Loss: 0.000648 | Train Accuracy: 0.999974 | Test Accuracy: 0.942555\n",
      "Current Layer Attributes - epochs:1 hidden layers:5 features count:1\n",
      "Initial Accuracy, before training: 0.07008351385593414\n",
      "Step 1 | Training Loss: 0.003596 | Train Accuracy: 0.989845 | Test Accuracy: 0.057610\n",
      "Step 1 | Training Loss: 0.000649 | Train Accuracy: 0.997166 | Test Accuracy: 0.708827\n",
      "Step 1 | Training Loss: 0.002109 | Train Accuracy: 0.996143 | Test Accuracy: 0.972210\n",
      "Current Layer Attributes - epochs:1 hidden layers:1 features count:1\n",
      "Initial Accuracy, before training: 0.9400991201400757\n",
      "Step 1 | Training Loss: 0.008941 | Train Accuracy: 0.999397 | Test Accuracy: 1.000000\n",
      "Step 1 | Training Loss: 0.010759 | Train Accuracy: 0.998006 | Test Accuracy: 1.000000\n",
      "Step 1 | Training Loss: 0.010850 | Train Accuracy: 0.999213 | Test Accuracy: 1.000000\n",
      "Current Layer Attributes - epochs:1 hidden layers:3 features count:1\n",
      "Initial Accuracy, before training: 0.3934985101222992\n",
      "Step 1 | Training Loss: 0.000649 | Train Accuracy: 0.999974 | Test Accuracy: 0.942392\n",
      "Step 1 | Training Loss: 0.000648 | Train Accuracy: 0.999974 | Test Accuracy: 0.942392\n",
      "Step 1 | Training Loss: 0.000650 | Train Accuracy: 0.999974 | Test Accuracy: 0.942352\n",
      "Current Layer Attributes - epochs:1 hidden layers:5 features count:1\n",
      "Initial Accuracy, before training: 0.5955173373222351\n",
      "Step 1 | Training Loss: 0.076827 | Train Accuracy: 0.895253 | Test Accuracy: 0.942392\n",
      "Step 1 | Training Loss: 0.006303 | Train Accuracy: 0.995592 | Test Accuracy: 0.942392\n",
      "Step 1 | Training Loss: 0.003523 | Train Accuracy: 0.996851 | Test Accuracy: 0.942392\n",
      "14min 51s ± 0 ns per loop (mean ± std. dev. of 1 run, 1 loop each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit -r 1\n",
    "\n",
    "Hyperparameters.start_training()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-06-16T20:12:38.742950Z",
     "start_time": "2017-06-16T20:12:38.705898Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-06-16T20:12:38.748800Z",
     "start_time": "2017-06-16T20:12:38.744607Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-06-30T21:48:15.894075Z",
     "start_time": "2017-06-30T21:48:15.866669Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>epoch</th>\n",
       "      <th>no_of_features</th>\n",
       "      <th>hidden_layers</th>\n",
       "      <th>train_score</th>\n",
       "      <th>test_score</th>\n",
       "      <th>time_taken</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.999397</td>\n",
       "      <td>1.0</td>\n",
       "      <td>37.588114</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   epoch  no_of_features  hidden_layers  train_score  test_score  time_taken\n",
       "0      2               1              1     0.999397         1.0   37.588114"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "g = df_results.groupby(by=['no_of_features'])\n",
    "idx = g['test_score'].transform(max) == df_results['test_score']\n",
    "df_results[idx].sort_values(by = 'test_score', ascending = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-06-30T21:48:15.946541Z",
     "start_time": "2017-06-30T21:48:15.920658Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>epoch</th>\n",
       "      <th>no_of_features</th>\n",
       "      <th>hidden_layers</th>\n",
       "      <th>train_score</th>\n",
       "      <th>test_score</th>\n",
       "      <th>time_taken</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.999397</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>37.588114</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0.999974</td>\n",
       "      <td>0.942392</td>\n",
       "      <td>111.364882</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>0.895253</td>\n",
       "      <td>0.942392</td>\n",
       "      <td>185.609044</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   epoch  no_of_features  hidden_layers  train_score  test_score  time_taken\n",
       "0      2               1              1     0.999397    1.000000   37.588114\n",
       "1      2               1              3     0.999974    0.942392  111.364882\n",
       "2      2               1              5     0.895253    0.942392  185.609044"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_results.sort_values(by = 'test_score', ascending = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-06-30T21:48:16.022720Z",
     "start_time": "2017-06-30T21:48:15.956565Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pd.Panel(Train.predictions).to_pickle(\"dataset/tf_lstm_nsl_kdd_predictions.pkl\")\n",
    "df_results.to_pickle(\"dataset/tf_lstm_nsl_kdd_scores.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-06-30T21:48:16.084181Z",
     "start_time": "2017-06-30T21:48:16.024397Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import itertools\n",
    "\n",
    "def plot_confusion_matrix(cm, classes,\n",
    "                          normalize=False,\n",
    "                          title='Confusion matrix',\n",
    "                          cmap=plt.cm.Blues):\n",
    "    \"\"\"\n",
    "    This function prints and plots the confusion matrix.\n",
    "    Normalization can be applied by setting `normalize=True`.\n",
    "    \"\"\"\n",
    "    np.set_printoptions(precision=4)\n",
    "\n",
    "    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n",
    "    plt.title(title)\n",
    "    plt.colorbar()\n",
    "    tick_marks = np.arange(len(classes))\n",
    "    plt.xticks(tick_marks, classes, rotation=45)\n",
    "    plt.yticks(tick_marks, classes)\n",
    "\n",
    "    if normalize:\n",
    "        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "        print(\"Normalized confusion matrix\")\n",
    "    else:\n",
    "        print('Confusion matrix, without normalization')\n",
    "\n",
    "    print(cm)\n",
    "\n",
    "    thresh = cm.max() / 2.\n",
    "    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
    "        plt.text(j, i, cm[i, j].round(4),\n",
    "                 horizontalalignment=\"center\",\n",
    "                 color=\"white\" if cm[i, j] > thresh else \"black\")\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.ylabel('True label')\n",
    "    plt.xlabel('Predicted label')\n",
    "\n",
    "def plot(actual_value, pred_value):\n",
    "    from sklearn.metrics import confusion_matrix\n",
    "    cm_2labels = confusion_matrix(y_pred = pred_value, y_true = actual_value)\n",
    "    plt.figure(figsize=[6,6])\n",
    "    plot_confusion_matrix(cm_2labels, preprocess.output_columns_2labels, normalize = False,\n",
    "                         title = Train.best_parameters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-06-30T21:48:17.143983Z",
     "start_time": "2017-06-30T21:48:16.085715Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion matrix, without normalization\n",
      "[[330399      0]\n",
      " [     0  20197]]\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAbUAAAGoCAYAAADB4nuYAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nmZXG/wfs+DT2wBRNWwAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f97f200d940>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot(actual_value = Train.actual_value, pred_value = Train.pred_value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-06-30T21:48:38.061101Z",
     "start_time": "2017-06-30T21:48:37.124365Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#4.5 GB\n",
    "pd.Series(Train.pred_value).to_csv('LSTM_prediction_values.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-06-30T21:48:38.087705Z",
     "start_time": "2017-06-30T21:48:38.065283Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>epoch</th>\n",
       "      <th>train_score</th>\n",
       "      <th>test_score</th>\n",
       "      <th>time_taken</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>no_of_features</th>\n",
       "      <th>hidden_layers</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"12\" valign=\"top\">1</th>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>0.999711</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>22.828227</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2</td>\n",
       "      <td>0.998872</td>\n",
       "      <td>0.942509</td>\n",
       "      <td>80.324496</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>6</td>\n",
       "      <td>0.999974</td>\n",
       "      <td>0.942555</td>\n",
       "      <td>256.414336</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2</td>\n",
       "      <td>0.989845</td>\n",
       "      <td>0.057610</td>\n",
       "      <td>180.490395</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>4</td>\n",
       "      <td>0.997166</td>\n",
       "      <td>0.708827</td>\n",
       "      <td>328.963031</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>6</td>\n",
       "      <td>0.996143</td>\n",
       "      <td>0.972210</td>\n",
       "      <td>477.115556</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>0.999711</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>22.828227</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2</td>\n",
       "      <td>0.998872</td>\n",
       "      <td>0.942509</td>\n",
       "      <td>80.324496</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>6</td>\n",
       "      <td>0.999974</td>\n",
       "      <td>0.942555</td>\n",
       "      <td>256.414336</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2</td>\n",
       "      <td>0.989845</td>\n",
       "      <td>0.057610</td>\n",
       "      <td>180.490395</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>4</td>\n",
       "      <td>0.997166</td>\n",
       "      <td>0.708827</td>\n",
       "      <td>328.963031</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>6</td>\n",
       "      <td>0.996143</td>\n",
       "      <td>0.972210</td>\n",
       "      <td>477.115556</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                              epoch  train_score  test_score  time_taken\n",
       "no_of_features hidden_layers                                            \n",
       "1              1                  2     0.999711    1.000000   22.828227\n",
       "               3                  2     0.998872    0.942509   80.324496\n",
       "               3                  6     0.999974    0.942555  256.414336\n",
       "               5                  2     0.989845    0.057610  180.490395\n",
       "               5                  4     0.997166    0.708827  328.963031\n",
       "               5                  6     0.996143    0.972210  477.115556\n",
       "               1                  2     0.999711    1.000000   22.828227\n",
       "               3                  2     0.998872    0.942509   80.324496\n",
       "               3                  6     0.999974    0.942555  256.414336\n",
       "               5                  2     0.989845    0.057610  180.490395\n",
       "               5                  4     0.997166    0.708827  328.963031\n",
       "               5                  6     0.996143    0.972210  477.115556"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "past_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-06-30T21:48:38.107565Z",
     "start_time": "2017-06-30T21:48:38.091272Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>epoch</th>\n",
       "      <th>train_score</th>\n",
       "      <th>test_score</th>\n",
       "      <th>time_taken</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>no_of_features</th>\n",
       "      <th>hidden_layers</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">1</th>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>0.999711</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>22.828227</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>0.999423</td>\n",
       "      <td>0.942532</td>\n",
       "      <td>168.369416</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>4</td>\n",
       "      <td>0.994385</td>\n",
       "      <td>0.579549</td>\n",
       "      <td>328.856327</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                              epoch  train_score  test_score  time_taken\n",
       "no_of_features hidden_layers                                            \n",
       "1              1                  2     0.999711    1.000000   22.828227\n",
       "               3                  4     0.999423    0.942532  168.369416\n",
       "               5                  4     0.994385    0.579549  328.856327"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pgb = past_scores.groupby(by=['no_of_features', 'hidden_layers'])\n",
    "pgb.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-06-30T21:48:38.468823Z",
     "start_time": "2017-06-30T21:48:38.452892Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>epoch</th>\n",
       "      <th>train_score</th>\n",
       "      <th>test_score</th>\n",
       "      <th>time_taken</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>no_of_features</th>\n",
       "      <th>hidden_layers</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">1</th>\n",
       "      <th>1</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2.309401</td>\n",
       "      <td>0.000636</td>\n",
       "      <td>0.000026</td>\n",
       "      <td>101.665517</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1.788854</td>\n",
       "      <td>0.003546</td>\n",
       "      <td>0.421101</td>\n",
       "      <td>132.654831</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                 epoch  train_score  test_score  time_taken\n",
       "no_of_features hidden_layers                                               \n",
       "1              1              0.000000     0.000000    0.000000    0.000000\n",
       "               3              2.309401     0.000636    0.000026  101.665517\n",
       "               5              1.788854     0.003546    0.421101  132.654831"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pgb.std()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "_draft": {
   "nbviewer_url": "https://gist.github.com/7d1ace18a82178e15ece8fc5252fce88"
  },
  "anaconda-cloud": {},
  "gist": {
   "data": {
    "description": "Hyper parameter tuning",
    "public": false
   },
   "id": "7d1ace18a82178e15ece8fc5252fce88"
  },
  "kernelspec": {
   "display_name": "Python [conda env:p3]",
   "language": "python",
   "name": "conda-env-p3-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
