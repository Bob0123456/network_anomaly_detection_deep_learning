{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Read Data Sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-06-02T15:38:09.766634Z",
     "start_time": "2017-06-02T15:38:09.350511Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "from collections import namedtuple\n",
    "pd.set_option(\"display.max_rows\",35)\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-06-02T15:38:09.856862Z",
     "start_time": "2017-06-02T15:38:09.768216Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class dataset:\n",
    "    kdd_train_2labels = pd.read_pickle(\"dataset/kdd_train_2labels.pkl\")\n",
    "    kdd_test_2labels = pd.read_pickle(\"dataset/kdd_test_2labels.pkl\")\n",
    "    kdd_test__2labels = pd.read_pickle(\"dataset/kdd_test__2labels.pkl\")\n",
    "\n",
    "    kdd_train_5labels = pd.read_pickle(\"dataset/kdd_train_5labels.pkl\")\n",
    "    kdd_test_5labels = pd.read_pickle(\"dataset/kdd_test_5labels.pkl\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-06-02T15:38:09.863701Z",
     "start_time": "2017-06-02T15:38:09.858485Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(125973, 124)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.kdd_train_2labels.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-06-02T15:38:09.869792Z",
     "start_time": "2017-06-02T15:38:09.865478Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(22544, 124)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.kdd_test_2labels.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-06-02T15:38:10.590730Z",
     "start_time": "2017-06-02T15:38:09.871427Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(125973, 122)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn import model_selection as ms\n",
    "from sklearn import preprocessing as pp\n",
    "\n",
    "class preprocess:\n",
    "    \n",
    "    output_columns_2labels = ['is_Normal','is_Attack']\n",
    "    \n",
    "    x_input = dataset.kdd_train_2labels.drop(output_columns_2labels, axis = 1)\n",
    "    y_output = dataset.kdd_train_2labels.loc[:,output_columns_2labels]\n",
    "\n",
    "    x_test_input = dataset.kdd_test_2labels.drop(output_columns_2labels, axis = 1)\n",
    "    y_test = dataset.kdd_test_2labels.loc[:,output_columns_2labels]\n",
    "    \n",
    "    x_test__input = dataset.kdd_test__2labels.drop(output_columns_2labels, axis = 1)\n",
    "    y_test_ = dataset.kdd_test__2labels.loc[:,output_columns_2labels]\n",
    "\n",
    "    ss = pp.StandardScaler()\n",
    "\n",
    "    x_train = ss.fit_transform(x_input)\n",
    "    x_test = ss.transform(x_test_input)\n",
    "    x_test_ = ss.transform(x_test__input)\n",
    "\n",
    "    y_train = y_output.values\n",
    "    y_test = y_test.values\n",
    "    y_test_ = y_test_.values\n",
    "\n",
    "preprocess.x_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-06-02T15:38:11.661653Z",
     "start_time": "2017-06-02T15:38:10.592296Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-06-02T15:38:11.848032Z",
     "start_time": "2017-06-02T15:38:11.663384Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class network(object):\n",
    "    \n",
    "    input_dim = 122\n",
    "    classes = 2\n",
    "    hidden_encoder_dim = 122\n",
    "    hidden_layers = 1\n",
    "    latent_dim = 18\n",
    "\n",
    "    def __init__(self, classes, hidden_layers, num_of_features):\n",
    "        self.classes = classes\n",
    "        self.hidden_layers = hidden_layers\n",
    "        self.latent_dim = num_of_features\n",
    "            \n",
    "    def build_layers(self):\n",
    "        tf.reset_default_graph()\n",
    "        #learning_rate = tf.Variable(initial_value=0.001)\n",
    "\n",
    "        input_dim = self.input_dim\n",
    "        classes = self.classes\n",
    "        hidden_encoder_dim = self.hidden_encoder_dim\n",
    "        hidden_layers = self.hidden_layers\n",
    "        latent_dim = self.latent_dim\n",
    "        \n",
    "        with tf.variable_scope(\"Input\"):\n",
    "            self.x = tf.placeholder(\"float\", shape=[None, input_dim])\n",
    "            self.y_ = tf.placeholder(\"float\", shape=[None, classes])\n",
    "            self.keep_prob = tf.placeholder(\"float\")\n",
    "            self.lr = tf.placeholder(\"float\")\n",
    "        \n",
    "        with tf.variable_scope(\"Layer_Encoder\"):\n",
    "\n",
    "            hidden_encoder = tf.layers.dense(self.x, hidden_encoder_dim, activation = tf.nn.relu, kernel_regularizer=tf.nn.l2_loss)\n",
    "            hidden_encoder = tf.nn.dropout(hidden_encoder, self.keep_prob)\n",
    "            for h in range(hidden_layers - 1):\n",
    "                hidden_encoder = tf.layers.dense(hidden_encoder, latent_dim, activation = tf.nn.relu, kernel_regularizer=tf.nn.l2_loss)\n",
    "                hidden_encoder = tf.nn.dropout(hidden_encoder, self.keep_prob)\n",
    "            \n",
    "            #hidden_encoder = tf.layers.dense(self.x, latent_dim, activation = tf.nn.relu, kernel_regularizer=tf.nn.l2_loss)\n",
    "            #hidden_encoder = tf.nn.dropout(hidden_encoder, self.keep_prob)\n",
    "            \n",
    "        with tf.variable_scope(\"Layer_Dense_Softmax\"):\n",
    "            self.y = tf.layers.dense(hidden_encoder, classes, activation=tf.nn.softmax)\n",
    "            \n",
    "        with tf.variable_scope(\"Loss\"):\n",
    "            \n",
    "            loss = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(labels = self.y_, logits = self.y))\n",
    "\n",
    "            #loss = tf.clip_by_value(loss, -1e-1, 1e-1)\n",
    "            #loss = tf.where(tf.is_nan(loss), 1e-1, loss)\n",
    "            #loss = tf.where(tf.equal(loss, -1e-1), tf.random_normal(loss.shape), loss)\n",
    "            #loss = tf.where(tf.equal(loss, 1e-1), tf.random_normal(loss.shape), loss)\n",
    "            \n",
    "            self.regularized_loss = loss\n",
    "            correct_prediction = tf.equal(tf.argmax(self.y_, 1), tf.argmax(self.y, 1))\n",
    "            self.tf_accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32), name = \"Accuracy\")\n",
    "\n",
    "        with tf.variable_scope(\"Optimizer\"):\n",
    "            learning_rate=self.lr\n",
    "            optimizer = tf.train.AdamOptimizer(learning_rate)\n",
    "            gradients, variables = zip(*optimizer.compute_gradients(self.regularized_loss))\n",
    "            gradients = [\n",
    "                None if gradient is None else tf.clip_by_value(gradient, -1, 1)\n",
    "                for gradient in gradients]\n",
    "            self.train_op = optimizer.apply_gradients(zip(gradients, variables))\n",
    "            #self.train_op = optimizer.minimize(self.regularized_loss)\n",
    "            \n",
    "        # add op for merging summary\n",
    "        #self.summary_op = tf.summary.merge_all()\n",
    "        self.pred = tf.argmax(self.y, axis = 1)\n",
    "        self.actual = tf.argmax(self.y_, axis = 1)\n",
    "\n",
    "        # add Saver ops\n",
    "        self.saver = tf.train.Saver()\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-06-02T15:38:12.144333Z",
     "start_time": "2017-06-02T15:38:11.849601Z"
    },
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import collections\n",
    "import time\n",
    "\n",
    "class Train:    \n",
    "    \n",
    "    result = namedtuple(\"score\", ['epoch', 'no_of_features','hidden_layers','train_score', 'test_score', 'test_score_20', 'time_taken'])\n",
    "\n",
    "    predictions = {}\n",
    "\n",
    "    results = []\n",
    "    best_acc = 0\n",
    "    best_acc_global = 0\n",
    "    \n",
    "    def train(epochs, net, h,f, lrs):\n",
    "        batch_iterations = 200\n",
    "        train_loss = None\n",
    "        Train.best_acc = 0\n",
    "        os.makedirs(\"dataset/tf_dense_only_nsl_kdd/hidden layers_{}_features count_{}\".format(epochs,h,f),\n",
    "                    exist_ok = True)\n",
    "        with tf.Session() as sess:\n",
    "            #summary_writer_train = tf.summary.FileWriter('./logs/kdd/VAE/training', graph=sess.graph)\n",
    "            #summary_writer_valid = tf.summary.FileWriter('./logs/kdd/VAE/validation')\n",
    "\n",
    "            sess.run(tf.global_variables_initializer())\n",
    "            start_time = time.perf_counter()\n",
    "            for lr in lrs:\n",
    "                for epoch in range(1, (epochs+1)):\n",
    "                    x_train, x_valid, y_train, y_valid, = ms.train_test_split(preprocess.x_train, \n",
    "                                                                              preprocess.y_train, \n",
    "                                                                              test_size=0.1)\n",
    "                    batch_indices = np.array_split(np.arange(x_train.shape[0]), \n",
    "                                               batch_iterations)\n",
    "\n",
    "                    for i in batch_indices:\n",
    "\n",
    "                        def train_batch():\n",
    "                            nonlocal train_loss\n",
    "                            _, train_loss = sess.run([net.train_op, \n",
    "                                                               net.regularized_loss, \n",
    "                                                               ], #net.summary_op\n",
    "                                                              feed_dict={net.x: x_train[i,:], \n",
    "                                                                         net.y_: y_train[i,:], \n",
    "                                                                         net.keep_prob:0.5, net.lr:lr})\n",
    "\n",
    "                        train_batch()\n",
    "                        #summary_writer_train.add_summary(summary_str, epoch)\n",
    "                        while((train_loss > 1e4 or np.isnan(train_loss)) and epoch > 1):\n",
    "                            print(\"Step {} | Training Loss: {:.6f}\".format(epoch, train_loss))\n",
    "                            net.saver.restore(sess, \n",
    "                                              tf.train.latest_checkpoint('dataset/tf_dense_only_nsl_kdd/hidden_layers_{}_features_count_{}'\n",
    "                                                                         .format(epochs,h,f)))\n",
    "                            train_batch()\n",
    "\n",
    "\n",
    "                    valid_accuracy = sess.run(net.tf_accuracy, #net.summary_op \n",
    "                                                          feed_dict={net.x: x_valid, \n",
    "                                                                     net.y_: y_valid, \n",
    "                                                                     net.keep_prob:1, net.lr:lr})\n",
    "                    #summary_writer_valid.add_summary(summary_str, epoch)\n",
    "\n",
    "\n",
    "                    accuracy, pred_value, actual_value, y_pred = sess.run([net.tf_accuracy, \n",
    "                                                                   net.pred, \n",
    "                                                                   net.actual, net.y], \n",
    "                                                                  feed_dict={net.x: preprocess.x_test, \n",
    "                                                                             net.y_: preprocess.y_test, \n",
    "                                                                             net.keep_prob:1, net.lr:lr})\n",
    "                    \n",
    "                    accuracy_, pred_value_, actual_value_, y_pred_ = sess.run([net.tf_accuracy, \n",
    "                                                                   net.pred, \n",
    "                                                                   net.actual, net.y], \n",
    "                                                                  feed_dict={net.x: preprocess.x_test_, \n",
    "                                                                             net.y_: preprocess.y_test_, \n",
    "                                                                             net.keep_prob:1, net.lr:lr})\n",
    "\n",
    "                    print(\"Step {} | Training Loss: {:.6f} | Validation Accuracy: {:.6f}\".format(epoch, train_loss, valid_accuracy))\n",
    "                    print(\"Accuracy on Test data: {}, {}\".format(accuracy, accuracy_))\n",
    "\n",
    "                    if accuracy > Train.best_acc_global:\n",
    "                        Train.best_acc_global = accuracy\n",
    "                        Train.pred_value = pred_value\n",
    "                        Train.actual_value = actual_value\n",
    "                        Train.pred_value = pred_value_\n",
    "                        Train.actual_value = actual_value_\n",
    "                        Train.best_parameters = \"Hidden Layers:{}, Features Count:{}\".format(h, f)\n",
    "\n",
    "                    if accuracy > Train.best_acc:\n",
    "                        Train.best_acc = accuracy\n",
    "\n",
    "                        if not (np.isnan(train_loss)):\n",
    "                            net.saver.save(sess, \n",
    "                                       \"dataset/tf_dense_only_nsl_kdd/hidden_layers_{}_features_count_{}\".format(h,f),\n",
    "                                        global_step = epochs)\n",
    "                        curr_pred = pd.DataFrame({\"Attack_prob\":y_pred[:,-2], \"Normal_prob\":y_pred[:, -1], \"Prediction\":pred_value})\n",
    "                        Train.predictions.update({\"{}_{}_{}\".format(epochs*len(lrs),f,h):(curr_pred, \n",
    "                                                   Train.result(epochs*len(lrs), f, h, valid_accuracy, accuracy, accuracy_, time.perf_counter() - start_time))})\n",
    "\n",
    "                        #Train.results.append(Train.result(epochs, f, h,valid_accuracy, accuracy))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-06-02T15:45:13.719651Z",
     "start_time": "2017-06-02T15:38:12.145893Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current Layer Attributes - epochs:10 hidden layers:2 features count:4\n",
      "Step 1 | Training Loss: 0.675113 | Validation Accuracy: 0.571678\n",
      "Accuracy on Test data: 0.4728530943393707, 0.25274261832237244\n",
      "Step 2 | Training Loss: 0.669071 | Validation Accuracy: 0.696460\n",
      "Accuracy on Test data: 0.556777834892273, 0.26987341046333313\n",
      "Step 3 | Training Loss: 0.654100 | Validation Accuracy: 0.736863\n",
      "Accuracy on Test data: 0.6245564222335815, 0.3119831085205078\n",
      "Step 4 | Training Loss: 0.633772 | Validation Accuracy: 0.771234\n",
      "Accuracy on Test data: 0.6502395272254944, 0.35839661955833435\n",
      "Step 5 | Training Loss: 0.639465 | Validation Accuracy: 0.796476\n",
      "Accuracy on Test data: 0.6590667366981506, 0.37409281730651855\n",
      "Step 6 | Training Loss: 0.628130 | Validation Accuracy: 0.818860\n",
      "Accuracy on Test data: 0.6678938865661621, 0.38860759139060974\n",
      "Step 7 | Training Loss: 0.610338 | Validation Accuracy: 0.852278\n",
      "Accuracy on Test data: 0.6789833307266235, 0.4070042073726654\n",
      "Step 8 | Training Loss: 0.598027 | Validation Accuracy: 0.881013\n",
      "Accuracy on Test data: 0.6988999247550964, 0.44253164529800415\n",
      "Step 9 | Training Loss: 0.586748 | Validation Accuracy: 0.890459\n",
      "Accuracy on Test data: 0.7095014452934265, 0.4621940851211548\n",
      "Step 10 | Training Loss: 0.581584 | Validation Accuracy: 0.905779\n",
      "Accuracy on Test data: 0.7189496159553528, 0.47839662432670593\n",
      "Step 1 | Training Loss: 0.586203 | Validation Accuracy: 0.904906\n",
      "Accuracy on Test data: 0.7202360033988953, 0.48059073090553284\n",
      "Step 2 | Training Loss: 0.575535 | Validation Accuracy: 0.906969\n",
      "Accuracy on Test data: 0.7210344076156616, 0.4819409251213074\n",
      "Step 3 | Training Loss: 0.574830 | Validation Accuracy: 0.908954\n",
      "Accuracy on Test data: 0.7217885255813599, 0.4832911491394043\n",
      "Step 4 | Training Loss: 0.593113 | Validation Accuracy: 0.904509\n",
      "Accuracy on Test data: 0.7237402200698853, 0.4859071671962738\n",
      "Step 5 | Training Loss: 0.561999 | Validation Accuracy: 0.910224\n",
      "Accuracy on Test data: 0.7264460325241089, 0.4903797507286072\n",
      "Step 6 | Training Loss: 0.584492 | Validation Accuracy: 0.913399\n",
      "Accuracy on Test data: 0.728974461555481, 0.4931645691394806\n",
      "Step 7 | Training Loss: 0.577554 | Validation Accuracy: 0.914510\n",
      "Accuracy on Test data: 0.7311923503875732, 0.49628692865371704\n",
      "Step 8 | Training Loss: 0.569501 | Validation Accuracy: 0.919829\n",
      "Accuracy on Test data: 0.7331440448760986, 0.499578058719635\n",
      "Step 9 | Training Loss: 0.581319 | Validation Accuracy: 0.920622\n",
      "Accuracy on Test data: 0.7341199517250061, 0.5010126829147339\n",
      "Step 10 | Training Loss: 0.578692 | Validation Accuracy: 0.923877\n",
      "Accuracy on Test data: 0.7354950308799744, 0.5034599304199219\n",
      "Current Layer Attributes - epochs:10 hidden layers:2 features count:8\n",
      "Step 1 | Training Loss: 0.656922 | Validation Accuracy: 0.754644\n",
      "Accuracy on Test data: 0.6646558046340942, 0.38008439540863037\n",
      "Step 2 | Training Loss: 0.636472 | Validation Accuracy: 0.786395\n",
      "Accuracy on Test data: 0.6855039000511169, 0.4174683690071106\n",
      "Step 3 | Training Loss: 0.642803 | Validation Accuracy: 0.810843\n",
      "Accuracy on Test data: 0.7055535912513733, 0.4532489478588104\n",
      "Step 4 | Training Loss: 0.619767 | Validation Accuracy: 0.836323\n",
      "Accuracy on Test data: 0.7247604727745056, 0.4882700443267822\n",
      "Step 5 | Training Loss: 0.589211 | Validation Accuracy: 0.851961\n",
      "Accuracy on Test data: 0.7372249960899353, 0.5111392140388489\n",
      "Step 6 | Training Loss: 0.584423 | Validation Accuracy: 0.872519\n",
      "Accuracy on Test data: 0.7517299652099609, 0.5382278561592102\n",
      "Step 7 | Training Loss: 0.556995 | Validation Accuracy: 0.892602\n",
      "Accuracy on Test data: 0.7827803492546082, 0.5929113626480103\n",
      "Step 8 | Training Loss: 0.547341 | Validation Accuracy: 0.910541\n",
      "Accuracy on Test data: 0.787748396396637, 0.601772129535675\n",
      "Step 9 | Training Loss: 0.541497 | Validation Accuracy: 0.917050\n",
      "Accuracy on Test data: 0.7908534407615662, 0.6064978837966919\n",
      "Step 10 | Training Loss: 0.532767 | Validation Accuracy: 0.924353\n",
      "Accuracy on Test data: 0.7954666614532471, 0.6151055097579956\n",
      "Step 1 | Training Loss: 0.517866 | Validation Accuracy: 0.922131\n",
      "Accuracy on Test data: 0.795821487903595, 0.6156117916107178\n",
      "Step 2 | Training Loss: 0.515654 | Validation Accuracy: 0.921495\n",
      "Accuracy on Test data: 0.796353816986084, 0.6163713335990906\n",
      "Step 3 | Training Loss: 0.524492 | Validation Accuracy: 0.922131\n",
      "Accuracy on Test data: 0.7964425086975098, 0.6165400743484497\n",
      "Step 4 | Training Loss: 0.518813 | Validation Accuracy: 0.921654\n",
      "Accuracy on Test data: 0.7965756058692932, 0.6167932748794556\n",
      "Step 5 | Training Loss: 0.511698 | Validation Accuracy: 0.920225\n",
      "Accuracy on Test data: 0.7966199517250061, 0.6166244745254517\n",
      "Step 6 | Training Loss: 0.522945 | Validation Accuracy: 0.925226\n",
      "Accuracy on Test data: 0.7967086434364319, 0.6167088747024536\n",
      "Step 7 | Training Loss: 0.519075 | Validation Accuracy: 0.926258\n",
      "Accuracy on Test data: 0.7967973947525024, 0.6168776154518127\n",
      "Step 8 | Training Loss: 0.515614 | Validation Accuracy: 0.924909\n",
      "Accuracy on Test data: 0.7967529892921448, 0.6167088747024536\n",
      "Step 9 | Training Loss: 0.515867 | Validation Accuracy: 0.923639\n",
      "Accuracy on Test data: 0.796974778175354, 0.6170464158058167\n",
      "Step 10 | Training Loss: 0.517014 | Validation Accuracy: 0.923321\n",
      "Accuracy on Test data: 0.7972853183746338, 0.6176371574401855\n",
      "Current Layer Attributes - epochs:10 hidden layers:2 features count:16\n",
      "Step 1 | Training Loss: 0.725760 | Validation Accuracy: 0.731227\n",
      "Accuracy on Test data: 0.6496185064315796, 0.5816877484321594\n",
      "Step 2 | Training Loss: 0.672090 | Validation Accuracy: 0.816876\n",
      "Accuracy on Test data: 0.7047995328903198, 0.6197468638420105\n",
      "Step 3 | Training Loss: 0.639123 | Validation Accuracy: 0.866407\n",
      "Accuracy on Test data: 0.7542583346366882, 0.6298733949661255\n",
      "Step 4 | Training Loss: 0.591235 | Validation Accuracy: 0.891253\n",
      "Accuracy on Test data: 0.8254081010818481, 0.6756961941719055\n",
      "Step 5 | Training Loss: 0.563008 | Validation Accuracy: 0.907049\n",
      "Accuracy on Test data: 0.8248314261436462, 0.6728270053863525\n",
      "Step 6 | Training Loss: 0.559079 | Validation Accuracy: 0.907843\n",
      "Accuracy on Test data: 0.8273598551750183, 0.6772995591163635\n",
      "Step 7 | Training Loss: 0.523739 | Validation Accuracy: 0.905461\n",
      "Accuracy on Test data: 0.8305979371070862, 0.6830379962921143\n",
      "Step 8 | Training Loss: 0.514554 | Validation Accuracy: 0.909113\n",
      "Accuracy on Test data: 0.83525550365448, 0.6908016800880432\n",
      "Step 9 | Training Loss: 0.502082 | Validation Accuracy: 0.929830\n",
      "Accuracy on Test data: 0.8387153744697571, 0.6971307992935181\n",
      "Step 10 | Training Loss: 0.486439 | Validation Accuracy: 0.940943\n",
      "Accuracy on Test data: 0.8420866131782532, 0.703291118144989\n",
      "Step 1 | Training Loss: 0.464925 | Validation Accuracy: 0.945864\n",
      "Accuracy on Test data: 0.8423970937728882, 0.703713059425354\n",
      "Step 2 | Training Loss: 0.475893 | Validation Accuracy: 0.941975\n",
      "Accuracy on Test data: 0.8431068062782288, 0.7050632834434509\n",
      "Step 3 | Training Loss: 0.488199 | Validation Accuracy: 0.945150\n",
      "Accuracy on Test data: 0.843328595161438, 0.7054852247238159\n",
      "Step 4 | Training Loss: 0.488531 | Validation Accuracy: 0.947293\n",
      "Accuracy on Test data: 0.843328595161438, 0.7054852247238159\n",
      "Step 5 | Training Loss: 0.479951 | Validation Accuracy: 0.947214\n",
      "Accuracy on Test data: 0.8434173464775085, 0.7056540250778198\n",
      "Step 6 | Training Loss: 0.465787 | Validation Accuracy: 0.946341\n",
      "Accuracy on Test data: 0.843328595161438, 0.7054852247238159\n",
      "Step 7 | Training Loss: 0.462430 | Validation Accuracy: 0.949913\n",
      "Accuracy on Test data: 0.8433729410171509, 0.7055696249008179\n",
      "Step 8 | Training Loss: 0.470256 | Validation Accuracy: 0.943562\n",
      "Accuracy on Test data: 0.8436391353607178, 0.7060759663581848\n",
      "Step 9 | Training Loss: 0.463318 | Validation Accuracy: 0.945547\n",
      "Accuracy on Test data: 0.8436391353607178, 0.7060759663581848\n",
      "Step 10 | Training Loss: 0.472304 | Validation Accuracy: 0.946817\n",
      "Accuracy on Test data: 0.8433729410171509, 0.7055696249008179\n",
      "Current Layer Attributes - epochs:10 hidden layers:2 features count:32\n",
      "Step 1 | Training Loss: 0.704827 | Validation Accuracy: 0.667646\n",
      "Accuracy on Test data: 0.5225780606269836, 0.2828691899776459\n",
      "Step 2 | Training Loss: 0.640877 | Validation Accuracy: 0.719956\n",
      "Accuracy on Test data: 0.5445795059204102, 0.31873416900634766\n",
      "Step 3 | Training Loss: 0.611325 | Validation Accuracy: 0.817431\n",
      "Accuracy on Test data: 0.6593772172927856, 0.3734177350997925\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 4 | Training Loss: 0.554127 | Validation Accuracy: 0.890538\n",
      "Accuracy on Test data: 0.6981902122497559, 0.4398312270641327\n",
      "Step 5 | Training Loss: 0.528984 | Validation Accuracy: 0.936657\n",
      "Accuracy on Test data: 0.755189836025238, 0.5412658452987671\n",
      "Step 6 | Training Loss: 0.520131 | Validation Accuracy: 0.954120\n",
      "Accuracy on Test data: 0.7984386086463928, 0.6217721700668335\n",
      "Step 7 | Training Loss: 0.506874 | Validation Accuracy: 0.959121\n",
      "Accuracy on Test data: 0.8111249208450317, 0.6450632810592651\n",
      "Step 8 | Training Loss: 0.485590 | Validation Accuracy: 0.958644\n",
      "Accuracy on Test data: 0.8140525221824646, 0.650632917881012\n",
      "Step 9 | Training Loss: 0.445833 | Validation Accuracy: 0.956501\n",
      "Accuracy on Test data: 0.8163147568702698, 0.655021071434021\n",
      "Step 10 | Training Loss: 0.446417 | Validation Accuracy: 0.959041\n",
      "Accuracy on Test data: 0.8166696429252625, 0.6555274128913879\n",
      "Step 1 | Training Loss: 0.444995 | Validation Accuracy: 0.961978\n",
      "Accuracy on Test data: 0.8167583346366882, 0.6556118130683899\n",
      "Step 2 | Training Loss: 0.442560 | Validation Accuracy: 0.959994\n",
      "Accuracy on Test data: 0.816847026348114, 0.6556962132453918\n",
      "Step 3 | Training Loss: 0.444860 | Validation Accuracy: 0.960073\n",
      "Accuracy on Test data: 0.8167583346366882, 0.6555274128913879\n",
      "Step 4 | Training Loss: 0.445519 | Validation Accuracy: 0.958485\n",
      "Accuracy on Test data: 0.8167139887809753, 0.655443012714386\n",
      "Step 5 | Training Loss: 0.445260 | Validation Accuracy: 0.960629\n",
      "Accuracy on Test data: 0.8167583346366882, 0.6555274128913879\n",
      "Step 6 | Training Loss: 0.440951 | Validation Accuracy: 0.959121\n",
      "Accuracy on Test data: 0.8167583346366882, 0.6555274128913879\n",
      "Step 7 | Training Loss: 0.435251 | Validation Accuracy: 0.958485\n",
      "Accuracy on Test data: 0.8169357776641846, 0.655864953994751\n",
      "Step 8 | Training Loss: 0.431653 | Validation Accuracy: 0.959200\n",
      "Accuracy on Test data: 0.8170244693756104, 0.6559493541717529\n",
      "Step 9 | Training Loss: 0.434701 | Validation Accuracy: 0.958644\n",
      "Accuracy on Test data: 0.8172462582588196, 0.656286895275116\n",
      "Step 10 | Training Loss: 0.429217 | Validation Accuracy: 0.961581\n",
      "Accuracy on Test data: 0.817379355430603, 0.6565400958061218\n",
      "Current Layer Attributes - epochs:10 hidden layers:4 features count:4\n",
      "Step 1 | Training Loss: 0.695872 | Validation Accuracy: 0.536672\n",
      "Accuracy on Test data: 0.43075764179229736, 0.18160337209701538\n",
      "Step 2 | Training Loss: 0.690701 | Validation Accuracy: 0.529925\n",
      "Accuracy on Test data: 0.43075764179229736, 0.18160337209701538\n",
      "Step 3 | Training Loss: 0.688115 | Validation Accuracy: 0.536117\n",
      "Accuracy on Test data: 0.43075764179229736, 0.18160337209701538\n",
      "Step 4 | Training Loss: 0.687240 | Validation Accuracy: 0.534053\n",
      "Accuracy on Test data: 0.43075764179229736, 0.18160337209701538\n",
      "Step 5 | Training Loss: 0.681955 | Validation Accuracy: 0.531751\n",
      "Accuracy on Test data: 0.43075764179229736, 0.18160337209701538\n",
      "Step 6 | Training Loss: 0.683212 | Validation Accuracy: 0.531672\n",
      "Accuracy on Test data: 0.43075764179229736, 0.18160337209701538\n",
      "Step 7 | Training Loss: 0.671850 | Validation Accuracy: 0.541911\n",
      "Accuracy on Test data: 0.43075764179229736, 0.18160337209701538\n",
      "Step 8 | Training Loss: 0.669476 | Validation Accuracy: 0.529687\n",
      "Accuracy on Test data: 0.43075764179229736, 0.18160337209701538\n",
      "Step 9 | Training Loss: 0.673183 | Validation Accuracy: 0.534212\n",
      "Accuracy on Test data: 0.43075764179229736, 0.18160337209701538\n",
      "Step 10 | Training Loss: 0.667144 | Validation Accuracy: 0.535641\n",
      "Accuracy on Test data: 0.43075764179229736, 0.18160337209701538\n",
      "Step 1 | Training Loss: 0.663143 | Validation Accuracy: 0.537387\n",
      "Accuracy on Test data: 0.43075764179229736, 0.18160337209701538\n",
      "Step 2 | Training Loss: 0.667076 | Validation Accuracy: 0.538498\n",
      "Accuracy on Test data: 0.43075764179229736, 0.18160337209701538\n",
      "Step 3 | Training Loss: 0.666234 | Validation Accuracy: 0.533656\n",
      "Accuracy on Test data: 0.43075764179229736, 0.18160337209701538\n",
      "Step 4 | Training Loss: 0.661703 | Validation Accuracy: 0.531037\n",
      "Accuracy on Test data: 0.43075764179229736, 0.18160337209701538\n",
      "Step 5 | Training Loss: 0.666666 | Validation Accuracy: 0.533894\n",
      "Accuracy on Test data: 0.43075764179229736, 0.18160337209701538\n",
      "Step 6 | Training Loss: 0.662821 | Validation Accuracy: 0.533180\n",
      "Accuracy on Test data: 0.43075764179229736, 0.18160337209701538\n",
      "Step 7 | Training Loss: 0.664302 | Validation Accuracy: 0.536911\n",
      "Accuracy on Test data: 0.43075764179229736, 0.18160337209701538\n",
      "Step 8 | Training Loss: 0.669814 | Validation Accuracy: 0.531195\n",
      "Accuracy on Test data: 0.43075764179229736, 0.18160337209701538\n",
      "Step 9 | Training Loss: 0.669528 | Validation Accuracy: 0.536911\n",
      "Accuracy on Test data: 0.43075764179229736, 0.18160337209701538\n",
      "Step 10 | Training Loss: 0.668235 | Validation Accuracy: 0.529449\n",
      "Accuracy on Test data: 0.43075764179229736, 0.18160337209701538\n",
      "Current Layer Attributes - epochs:10 hidden layers:4 features count:8\n",
      "Step 1 | Training Loss: 0.703235 | Validation Accuracy: 0.565566\n",
      "Accuracy on Test data: 0.7154009938240051, 0.6362869143486023\n",
      "Step 2 | Training Loss: 0.683884 | Validation Accuracy: 0.631132\n",
      "Accuracy on Test data: 0.7458747625350952, 0.6523206830024719\n",
      "Step 3 | Training Loss: 0.693110 | Validation Accuracy: 0.764010\n",
      "Accuracy on Test data: 0.7950674295425415, 0.6735864877700806\n",
      "Step 4 | Training Loss: 0.686302 | Validation Accuracy: 0.849579\n",
      "Accuracy on Test data: 0.8181334137916565, 0.6794092655181885\n",
      "Step 5 | Training Loss: 0.685476 | Validation Accuracy: 0.876091\n",
      "Accuracy on Test data: 0.827182412147522, 0.6870886087417603\n",
      "Step 6 | Training Loss: 0.675708 | Validation Accuracy: 0.883474\n",
      "Accuracy on Test data: 0.8258960247039795, 0.6816877722740173\n",
      "Step 7 | Training Loss: 0.661641 | Validation Accuracy: 0.905858\n",
      "Accuracy on Test data: 0.8357434272766113, 0.6991561055183411\n",
      "Step 8 | Training Loss: 0.661338 | Validation Accuracy: 0.906096\n",
      "Accuracy on Test data: 0.8374290466308594, 0.700928270816803\n",
      "Step 9 | Training Loss: 0.663363 | Validation Accuracy: 0.911494\n",
      "Accuracy on Test data: 0.8369854688644409, 0.6998312473297119\n",
      "Step 10 | Training Loss: 0.655557 | Validation Accuracy: 0.918797\n",
      "Accuracy on Test data: 0.8406671285629272, 0.7057384252548218\n",
      "Step 1 | Training Loss: 0.654715 | Validation Accuracy: 0.923321\n",
      "Accuracy on Test data: 0.8407114744186401, 0.705822765827179\n",
      "Step 2 | Training Loss: 0.662883 | Validation Accuracy: 0.919511\n",
      "Accuracy on Test data: 0.8411107063293457, 0.7064979076385498\n",
      "Step 3 | Training Loss: 0.660845 | Validation Accuracy: 0.919987\n",
      "Accuracy on Test data: 0.841288149356842, 0.7064979076385498\n",
      "Step 4 | Training Loss: 0.654492 | Validation Accuracy: 0.922924\n",
      "Accuracy on Test data: 0.8414655923843384, 0.7064979076385498\n",
      "Step 5 | Training Loss: 0.655409 | Validation Accuracy: 0.923718\n",
      "Accuracy on Test data: 0.8419978618621826, 0.7073417901992798\n",
      "Step 6 | Training Loss: 0.654446 | Validation Accuracy: 0.922924\n",
      "Accuracy on Test data: 0.8427519798278809, 0.7086919546127319\n",
      "Step 7 | Training Loss: 0.653126 | Validation Accuracy: 0.921734\n",
      "Accuracy on Test data: 0.8427519798278809, 0.7086076140403748\n",
      "Step 8 | Training Loss: 0.650205 | Validation Accuracy: 0.922289\n",
      "Accuracy on Test data: 0.8431068062782288, 0.7091138958930969\n",
      "Step 9 | Training Loss: 0.646290 | Validation Accuracy: 0.920622\n",
      "Accuracy on Test data: 0.8430624604225159, 0.7090295553207397\n",
      "Step 10 | Training Loss: 0.648323 | Validation Accuracy: 0.922686\n",
      "Accuracy on Test data: 0.8432399034500122, 0.7092826962471008\n",
      "Current Layer Attributes - epochs:10 hidden layers:4 features count:16\n",
      "Step 1 | Training Loss: 0.721908 | Validation Accuracy: 0.452135\n",
      "Accuracy on Test data: 0.5392122268676758, 0.7597468495368958\n",
      "Step 2 | Training Loss: 0.727403 | Validation Accuracy: 0.492935\n",
      "Accuracy on Test data: 0.5605482459068298, 0.7641350030899048\n",
      "Step 3 | Training Loss: 0.706947 | Validation Accuracy: 0.741149\n",
      "Accuracy on Test data: 0.8174680471420288, 0.750886082649231\n",
      "Step 4 | Training Loss: 0.697145 | Validation Accuracy: 0.775441\n",
      "Accuracy on Test data: 0.8301100134849548, 0.7497890591621399\n",
      "Step 5 | Training Loss: 0.695600 | Validation Accuracy: 0.813701\n",
      "Accuracy on Test data: 0.8345014452934265, 0.7384809851646423\n",
      "Step 6 | Training Loss: 0.684785 | Validation Accuracy: 0.871011\n",
      "Accuracy on Test data: 0.8310858607292175, 0.701350212097168\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 7 | Training Loss: 0.682439 | Validation Accuracy: 0.903636\n",
      "Accuracy on Test data: 0.8287349343299866, 0.6886075735092163\n",
      "Step 8 | Training Loss: 0.684875 | Validation Accuracy: 0.913081\n",
      "Accuracy on Test data: 0.8213715553283691, 0.6740928292274475\n",
      "Step 9 | Training Loss: 0.666925 | Validation Accuracy: 0.923401\n",
      "Accuracy on Test data: 0.8195084929466248, 0.6699578166007996\n",
      "Step 10 | Training Loss: 0.673148 | Validation Accuracy: 0.928004\n",
      "Accuracy on Test data: 0.8187987804412842, 0.6681012511253357\n",
      "Step 1 | Training Loss: 0.656163 | Validation Accuracy: 0.927052\n",
      "Accuracy on Test data: 0.8188875317573547, 0.6682700514793396\n",
      "Step 2 | Training Loss: 0.666454 | Validation Accuracy: 0.923956\n",
      "Accuracy on Test data: 0.8189762234687805, 0.6680168509483337\n",
      "Step 3 | Training Loss: 0.679674 | Validation Accuracy: 0.922527\n",
      "Accuracy on Test data: 0.8188875317573547, 0.6675949096679688\n",
      "Step 4 | Training Loss: 0.661782 | Validation Accuracy: 0.925067\n",
      "Accuracy on Test data: 0.8180890679359436, 0.6660759449005127\n",
      "Step 5 | Training Loss: 0.687109 | Validation Accuracy: 0.926734\n",
      "Accuracy on Test data: 0.8171132206916809, 0.6640506386756897\n",
      "Step 6 | Training Loss: 0.657219 | Validation Accuracy: 0.929513\n",
      "Accuracy on Test data: 0.8170244693756104, 0.6638818383216858\n",
      "Step 7 | Training Loss: 0.664554 | Validation Accuracy: 0.928878\n",
      "Accuracy on Test data: 0.8168914318084717, 0.6636286973953247\n",
      "Step 8 | Training Loss: 0.650445 | Validation Accuracy: 0.927131\n",
      "Accuracy on Test data: 0.8170244693756104, 0.6637974977493286\n",
      "Step 9 | Training Loss: 0.651403 | Validation Accuracy: 0.925703\n",
      "Accuracy on Test data: 0.8170688152313232, 0.6638818383216858\n",
      "Step 10 | Training Loss: 0.667719 | Validation Accuracy: 0.928878\n",
      "Accuracy on Test data: 0.8169357776641846, 0.6635442972183228\n",
      "Current Layer Attributes - epochs:10 hidden layers:4 features count:32\n",
      "Step 1 | Training Loss: 0.706165 | Validation Accuracy: 0.674075\n",
      "Accuracy on Test data: 0.6759669780731201, 0.46987342834472656\n",
      "Step 2 | Training Loss: 0.704178 | Validation Accuracy: 0.718765\n",
      "Accuracy on Test data: 0.6943311095237732, 0.4911392331123352\n",
      "Step 3 | Training Loss: 0.684303 | Validation Accuracy: 0.807985\n",
      "Accuracy on Test data: 0.7354506850242615, 0.547932505607605\n",
      "Step 4 | Training Loss: 0.653213 | Validation Accuracy: 0.847436\n",
      "Accuracy on Test data: 0.7501330971717834, 0.5652320384979248\n",
      "Step 5 | Training Loss: 0.675744 | Validation Accuracy: 0.879346\n",
      "Accuracy on Test data: 0.7511976361274719, 0.5569620132446289\n",
      "Step 6 | Training Loss: 0.657759 | Validation Accuracy: 0.905620\n",
      "Accuracy on Test data: 0.7607789039611816, 0.5664135217666626\n",
      "Step 7 | Training Loss: 0.625282 | Validation Accuracy: 0.913161\n",
      "Accuracy on Test data: 0.7642388343811035, 0.5673417448997498\n",
      "Step 8 | Training Loss: 0.624927 | Validation Accuracy: 0.922765\n",
      "Accuracy on Test data: 0.7674769163131714, 0.5715611577033997\n",
      "Step 9 | Training Loss: 0.598395 | Validation Accuracy: 0.922686\n",
      "Accuracy on Test data: 0.7714247703552246, 0.5769620537757874\n",
      "Step 10 | Training Loss: 0.606065 | Validation Accuracy: 0.929513\n",
      "Accuracy on Test data: 0.7787438035011292, 0.5862447023391724\n",
      "Step 1 | Training Loss: 0.602433 | Validation Accuracy: 0.930306\n",
      "Accuracy on Test data: 0.7791873812675476, 0.5870885848999023\n",
      "Step 2 | Training Loss: 0.576326 | Validation Accuracy: 0.930386\n",
      "Accuracy on Test data: 0.7794091701507568, 0.5874261856079102\n",
      "Step 3 | Training Loss: 0.587835 | Validation Accuracy: 0.930465\n",
      "Accuracy on Test data: 0.7798970937728882, 0.5881012678146362\n",
      "Step 4 | Training Loss: 0.586380 | Validation Accuracy: 0.925226\n",
      "Accuracy on Test data: 0.7802075743675232, 0.5886920094490051\n",
      "Step 5 | Training Loss: 0.592169 | Validation Accuracy: 0.928719\n",
      "Accuracy on Test data: 0.7802963256835938, 0.5887763500213623\n",
      "Step 6 | Training Loss: 0.557483 | Validation Accuracy: 0.931656\n",
      "Accuracy on Test data: 0.7806511521339417, 0.5892826914787292\n",
      "Step 7 | Training Loss: 0.580438 | Validation Accuracy: 0.933085\n",
      "Accuracy on Test data: 0.7813608646392822, 0.5905485153198242\n",
      "Step 8 | Training Loss: 0.596843 | Validation Accuracy: 0.928639\n",
      "Accuracy on Test data: 0.7815826535224915, 0.5908860564231873\n",
      "Step 9 | Training Loss: 0.602641 | Validation Accuracy: 0.930545\n",
      "Accuracy on Test data: 0.7818044424057007, 0.5913923978805542\n",
      "Step 10 | Training Loss: 0.567454 | Validation Accuracy: 0.928004\n",
      "Accuracy on Test data: 0.7821149826049805, 0.5919831395149231\n",
      "Current Layer Attributes - epochs:10 hidden layers:6 features count:4\n",
      "Step 1 | Training Loss: 0.695100 | Validation Accuracy: 0.543817\n",
      "Accuracy on Test data: 0.43306422233581543, 0.1849789023399353\n",
      "Step 2 | Training Loss: 0.693804 | Validation Accuracy: 0.538895\n",
      "Accuracy on Test data: 0.4313342869281769, 0.18185654282569885\n",
      "Step 3 | Training Loss: 0.690754 | Validation Accuracy: 0.536752\n",
      "Accuracy on Test data: 0.43084633350372314, 0.1817721575498581\n",
      "Step 4 | Training Loss: 0.689559 | Validation Accuracy: 0.532624\n",
      "Accuracy on Test data: 0.43075764179229736, 0.18160337209701538\n",
      "Step 5 | Training Loss: 0.691845 | Validation Accuracy: 0.530878\n",
      "Accuracy on Test data: 0.43075764179229736, 0.18160337209701538\n",
      "Step 6 | Training Loss: 0.696861 | Validation Accuracy: 0.538816\n",
      "Accuracy on Test data: 0.43075764179229736, 0.18160337209701538\n",
      "Step 7 | Training Loss: 0.692065 | Validation Accuracy: 0.530799\n",
      "Accuracy on Test data: 0.43075764179229736, 0.18160337209701538\n",
      "Step 8 | Training Loss: 0.686422 | Validation Accuracy: 0.534767\n",
      "Accuracy on Test data: 0.43075764179229736, 0.18160337209701538\n",
      "Step 9 | Training Loss: 0.692317 | Validation Accuracy: 0.536514\n",
      "Accuracy on Test data: 0.43075764179229736, 0.18160337209701538\n",
      "Step 10 | Training Loss: 0.688284 | Validation Accuracy: 0.535085\n",
      "Accuracy on Test data: 0.43075764179229736, 0.18160337209701538\n",
      "Step 1 | Training Loss: 0.688516 | Validation Accuracy: 0.531275\n",
      "Accuracy on Test data: 0.43075764179229736, 0.18160337209701538\n",
      "Step 2 | Training Loss: 0.691511 | Validation Accuracy: 0.531354\n",
      "Accuracy on Test data: 0.43075764179229736, 0.18160337209701538\n",
      "Step 3 | Training Loss: 0.689770 | Validation Accuracy: 0.537943\n",
      "Accuracy on Test data: 0.43075764179229736, 0.18160337209701538\n",
      "Step 4 | Training Loss: 0.686021 | Validation Accuracy: 0.537863\n",
      "Accuracy on Test data: 0.43075764179229736, 0.18160337209701538\n",
      "Step 5 | Training Loss: 0.685050 | Validation Accuracy: 0.529290\n",
      "Accuracy on Test data: 0.43075764179229736, 0.18160337209701538\n",
      "Step 6 | Training Loss: 0.691019 | Validation Accuracy: 0.546436\n",
      "Accuracy on Test data: 0.43075764179229736, 0.18160337209701538\n",
      "Step 7 | Training Loss: 0.690447 | Validation Accuracy: 0.531751\n",
      "Accuracy on Test data: 0.43075764179229736, 0.18160337209701538\n",
      "Step 8 | Training Loss: 0.689280 | Validation Accuracy: 0.540800\n",
      "Accuracy on Test data: 0.43075764179229736, 0.18160337209701538\n",
      "Step 9 | Training Loss: 0.690850 | Validation Accuracy: 0.541118\n",
      "Accuracy on Test data: 0.43075764179229736, 0.18160337209701538\n",
      "Step 10 | Training Loss: 0.689340 | Validation Accuracy: 0.538022\n",
      "Accuracy on Test data: 0.43075764179229736, 0.18160337209701538\n",
      "Current Layer Attributes - epochs:10 hidden layers:6 features count:8\n",
      "Step 1 | Training Loss: 0.728373 | Validation Accuracy: 0.537704\n",
      "Accuracy on Test data: 0.43173348903656006, 0.18345992267131805\n",
      "Step 2 | Training Loss: 0.696725 | Validation Accuracy: 0.533497\n",
      "Accuracy on Test data: 0.43075764179229736, 0.18160337209701538\n",
      "Step 3 | Training Loss: 0.702357 | Validation Accuracy: 0.532069\n",
      "Accuracy on Test data: 0.43075764179229736, 0.18160337209701538\n",
      "Step 4 | Training Loss: 0.714518 | Validation Accuracy: 0.534688\n",
      "Accuracy on Test data: 0.43075764179229736, 0.18160337209701538\n",
      "Step 5 | Training Loss: 0.679714 | Validation Accuracy: 0.537704\n",
      "Accuracy on Test data: 0.43075764179229736, 0.18160337209701538\n",
      "Step 6 | Training Loss: 0.698936 | Validation Accuracy: 0.531116\n",
      "Accuracy on Test data: 0.43075764179229736, 0.18160337209701538\n",
      "Step 7 | Training Loss: 0.695840 | Validation Accuracy: 0.537784\n",
      "Accuracy on Test data: 0.43075764179229736, 0.18160337209701538\n",
      "Step 8 | Training Loss: 0.686114 | Validation Accuracy: 0.535641\n",
      "Accuracy on Test data: 0.43075764179229736, 0.18160337209701538\n",
      "Step 9 | Training Loss: 0.689381 | Validation Accuracy: 0.536831\n",
      "Accuracy on Test data: 0.43075764179229736, 0.18160337209701538\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 10 | Training Loss: 0.711842 | Validation Accuracy: 0.535006\n",
      "Accuracy on Test data: 0.43075764179229736, 0.18160337209701538\n",
      "Step 1 | Training Loss: 0.689808 | Validation Accuracy: 0.536593\n",
      "Accuracy on Test data: 0.43075764179229736, 0.18160337209701538\n",
      "Step 2 | Training Loss: 0.677702 | Validation Accuracy: 0.538022\n",
      "Accuracy on Test data: 0.43075764179229736, 0.18160337209701538\n",
      "Step 3 | Training Loss: 0.693951 | Validation Accuracy: 0.538974\n",
      "Accuracy on Test data: 0.43075764179229736, 0.18160337209701538\n",
      "Step 4 | Training Loss: 0.686935 | Validation Accuracy: 0.535641\n",
      "Accuracy on Test data: 0.43075764179229736, 0.18160337209701538\n",
      "Step 5 | Training Loss: 0.690458 | Validation Accuracy: 0.533974\n",
      "Accuracy on Test data: 0.43075764179229736, 0.18160337209701538\n",
      "Step 6 | Training Loss: 0.679016 | Validation Accuracy: 0.538181\n",
      "Accuracy on Test data: 0.43075764179229736, 0.18160337209701538\n",
      "Step 7 | Training Loss: 0.701842 | Validation Accuracy: 0.534529\n",
      "Accuracy on Test data: 0.43075764179229736, 0.18160337209701538\n",
      "Step 8 | Training Loss: 0.690186 | Validation Accuracy: 0.525480\n",
      "Accuracy on Test data: 0.43075764179229736, 0.18160337209701538\n",
      "Step 9 | Training Loss: 0.691553 | Validation Accuracy: 0.534688\n",
      "Accuracy on Test data: 0.43075764179229736, 0.18160337209701538\n",
      "Step 10 | Training Loss: 0.683665 | Validation Accuracy: 0.523178\n",
      "Accuracy on Test data: 0.43075764179229736, 0.18160337209701538\n",
      "Current Layer Attributes - epochs:10 hidden layers:6 features count:16\n",
      "Step 1 | Training Loss: 0.720316 | Validation Accuracy: 0.639705\n",
      "Accuracy on Test data: 0.6682487726211548, 0.46506330370903015\n",
      "Step 2 | Training Loss: 0.690455 | Validation Accuracy: 0.644626\n",
      "Accuracy on Test data: 0.6761887669563293, 0.48033756017684937\n",
      "Step 3 | Training Loss: 0.703020 | Validation Accuracy: 0.646214\n",
      "Accuracy on Test data: 0.6769428849220276, 0.4824472665786743\n",
      "Step 4 | Training Loss: 0.696385 | Validation Accuracy: 0.655580\n",
      "Accuracy on Test data: 0.6824432015419006, 0.4915611743927002\n",
      "Step 5 | Training Loss: 0.683551 | Validation Accuracy: 0.670583\n",
      "Accuracy on Test data: 0.6870120763778687, 0.49873417615890503\n",
      "Step 6 | Training Loss: 0.703130 | Validation Accuracy: 0.695110\n",
      "Accuracy on Test data: 0.6930003762245178, 0.5092827081680298\n",
      "Step 7 | Training Loss: 0.694504 | Validation Accuracy: 0.703048\n",
      "Accuracy on Test data: 0.7043559551239014, 0.5275949239730835\n",
      "Step 8 | Training Loss: 0.704166 | Validation Accuracy: 0.702651\n",
      "Accuracy on Test data: 0.7157114744186401, 0.547004222869873\n",
      "Step 9 | Training Loss: 0.678331 | Validation Accuracy: 0.721226\n",
      "Accuracy on Test data: 0.7244499921798706, 0.5616877675056458\n",
      "Step 10 | Training Loss: 0.681723 | Validation Accuracy: 0.723924\n",
      "Accuracy on Test data: 0.7362047433853149, 0.5825316309928894\n",
      "Step 1 | Training Loss: 0.690398 | Validation Accuracy: 0.718447\n",
      "Accuracy on Test data: 0.7369144558906555, 0.5836287140846252\n",
      "Step 2 | Training Loss: 0.693892 | Validation Accuracy: 0.722099\n",
      "Accuracy on Test data: 0.7378016114234924, 0.5852320790290833\n",
      "Step 3 | Training Loss: 0.679697 | Validation Accuracy: 0.728131\n",
      "Accuracy on Test data: 0.7384226322174072, 0.5863291025161743\n",
      "Step 4 | Training Loss: 0.693283 | Validation Accuracy: 0.733370\n",
      "Accuracy on Test data: 0.7395759224891663, 0.5881856679916382\n",
      "Step 5 | Training Loss: 0.706997 | Validation Accuracy: 0.731307\n",
      "Accuracy on Test data: 0.7403743863105774, 0.5896202325820923\n",
      "Step 6 | Training Loss: 0.682522 | Validation Accuracy: 0.738847\n",
      "Accuracy on Test data: 0.7416607737541199, 0.592067539691925\n",
      "Step 7 | Training Loss: 0.691784 | Validation Accuracy: 0.742340\n",
      "Accuracy on Test data: 0.7428140640258789, 0.5941771864891052\n",
      "Step 8 | Training Loss: 0.680940 | Validation Accuracy: 0.742023\n",
      "Accuracy on Test data: 0.7438786625862122, 0.595358669757843\n",
      "Step 9 | Training Loss: 0.682698 | Validation Accuracy: 0.749643\n",
      "Accuracy on Test data: 0.7454755306243896, 0.596962034702301\n",
      "Step 10 | Training Loss: 0.680305 | Validation Accuracy: 0.753612\n",
      "Accuracy on Test data: 0.748846709728241, 0.5988185405731201\n",
      "Current Layer Attributes - epochs:10 hidden layers:6 features count:32\n",
      "Step 1 | Training Loss: 0.723357 | Validation Accuracy: 0.455707\n",
      "Accuracy on Test data: 0.5691980123519897, 0.8183122277259827\n",
      "Step 2 | Training Loss: 0.711862 | Validation Accuracy: 0.466582\n",
      "Accuracy on Test data: 0.5692423582077026, 0.8183966279029846\n",
      "Step 3 | Training Loss: 0.692198 | Validation Accuracy: 0.479441\n",
      "Accuracy on Test data: 0.5789567232131958, 0.8180590867996216\n",
      "Step 4 | Training Loss: 0.687021 | Validation Accuracy: 0.806160\n",
      "Accuracy on Test data: 0.854817271232605, 0.8244725465774536\n",
      "Step 5 | Training Loss: 0.703553 | Validation Accuracy: 0.844182\n",
      "Accuracy on Test data: 0.8619588613510132, 0.7945147752761841\n",
      "Step 6 | Training Loss: 0.676383 | Validation Accuracy: 0.886093\n",
      "Accuracy on Test data: 0.8543736934661865, 0.752911388874054\n",
      "Step 7 | Training Loss: 0.671840 | Validation Accuracy: 0.903874\n",
      "Accuracy on Test data: 0.8522001504898071, 0.7449789047241211\n",
      "Step 8 | Training Loss: 0.684669 | Validation Accuracy: 0.913081\n",
      "Accuracy on Test data: 0.856813371181488, 0.7470042109489441\n",
      "Step 9 | Training Loss: 0.653928 | Validation Accuracy: 0.920067\n",
      "Accuracy on Test data: 0.8619144558906555, 0.7518987059593201\n",
      "Step 10 | Training Loss: 0.640593 | Validation Accuracy: 0.921892\n",
      "Accuracy on Test data: 0.8634226322174072, 0.754092812538147\n",
      "Step 1 | Training Loss: 0.644402 | Validation Accuracy: 0.916892\n",
      "Accuracy on Test data: 0.8634226322174072, 0.754092812538147\n",
      "Step 2 | Training Loss: 0.660702 | Validation Accuracy: 0.924750\n",
      "Accuracy on Test data: 0.8636444211006165, 0.75443035364151\n",
      "Step 3 | Training Loss: 0.642687 | Validation Accuracy: 0.918162\n",
      "Accuracy on Test data: 0.8637775182723999, 0.7546835541725159\n",
      "Step 4 | Training Loss: 0.646015 | Validation Accuracy: 0.919432\n",
      "Accuracy on Test data: 0.8639549612998962, 0.754936695098877\n",
      "Step 5 | Training Loss: 0.644929 | Validation Accuracy: 0.923162\n",
      "Accuracy on Test data: 0.8641323447227478, 0.75527423620224\n",
      "Step 6 | Training Loss: 0.647936 | Validation Accuracy: 0.920305\n",
      "Accuracy on Test data: 0.8642210960388184, 0.7554430365562439\n",
      "Step 7 | Training Loss: 0.651664 | Validation Accuracy: 0.919035\n",
      "Accuracy on Test data: 0.8641323447227478, 0.7553586363792419\n",
      "Step 8 | Training Loss: 0.640933 | Validation Accuracy: 0.918241\n",
      "Accuracy on Test data: 0.8639105558395386, 0.754936695098877\n",
      "Step 9 | Training Loss: 0.633158 | Validation Accuracy: 0.925226\n",
      "Accuracy on Test data: 0.8641767501831055, 0.7554430365562439\n",
      "Step 10 | Training Loss: 0.649491 | Validation Accuracy: 0.919670\n",
      "Accuracy on Test data: 0.8639549612998962, 0.7550210952758789\n"
     ]
    }
   ],
   "source": [
    "import itertools\n",
    "class Hyperparameters:\n",
    "#    features_arr = [2, 4, 8, 16, 32, 64, 128, 256]\n",
    "#    hidden_layers_arr = [2, 4, 6, 10]\n",
    "    features_arr = [4, 8, 16, 32]\n",
    "    hidden_layers_arr = [2, 4, 6]\n",
    "    \n",
    "    epochs = [10]\n",
    "    lrs = [1e-5, 1e-6]\n",
    "    for e, h, f in itertools.product(epochs, hidden_layers_arr, features_arr):\n",
    "        print(\"Current Layer Attributes - epochs:{} hidden layers:{} features count:{}\".format(e,h,f))\n",
    "        n = network(2,h,f)\n",
    "        n.build_layers()\n",
    "        Train.train(e, n, h,f, lrs)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-06-02T15:45:13.726152Z",
     "start_time": "2017-06-02T15:45:13.721407Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dict1 = {}\n",
    "dict2 = []\n",
    "for k, (v1, v2) in Train.predictions.items():\n",
    "    dict1.update({k: v1})\n",
    "    dict2.append(v2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-06-02T15:45:13.792811Z",
     "start_time": "2017-06-02T15:45:13.727728Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Train.predictions = dict1\n",
    "Train.results = dict2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-06-02T15:45:13.846861Z",
     "start_time": "2017-06-02T15:45:13.794377Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_results = pd.DataFrame(Train.results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-06-02T15:45:13.912561Z",
     "start_time": "2017-06-02T15:45:13.848595Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>epoch</th>\n",
       "      <th>no_of_features</th>\n",
       "      <th>hidden_layers</th>\n",
       "      <th>train_score</th>\n",
       "      <th>test_score</th>\n",
       "      <th>test_score_20</th>\n",
       "      <th>time_taken</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>20</td>\n",
       "      <td>32</td>\n",
       "      <td>6</td>\n",
       "      <td>0.920305</td>\n",
       "      <td>0.864221</td>\n",
       "      <td>0.755443</td>\n",
       "      <td>39.314166</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>20</td>\n",
       "      <td>16</td>\n",
       "      <td>2</td>\n",
       "      <td>0.943562</td>\n",
       "      <td>0.843639</td>\n",
       "      <td>0.706076</td>\n",
       "      <td>27.613436</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>20</td>\n",
       "      <td>8</td>\n",
       "      <td>4</td>\n",
       "      <td>0.922686</td>\n",
       "      <td>0.843240</td>\n",
       "      <td>0.709283</td>\n",
       "      <td>34.334415</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>20</td>\n",
       "      <td>16</td>\n",
       "      <td>4</td>\n",
       "      <td>0.813701</td>\n",
       "      <td>0.834501</td>\n",
       "      <td>0.738481</td>\n",
       "      <td>9.855491</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>20</td>\n",
       "      <td>32</td>\n",
       "      <td>2</td>\n",
       "      <td>0.961581</td>\n",
       "      <td>0.817379</td>\n",
       "      <td>0.656540</td>\n",
       "      <td>31.860774</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>20</td>\n",
       "      <td>8</td>\n",
       "      <td>2</td>\n",
       "      <td>0.923321</td>\n",
       "      <td>0.797285</td>\n",
       "      <td>0.617637</td>\n",
       "      <td>30.654842</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>20</td>\n",
       "      <td>32</td>\n",
       "      <td>4</td>\n",
       "      <td>0.928004</td>\n",
       "      <td>0.782115</td>\n",
       "      <td>0.591983</td>\n",
       "      <td>43.845499</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>20</td>\n",
       "      <td>16</td>\n",
       "      <td>6</td>\n",
       "      <td>0.753612</td>\n",
       "      <td>0.748847</td>\n",
       "      <td>0.598819</td>\n",
       "      <td>46.110596</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>20</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>0.923877</td>\n",
       "      <td>0.735495</td>\n",
       "      <td>0.503460</td>\n",
       "      <td>30.391368</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>20</td>\n",
       "      <td>4</td>\n",
       "      <td>6</td>\n",
       "      <td>0.543817</td>\n",
       "      <td>0.433064</td>\n",
       "      <td>0.184979</td>\n",
       "      <td>2.130615</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>20</td>\n",
       "      <td>8</td>\n",
       "      <td>6</td>\n",
       "      <td>0.537704</td>\n",
       "      <td>0.431733</td>\n",
       "      <td>0.183460</td>\n",
       "      <td>2.159170</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>20</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>0.536672</td>\n",
       "      <td>0.430758</td>\n",
       "      <td>0.181603</td>\n",
       "      <td>1.805248</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    epoch  no_of_features  hidden_layers  train_score  test_score  \\\n",
       "11     20              32              6     0.920305    0.864221   \n",
       "2      20              16              2     0.943562    0.843639   \n",
       "5      20               8              4     0.922686    0.843240   \n",
       "6      20              16              4     0.813701    0.834501   \n",
       "3      20              32              2     0.961581    0.817379   \n",
       "1      20               8              2     0.923321    0.797285   \n",
       "7      20              32              4     0.928004    0.782115   \n",
       "10     20              16              6     0.753612    0.748847   \n",
       "0      20               4              2     0.923877    0.735495   \n",
       "8      20               4              6     0.543817    0.433064   \n",
       "9      20               8              6     0.537704    0.431733   \n",
       "4      20               4              4     0.536672    0.430758   \n",
       "\n",
       "    test_score_20  time_taken  \n",
       "11       0.755443   39.314166  \n",
       "2        0.706076   27.613436  \n",
       "5        0.709283   34.334415  \n",
       "6        0.738481    9.855491  \n",
       "3        0.656540   31.860774  \n",
       "1        0.617637   30.654842  \n",
       "7        0.591983   43.845499  \n",
       "10       0.598819   46.110596  \n",
       "0        0.503460   30.391368  \n",
       "8        0.184979    2.130615  \n",
       "9        0.183460    2.159170  \n",
       "4        0.181603    1.805248  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_results.sort_values(by = 'test_score', ascending = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-06-02T15:45:13.965021Z",
     "start_time": "2017-06-02T15:45:13.914852Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pd.Panel(Train.predictions).to_pickle(\"dataset/tf_dense_only_nsl_kdd_predictions.pkl\")\n",
    "df_results.to_pickle(\"dataset/tf_dense_only_nsl_kdd_scores.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-06-02T15:45:14.070810Z",
     "start_time": "2017-06-02T15:45:13.966728Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import itertools\n",
    "\n",
    "def plot_confusion_matrix(cm, classes,\n",
    "                          normalize=False,\n",
    "                          title='Confusion matrix',\n",
    "                          cmap=plt.cm.Blues):\n",
    "    \"\"\"\n",
    "    This function prints and plots the confusion matrix.\n",
    "    Normalization can be applied by setting `normalize=True`.\n",
    "    \"\"\"\n",
    "    np.set_printoptions(precision=4)\n",
    "\n",
    "    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n",
    "    plt.title(title)\n",
    "    plt.colorbar()\n",
    "    tick_marks = np.arange(len(classes))\n",
    "    plt.xticks(tick_marks, classes, rotation=45)\n",
    "    plt.yticks(tick_marks, classes)\n",
    "\n",
    "    if normalize:\n",
    "        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "        print(\"Normalized confusion matrix\")\n",
    "    else:\n",
    "        print('Confusion matrix, without normalization')\n",
    "\n",
    "    print(cm)\n",
    "\n",
    "    thresh = cm.max() / 2.\n",
    "    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
    "        plt.text(j, i, cm[i, j].round(4),\n",
    "                 horizontalalignment=\"center\",\n",
    "                 color=\"white\" if cm[i, j] > thresh else \"black\")\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.ylabel('True label')\n",
    "    plt.xlabel('Predicted label')\n",
    "\n",
    "def plot(actual_value, pred_value):\n",
    "    from sklearn.metrics import confusion_matrix\n",
    "    cm_2labels = confusion_matrix(y_pred = pred_value, y_true = actual_value)\n",
    "    plt.figure(figsize=[6,6])\n",
    "    plot_confusion_matrix(cm_2labels, preprocess.output_columns_2labels, normalize = True,\n",
    "                         title = Train.best_parameters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-06-02T15:45:14.359062Z",
     "start_time": "2017-06-02T15:45:14.072401Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Normalized confusion matrix\n",
      "[[ 0.6636  0.3364]\n",
      " [ 0.2242  0.7758]]\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAbUAAAGgCAYAAAAtsfn1AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAAIABJREFUeJzt3XmclXX5//HXe4ZVkE0QFVBccAFyA5WfmfuCK2apmAup\naZmVlZqamUtZfsusrNS0TNRKUVMxU0NScwkV3HdxBUQBUUHZhpnr98f9mfEwzgwzcGY79/vp4zzm\nPp97+5zD8Vznuu7Pfd+KCMzMzEpBWWt3wMzMrFgc1MzMrGQ4qJmZWclwUDMzs5LhoGZmZiXDQc3M\nzEqGg5qZmZUMBzUzMysZDmpmZlYyOrR2B8zMrHmV99ggYvniom0vFs+9JyJGF22DReSgZmZW4mL5\nYjpvdljRtrfkqT/0LdrGisxBzcys5AmUj6NN+XiVZmaWC87UzMxKnQCptXvRIhzUzMzywOVHMzOz\n9sWZmplZHrj8aGZmpcGjH83MzNodZ2pmZnng8qOZmZUE4fKjmZlZe+NMzcys5MnlRzMzKyEuP5qZ\nmbUvztTMzPLA5UczMysNPvnazMys3XGmZmZW6nzrGTMzKykuP5qZmbUvztTMzEpefgaKOKiZmeVB\nWT6OqeUjdJuZWS44UzMzK3W+Sr+ZmdmqkbSZpKcKHgskfVdSH0mTJL2a/vYuWOcsSdMlvSxpn4L2\nEZKeTfMulRo+N8FBzcwsD6TiPVYiIl6OiK0jYmtgBLAIuBU4E5gcEUOAyek5koYCY4FhwGjgMknl\naXOXAycAQ9JjdEP7dlAzMyt5afRjsR5NswfwWkS8BYwBxqf28cDBaXoMcENELI2IN4DpwPaS1gV6\nRMSUiAjg2oJ16uSgZmZmzWks8Pc03T8iZqfpd4H+aXoAMKNgnZmpbUCart1eLw8UMTPLg+JeJquv\npKkFz6+MiCs/u0t1Ag4Czqo9LyJCUhSzU+CgZmaWD8Ud/TgvIkY2Yrl9gSci4r30/D1J60bE7FRa\nnJPaZwGDCtYbmNpmpena7fVy+dHMzJrLEXxaegSYCIxL0+OA2wvax0rqLGlDsgEhj6VS5QJJo9Ko\nx2MK1qmTMzUzs1LXyFGLxd2lugF7AV8vaL4ImCDpeOAt4DCAiHhe0gTgBWA5cHJEVKZ1vglcA3QF\n7kqPejmomZnlQQuffB0RnwBr1Wp7n2w0ZF3LXwhcWEf7VGB4Y/fr8qOZmZUMB7UckPS8pF3rmber\npJl1zUvzr5H002brnJm1jBY8+bo1Oai1c5LelLRnrbavSnqo+nlEDIuI+1u8cw2o3cf2QFI/SX+T\n9JGkDyT9tZHrDZYUkj4ueDxdhP6cJ+n61d1OsUjaVNJNkual9+gZSd8vuDJEc+13pT+8JF0v6d10\nuaZXJH2tYN6odMmm+ZLmptewbnP2ueW16snXLapt986smSjT1M//P8hOGF0fWBu4uInr94qI7umx\nVRPXLTpJRTumLmlj4FGyE2g/FxE9gUPJLpG0ZrH2sxouAjaKiB5k5039VNKINK83cCUwGNgAWAj8\npTU6aavPQS0HCrM5SV3TL9sPJL0AbFdr2W0kPSFpoaQbgS615h+QLlD6oaRHJG1Zaz+npV/oH0m6\nUdIK6zeyv8dKejH14XVJXy+Y95ykAwued0yZwTbp+ajUrw8lPV1YdpV0v6QLJT1Mdi26jVLG+Hra\n1xuSjqynT3uTnUdzekR8FBEVEfFkU19bPds+Lr3eDyTdI2mDgnm/lTQjZRjTJH0htY8GfggcXpj5\n1c7cC7O5gozxeElvA/9pxHvWqPcHOB94JCK+X33FiHT9vyMj4sO0rYOUlcI/TP8WWxTsJyRtUvC8\nJvtSKpFLOlXSHEmzJR2b5p0IHAn8IL0Pd9TVuYh4LiIWVT9Nj43TvLsi4qaIWJCW+T3w+Qb+ydon\nlx+tRJ1L9j/zxsA+fHrOSPXZ/7cB1wF9gJuALxXM3wa4mmyI7lrAH4GJkjoXbP8wsguObghsCXx1\nFfo4BzgA6AEcC/xa0rZp3rXAUQXL7gfMjognJQ0A7gR+mvp/GnCLpH4Fyx8NnEiWPcwFLgX2jYg1\ngR2Bp9JrXT99+a6f1hsFvAyMl/S+pMcl7bIKr20FksaQBadDgH7Ag6x4Xs/jwNbp9fwNuElSl4i4\nG/gZcOMqZH67AFsA+zT0nikbkl3n+1OHPYGbG3idm6bX9d30Ov8F3JE+c42xDtCT7BJJxwN/kNQ7\nXcXir8Av0vtwYNrfZZIuq9WHyyQtAl4CZqc+1GVn4PlG9qt9qL71jMuP1k7clr6AP5T0IXBZA8se\nBlwYEfMjYgbZl1a1UUBH4DcpE7mZ7Eu12onAHyPi0YiojIjxwNK0XrVLI+KdiJgP3EH2hdwkEXFn\nRLwWmQeAfwNfSLOvB/aT1CM9P5osCEMW7P4VEf+KiKqImARMJQt81a6JiOcjYjnZ+TBVwHBJXSNi\ndkQ8n/rwdkT0ioi303oDgb2B+8i+YH8F3C6pbxNe2ryCf6fTUts3gJ9HxIupTz8Dtq7O1iLi+oh4\nPyKWR8SvgM7AZk3YZ13Oi4hPImIxK3/P6nx/6rAWWaCoz+HAnRExKSIqyEq3XckCZWNUABekz+W/\ngI9p4H2IiG9GxDdrt5H9mPkCWSl5ae31UuXhx8DpjeyXtTEOaqXh4PQF3CsiepGdrFif9VjxwqFv\n1Zo3K10Nu675GwCn1gqgg9J61d4tmF4EdG/KCwGQtK+kKcoO3H9I9gXbFyAi3gEeBr4kqRfZZXiq\nB2xsABxaq387AYUH/WteezqP5nCywDJb0p2SNq+nW4uBNyPiz+mL9Ya0raaUqfoW/DtVH4/bAPht\nQX/nk/2uHpDei9NSafKjNL9n9XuxGgr//et9z5r4/rzPiu9zbetR8FmKiKrUjwYvTlu4/RT0q63S\nZyv9GHuI7EfKSYXzUvnzLuCUiHiwqdtu2zxQxErXbFa8xtr6teYNkFYomhfOn0GW5fUqeKwREYXl\nstWSSpm3kP2S75+C9L/IvuirjSfLMA4F/hcR1deCmwFcV6t/3SLiooJ1V7iAakTcExF7kX0hvwRc\nVU/Xnqm9bh3PV8UM4Ou1+tw1Ih5Jx89+QJZd907vxUd8+l7Utf9PgDUKnq9TxzKF6zX4njXh/bmX\nglJ1Hd4hC6BANlCH7HNY/W+3qBH9rs+q/Dt0IB1TS/3ZgOw1/CQirqt3rfbMx9SsRE0AzpLUW9JA\n4NsF8/5HVpL7jrIBGIcA2xfMvwr4hqQdlOkmaX9Jqzq6TZK6FD6ATmQltrnAckn7kpX9Ct0GbAuc\nQnaMrdr1wIGS9pFUnra5a3qdde28v6Qx6djRUrKSVlU9fb0V6C1pXNr2l8l+7T+ctnWepPtX4T24\nguzfY1jaTk9Jh6Z5a5L9e8wFOkj6MdlxxmrvAYO14ijOp8iuoddR0kjgyyvZf73vWRPfn3OBHSX9\nUtI66bVsomwofS+yz93+kvaQ1BE4NW3zkYJ+fyX1YTTZcb/Geg/YqL6ZktaWNFZS97T9fciuSTg5\nzR9ANmjm9xFxRRP2a22Qg1r+nE9WBnqD7FhVza/SiFhGNmDhq2RlsMPJjj1Uz59Kdgfa3wMfkN3I\n76ur0Zcdycp6tR/fIfsS/AD4CtnFTmukY0G3kA1GKezfDLKbDf6QLBDMIDs2Ut/nvAz4PlkWMZ/s\ni/QkqBko8nH1QJF0jPAgsoEUH5HdsXdMRMxL2xpECnBNERG3Av8H3CBpAfAcWUkV4B7gbuAVsn+z\nJaxYOrwp/X1f0hNp+hyyDOQDsn/rv61k/w29Z/W+P3Vs5zXg/5ENi39e0kdk/0ZTgYUR8TJZdv07\nYB5wIHBg+sxB9gPlQOBDstGMtzXU71r+DAxN5dPbACRdIak6QEXq90yy9+Vi4LsRUf25+hpZUDxP\nBecSNmH/7UNOyo9a8fCJWfuQspZNI+KolS7cAiQ9BewR2bXtzNqUsl4bROddzy7a9pbc/vVp0bhb\nz7Q4X9DY2h1JfciGdR/d2n2pFhFNHuVpZsXXtvNIs1oknUBWIrsrIv7b2v0xaxeUn9GPztSsXYmI\nq6h/BJ6Z1aeNj1oslrYdcs3MzJrAmZqZWQ4oJ5mag9oq6rNW3xg4aIOVL2hWoGN5Pr5YrHjeeutN\n5s2bt1ofHOGgZisxcNAG3PmfR1a+oFmBfj06r3whswKf36FNjpxvsxzUzMxKnVjxQnMlzEHNzKzk\nKTflR49+NDOzkuFMzcwsB/KSqTmomZnlQF6CmsuPZmZWMpypmZnlQF4yNQc1M7NSl6Mh/S4/mplZ\nyXCmZmZW4pSj89Qc1MzMciAvQc3lRzMzKxnO1MzMciAvmZqDmplZDuQlqLn8aGZmJcOZmplZqcvR\neWoOamZmOeDyo5mZWTvjTM3MrMT55GszMyspeQlqLj+amVnJcKZmZpYH+UjUHNTMzEqeXH40MzNr\nd5ypmZnlQF4yNQc1M7McyEtQc/nRzMxKhjM1M7MS55OvzcystOQjprn8aGZmxSepl6SbJb0k6UVJ\n/09SH0mTJL2a/vYuWP4sSdMlvSxpn4L2EZKeTfMu1UpSTgc1M7NSl85TK9ajkX4L3B0RmwNbAS8C\nZwKTI2IIMDk9R9JQYCwwDBgNXCapPG3ncuAEYEh6jG5opw5qZmY50JJBTVJPYGfgzwARsSwiPgTG\nAOPTYuOBg9P0GOCGiFgaEW8A04HtJa0L9IiIKRERwLUF69TJQc3MzIptQ2Au8BdJT0r6k6RuQP+I\nmJ2WeRfon6YHADMK1p+Z2gak6drt9XJQMzPLgSJnan0lTS14nFhrdx2AbYHLI2Ib4BNSqbFayryi\n2K/Tox/NzPKguKMf50XEyAbmzwRmRsSj6fnNZEHtPUnrRsTsVFqck+bPAgYVrD8wtc1K07Xb6+VM\nzczMiioi3gVmSNosNe0BvABMBMaltnHA7Wl6IjBWUmdJG5INCHkslSoXSBqVRj0eU7BOnZypmZnl\nQCucfP1t4K+SOgGvA8eSJVITJB0PvAUcBhARz0uaQBb4lgMnR0Rl2s43gWuArsBd6VEvBzUzsxLX\nxKH4RRERTwF1lSj3qGf5C4EL62ifCgxv7H5dfjQzs5LhTM3MLAd87UczMysZeQlqLj+amVnJcKZm\nZpYH+UjUHNTMzPLA5UczM7N2xpmamVmpU34yNQc1M7MSJyAnMc3lRzMzKx3O1MzMSl7LXyartTio\nmZnlQE5imsuPZmZWOpypmZnlQF7Kj87UzMysZDhTMzMrdcrPMTUHNTOzEiegrCwfUc3lRzMzKxnO\n1MzMcsDlRzMzKxke/WhmZtbOOFMzMyt1Hv1oZmalIrtKfz6imsuPtoIuHcU6PTuyTs9OrNmlvM5l\nOncQ/Xt0ZJ0eHem3ZseadgnW6t4hrd+RTh2y/4l6dC2nf4+O9E/LF44s7lgu1k7b6t+jY+1dWTvx\n73vuZsthmzFs80345S8u+sz8OybeznbbbMkOI7bm8zuM5OGHHgJgyZIl7PT/tmf7bbdi262G8ZPz\nz11hvct+/zu2Gr452241jB+e+YMV5r399tv07dWdX19ycfO9MGt3nKnZCnqv0ZE5C5dRWQX9e3Rk\n8bIqlldFzXwJenfrwNyFFVRWsUKA6r1GB5ZUVPH+x1U1ywIsXFzJgsWVAHTvXE7Prh34YNFyAPp0\n68D8T5ZTURnk5DSaklNZWcl3v3Myd941iQEDB7LTqO044ICD2GLo0Jpldtt9Dw448CAk8ewzz3DU\nVw7j6edeonPnztw96T90796diooKdt9lJ/beZ192GDWKB+6/j3/ecTuPTXuazp07M2fOnBX2e8bp\n32fv0fu29Mttp/JzlX5nalajUwdRURVUZjGJRcuq6NppxY9It05lLFpWVbNMdbyToHOHMj5ZWlWz\nbKR5UbB+4f9XXTqWUVEZVFTGCtuy9uXxxx5j4403YcONNqJTp04cevhY/nnH7Sss071795ov1U8+\n+aRmWhLdu3cHoKKiguUVFTXzrvzj5Zz2gzPp3LkzAGuvvXbN9ibefhuDB2/I0KHDmv31lQqpeI+2\nzEHNapRLVFZ+Glkqq4LyWulTh3JRJtFvzaxcuEYKeh3KRGUEfbp1oH+PjvReowOFa/bsWs66PTvR\nrVMZHy1eXrMOQN+0rfrKnda2vfPOLAYOHFTzfMCAgcyaNeszy91+261sNXxzDhmzP1dceXVNe2Vl\nJTuM2Jr111ub3ffci+132AGA6a+8wsMPPcgXdtyBvXbfhamPPw7Axx9/zK9++X+cfc65n9mHmYOa\nNZHo1EHMW1jB3IUV9OhaXhOcOpWLj5dU8t6CCoJgza6fBqmPFlcy+6NlfLKsiu4peFVnd/M/rmDO\nggq6diqjc4c2/jPQVtmYg7/I08+9xIRbbuOC886paS8vL+fRaU8x/c2ZTH38MZ5/7jkAllcuZ/78\n+fz34Sn87KJfctRXDiMi+OkF5/HtU75Xk+FZ40gq2qMta7ZjapIeiYgdm7jOm8C0iPhSev5l4ICI\n+Grxe1hvH84DPo6I3B19roygvPzTD2x5maisVROsrAqWVARBVl5cujzoWC6WLs9KkstSprdoWRU9\n6si8Fi2rpF/3jixYXMnyqmDp8qqasuOSZVV06lDG0uWVzfYarfjWW28AM2fOqHk+a9ZMBgwYUO/y\nO31hZ95443XmzZtH3759a9p79erFLrvuxr//fTfDhg9nwICBHPzFQ5DEdttvT1lZGfPmzePxxx7l\n1n/czNln/YCPPvyQsrIyunTuwkknf6tZX2e71g7KhsXSbJlaUwNagRGShq58sc+S5IEvq2HZ8qBj\nmShPn4o1OpWxuKJqhWUWL6uic4dsAQGdy8XyqqAqsoBXnbVVHy+DT8uMAF07llGRotiSiio6lqum\nTNm5YB1rP0Zutx3Tp7/Km2+8wbJly7jpxhvY/4CDVljmtenTiXSQ9cknnmDp0qWstdZazJ07lw8/\n/BCAxYsXM/neSWy22eYAHHjQwTxw/30AvPrKKyxbtoy+ffsy+f4HeXn6m7w8/U2+9Z3vcvqZP3RA\nsxrNmal9HBHdJa0L3Aj0SPs7KSIebGDVXwFnA0fW2l4f4GpgI2ARcGJEPJMyq41T+9uS7gEOBroB\nQ4CLgU7A0cBSYL+ImC/pBODENG86cHRELCrKi2/HPli0nH5rdkSIj5dWsrwy6NY5C2KfLM1GQi6p\nqGKdnh0h4OOlVTWB6INFy1mre/aRWl4VzP8kO3bWc41yOpaJIAt8H6T2CFi4pLJmKP/iiiqW1Aqi\n1vZ16NCBX//29xy4/z5UVlYy7qvHMXTYMK764xUAnPD1b3Drrbfwt+uvpWOHjnTp2pXr/nojknh3\n9mxOOG4clZWVVEUVX/ryYey3/wEAjDv2OL7+teMYsfVwOnXsxJ+uHt/mS19tVZ7OU1P1r6eib/jT\noHYq0CUiLpRUDqwREQvrWedNYAfgfuBAYGtS+VHS74B5EXG+pN2BSyJi6xTUDgR2iojFkr4K/AjY\nBuhCFrDOiIgrJP0aeCsifiNprYh4P+33p8B7EfG7hsqPkk4kC4QMGDhoxP+efrUo75XlR78enVu7\nC9bOfH6HkUybNnW1IlK3AZvFFiddUawuMe2c3adFxMiibbCIWmKgyOPAsSlYfK6+gFagEvglcFat\n9p2A6wAi4j/AWpJ6pHkTI2JxwbL3RcTCiJgLfATckdqfBQan6eGSHpT0LFlWuNKxwRFxZUSMjIiR\nfdbqt7LFzcyshTV7UIuI/wI7A7OAayQd04jVrkvrDFrZgskntZ4vLZiuKnhexacl12uAb0XE54Dz\nybI6M7OSlJfRj80e1CRtQFbauwr4E7DtytaJiArg18D3CpofJB1nk7QrWSlywWp0bU1gtqSO1Dp+\nZ2ZWavJy8nVLjBbcFThdUgXwMdCYTA3gz2THxqqdB1wt6RmygSLjVrNf5wCPAnPT3zVXc3tmZtbK\nmi2oRUT39Hc8ML6R6wwumF4KrFfwfD7ZqMba65xX6/k1ZKXFurZZMy8iLgcuX9n2zMzaPeVn9KPP\n6zIzK3HZkP7W7kXLaJWgJulRoPbY5qMj4tnW6I+ZmZWGVglqEbFDa+zXzCyf2v6oxWJx+dHMLAdy\nEtN8lX4zMysdztTMzHLA5UczMysN7eCk6WJx+dHMzEqGMzUzsxKXp1vPOKiZmeVAXoKay49mZlYy\nHNTMzHKgpa/SL+lNSc9KekrS1NTWR9IkSa+mv70Llj9L0nRJL0vap6B9RNrOdEmXaiUpp4OamVkO\ntNL91HaLiK0L7pJ9JjA5IoYAk9NzJA0FxpLdrHk0cJmk8rTO5cAJwJD0GN3QDh3UzMyspYzh07u2\njOfTO6+MAW6IiKUR8QYwHdhe0rpAj4iYEhEBXEsdd2sp5KBmZlbqilh6bEKiFsC9kqZJOjG19Y+I\n2Wn6XaB/mh4AzChYd2ZqG5Cma7fXy6MfzcxKnIp/QeO+1cfJkisj4spay+wUEbMkrQ1MkvRS4cyI\nCElRzE6Bg5qZmTXdvILjZHWKiFnp7xxJtwLbA+9JWjciZqfS4py0+CxgUMHqA1PbrDRdu71eLj+a\nmeVAS5YfJXWTtGb1NLA38BwwERiXFhsH3J6mJwJjJXWWtCHZgJDHUqlygaRRadTjMQXr1MmZmplZ\nDpS17MnX/YFbU8mzA/C3iLhb0uPABEnHA28BhwFExPOSJgAvAMuBkyOiMm3rm8A1QFfgrvSol4Oa\nmZkVVUS8DmxVR/v7wB71rHMhcGEd7VOB4Y3dt4OamVkO5OQqWQ5qZmalLjsWlo+o5oEiZmZWMpyp\nmZnlQFk+EjUHNTOzPHD50czMrJ1xpmZmlgM5SdQc1MzMSp3Irv+YBy4/mplZyXCmZmaWAx79aGZm\npaHpd6xut1x+NDOzkuFMzcwsB3KSqDmomZmVOtHit55pNS4/mplZyXCmZmaWAzlJ1BzUzMzywKMf\nzczM2hlnamZmJS67SWhr96JlOKiZmeWARz+amZm1M/VmapJ6NLRiRCwofnfMzKw55CNPa7j8+DwQ\nrPheVD8PYP1m7JeZmRVRXkY/1hvUImJQS3bEzMxsdTXqmJqksZJ+mKYHShrRvN0yM7NiyS6TVbxH\nW7bSoCbp98BuwNGpaRFwRXN2yszMiijdeqZYj7asMUP6d4yIbSU9CRAR8yV1auZ+mZmZNVljglqF\npDKywSFIWguoatZemZlZUbXxBKtoGhPU/gDcAvSTdD5wGHB+s/bKzMyKqq2XDYtlpUEtIq6VNA3Y\nMzUdGhHPNW+3zMzMmq6xl8kqByrISpC+ComZWTtSPfoxDxoz+vFs4O/AesBA4G+SzmrujpmZWfF4\n9OOnjgG2iYhFAJIuBJ4Eft6cHTMzM2uqxgS12bWW65DazMysnWjb+VXxNHRB41+THUObDzwv6Z70\nfG/g8ZbpnpmZrS4pP7eeaShTqx7h+DxwZ0H7lObrjpmZ2apr6ILGf27JjpiZWfPJSaK28mNqkjYG\nLgSGAl2q2yNi02bsl5mZWZM15pyza4C/kB1n3BeYANzYjH0yM7Miy8uQ/sYEtTUi4h6AiHgtIn5E\nFtzMzKydkIr3aMsaM6R/abqg8WuSvgHMAtZs3m6ZmZk1XWOC2veAbsB3yI6t9QSOa85OmZlZ8Qh5\nSH+1iHg0TS7k0xuFmplZe9EOyobF0tDJ17eS7qFWl4g4pFl6ZGZmtooaytR+32K9aIeWV1Uxd8HS\n1u6GtTOb7nFqa3fB2pmlL79dlO209VGLxdLQydeTW7IjZmbWfPJyz7C8vE4zM8uBxt4k1MzM2imR\nn/JjozM1SZ2bsyNmZtZ8ylS8R2NIKpf0pKR/pud9JE2S9Gr627tg2bMkTZf0sqR9CtpHSHo2zbtU\njYjMjbnz9faSngVeTc+3kvS7xr0sMzPLqVOAFwuenwlMjoghwOT0HElDgbHAMGA0cJmk8rTO5cAJ\nwJD0GL2ynTYmU7sUOAB4HyAingZ2a8R6ZmbWRrRkpiZpILA/8KeC5jHA+DQ9Hji4oP2GiFgaEW8A\n04HtJa0L9IiIKRERwLUF69SrMcfUyiLirVpZX2Uj1jMzszYgu2Zjix5T+w3wA1a8pGL/iJidpt8F\n+qfpAax4n86Zqa0iTddub1BjMrUZkrYHItVIvwu80oj1zMysNPWVNLXgcWL1DEkHAHMiYlp9K6fM\nq96Le6yOxmRqJ5GVINcH3gPuTW1mZtZONHaARyPNi4iR9cz7PHCQpP3I7sHZQ9L1wHuS1o2I2am0\nOCctPwsYVLD+wNQ2K03Xbm/QSjO1iJgTEWMjom96jI2IeStbz8zM2o6WuvVMRJwVEQMjYjDZAJD/\nRMRRwERgXFpsHHB7mp4IjJXUWdKGZANCHkulygWSRqVRj8cUrFOvxtz5+irqSBMj4sQ6FjczM6vL\nRcAESccDbwGHAUTE85ImAC8Ay4GTI6J63MY3yW5U3RW4Kz0a1Jjy470F012ALwIzGvcazMystQla\n5dYzEXE/cH+afh/Yo57lLiS7tVnt9qnA8KbsszG3nrmx8Lmk64CHmrITMzNrXXm5JuKqvM4N+XQo\nppmZWZvRmGNqH/DpMbUyYD7pTHAzM2sfcnLpx4aDWhpxshWfDqOsSucXmJlZOyGpVY6ptYYGy48p\ngP0rIirTwwHNzMzarMYcU3tK0jbN3hMzM2s2LXWeWmurt/woqUNELAe2AR6X9BrwCdno0IiIbVuo\nj2ZmtpqKfEWRNquhY2qPAdsCB7VQX8zMzFZLQ0FNABHxWgv1xczMmkFrnXzdGhoKav0kfb++mRFx\nSTP0x8zMmkFOYlqDQa0c6E7K2MzMzNq6hoLa7Ii4oMV6YmZmzaORd6wuBSs9pmZmZu2fcvKV3tB5\nanVeTdnMzKytqjdTi4j5LdkRMzNrHtnox9buRctozP3UzMysnctLUMvLLXbMzCwHnKmZmeWAcnKi\nmoOamVmJy9MxNZcfzcysZDhTMzMrde3gljHF4qBmZpYDebmgscuPZmZWMpypmZmVuDwNFHFQMzPL\ngZxUH11+NDOz0uFMzcys5ImynFyl30HNzKzECZcfzczM2h1namZmpc53vjYzs1Lik6/NzMzaGWdq\nZmYlLk9Kx7koAAAbu0lEQVQDRRzUzMxywOVHMzOzdsaZmplZDuQkUXNQMzMrdSI/Zbm8vE4zM8sB\nZ2pmZqVOoJzUHx3UzMxyIB8hzeVHMzMrIc7UzMxKXHbn63zkag5qZmY5kI+Q5vKjmZmVEGdqZmY5\nkJPqo4OamVnpU26G9Lv8aGZmJcOZmplZifNlsszMrKRIKtqjEfvqIukxSU9Lel7S+am9j6RJkl5N\nf3sXrHOWpOmSXpa0T0H7CEnPpnmXaiUdcFAzM7NiWwrsHhFbAVsDoyWNAs4EJkfEEGByeo6kocBY\nYBgwGrhMUnna1uXACcCQ9Bjd0I4d1MzMckBFfKxMZD5OTzumRwBjgPGpfTxwcJoeA9wQEUsj4g1g\nOrC9pHWBHhExJSICuLZgnTr5mJqt4JEH7uXi88+gsqqSgw8/hmNP+v4K8/912wTGX/EbgqBbt+6c\n9ZNL2HTo53j3nZn8+NRvMH/eHCTxxSO+yleOPWmFda+76nf85mc/4t5pr9O7z1pMefA//O4X51FR\nUUHHjh055ayfsP2Ou7Tky7Ui2WvHLbj49C9TXlbGNbc9wsV/mbTC/O8dsweH77cdAB3Ky9h8w3UY\ntPuZ9O3dnev+77ia5TYcsBY/ufxOfv+3+zn76/tx3CE7MveD7Lvx3N9P5J6HXqBDhzIu//GRbL35\nIDqUl/HXOx/j4qv/3WKvtV0q/gWN+0qaWvD8yoi4coVdZpnWNGAT4A8R8aik/hExOy3yLtA/TQ8A\nphSsPjO1VaTp2u31clCzGpWVlVz041O57Lrb6L/OAI4esxu77LkfGw3ZvGaZAYM24Kob76RHz948\nfP8kfvrDU7j2tv9Q3qED3zv7p2wxfGs++XghRx24C6N22q1m3XffmcmUB//DOusNqtlWrz5r8Zs/\n3Ui//usy/eUX+Na4Q7h7ykst/rpt9ZSVid+ceRj7n/R7Zr33IQ/99XT++cCzvPT6uzXL/Prayfz6\n2skA7LfzcL595G58sGARHyxYxKixF9Vs57V7LmTifU/XrPe76+/jN9dNXmF/X9pzWzp36sB2h/2M\nrl068uQtP2LCXVN5e/b8Fni1lsyLiJENLRARlcDWknoBt0oaXmt+SIpid8zlR6vx/NPTGLTBRgxc\nf0M6durE3gcewv2T7lxhma1G7ECPntmx3c9tM5I5774DQL+112GL4VsD0K37mmy4yWY18wAu+clZ\nnHLmBSv8Wtx82Fb0678uABtvugVLlyxm2dKlzfoarfi2Gz6Y12bM481Z71OxvJKb7nmCA3bdst7l\nDxs9kgl3T/tM+27bb8YbM+fy9uwPGtxfEKzRpRPl5WV07dyJZRWVLPxkyWq/jlJWPfqxWI+miIgP\ngfvIjoW9l0qKpL9z0mKzgEEFqw1MbbPSdO32ejmoWY05775D/3U/zez7rzOAue/Ornf52268jh13\n2fMz7e/MfIuXXniG4VtnP+Tu//ed9FtnPTYd+rl6tzX5rtvZfPhWdOrceTVegbWG9dbuycz3Pg1E\ns977gAH9eta5bNcuHdlrxy24bfJTn5l36D4jPhPsTjpiFx678SyuOPdIeq3ZFYB/3Pski5Ys441J\nF/LKXRfwm2sn88GCRUV8RaWphUc/9ksZGpK6AnsBLwETgXFpsXHA7Wl6IjBWUmdJG5INCHkslSoX\nSBqVRj0eU7BOnRzUbJU8/r//cvuE6/jOmRes0L7ok485/aSjOe2cn9N9zR4sXryIqy/7Fd/43g/r\n3dZrr7zIpf93Lj+88DfN3W1rZfvv/Dn+99TrnwlCHTuUs/8un+Mfk56sabvqpgfZ4oBz2WHsRbw7\nbwEXff8QALYbNpjKyio22vtsttj/XE45encGD1irRV+HrdS6wH2SngEeByZFxD+Bi4C9JL0K7Jme\nExHPAxOAF4C7gZNT+RLgm8CfyAaPvAbc1dCOWyyoSXpkFdfbWlJIGl3Q1kvSNwueD5b0ldXo2/2S\nGqwP58Ha66zHe7M/zezfe3cW/dZZ9zPLvfric/zkzG9zyZV/p1fvPjXtFRUVnH7S0ew75jB2H30Q\nADPfeoN3Zr7FEfvtxAE7fY45787iyAN3Zt7c97J9zJ7FaV8/kgt+9UcGbbBRM79Caw7vzPmIgf1r\nTjdiQP/ezJr7UZ3LHrrPCG6qo/S4z05DeeqlGcyZv7Cmbc78hVRVBRHB1f94mJHDNwDgsH1H8u9H\nXmD58irmfvAx/3vqdUYMXb/Ir6r0tPDox2ciYpuI2DIihkfEBan9/YjYIyKGRMSeETG/YJ0LI2Lj\niNgsIu4qaJ+atrFxRHwrjYKsV4sFtYjYcRVXPQJ4KP2t1osselcbDKxyULPM0C23ZcabrzFrxptU\nLFvGv+/4B7vsud8Ky8yeNYPTTjqKn1xyJRtstElNe0TwkzO+xYabbMZRX/tWTfuQzYdx79TX+OdD\nz/LPh55l7XUG8Nc7/kvffv1ZuOBDTjnuML59xnlsPXJUi71OK66pz7/FJuv3Y4P11qJjh3IO3Wdb\n7rz/mc8s16N7F3YasQl31DGvruNs6/TtUTM9ZveteOG1rBQ+89357LrdZgCs0aUT2285mJfffK+Y\nL8nasRYb/Sjp44jong4O3gj0SPs/KSIerGcdAYeS1WMflNQlIpaQpawbS3oKmAR8AdgiPR8P3Apc\nB3RLm/pWRDyStnkGcBRQBdwVEWcW7K8MuBqYGRE/qqM/JwInAiuM4isVHTp04AfnX8y3jjmEyqpK\nxhx6FBtvugU3//XPAHz5yOO56tL/46MP5nPROacCUN6hnOsnPsBTU6dw5603sMlmwzhiv50AOPn0\nH7PTbnvXu78bx1/FjLde56pLf8FVl/4CgD9ceyt9+vZr5ldqxVRZWcX3/m8Cd1x2MuVlYvztU3jx\n9Xf52pezz8Gfbn4IgIN224rJU15i0ZJlK6y/RpdO7L7D5nzrp39fof3CUw5my80GEhG8NXs+307z\nr7jxv1x5/lFMu/lsJLju9ik89+o7WMNycj1jtJJMrng7+jSonQp0iYgL03kMa0TEwnrW+TxwQUTs\nIelvwC0RcYukwcA/I2J4Wm5X4LSIOCA9XwOoioglkoYAf4+IkZL2Bc4B9oyIRZL6RMR8SfeTndl+\nCvBcRFy4stczdMtt4vqJD6zWe2L58/kv1n9s0awuS1+eQNWiOasVkoYM2youuaF45/IdtOU601Y2\npL+1tMZAkceBYyWdB3yuvoCWHAHckKZvYMUSZEM6AldJeha4CRia2vcE/hIRiwAK67nAH2lkQDMz\ns7apxYNaRPwX2JnsXINrJB1T13Ipi/sS8GNJbwK/I7t+2JqN2M33gPeArYCRQKdGrPMIsJukLo1Y\n1sysXZGK92jLWjyoSdoAeC8iriIbprltPYvuATwTEYMiYnBEbADcAnwRWAgUBrfaz3sCsyOiCjga\nqL4w5iSyLHGN1Jc+Bev8GfgXMEGSr7RiZiVERf2vLWuN8uOuwNOSngQOB35bz3JHkA34KHQLcERE\nvA88LOk5Sb8EngEq020OvgdcBoyT9DSwOfAJQETcTXaS39Q0qOS0wo1HxCXAk8B1adCImZm1Iy2W\nkURE9/R3PJ9epbmh5Y+to20iWVAiImoP4d+91vPC6/ScUbCNi0gn/BW07Vowfe7K+mZm1t609bJh\nsbjMZmZW4rJrP+YjqrWJoCbpUaD2Rf+OjohnW6M/ZmbWPrWJoBYRO7R2H8zMSlY7GLVYLG0iqJmZ\nWfPKS1DzCD8zMysZztTMzHKgrZ9fViwOamZmJU5AWT5imsuPZmZWOpypmZnlgMuPZmZWMjz60czM\nrJ1xpmZmlgMuP5qZWUnw6EczM7N2yJmamVnJa/s39ywWBzUzs1KXowsau/xoZmYlw5mamVkO5CRR\nc1AzMyt12ejHfIQ1lx/NzKxkOFMzM8uBfORpDmpmZvmQk6jm8qOZmZUMZ2pmZjngk6/NzKxk5GTw\no8uPZmZWOpypmZnlQE4SNQc1M7NcyElUc/nRzMxKhjM1M7MSJzz60czMSoVvPWNmZtb+OFMzM8uB\nnCRqDmpmZrmQk6jm8qOZmZUMZ2pmZiVPHv1oZmalw6MfzczM2hlnamZmJU7kZpyIg5qZWS7kJKq5\n/GhmZkUlaZCk+yS9IOl5Saek9j6SJkl6Nf3tXbDOWZKmS3pZ0j4F7SMkPZvmXSo1fHTQQc3MLAdU\nxP8aYTlwakQMBUYBJ0saCpwJTI6IIcDk9Jw0bywwDBgNXCapPG3rcuAEYEh6jG5oxw5qZmY5IBXv\nsTIRMTsinkjTC4EXgQHAGGB8Wmw8cHCaHgPcEBFLI+INYDqwvaR1gR4RMSUiAri2YJ06+ZiamZk1\nVV9JUwueXxkRV9a1oKTBwDbAo0D/iJidZr0L9E/TA4ApBavNTG0Vabp2e70c1MzMcqDI40TmRcTI\nle5T6g7cAnw3IhYUHg6LiJAUxe2Wy49mZqVPRX40ZpdSR7KA9teI+Edqfi+VFEl/56T2WcCggtUH\nprZZabp2e70c1MzMrKjSCMU/Ay9GxCUFsyYC49L0OOD2gvaxkjpL2pBsQMhjqVS5QNKotM1jCtap\nk8uPZmY50MLXfvw8cDTwrKSnUtsPgYuACZKOB94CDgOIiOclTQBeIBs5eXJEVKb1vglcA3QF7kqP\nejmomZmVONGy136MiIeov1C5Rz3rXAhcWEf7VGB4Y/ft8qOZmZUMZ2pmZjmQk6tkOaiZmeVCTqKa\ny49mZlYynKmZmeWA73xtZmYlw3e+NjMza2ecqZmZ5UBOEjUHNTOzXMhJVHP50czMSoYzNTOzEpdd\nXD8fqZqDmplZqWvkHatLgcuPZmZWMpypmZnlQE4SNQc1M7NcyElUc1BbRS8++9S8ERv2fKu1+9EG\n9QXmtXYnrN3x56Z+G7R2B9oTB7VVFBH9WrsPbZGkqRExsrX7Ye2LPzfNTR79aGZmpcOjH83MzNoZ\nZ2pWbFe2dgesXfLnphmJ3IwTcVCz4ooIfzlZk/lz0wJyEtVcfjQzs5LhTM3MLAfyMvrRmZqZmZUM\nZ2rW6iT1AfpGxCut3RdrfyQpIqK1+9HWeUi/WQuQ1AX4DnCcpC1auz/WfkgaBOCA1jgq4qMtc1Cz\nVhURS4B709NDJQ1tzf5Y2yWpu6ROaXoL4BeS1mzlblkb46BmrUbKCiIR8RAwEegBfNmBzWqT1A34\nK3BoalqUHh9L6piWaetJROtJ91Mr1qMtc1CzVlF9HETShpI6RMQjwF+AnmSBzaVIqxERnwA3AsdK\nOhwYDCyOTEVaxmXIBuWjAOmBItYqUkDbHzgHeFDSx8BvyK4scTxwlKS/RsQLrdlPa32SyiOiMiL+\nJmkucAYwDdhQ0m+BmcBSoENEXNKafbXW50zNWoWkUcDPgMPJflwdDPwCmAuMB7oBy1qtg9YmpIy+\nUtJekn4REZOA3wJ7kH0+3k5/uwOPtmJX2zSRn/KjMzVrUZLKgCC7f9YxwObAzsCZwInAxWS/xM9O\nJSfLsZTR7wFcBnw9td0haTnwfeCViLijNfvYXrTxWFQ0ztSsRRQcxO+ejoP8MyKeJsvQvhYR9wBz\nyH5o9XdAM2U6AKOBcyLiP9WjHyPiLuAK4AxJA1qzn9a2OKhZiyg4hjZZ0nmSDkmz1gZOlLQDsD1w\ncUQ812odtTYj/fhZDiwBRknqEhHLACRtB/wLOCgiZrVmP9uLvJQfHdSsRUhaFziSrLw4H9gnBbnj\ngEHAj4GfR8QzrddLa23VGb2k9SUNTM13AR2BXdK8rYBfA5tGxPxW6Wg7pCL+15b5mJo1O0kjga2A\nWRFxo6R+wD7AF4GOEXGApDUiYpEveZRvBRn9z4FHJPWJiMPSKR5HSzqD7LSPn6bytdkKHNSsWUna\nlWw04z1kw/T/HhFPSLoL6ASMkfRYRLwDPtcorwrOWxxFNgr2ALLM7GpJ90bEnpKuIftx9FFEvOYf\nQE3UthOsonFQs2YjaUPgh8DREfFfSdOB6yUdGRFPSroduLs6oFn+pGt/VqRh+/2B94HDgCFkox17\nAvdLeiQidgSeqF7XAa1pchLTfEzNiqvgmMh2ZL+0e5KNcCQifgH8GZgoaUREvO+All/p9I4dge9K\nOoDsuOpC4AVgf+DqiFhIlumvnz5TZg1yULOiSiWknclKSM+SnWC9hqRvpfm/Av5AdrKs2TPA3sB1\nwM0R8S5ZUjEb2FjSCWSlyL0i4vHW62b7VsyRjx79aLkiaTPgJOCaiJgG3A9MBjaXdCpARFwUEQ/4\nArT5JKmbpIERUQVskJrvA/ZNw/aryO7csIgsoF0RES+2UndLRl5GPzqoWbF9DugP7CmpX0R8BNwN\nPAJsJqn6S8zHRPJrMPA7SWcDpwGnAt8mu0tD9bUbXycLdF+KiH/4B5A1loOarZaCY2gDJfWMiJvJ\nLlK8gOxq+2ul4yJ3AD+OiLdasbvWBkTE88B0skFEj6aT7eeSXQqrs6TJZBl+RTr52j+AiiEfF+n3\n6EdbdZLKIqJK0r5kx9BelrQ22cCQfwL7kp1bdF1EvE82CMBySFIvYFlELEpNzwG/Ao6R9GxETAae\nSdnbXsA7ETGllbpbktp4LCoaBzVrMkldI2JxCmibAD8Bvh4Rj0i6FLiN7OTqjulvN7Kh2pZDkvoA\nrwD3SnowIv4QEePTvBnAJZLGAR8Ch1TfPsbnodmqcFCzJpHUE7hI0q0R8W+yL6KXyL60iIjvSPo7\ncGZEnCvp8YiY3Ypdttb3AfBvshGNR0raHngIuCkirpK0DLgFWA58t3olB7TiystRSR9Ts6bqQXY8\n5CvpliALgLWAPQuW+RfpXmgOaJaC0xNkA4h2Bq5Jfx+QtBvZgJAdyAaF3NVa/SxtxRz72Lajo4Oa\nNYqkNQEiYgZwLdmdh48jux/aD4Gz0tX3vwf8gIIrP5hFxMVAH7IfP68CW5Nl92OBv6RlfHeGEiHp\naklzJD1X0NZH0iRJr6a/vQvmnSVpuqSXJe1T0D5C0rNp3qWNGQXroGYrJWkwcJ+kP6bsrCvZF9ED\nZMOxlwKHkpWZ1gG+FxF3eRi2AUgqT5PXkF3EehIwPiIOJRspe0xEzGul7uVCK9z5+hqy++AVOhOY\nHBFDyM5dPRNA0lCyHzfD0jqXFXxmLgdOILts2pA6tvkZDmrWGF2AdYExZPc8+zfwNWAA2fln5wCd\nIuK3EXFGRNwLPiZimYioTJOPAl8A/pcyN4C5vh9a6YmI/5LdYqrQGLJLnpH+HlzQfkNELI2IN8gO\nb2yfblfVIyKmpO+SawvWqZeDmjUoDdt/iaxs9BHwNnA48A7ZtR2/nJ7/QlKvdD0/sxWkkYxvAd8H\nuivdrdo/fHKlf8Ex9nfJjrFC9uN4RsFyM1PbgDRdu71BHv1oDUrD9ssi4kVJRwE3AD+LiD9Lupms\nJDAGeCoiPmzVzlqrKrh9TFm61FWNguA1E6j67NrW3Ip8MKCvpKkFz6+MiCsbu3L6nDTLDxoHNVup\ngsD2uKSxwN/TNfr+ALxMduK1zyvKsYKAtgdZJnZPRCypvVxEPCfpDJccW16RRy3Oi4iRTVznPUnr\nRsTsVFqck9pnAYMKlhuY2mal6drtDXKpyBqlMLCRlRvPkXRyrWUc0HJIUnkKaKPJDux/UFdAU6Ys\nIt6StIaktVq+t9aKJgLj0vQ44PaC9rGSOiu7B+MQ4LFUqlwgaVQadHZMwTr1clCzFRRcy/Ezn42C\nwDYNOBB4vqX7Z22HpE0krZlu8NmbbMDQN9INYb8gaVw60bpa9WXVepGdm9anVTqeRy1865l0AYb/\nkV3EfKak44GLgL0kvUp2jP4iqLkW6ASy++jdDZxcMLjom8CfyAaPvAas9DxG+ce1VatdQgLqLCEV\nHjNxyTG/JH0eCGBKClY/BTYk+7FcBlQAb0bEjyR1iIjl6Yo0NwM/SSPkrAVsO2JkPPDwY0XbXo+u\n5dNWofzYIpypGdD4ElL14mmdrkDvepaxEhcRD5PdCPZ1ST3Izk16DPhdRBxO9ut7mKROKaD1Bm4F\nLnBAs+bioJZzTS0hpeBXmUpI95NdIstyKt1W6BSy8xXnpXMVH5H0BbILXf8pIpalxY8AfhoRD7ZS\nd/PNt56xnOgPrC1pSkR8IOk+4HhJJ/BpCWkI8FitEtJNwOkR8Wrrdd3agoi4XVIFME3SCGAJ2fmL\nP4qIO6tL1BFxWev2NN/a+jUbi8VBLeci4uF0XcfXJW1JVkLaH3g8/eI+CDg2lZCWpWzuFuBc/+K2\nahHxL0lVwIvAZsAZEbGk4Ditj71ai3D50VxCsqKIiLvJLp+2TfXx2OpA5oDW+lr42o+txpmaAS4h\nWXFExJ3gUbFtURuPRUXjoGY1XEKyYvHnxFqLy4+2ApeQzEqURz9aXrmEZFZ68jL60Zma1csBzcza\nG2dqZmYlrvrO13ngaz+amZU4SXcDfYu4yXkRMbqI2ysaBzUzMysZPqZmJUtSpaSnJD0n6SZJa6zG\ntnaV9M80fZCkMxtYtpekb67CPs6TdFpj22stc42kLzdhX4MlPdfUPpq1dQ5qVsoWR8TWETEcWAZ8\no3Bm9U0rm7rRiJgYERc1sEgvsvtAmVkLc1CzvHgQ2CRlKC9LuhZ4DhgkaW9J/5P0RMrougNIGi3p\nJUlPAIdUb0jSVyX9Pk33l3SrpKfTY0eymx9unLLEX6blTpf0uKRnJJ1fsK2zJb0i6SGyE94bJOmE\ntJ2nJd1SK/vcU9LUtL0D0vLlkn5ZsO+vr+4badaWOahZyZPUAdiX7N5fkN114LKIGAZ8AvwI2DMi\ntgWmAt+X1AW4iuwO3yOAderZ/KXAAxGxFbAt2d3AzwReS1ni6ZL2TvvcHtgaGCFp53Q5srGpbT9g\nu0a8nH9ExHZpfy8CxxfMG5z2sT9wRXoNxwMfRcR2afsnSNqwEfsxa5c8pN9KWVdJT6XpB4E/A+sB\nb0XElNQ+ChgKPKxszHMnstvQbw68UX1rHUnXAyfWsY/dgWMA0i3oP0p3Mii0d3o8mZ53JwtyawK3\nRsSitI+JjXhNw5XdYbpX2s49BfMmpDuSvyrp9fQa9ga2LDje1jPt+5VG7Mus3XFQs1K2OCK2LmxI\ngeuTwiZgUkQcUWu5FdZbTQJ+HhF/rLWP767Ctq4BDo6IpyV9Fdi1YF7tocyR9v3tiCgMfkgavAr7\nNmvzXH60vJsCfF7SJgCSuknaFHgJGCxp47TcEfWsPxk4Ka1bnm6gupAsC6t2D3BcwbG6AZLWBv4L\nHCypa7qn3YGN6O+awGxJHYEja807VFJZ6vNGwMtp3yel5ZG0qaRujdiPWbvkTM1yLSLmpozn75I6\np+YfRcQrkk4E7pS0iKx8uWYdmzgFuFLS8UAlcFJE/E/Sw2nI/F3puNoWwP9SpvgxcFREPCHpRuBp\nYA7weCO6fA7wKDA3/S3s09vAY0AP4BvpDgt/IjvW9oSync8FDm7cu2PW/vjkazMzKxkuP5qZWclw\nUDMzs5LhoGZmZiXDQc3MzEqGg5qZmZUMBzUzMysZDmpmZlYyHNTMzKxk/H8GwLFP92vqJAAAAABJ\nRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f06826e2320>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot(actual_value = Train.actual_value, pred_value = Train.pred_value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-06-02T15:45:14.493972Z",
     "start_time": "2017-06-02T15:45:14.360700Z"
    }
   },
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "type object 'Train' has no attribute 'actual_value_'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-17-fea99b614066>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mactual_value\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTrain\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mactual_value_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpred_value\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTrain\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpred_value_\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m: type object 'Train' has no attribute 'actual_value_'"
     ]
    }
   ],
   "source": [
    "plot(actual_value = Train.actual_value_, pred_value = Train.pred_value_)"
   ]
  }
 ],
 "metadata": {
  "_draft": {
   "nbviewer_url": "https://gist.github.com/7d1ace18a82178e15ece8fc5252fce88"
  },
  "anaconda-cloud": {},
  "gist": {
   "data": {
    "description": "Hyper parameter tuning",
    "public": false
   },
   "id": "7d1ace18a82178e15ece8fc5252fce88"
  },
  "kernelspec": {
   "display_name": "Python [conda env:p3]",
   "language": "python",
   "name": "conda-env-p3-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
