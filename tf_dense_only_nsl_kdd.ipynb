{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Read Data Sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-05-14T21:32:54.208611Z",
     "start_time": "2017-05-14T21:32:53.788293Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from collections import namedtuple\n",
    "pd.set_option(\"display.max_rows\",35)\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-05-14T21:32:54.296438Z",
     "start_time": "2017-05-14T21:32:54.210243Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class dataset:\n",
    "    kdd_train_2labels = pd.read_pickle(\"dataset/kdd_train_2labels.pkl\")\n",
    "    kdd_test_2labels = pd.read_pickle(\"dataset/kdd_test_2labels.pkl\")\n",
    "    \n",
    "    kdd_train_5labels = pd.read_pickle(\"dataset/kdd_train_5labels.pkl\")\n",
    "    kdd_test_5labels = pd.read_pickle(\"dataset/kdd_test_5labels.pkl\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-05-14T21:32:54.303083Z",
     "start_time": "2017-05-14T21:32:54.298205Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(125973, 124)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.kdd_train_2labels.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-05-14T21:32:54.309267Z",
     "start_time": "2017-05-14T21:32:54.304837Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(22544, 124)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.kdd_test_2labels.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-05-14T21:32:55.030628Z",
     "start_time": "2017-05-14T21:32:54.310756Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(125973, 122)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn import model_selection as ms\n",
    "from sklearn import preprocessing as pp\n",
    "\n",
    "class preprocess:\n",
    "    \n",
    "    output_columns_2labels = ['is_Attack','is_Normal']\n",
    "    \n",
    "    x_input = dataset.kdd_train_2labels.drop(output_columns_2labels, axis = 1)\n",
    "    y_output = dataset.kdd_train_2labels.loc[:,output_columns_2labels]\n",
    "\n",
    "    x_test_input = dataset.kdd_test_2labels.drop(output_columns_2labels, axis = 1)\n",
    "    y_test = dataset.kdd_test_2labels.loc[:,output_columns_2labels]\n",
    "\n",
    "    ss = pp.StandardScaler()\n",
    "\n",
    "    x_train = ss.fit_transform(x_input)\n",
    "    x_test = ss.transform(x_test_input)\n",
    "\n",
    "    y_train = y_output.values\n",
    "    y_test = y_test.values\n",
    "\n",
    "preprocess.x_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-05-14T21:32:56.074345Z",
     "start_time": "2017-05-14T21:32:55.032301Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-05-14T21:32:56.258538Z",
     "start_time": "2017-05-14T21:32:56.076013Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class network(object):\n",
    "    \n",
    "    input_dim = 122\n",
    "    classes = 2\n",
    "    hidden_encoder_dim = 122\n",
    "    hidden_layers = 1\n",
    "    latent_dim = 18\n",
    "\n",
    "    def __init__(self, classes, hidden_layers, num_of_features):\n",
    "        self.classes = classes\n",
    "        self.hidden_layers = hidden_layers\n",
    "        self.latent_dim = num_of_features\n",
    "            \n",
    "    def build_layers(self):\n",
    "        tf.reset_default_graph()\n",
    "        #learning_rate = tf.Variable(initial_value=0.001)\n",
    "\n",
    "        input_dim = self.input_dim\n",
    "        classes = self.classes\n",
    "        hidden_encoder_dim = self.hidden_encoder_dim\n",
    "        hidden_layers = self.hidden_layers\n",
    "        latent_dim = self.latent_dim\n",
    "        \n",
    "        with tf.variable_scope(\"Input\"):\n",
    "            self.x = tf.placeholder(\"float\", shape=[None, input_dim])\n",
    "            self.y_ = tf.placeholder(\"float\", shape=[None, classes])\n",
    "            self.keep_prob = tf.placeholder(\"float\")\n",
    "        \n",
    "        with tf.variable_scope(\"Layer_Encoder\"):\n",
    "\n",
    "            hidden_encoder = tf.layers.dense(self.x, hidden_encoder_dim, activation = tf.nn.relu, kernel_regularizer=tf.nn.l2_loss)\n",
    "            hidden_encoder = tf.nn.dropout(hidden_encoder, self.keep_prob)\n",
    "            for h in range(hidden_layers - 1):\n",
    "                hidden_encoder = tf.layers.dense(hidden_encoder, latent_dim, activation = tf.nn.relu, kernel_regularizer=tf.nn.l2_loss)\n",
    "                hidden_encoder = tf.nn.dropout(hidden_encoder, self.keep_prob)\n",
    "            \n",
    "            #hidden_encoder = tf.layers.dense(self.x, latent_dim, activation = tf.nn.relu, kernel_regularizer=tf.nn.l2_loss)\n",
    "            #hidden_encoder = tf.nn.dropout(hidden_encoder, self.keep_prob)\n",
    "            \n",
    "        with tf.variable_scope(\"Layer_Dense_Softmax\"):\n",
    "            self.y = tf.layers.dense(hidden_encoder, classes, activation=tf.nn.softmax)\n",
    "            \n",
    "        with tf.variable_scope(\"Loss\"):\n",
    "            \n",
    "            loss = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(labels = self.y_, logits = self.y))\n",
    "\n",
    "            #loss = tf.clip_by_value(loss, -1e-1, 1e-1)\n",
    "            #loss = tf.where(tf.is_nan(loss), 1e-1, loss)\n",
    "            #loss = tf.where(tf.equal(loss, -1e-1), tf.random_normal(loss.shape), loss)\n",
    "            #loss = tf.where(tf.equal(loss, 1e-1), tf.random_normal(loss.shape), loss)\n",
    "            \n",
    "            self.regularized_loss = loss\n",
    "            correct_prediction = tf.equal(tf.argmax(self.y_, 1), tf.argmax(self.y, 1))\n",
    "            self.tf_accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32), name = \"Accuracy\")\n",
    "\n",
    "        with tf.variable_scope(\"Optimizer\"):\n",
    "            learning_rate=1e-5\n",
    "            optimizer = tf.train.AdamOptimizer(learning_rate)\n",
    "            gradients, variables = zip(*optimizer.compute_gradients(self.regularized_loss))\n",
    "            gradients = [\n",
    "                None if gradient is None else tf.clip_by_value(gradient, -1, 1)\n",
    "                for gradient in gradients]\n",
    "            self.train_op = optimizer.apply_gradients(zip(gradients, variables))\n",
    "            #self.train_op = optimizer.minimize(self.regularized_loss)\n",
    "            \n",
    "        # add op for merging summary\n",
    "        #self.summary_op = tf.summary.merge_all()\n",
    "        self.pred = tf.argmax(self.y, axis = 1)\n",
    "        self.actual = tf.argmax(self.y_, axis = 1)\n",
    "\n",
    "        # add Saver ops\n",
    "        self.saver = tf.train.Saver()\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-05-14T21:32:56.375655Z",
     "start_time": "2017-05-14T21:32:56.259972Z"
    },
    "collapsed": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import collections\n",
    "\n",
    "class Train:    \n",
    "    \n",
    "    result = namedtuple(\"score\", ['epoch', 'no_of_features','hidden_layers','train_score', 'test_score'])\n",
    "\n",
    "    predictions = {}\n",
    "\n",
    "    results = []\n",
    "    best_acc = 0\n",
    "    \n",
    "    def train(epochs, net, h,f):\n",
    "        batch_iterations = 200\n",
    "    \n",
    "        with tf.Session() as sess:\n",
    "            #summary_writer_train = tf.summary.FileWriter('./logs/kdd/VAE/training', graph=sess.graph)\n",
    "            #summary_writer_valid = tf.summary.FileWriter('./logs/kdd/VAE/validation')\n",
    "\n",
    "            sess.run(tf.global_variables_initializer())\n",
    "\n",
    "            for epoch in range(1, (epochs+1)):\n",
    "                x_train, x_valid, y_train, y_valid, = ms.train_test_split(preprocess.x_train, \n",
    "                                                                          preprocess.y_train, \n",
    "                                                                          test_size=0.1)\n",
    "                batch_indices = np.array_split(np.arange(x_train.shape[0]), \n",
    "                                           batch_iterations)\n",
    "                                                                          \n",
    "                for i in batch_indices:\n",
    "                    _, train_loss = sess.run([net.train_op, \n",
    "                                                           net.regularized_loss, \n",
    "                                                           ], #net.summary_op\n",
    "                                                          feed_dict={net.x: x_train[i,:], \n",
    "                                                                     net.y_: y_train[i,:], \n",
    "                                                                     net.keep_prob:0.5})\n",
    "                    \n",
    "                    #summary_writer_train.add_summary(summary_str, epoch)\n",
    "                    if(train_loss > 1e9):\n",
    "                        print(\"Step {} | Training Loss: {:.6f}\".format(epoch, train_loss))\n",
    "                    \n",
    "\n",
    "                valid_accuracy = sess.run(net.tf_accuracy, #net.summary_op \n",
    "                                                      feed_dict={net.x: x_valid, \n",
    "                                                                 net.y_: y_valid, \n",
    "                                                                 net.keep_prob:1})\n",
    "                #summary_writer_valid.add_summary(summary_str, epoch)\n",
    "\n",
    "                \n",
    "                accuracy, pred_value, actual_value, y_pred = sess.run([net.tf_accuracy, \n",
    "                                                               net.pred, \n",
    "                                                               net.actual, net.y], \n",
    "                                                              feed_dict={net.x: preprocess.x_test, \n",
    "                                                                         net.y_: preprocess.y_test, \n",
    "                                                                         net.keep_prob:1})\n",
    "\n",
    "                print(\"Step {} | Training Loss: {:.6f} | Validation Accuracy: {:.6f}\".format(epoch, train_loss, valid_accuracy))\n",
    "                print(\"Accuracy on Test data: {}\".format(accuracy))\n",
    "\n",
    "                if accuracy > Train.best_acc:\n",
    "                    Train.best_acc = accuracy\n",
    "                    Train.pred_value = pred_value\n",
    "                    Train.actual_value = actual_value\n",
    "                    Train.best_parameters = \"Hidden Layers:{}, Features Count:{}\".format(h, f)\n",
    "                    net.saver.save(sess, \n",
    "                                   \"dataset/tf_dense_only_nsl_kdd_hidden layers_{}_features count_{}\".format(h,f),\n",
    "                                    global_step = epochs)\n",
    "                    curr_pred = pd.DataFrame({\"Attack_prob\":y_pred[:,-2], \"Normal_prob\":y_pred[:, -1]})\n",
    "                    Train.predictions.update({\"{}_{}_{}\".format(epochs,f,h):curr_pred})\n",
    "\n",
    "                    Train.results.append(Train.result(epochs, f, h,valid_accuracy, accuracy))\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-05-14T21:49:47.202314Z",
     "start_time": "2017-05-14T21:32:56.377149Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current Layer Attributes - epochs:100 hidden layers:4 features count:4\n",
      "Step 1 | Training Loss: 0.694541 | Validation Accuracy: 0.736863\n",
      "Accuracy on Test data: 0.8004347085952759\n",
      "Step 2 | Training Loss: 0.704481 | Validation Accuracy: 0.774964\n",
      "Accuracy on Test data: 0.8143630027770996\n",
      "Step 3 | Training Loss: 0.683983 | Validation Accuracy: 0.802032\n",
      "Accuracy on Test data: 0.8250975608825684\n",
      "Step 4 | Training Loss: 0.691342 | Validation Accuracy: 0.850452\n",
      "Accuracy on Test data: 0.8640879988670349\n",
      "Step 5 | Training Loss: 0.670866 | Validation Accuracy: 0.872837\n",
      "Accuracy on Test data: 0.8533090949058533\n",
      "Step 6 | Training Loss: 0.675836 | Validation Accuracy: 0.897047\n",
      "Accuracy on Test data: 0.8483853936195374\n",
      "Step 7 | Training Loss: 0.668828 | Validation Accuracy: 0.909033\n",
      "Accuracy on Test data: 0.8511798977851868\n",
      "Step 8 | Training Loss: 0.674895 | Validation Accuracy: 0.918638\n",
      "Accuracy on Test data: 0.8477200269699097\n",
      "Step 9 | Training Loss: 0.669289 | Validation Accuracy: 0.921019\n",
      "Accuracy on Test data: 0.8451029062271118\n",
      "Step 10 | Training Loss: 0.671142 | Validation Accuracy: 0.927131\n",
      "Accuracy on Test data: 0.8435060381889343\n",
      "Step 11 | Training Loss: 0.654938 | Validation Accuracy: 0.925226\n",
      "Accuracy on Test data: 0.8439052700996399\n",
      "Step 12 | Training Loss: 0.667330 | Validation Accuracy: 0.932132\n",
      "Accuracy on Test data: 0.8431511521339417\n",
      "Step 13 | Training Loss: 0.655870 | Validation Accuracy: 0.935783\n",
      "Accuracy on Test data: 0.8445262312889099\n",
      "Step 14 | Training Loss: 0.657579 | Validation Accuracy: 0.939514\n",
      "Accuracy on Test data: 0.846522331237793\n",
      "Step 15 | Training Loss: 0.658289 | Validation Accuracy: 0.945229\n",
      "Accuracy on Test data: 0.846522331237793\n",
      "Step 16 | Training Loss: 0.655380 | Validation Accuracy: 0.949198\n",
      "Accuracy on Test data: 0.8464779853820801\n",
      "Step 17 | Training Loss: 0.658696 | Validation Accuracy: 0.950151\n",
      "Accuracy on Test data: 0.8442600965499878\n",
      "Step 18 | Training Loss: 0.657626 | Validation Accuracy: 0.946658\n",
      "Accuracy on Test data: 0.8431955575942993\n",
      "Step 19 | Training Loss: 0.652850 | Validation Accuracy: 0.955628\n",
      "Accuracy on Test data: 0.8409332633018494\n",
      "Step 20 | Training Loss: 0.649842 | Validation Accuracy: 0.955549\n",
      "Accuracy on Test data: 0.833525538444519\n",
      "Step 21 | Training Loss: 0.644021 | Validation Accuracy: 0.957850\n",
      "Accuracy on Test data: 0.8293115496635437\n",
      "Step 22 | Training Loss: 0.639024 | Validation Accuracy: 0.958406\n",
      "Accuracy on Test data: 0.8262509107589722\n",
      "Step 23 | Training Loss: 0.648144 | Validation Accuracy: 0.953643\n",
      "Accuracy on Test data: 0.8238555788993835\n",
      "Step 24 | Training Loss: 0.649112 | Validation Accuracy: 0.955945\n",
      "Accuracy on Test data: 0.8187100887298584\n",
      "Step 25 | Training Loss: 0.650910 | Validation Accuracy: 0.960549\n",
      "Accuracy on Test data: 0.8145847916603088\n",
      "Step 26 | Training Loss: 0.636072 | Validation Accuracy: 0.958247\n",
      "Accuracy on Test data: 0.8086852431297302\n",
      "Step 27 | Training Loss: 0.642982 | Validation Accuracy: 0.958485\n",
      "Accuracy on Test data: 0.8063342571258545\n",
      "Step 28 | Training Loss: 0.646065 | Validation Accuracy: 0.961184\n",
      "Accuracy on Test data: 0.7972409725189209\n",
      "Step 29 | Training Loss: 0.635840 | Validation Accuracy: 0.961978\n",
      "Accuracy on Test data: 0.7947125434875488\n",
      "Step 30 | Training Loss: 0.621108 | Validation Accuracy: 0.959835\n",
      "Accuracy on Test data: 0.7927608489990234\n",
      "Step 31 | Training Loss: 0.636255 | Validation Accuracy: 0.959438\n",
      "Accuracy on Test data: 0.7893009185791016\n",
      "Step 32 | Training Loss: 0.647229 | Validation Accuracy: 0.962216\n",
      "Accuracy on Test data: 0.7869943380355835\n",
      "Step 33 | Training Loss: 0.646755 | Validation Accuracy: 0.963645\n",
      "Accuracy on Test data: 0.7826472520828247\n",
      "Step 34 | Training Loss: 0.624699 | Validation Accuracy: 0.959835\n",
      "Accuracy on Test data: 0.7795422077178955\n",
      "Step 35 | Training Loss: 0.627348 | Validation Accuracy: 0.960867\n",
      "Accuracy on Test data: 0.7773243188858032\n",
      "Step 36 | Training Loss: 0.611921 | Validation Accuracy: 0.966423\n",
      "Accuracy on Test data: 0.7759048938751221\n",
      "Step 37 | Training Loss: 0.632282 | Validation Accuracy: 0.961502\n",
      "Accuracy on Test data: 0.7755056619644165\n",
      "Step 38 | Training Loss: 0.628681 | Validation Accuracy: 0.965391\n",
      "Accuracy on Test data: 0.7741749286651611\n",
      "Step 39 | Training Loss: 0.627971 | Validation Accuracy: 0.962216\n",
      "Accuracy on Test data: 0.7735095620155334\n",
      "Step 40 | Training Loss: 0.634105 | Validation Accuracy: 0.966979\n",
      "Accuracy on Test data: 0.7727998495101929\n",
      "Step 41 | Training Loss: 0.619606 | Validation Accuracy: 0.963804\n",
      "Accuracy on Test data: 0.7718683481216431\n",
      "Step 42 | Training Loss: 0.630034 | Validation Accuracy: 0.962375\n",
      "Accuracy on Test data: 0.7715134620666504\n",
      "Step 43 | Training Loss: 0.618908 | Validation Accuracy: 0.964359\n",
      "Accuracy on Test data: 0.7712473273277283\n",
      "Step 44 | Training Loss: 0.619684 | Validation Accuracy: 0.964121\n",
      "Accuracy on Test data: 0.7703601717948914\n",
      "Step 45 | Training Loss: 0.642642 | Validation Accuracy: 0.967058\n",
      "Accuracy on Test data: 0.7696948051452637\n",
      "Step 46 | Training Loss: 0.621517 | Validation Accuracy: 0.966820\n",
      "Accuracy on Test data: 0.7692512273788452\n",
      "Step 47 | Training Loss: 0.614557 | Validation Accuracy: 0.967296\n",
      "Accuracy on Test data: 0.7688519954681396\n",
      "Step 48 | Training Loss: 0.633534 | Validation Accuracy: 0.965471\n",
      "Accuracy on Test data: 0.768718957901001\n",
      "Step 49 | Training Loss: 0.619068 | Validation Accuracy: 0.963407\n",
      "Accuracy on Test data: 0.7676100134849548\n",
      "Step 50 | Training Loss: 0.608796 | Validation Accuracy: 0.965629\n",
      "Accuracy on Test data: 0.7674769163131714\n",
      "Step 51 | Training Loss: 0.624988 | Validation Accuracy: 0.964677\n",
      "Accuracy on Test data: 0.7667672038078308\n",
      "Step 52 | Training Loss: 0.618248 | Validation Accuracy: 0.965947\n",
      "Accuracy on Test data: 0.7668115496635437\n",
      "Step 53 | Training Loss: 0.625209 | Validation Accuracy: 0.965709\n",
      "Accuracy on Test data: 0.7663679718971252\n",
      "Step 54 | Training Loss: 0.622907 | Validation Accuracy: 0.965868\n",
      "Accuracy on Test data: 0.7664567232131958\n",
      "Step 55 | Training Loss: 0.610902 | Validation Accuracy: 0.966264\n",
      "Accuracy on Test data: 0.7656139135360718\n",
      "Step 56 | Training Loss: 0.618024 | Validation Accuracy: 0.967535\n",
      "Accuracy on Test data: 0.7651703357696533\n",
      "Step 57 | Training Loss: 0.613183 | Validation Accuracy: 0.965947\n",
      "Accuracy on Test data: 0.7648598551750183\n",
      "Step 58 | Training Loss: 0.608061 | Validation Accuracy: 0.966344\n",
      "Accuracy on Test data: 0.7645049691200256\n",
      "Step 59 | Training Loss: 0.610134 | Validation Accuracy: 0.963407\n",
      "Accuracy on Test data: 0.7625975608825684\n",
      "Step 60 | Training Loss: 0.604197 | Validation Accuracy: 0.968090\n",
      "Accuracy on Test data: 0.7624645233154297\n",
      "Step 61 | Training Loss: 0.594406 | Validation Accuracy: 0.965233\n",
      "Accuracy on Test data: 0.7624645233154297\n",
      "Step 62 | Training Loss: 0.602480 | Validation Accuracy: 0.965709\n",
      "Accuracy on Test data: 0.7620209455490112\n",
      "Step 63 | Training Loss: 0.618053 | Validation Accuracy: 0.969757\n",
      "Accuracy on Test data: 0.7607345581054688\n",
      "Step 64 | Training Loss: 0.610382 | Validation Accuracy: 0.967138\n",
      "Accuracy on Test data: 0.7607345581054688\n",
      "Step 65 | Training Loss: 0.606707 | Validation Accuracy: 0.966979\n",
      "Accuracy on Test data: 0.7603353261947632\n",
      "Step 66 | Training Loss: 0.593311 | Validation Accuracy: 0.967614\n",
      "Accuracy on Test data: 0.7602022886276245\n",
      "Step 67 | Training Loss: 0.601257 | Validation Accuracy: 0.966900\n",
      "Accuracy on Test data: 0.7599804997444153\n",
      "Step 68 | Training Loss: 0.594207 | Validation Accuracy: 0.966106\n",
      "Accuracy on Test data: 0.7599361538887024\n",
      "Step 69 | Training Loss: 0.598539 | Validation Accuracy: 0.967376\n",
      "Accuracy on Test data: 0.7595369219779968\n",
      "Step 70 | Training Loss: 0.613622 | Validation Accuracy: 0.966900\n",
      "Accuracy on Test data: 0.7592707872390747\n",
      "Step 71 | Training Loss: 0.596630 | Validation Accuracy: 0.966503\n",
      "Accuracy on Test data: 0.7591376900672913\n",
      "Step 72 | Training Loss: 0.616963 | Validation Accuracy: 0.968249\n",
      "Accuracy on Test data: 0.7590045928955078\n",
      "Step 73 | Training Loss: 0.580672 | Validation Accuracy: 0.968725\n",
      "Accuracy on Test data: 0.7588272094726562\n",
      "Step 74 | Training Loss: 0.597835 | Validation Accuracy: 0.965391\n",
      "Accuracy on Test data: 0.7588715553283691\n",
      "Step 75 | Training Loss: 0.596122 | Validation Accuracy: 0.966503\n",
      "Accuracy on Test data: 0.7587384581565857\n",
      "Step 76 | Training Loss: 0.596793 | Validation Accuracy: 0.968249\n",
      "Accuracy on Test data: 0.7585166692733765\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 77 | Training Loss: 0.596902 | Validation Accuracy: 0.967931\n",
      "Accuracy on Test data: 0.7585610151290894\n",
      "Step 78 | Training Loss: 0.599263 | Validation Accuracy: 0.969598\n",
      "Accuracy on Test data: 0.7582061886787415\n",
      "Step 79 | Training Loss: 0.592224 | Validation Accuracy: 0.968090\n",
      "Accuracy on Test data: 0.7582948803901672\n",
      "Step 80 | Training Loss: 0.588135 | Validation Accuracy: 0.969122\n",
      "Accuracy on Test data: 0.7581174373626709\n",
      "Step 81 | Training Loss: 0.606941 | Validation Accuracy: 0.967852\n",
      "Accuracy on Test data: 0.7578956484794617\n",
      "Step 82 | Training Loss: 0.588714 | Validation Accuracy: 0.966503\n",
      "Accuracy on Test data: 0.7578513026237488\n",
      "Step 83 | Training Loss: 0.594029 | Validation Accuracy: 0.969519\n",
      "Accuracy on Test data: 0.7576295137405396\n",
      "Step 84 | Training Loss: 0.596955 | Validation Accuracy: 0.967455\n",
      "Accuracy on Test data: 0.7576295137405396\n",
      "Step 85 | Training Loss: 0.585315 | Validation Accuracy: 0.967693\n",
      "Accuracy on Test data: 0.7576738595962524\n",
      "Step 86 | Training Loss: 0.600661 | Validation Accuracy: 0.966106\n",
      "Accuracy on Test data: 0.7575851678848267\n",
      "Step 87 | Training Loss: 0.612616 | Validation Accuracy: 0.968170\n",
      "Accuracy on Test data: 0.7573633790016174\n",
      "Step 88 | Training Loss: 0.593496 | Validation Accuracy: 0.971107\n",
      "Accuracy on Test data: 0.757230281829834\n",
      "Step 89 | Training Loss: 0.589222 | Validation Accuracy: 0.968646\n",
      "Accuracy on Test data: 0.757230281829834\n",
      "Step 90 | Training Loss: 0.587810 | Validation Accuracy: 0.968805\n",
      "Accuracy on Test data: 0.7569641470909119\n",
      "Step 91 | Training Loss: 0.594286 | Validation Accuracy: 0.971742\n",
      "Accuracy on Test data: 0.7566980123519897\n",
      "Step 92 | Training Loss: 0.590083 | Validation Accuracy: 0.968646\n",
      "Accuracy on Test data: 0.7567423582077026\n",
      "Step 93 | Training Loss: 0.601507 | Validation Accuracy: 0.968566\n",
      "Accuracy on Test data: 0.7567423582077026\n",
      "Step 94 | Training Loss: 0.574360 | Validation Accuracy: 0.970710\n",
      "Accuracy on Test data: 0.7566980123519897\n",
      "Step 95 | Training Loss: 0.590514 | Validation Accuracy: 0.972138\n",
      "Accuracy on Test data: 0.7562987804412842\n",
      "Step 96 | Training Loss: 0.575668 | Validation Accuracy: 0.969598\n",
      "Accuracy on Test data: 0.7563431262969971\n",
      "Step 97 | Training Loss: 0.585963 | Validation Accuracy: 0.970075\n",
      "Accuracy on Test data: 0.756609320640564\n",
      "Step 98 | Training Loss: 0.573036 | Validation Accuracy: 0.968487\n",
      "Accuracy on Test data: 0.7564318776130676\n",
      "Step 99 | Training Loss: 0.577837 | Validation Accuracy: 0.970075\n",
      "Accuracy on Test data: 0.7562544345855713\n",
      "Step 100 | Training Loss: 0.579168 | Validation Accuracy: 0.971503\n",
      "Accuracy on Test data: 0.7560326457023621\n",
      "Current Layer Attributes - epochs:100 hidden layers:4 features count:8\n",
      "Step 1 | Training Loss: 0.685676 | Validation Accuracy: 0.459835\n",
      "Accuracy on Test data: 0.46375975012779236\n",
      "Step 2 | Training Loss: 0.693360 | Validation Accuracy: 0.481902\n",
      "Accuracy on Test data: 0.4776880741119385\n",
      "Step 3 | Training Loss: 0.686417 | Validation Accuracy: 0.745198\n",
      "Accuracy on Test data: 0.771602213382721\n",
      "Step 4 | Training Loss: 0.685538 | Validation Accuracy: 0.793062\n",
      "Accuracy on Test data: 0.7982168197631836\n",
      "Step 5 | Training Loss: 0.682142 | Validation Accuracy: 0.825449\n",
      "Accuracy on Test data: 0.824609637260437\n",
      "Step 6 | Training Loss: 0.692191 | Validation Accuracy: 0.849103\n",
      "Accuracy on Test data: 0.8296220898628235\n",
      "Step 7 | Training Loss: 0.692230 | Validation Accuracy: 0.861565\n",
      "Accuracy on Test data: 0.832061767578125\n",
      "Step 8 | Training Loss: 0.675867 | Validation Accuracy: 0.869344\n",
      "Accuracy on Test data: 0.832682728767395\n",
      "Step 9 | Training Loss: 0.673203 | Validation Accuracy: 0.872361\n",
      "Accuracy on Test data: 0.8330376148223877\n",
      "Step 10 | Training Loss: 0.687473 | Validation Accuracy: 0.881965\n",
      "Accuracy on Test data: 0.8353441953659058\n",
      "Step 11 | Training Loss: 0.665899 | Validation Accuracy: 0.892443\n",
      "Accuracy on Test data: 0.8376064300537109\n",
      "Step 12 | Training Loss: 0.676378 | Validation Accuracy: 0.895142\n",
      "Accuracy on Test data: 0.838981568813324\n",
      "Step 13 | Training Loss: 0.673435 | Validation Accuracy: 0.904747\n",
      "Accuracy on Test data: 0.8287349343299866\n",
      "Step 14 | Training Loss: 0.663432 | Validation Accuracy: 0.908239\n",
      "Accuracy on Test data: 0.8327714800834656\n",
      "Step 15 | Training Loss: 0.655688 | Validation Accuracy: 0.915701\n",
      "Accuracy on Test data: 0.8349006175994873\n",
      "Step 16 | Training Loss: 0.665161 | Validation Accuracy: 0.915939\n",
      "Accuracy on Test data: 0.8383162021636963\n",
      "Step 17 | Training Loss: 0.659605 | Validation Accuracy: 0.917368\n",
      "Accuracy on Test data: 0.8414212465286255\n",
      "Step 18 | Training Loss: 0.662822 | Validation Accuracy: 0.922527\n",
      "Accuracy on Test data: 0.8438608646392822\n",
      "Step 19 | Training Loss: 0.652344 | Validation Accuracy: 0.927052\n",
      "Accuracy on Test data: 0.8466554284095764\n",
      "Step 20 | Training Loss: 0.668731 | Validation Accuracy: 0.932211\n",
      "Accuracy on Test data: 0.8494055867195129\n",
      "Step 21 | Training Loss: 0.654500 | Validation Accuracy: 0.933561\n",
      "Accuracy on Test data: 0.8532647490501404\n",
      "Step 22 | Training Loss: 0.650432 | Validation Accuracy: 0.936260\n",
      "Accuracy on Test data: 0.8544180393218994\n",
      "Step 23 | Training Loss: 0.639066 | Validation Accuracy: 0.936577\n",
      "Accuracy on Test data: 0.8546841740608215\n",
      "Step 24 | Training Loss: 0.634599 | Validation Accuracy: 0.940705\n",
      "Accuracy on Test data: 0.8552164435386658\n",
      "Step 25 | Training Loss: 0.649103 | Validation Accuracy: 0.940943\n",
      "Accuracy on Test data: 0.8561035990715027\n",
      "Step 26 | Training Loss: 0.657167 | Validation Accuracy: 0.942054\n",
      "Accuracy on Test data: 0.8560592532157898\n",
      "Step 27 | Training Loss: 0.628949 | Validation Accuracy: 0.946341\n",
      "Accuracy on Test data: 0.8573899865150452\n",
      "Step 28 | Training Loss: 0.636337 | Validation Accuracy: 0.946738\n",
      "Accuracy on Test data: 0.8576561212539673\n",
      "Step 29 | Training Loss: 0.642202 | Validation Accuracy: 0.946182\n",
      "Accuracy on Test data: 0.8576117753982544\n",
      "Step 30 | Training Loss: 0.625503 | Validation Accuracy: 0.948325\n",
      "Accuracy on Test data: 0.855970561504364\n",
      "Step 31 | Training Loss: 0.633550 | Validation Accuracy: 0.949040\n",
      "Accuracy on Test data: 0.8541962504386902\n",
      "Step 32 | Training Loss: 0.625054 | Validation Accuracy: 0.949198\n",
      "Accuracy on Test data: 0.85224449634552\n",
      "Step 33 | Training Loss: 0.630485 | Validation Accuracy: 0.946738\n",
      "Accuracy on Test data: 0.8512686491012573\n",
      "Step 34 | Training Loss: 0.611422 | Validation Accuracy: 0.950468\n",
      "Accuracy on Test data: 0.8503371477127075\n",
      "Step 35 | Training Loss: 0.632040 | Validation Accuracy: 0.949992\n",
      "Accuracy on Test data: 0.8498048186302185\n",
      "Step 36 | Training Loss: 0.627923 | Validation Accuracy: 0.950151\n",
      "Accuracy on Test data: 0.8489176630973816\n",
      "Step 37 | Training Loss: 0.617125 | Validation Accuracy: 0.948404\n",
      "Accuracy on Test data: 0.8481636047363281\n",
      "Step 38 | Training Loss: 0.606363 | Validation Accuracy: 0.949595\n",
      "Accuracy on Test data: 0.8457239270210266\n",
      "Step 39 | Training Loss: 0.595257 | Validation Accuracy: 0.948643\n",
      "Accuracy on Test data: 0.8435947299003601\n",
      "Step 40 | Training Loss: 0.601736 | Validation Accuracy: 0.954199\n",
      "Accuracy on Test data: 0.8427519798278809\n",
      "Step 41 | Training Loss: 0.629761 | Validation Accuracy: 0.954834\n",
      "Accuracy on Test data: 0.8426188826560974\n",
      "Step 42 | Training Loss: 0.608838 | Validation Accuracy: 0.953961\n",
      "Accuracy on Test data: 0.841598629951477\n",
      "Step 43 | Training Loss: 0.603809 | Validation Accuracy: 0.954517\n",
      "Accuracy on Test data: 0.8411550521850586\n",
      "Step 44 | Training Loss: 0.610606 | Validation Accuracy: 0.955469\n",
      "Accuracy on Test data: 0.841288149356842\n",
      "Step 45 | Training Loss: 0.604236 | Validation Accuracy: 0.953643\n",
      "Accuracy on Test data: 0.8410220146179199\n",
      "Step 46 | Training Loss: 0.616076 | Validation Accuracy: 0.953008\n",
      "Accuracy on Test data: 0.8410663604736328\n",
      "Step 47 | Training Loss: 0.593650 | Validation Accuracy: 0.958565\n",
      "Accuracy on Test data: 0.8402678966522217\n",
      "Step 48 | Training Loss: 0.610110 | Validation Accuracy: 0.953961\n",
      "Accuracy on Test data: 0.8391146063804626\n",
      "Step 49 | Training Loss: 0.598546 | Validation Accuracy: 0.954120\n",
      "Accuracy on Test data: 0.8376508355140686\n",
      "Step 50 | Training Loss: 0.572614 | Validation Accuracy: 0.955866\n",
      "Accuracy on Test data: 0.8374733924865723\n",
      "Step 51 | Training Loss: 0.600903 | Validation Accuracy: 0.958962\n",
      "Accuracy on Test data: 0.8369854688644409\n",
      "Step 52 | Training Loss: 0.595418 | Validation Accuracy: 0.960391\n",
      "Accuracy on Test data: 0.8236781358718872\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 53 | Training Loss: 0.594796 | Validation Accuracy: 0.959279\n",
      "Accuracy on Test data: 0.8148953318595886\n",
      "Step 54 | Training Loss: 0.591440 | Validation Accuracy: 0.957692\n",
      "Accuracy on Test data: 0.8107256889343262\n",
      "Step 55 | Training Loss: 0.576363 | Validation Accuracy: 0.958803\n",
      "Accuracy on Test data: 0.8089957237243652\n",
      "Step 56 | Training Loss: 0.578451 | Validation Accuracy: 0.960152\n",
      "Accuracy on Test data: 0.8052253127098083\n",
      "Step 57 | Training Loss: 0.577767 | Validation Accuracy: 0.964280\n",
      "Accuracy on Test data: 0.8046486973762512\n",
      "Step 58 | Training Loss: 0.584076 | Validation Accuracy: 0.961581\n",
      "Accuracy on Test data: 0.8031848669052124\n",
      "Step 59 | Training Loss: 0.574500 | Validation Accuracy: 0.961184\n",
      "Accuracy on Test data: 0.8022977113723755\n",
      "Step 60 | Training Loss: 0.571596 | Validation Accuracy: 0.960787\n",
      "Accuracy on Test data: 0.8014105558395386\n",
      "Step 61 | Training Loss: 0.569724 | Validation Accuracy: 0.959756\n",
      "Accuracy on Test data: 0.8001242280006409\n",
      "Step 62 | Training Loss: 0.578968 | Validation Accuracy: 0.963963\n",
      "Accuracy on Test data: 0.7990596294403076\n",
      "Step 63 | Training Loss: 0.563417 | Validation Accuracy: 0.963963\n",
      "Accuracy on Test data: 0.7974627614021301\n",
      "Step 64 | Training Loss: 0.580571 | Validation Accuracy: 0.963963\n",
      "Accuracy on Test data: 0.7964868545532227\n",
      "Step 65 | Training Loss: 0.560319 | Validation Accuracy: 0.962375\n",
      "Accuracy on Test data: 0.7957771420478821\n",
      "Step 66 | Training Loss: 0.569718 | Validation Accuracy: 0.962057\n",
      "Accuracy on Test data: 0.7954666614532471\n",
      "Step 67 | Training Loss: 0.575544 | Validation Accuracy: 0.962375\n",
      "Accuracy on Test data: 0.7951117753982544\n",
      "Step 68 | Training Loss: 0.561189 | Validation Accuracy: 0.964280\n",
      "Accuracy on Test data: 0.7943577170372009\n",
      "Step 69 | Training Loss: 0.565600 | Validation Accuracy: 0.965312\n",
      "Accuracy on Test data: 0.7937366962432861\n",
      "Step 70 | Training Loss: 0.566007 | Validation Accuracy: 0.965947\n",
      "Accuracy on Test data: 0.7930713295936584\n",
      "Step 71 | Training Loss: 0.566777 | Validation Accuracy: 0.962057\n",
      "Accuracy on Test data: 0.7924059629440308\n",
      "Step 72 | Training Loss: 0.575590 | Validation Accuracy: 0.962772\n",
      "Accuracy on Test data: 0.7915631532669067\n",
      "Step 73 | Training Loss: 0.551870 | Validation Accuracy: 0.963486\n",
      "Accuracy on Test data: 0.7913413643836975\n",
      "Step 74 | Training Loss: 0.551340 | Validation Accuracy: 0.965312\n",
      "Accuracy on Test data: 0.7911195755004883\n",
      "Step 75 | Training Loss: 0.549706 | Validation Accuracy: 0.964994\n",
      "Accuracy on Test data: 0.7911639213562012\n",
      "Step 76 | Training Loss: 0.543471 | Validation Accuracy: 0.965471\n",
      "Accuracy on Test data: 0.7909421324729919\n",
      "Step 77 | Training Loss: 0.563370 | Validation Accuracy: 0.967376\n",
      "Accuracy on Test data: 0.7909865379333496\n",
      "Step 78 | Training Loss: 0.547362 | Validation Accuracy: 0.966344\n",
      "Accuracy on Test data: 0.7908534407615662\n",
      "Step 79 | Training Loss: 0.553874 | Validation Accuracy: 0.964518\n",
      "Accuracy on Test data: 0.7905429601669312\n",
      "Step 80 | Training Loss: 0.545047 | Validation Accuracy: 0.963486\n",
      "Accuracy on Test data: 0.7903655171394348\n",
      "Step 81 | Training Loss: 0.537736 | Validation Accuracy: 0.967535\n",
      "Accuracy on Test data: 0.7899662852287292\n",
      "Step 82 | Training Loss: 0.543889 | Validation Accuracy: 0.964359\n",
      "Accuracy on Test data: 0.7898775935173035\n",
      "Step 83 | Training Loss: 0.545961 | Validation Accuracy: 0.964756\n",
      "Accuracy on Test data: 0.7899219393730164\n",
      "Step 84 | Training Loss: 0.545918 | Validation Accuracy: 0.963963\n",
      "Accuracy on Test data: 0.7897888422012329\n",
      "Step 85 | Training Loss: 0.533420 | Validation Accuracy: 0.965868\n",
      "Accuracy on Test data: 0.788901686668396\n",
      "Step 86 | Training Loss: 0.540647 | Validation Accuracy: 0.964994\n",
      "Accuracy on Test data: 0.7861515283584595\n",
      "Step 87 | Training Loss: 0.540065 | Validation Accuracy: 0.967455\n",
      "Accuracy on Test data: 0.7843772172927856\n",
      "Step 88 | Training Loss: 0.531050 | Validation Accuracy: 0.966106\n",
      "Accuracy on Test data: 0.7841997742652893\n",
      "Step 89 | Training Loss: 0.540063 | Validation Accuracy: 0.966423\n",
      "Accuracy on Test data: 0.783711850643158\n",
      "Step 90 | Training Loss: 0.534170 | Validation Accuracy: 0.966026\n",
      "Accuracy on Test data: 0.7832682728767395\n",
      "Step 91 | Training Loss: 0.536289 | Validation Accuracy: 0.965391\n",
      "Accuracy on Test data: 0.7832239270210266\n",
      "Step 92 | Training Loss: 0.517253 | Validation Accuracy: 0.963724\n",
      "Accuracy on Test data: 0.7832239270210266\n",
      "Step 93 | Training Loss: 0.528570 | Validation Accuracy: 0.967376\n",
      "Accuracy on Test data: 0.7826029062271118\n",
      "Step 94 | Training Loss: 0.530558 | Validation Accuracy: 0.968249\n",
      "Accuracy on Test data: 0.7822480201721191\n",
      "Step 95 | Training Loss: 0.526215 | Validation Accuracy: 0.967138\n",
      "Accuracy on Test data: 0.7820706367492676\n",
      "Step 96 | Training Loss: 0.533895 | Validation Accuracy: 0.965233\n",
      "Accuracy on Test data: 0.7814496159553528\n",
      "Step 97 | Training Loss: 0.520378 | Validation Accuracy: 0.967058\n",
      "Accuracy on Test data: 0.7805624604225159\n",
      "Step 98 | Training Loss: 0.527275 | Validation Accuracy: 0.970313\n",
      "Accuracy on Test data: 0.7802963256835938\n",
      "Step 99 | Training Loss: 0.512361 | Validation Accuracy: 0.969201\n",
      "Accuracy on Test data: 0.7798084020614624\n",
      "Step 100 | Training Loss: 0.523811 | Validation Accuracy: 0.966820\n",
      "Accuracy on Test data: 0.7795866131782532\n",
      "Current Layer Attributes - epochs:100 hidden layers:4 features count:32\n",
      "Step 1 | Training Loss: 0.697760 | Validation Accuracy: 0.661057\n",
      "Accuracy on Test data: 0.5530961751937866\n",
      "Step 2 | Training Loss: 0.695023 | Validation Accuracy: 0.721464\n",
      "Accuracy on Test data: 0.591864824295044\n",
      "Step 3 | Training Loss: 0.674476 | Validation Accuracy: 0.796158\n",
      "Accuracy on Test data: 0.7074165940284729\n",
      "Step 4 | Training Loss: 0.676125 | Validation Accuracy: 0.872837\n",
      "Accuracy on Test data: 0.7936035990715027\n",
      "Step 5 | Training Loss: 0.656315 | Validation Accuracy: 0.907366\n",
      "Accuracy on Test data: 0.8193311095237732\n",
      "Step 6 | Training Loss: 0.645216 | Validation Accuracy: 0.915622\n",
      "Accuracy on Test data: 0.8136089444160461\n",
      "Step 7 | Training Loss: 0.627210 | Validation Accuracy: 0.922448\n",
      "Accuracy on Test data: 0.8183995485305786\n",
      "Step 8 | Training Loss: 0.628993 | Validation Accuracy: 0.924591\n",
      "Accuracy on Test data: 0.8277590274810791\n",
      "Step 9 | Training Loss: 0.599351 | Validation Accuracy: 0.922765\n",
      "Accuracy on Test data: 0.8367193341255188\n",
      "Step 10 | Training Loss: 0.600410 | Validation Accuracy: 0.925861\n",
      "Accuracy on Test data: 0.8428406715393066\n",
      "Step 11 | Training Loss: 0.581847 | Validation Accuracy: 0.928639\n",
      "Accuracy on Test data: 0.8468328714370728\n",
      "Step 12 | Training Loss: 0.555420 | Validation Accuracy: 0.926973\n",
      "Accuracy on Test data: 0.8386266827583313\n",
      "Step 13 | Training Loss: 0.552706 | Validation Accuracy: 0.928243\n",
      "Accuracy on Test data: 0.8379613161087036\n",
      "Step 14 | Training Loss: 0.538773 | Validation Accuracy: 0.935625\n",
      "Accuracy on Test data: 0.8375177383422852\n",
      "Step 15 | Training Loss: 0.525686 | Validation Accuracy: 0.935148\n",
      "Accuracy on Test data: 0.8373402953147888\n",
      "Step 16 | Training Loss: 0.501706 | Validation Accuracy: 0.939117\n",
      "Accuracy on Test data: 0.8362757563591003\n",
      "Step 17 | Training Loss: 0.501312 | Validation Accuracy: 0.940784\n",
      "Accuracy on Test data: 0.8346788287162781\n",
      "Step 18 | Training Loss: 0.472185 | Validation Accuracy: 0.939752\n",
      "Accuracy on Test data: 0.8296220898628235\n",
      "Step 19 | Training Loss: 0.475602 | Validation Accuracy: 0.946976\n",
      "Accuracy on Test data: 0.826650083065033\n",
      "Step 20 | Training Loss: 0.456163 | Validation Accuracy: 0.947293\n",
      "Accuracy on Test data: 0.8252306580543518\n",
      "Step 21 | Training Loss: 0.461922 | Validation Accuracy: 0.950945\n",
      "Accuracy on Test data: 0.8242104053497314\n",
      "Step 22 | Training Loss: 0.458190 | Validation Accuracy: 0.951421\n",
      "Accuracy on Test data: 0.8234120011329651\n",
      "Step 23 | Training Loss: 0.457140 | Validation Accuracy: 0.960391\n",
      "Accuracy on Test data: 0.8237224817276001\n",
      "Step 24 | Training Loss: 0.438117 | Validation Accuracy: 0.956501\n",
      "Accuracy on Test data: 0.8235450387001038\n",
      "Step 25 | Training Loss: 0.436764 | Validation Accuracy: 0.960311\n",
      "Accuracy on Test data: 0.8236781358718872\n",
      "Step 26 | Training Loss: 0.428958 | Validation Accuracy: 0.963724\n",
      "Accuracy on Test data: 0.8213715553283691\n",
      "Step 27 | Training Loss: 0.416178 | Validation Accuracy: 0.962613\n",
      "Accuracy on Test data: 0.8172906041145325\n",
      "Step 28 | Training Loss: 0.409958 | Validation Accuracy: 0.961343\n",
      "Accuracy on Test data: 0.804737389087677\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 29 | Training Loss: 0.421217 | Validation Accuracy: 0.961264\n",
      "Accuracy on Test data: 0.7895227074623108\n",
      "Step 30 | Training Loss: 0.414353 | Validation Accuracy: 0.960867\n",
      "Accuracy on Test data: 0.7875709533691406\n",
      "Step 31 | Training Loss: 0.421692 | Validation Accuracy: 0.964598\n",
      "Accuracy on Test data: 0.7845990061759949\n",
      "Step 32 | Training Loss: 0.380601 | Validation Accuracy: 0.965629\n",
      "Accuracy on Test data: 0.7834900617599487\n",
      "Step 33 | Training Loss: 0.410987 | Validation Accuracy: 0.963407\n",
      "Accuracy on Test data: 0.781981885433197\n",
      "Step 34 | Training Loss: 0.402360 | Validation Accuracy: 0.965629\n",
      "Accuracy on Test data: 0.7810947299003601\n",
      "Step 35 | Training Loss: 0.402199 | Validation Accuracy: 0.967296\n",
      "Accuracy on Test data: 0.7806511521339417\n",
      "Step 36 | Training Loss: 0.385702 | Validation Accuracy: 0.968487\n",
      "Accuracy on Test data: 0.7804737687110901\n",
      "Step 37 | Training Loss: 0.379680 | Validation Accuracy: 0.967296\n",
      "Accuracy on Test data: 0.7804737687110901\n",
      "Step 38 | Training Loss: 0.383756 | Validation Accuracy: 0.968963\n",
      "Accuracy on Test data: 0.7804293632507324\n",
      "Step 39 | Training Loss: 0.387970 | Validation Accuracy: 0.968170\n",
      "Accuracy on Test data: 0.779985785484314\n",
      "Step 40 | Training Loss: 0.372760 | Validation Accuracy: 0.968487\n",
      "Accuracy on Test data: 0.7791430354118347\n",
      "Step 41 | Training Loss: 0.366569 | Validation Accuracy: 0.970392\n",
      "Accuracy on Test data: 0.7786550521850586\n",
      "Step 42 | Training Loss: 0.376851 | Validation Accuracy: 0.971186\n",
      "Accuracy on Test data: 0.7783889174461365\n",
      "Step 43 | Training Loss: 0.377197 | Validation Accuracy: 0.970154\n",
      "Accuracy on Test data: 0.7782114744186401\n",
      "Step 44 | Training Loss: 0.379838 | Validation Accuracy: 0.969757\n",
      "Accuracy on Test data: 0.7783889174461365\n",
      "Step 45 | Training Loss: 0.367912 | Validation Accuracy: 0.969440\n",
      "Accuracy on Test data: 0.7780784368515015\n",
      "Step 46 | Training Loss: 0.360525 | Validation Accuracy: 0.969757\n",
      "Accuracy on Test data: 0.7775017619132996\n",
      "Step 47 | Training Loss: 0.369666 | Validation Accuracy: 0.968170\n",
      "Accuracy on Test data: 0.7772799730300903\n",
      "Step 48 | Training Loss: 0.362219 | Validation Accuracy: 0.972297\n",
      "Accuracy on Test data: 0.7768363952636719\n",
      "Step 49 | Training Loss: 0.357377 | Validation Accuracy: 0.971662\n",
      "Accuracy on Test data: 0.7766146063804626\n",
      "Step 50 | Training Loss: 0.361184 | Validation Accuracy: 0.971424\n",
      "Accuracy on Test data: 0.7765259146690369\n",
      "Step 51 | Training Loss: 0.375444 | Validation Accuracy: 0.971107\n",
      "Accuracy on Test data: 0.7761266827583313\n",
      "Step 52 | Training Loss: 0.382197 | Validation Accuracy: 0.969995\n",
      "Accuracy on Test data: 0.7759048938751221\n",
      "Step 53 | Training Loss: 0.362487 | Validation Accuracy: 0.968566\n",
      "Accuracy on Test data: 0.7755500078201294\n",
      "Step 54 | Training Loss: 0.359786 | Validation Accuracy: 0.969360\n",
      "Accuracy on Test data: 0.775062084197998\n",
      "Step 55 | Training Loss: 0.360110 | Validation Accuracy: 0.971742\n",
      "Accuracy on Test data: 0.7745298147201538\n",
      "Step 56 | Training Loss: 0.369714 | Validation Accuracy: 0.971107\n",
      "Accuracy on Test data: 0.7745298147201538\n",
      "Step 57 | Training Loss: 0.364610 | Validation Accuracy: 0.971980\n",
      "Accuracy on Test data: 0.7741305828094482\n",
      "Step 58 | Training Loss: 0.354110 | Validation Accuracy: 0.972138\n",
      "Accuracy on Test data: 0.7734652161598206\n",
      "Step 59 | Training Loss: 0.365402 | Validation Accuracy: 0.969598\n",
      "Accuracy on Test data: 0.7731103897094727\n",
      "Step 60 | Training Loss: 0.362746 | Validation Accuracy: 0.970868\n",
      "Accuracy on Test data: 0.7727998495101929\n",
      "Step 61 | Training Loss: 0.355930 | Validation Accuracy: 0.971821\n",
      "Accuracy on Test data: 0.7728441953659058\n",
      "Step 62 | Training Loss: 0.355146 | Validation Accuracy: 0.970075\n",
      "Accuracy on Test data: 0.7723562717437744\n",
      "Step 63 | Training Loss: 0.352163 | Validation Accuracy: 0.969995\n",
      "Accuracy on Test data: 0.7725337147712708\n",
      "Step 64 | Training Loss: 0.352278 | Validation Accuracy: 0.970789\n",
      "Accuracy on Test data: 0.7721788287162781\n",
      "Step 65 | Training Loss: 0.350756 | Validation Accuracy: 0.972932\n",
      "Accuracy on Test data: 0.7718683481216431\n",
      "Step 66 | Training Loss: 0.357615 | Validation Accuracy: 0.971186\n",
      "Accuracy on Test data: 0.7715578675270081\n",
      "Step 67 | Training Loss: 0.361919 | Validation Accuracy: 0.971424\n",
      "Accuracy on Test data: 0.7715134620666504\n",
      "Step 68 | Training Loss: 0.344490 | Validation Accuracy: 0.972059\n",
      "Accuracy on Test data: 0.7715578675270081\n",
      "Step 69 | Training Loss: 0.347512 | Validation Accuracy: 0.970630\n",
      "Accuracy on Test data: 0.7711142897605896\n",
      "Step 70 | Training Loss: 0.350403 | Validation Accuracy: 0.972138\n",
      "Accuracy on Test data: 0.7708925008773804\n",
      "Step 71 | Training Loss: 0.350063 | Validation Accuracy: 0.972615\n",
      "Accuracy on Test data: 0.7707594037055969\n",
      "Step 72 | Training Loss: 0.358754 | Validation Accuracy: 0.972377\n",
      "Accuracy on Test data: 0.7705819606781006\n",
      "Step 73 | Training Loss: 0.361928 | Validation Accuracy: 0.973250\n",
      "Accuracy on Test data: 0.7704489231109619\n",
      "Step 74 | Training Loss: 0.351694 | Validation Accuracy: 0.972377\n",
      "Accuracy on Test data: 0.7701383829116821\n",
      "Step 75 | Training Loss: 0.340582 | Validation Accuracy: 0.968884\n",
      "Accuracy on Test data: 0.7705376148223877\n",
      "Step 76 | Training Loss: 0.347710 | Validation Accuracy: 0.973408\n",
      "Accuracy on Test data: 0.7705376148223877\n",
      "Step 77 | Training Loss: 0.342874 | Validation Accuracy: 0.970868\n",
      "Accuracy on Test data: 0.7704045176506042\n",
      "Step 78 | Training Loss: 0.344280 | Validation Accuracy: 0.972615\n",
      "Accuracy on Test data: 0.7697835564613342\n",
      "Step 79 | Training Loss: 0.361790 | Validation Accuracy: 0.972615\n",
      "Accuracy on Test data: 0.7693843245506287\n",
      "Step 80 | Training Loss: 0.343407 | Validation Accuracy: 0.972535\n",
      "Accuracy on Test data: 0.7692955732345581\n",
      "Step 81 | Training Loss: 0.352904 | Validation Accuracy: 0.972932\n",
      "Accuracy on Test data: 0.7688964009284973\n",
      "Step 82 | Training Loss: 0.347196 | Validation Accuracy: 0.973964\n",
      "Accuracy on Test data: 0.7686746120452881\n",
      "Step 83 | Training Loss: 0.345646 | Validation Accuracy: 0.970948\n",
      "Accuracy on Test data: 0.7681422829627991\n",
      "Step 84 | Training Loss: 0.344183 | Validation Accuracy: 0.971980\n",
      "Accuracy on Test data: 0.7679648399353027\n",
      "Step 85 | Training Loss: 0.340401 | Validation Accuracy: 0.970868\n",
      "Accuracy on Test data: 0.7672995328903198\n",
      "Step 86 | Training Loss: 0.348233 | Validation Accuracy: 0.972297\n",
      "Accuracy on Test data: 0.7672551274299622\n",
      "Step 87 | Training Loss: 0.342549 | Validation Accuracy: 0.973647\n",
      "Accuracy on Test data: 0.7670333385467529\n",
      "Step 88 | Training Loss: 0.344840 | Validation Accuracy: 0.968011\n",
      "Accuracy on Test data: 0.766678512096405\n",
      "Step 89 | Training Loss: 0.342581 | Validation Accuracy: 0.971345\n",
      "Accuracy on Test data: 0.7665897607803345\n",
      "Step 90 | Training Loss: 0.344510 | Validation Accuracy: 0.973488\n",
      "Accuracy on Test data: 0.7664567232131958\n",
      "Step 91 | Training Loss: 0.349431 | Validation Accuracy: 0.976107\n",
      "Accuracy on Test data: 0.7660131454467773\n",
      "Step 92 | Training Loss: 0.351047 | Validation Accuracy: 0.972138\n",
      "Accuracy on Test data: 0.7655695676803589\n",
      "Step 93 | Training Loss: 0.353780 | Validation Accuracy: 0.970868\n",
      "Accuracy on Test data: 0.7655695676803589\n",
      "Step 94 | Training Loss: 0.353441 | Validation Accuracy: 0.971821\n",
      "Accuracy on Test data: 0.7653921246528625\n",
      "Step 95 | Training Loss: 0.339181 | Validation Accuracy: 0.973805\n",
      "Accuracy on Test data: 0.7649485468864441\n",
      "Step 96 | Training Loss: 0.347910 | Validation Accuracy: 0.971662\n",
      "Accuracy on Test data: 0.7650372385978699\n",
      "Step 97 | Training Loss: 0.341363 | Validation Accuracy: 0.972059\n",
      "Accuracy on Test data: 0.7644162774085999\n",
      "Step 98 | Training Loss: 0.334261 | Validation Accuracy: 0.973329\n",
      "Accuracy on Test data: 0.7643275260925293\n",
      "Step 99 | Training Loss: 0.355295 | Validation Accuracy: 0.974996\n",
      "Accuracy on Test data: 0.7638839483261108\n",
      "Step 100 | Training Loss: 0.338601 | Validation Accuracy: 0.976822\n",
      "Accuracy on Test data: 0.7637065052986145\n",
      "Current Layer Attributes - epochs:100 hidden layers:4 features count:64\n",
      "Step 1 | Training Loss: 0.715986 | Validation Accuracy: 0.561518\n",
      "Accuracy on Test data: 0.5945262312889099\n",
      "Step 2 | Training Loss: 0.707838 | Validation Accuracy: 0.777346\n",
      "Accuracy on Test data: 0.8020315766334534\n",
      "Step 3 | Training Loss: 0.674392 | Validation Accuracy: 0.898158\n",
      "Accuracy on Test data: 0.851091206073761\n",
      "Step 4 | Training Loss: 0.653829 | Validation Accuracy: 0.902524\n",
      "Accuracy on Test data: 0.8376064300537109\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 5 | Training Loss: 0.609877 | Validation Accuracy: 0.908716\n",
      "Accuracy on Test data: 0.8219925761222839\n",
      "Step 6 | Training Loss: 0.615432 | Validation Accuracy: 0.916574\n",
      "Accuracy on Test data: 0.8202182650566101\n",
      "Step 7 | Training Loss: 0.580660 | Validation Accuracy: 0.922289\n",
      "Accuracy on Test data: 0.819730281829834\n",
      "Step 8 | Training Loss: 0.546790 | Validation Accuracy: 0.920781\n",
      "Accuracy on Test data: 0.8207061886787415\n",
      "Step 9 | Training Loss: 0.531633 | Validation Accuracy: 0.926734\n",
      "Accuracy on Test data: 0.8180890679359436\n",
      "Step 10 | Training Loss: 0.514718 | Validation Accuracy: 0.928560\n",
      "Accuracy on Test data: 0.8168026804924011\n",
      "Step 11 | Training Loss: 0.491329 | Validation Accuracy: 0.934275\n",
      "Accuracy on Test data: 0.8148509860038757\n",
      "Step 12 | Training Loss: 0.465700 | Validation Accuracy: 0.939911\n",
      "Accuracy on Test data: 0.813342809677124\n",
      "Step 13 | Training Loss: 0.472370 | Validation Accuracy: 0.946420\n",
      "Accuracy on Test data: 0.8122782111167908\n",
      "Step 14 | Training Loss: 0.446437 | Validation Accuracy: 0.952453\n",
      "Accuracy on Test data: 0.8123225569725037\n",
      "Step 15 | Training Loss: 0.442385 | Validation Accuracy: 0.953088\n",
      "Accuracy on Test data: 0.8123225569725037\n",
      "Step 16 | Training Loss: 0.418222 | Validation Accuracy: 0.955310\n",
      "Accuracy on Test data: 0.8126330971717834\n",
      "Step 17 | Training Loss: 0.410344 | Validation Accuracy: 0.957850\n",
      "Accuracy on Test data: 0.811346709728241\n",
      "Step 18 | Training Loss: 0.404507 | Validation Accuracy: 0.954517\n",
      "Accuracy on Test data: 0.8110805749893188\n",
      "Step 19 | Training Loss: 0.414533 | Validation Accuracy: 0.963963\n",
      "Accuracy on Test data: 0.8111249208450317\n",
      "Step 20 | Training Loss: 0.383761 | Validation Accuracy: 0.964518\n",
      "Accuracy on Test data: 0.8098385334014893\n",
      "Step 21 | Training Loss: 0.393084 | Validation Accuracy: 0.960549\n",
      "Accuracy on Test data: 0.8089957237243652\n",
      "Step 22 | Training Loss: 0.391960 | Validation Accuracy: 0.963010\n",
      "Accuracy on Test data: 0.8056245446205139\n",
      "Step 23 | Training Loss: 0.381217 | Validation Accuracy: 0.968408\n",
      "Accuracy on Test data: 0.803894579410553\n",
      "Step 24 | Training Loss: 0.379961 | Validation Accuracy: 0.968805\n",
      "Accuracy on Test data: 0.8025638461112976\n",
      "Step 25 | Training Loss: 0.384104 | Validation Accuracy: 0.969201\n",
      "Accuracy on Test data: 0.8015879988670349\n",
      "Step 26 | Training Loss: 0.372476 | Validation Accuracy: 0.965947\n",
      "Accuracy on Test data: 0.8010113835334778\n",
      "Step 27 | Training Loss: 0.377491 | Validation Accuracy: 0.969598\n",
      "Accuracy on Test data: 0.8005234003067017\n",
      "Step 28 | Training Loss: 0.373733 | Validation Accuracy: 0.969440\n",
      "Accuracy on Test data: 0.8001242280006409\n",
      "Step 29 | Training Loss: 0.365036 | Validation Accuracy: 0.969122\n",
      "Accuracy on Test data: 0.799858033657074\n",
      "Step 30 | Training Loss: 0.367632 | Validation Accuracy: 0.968249\n",
      "Accuracy on Test data: 0.7996362447738647\n",
      "Step 31 | Training Loss: 0.358252 | Validation Accuracy: 0.971186\n",
      "Accuracy on Test data: 0.7991926670074463\n",
      "Step 32 | Training Loss: 0.368248 | Validation Accuracy: 0.970392\n",
      "Accuracy on Test data: 0.7988821864128113\n",
      "Step 33 | Training Loss: 0.351194 | Validation Accuracy: 0.967058\n",
      "Accuracy on Test data: 0.7985273003578186\n",
      "Step 34 | Training Loss: 0.342266 | Validation Accuracy: 0.968963\n",
      "Accuracy on Test data: 0.7982168197631836\n",
      "Step 35 | Training Loss: 0.358719 | Validation Accuracy: 0.967614\n",
      "Accuracy on Test data: 0.7977732419967651\n",
      "Step 36 | Training Loss: 0.360918 | Validation Accuracy: 0.969201\n",
      "Accuracy on Test data: 0.7975514531135559\n",
      "Step 37 | Training Loss: 0.355408 | Validation Accuracy: 0.969995\n",
      "Accuracy on Test data: 0.7970635294914246\n",
      "Step 38 | Training Loss: 0.350038 | Validation Accuracy: 0.968566\n",
      "Accuracy on Test data: 0.7965312004089355\n",
      "Step 39 | Training Loss: 0.359911 | Validation Accuracy: 0.968566\n",
      "Accuracy on Test data: 0.7959989309310913\n",
      "Step 40 | Training Loss: 0.349959 | Validation Accuracy: 0.966741\n",
      "Accuracy on Test data: 0.7953335642814636\n",
      "Step 41 | Training Loss: 0.355751 | Validation Accuracy: 0.972377\n",
      "Accuracy on Test data: 0.7901437282562256\n",
      "Step 42 | Training Loss: 0.358625 | Validation Accuracy: 0.970154\n",
      "Accuracy on Test data: 0.7887242436408997\n",
      "Step 43 | Training Loss: 0.346632 | Validation Accuracy: 0.970233\n",
      "Accuracy on Test data: 0.7878371477127075\n",
      "Step 44 | Training Loss: 0.344028 | Validation Accuracy: 0.969122\n",
      "Accuracy on Test data: 0.786550760269165\n",
      "Step 45 | Training Loss: 0.351600 | Validation Accuracy: 0.970630\n",
      "Accuracy on Test data: 0.7851312756538391\n",
      "Step 46 | Training Loss: 0.345204 | Validation Accuracy: 0.971980\n",
      "Accuracy on Test data: 0.7846876978874207\n",
      "Step 47 | Training Loss: 0.347990 | Validation Accuracy: 0.971980\n",
      "Accuracy on Test data: 0.7833569645881653\n",
      "Step 48 | Training Loss: 0.356559 | Validation Accuracy: 0.971424\n",
      "Accuracy on Test data: 0.7817157506942749\n",
      "Step 49 | Training Loss: 0.358309 | Validation Accuracy: 0.971186\n",
      "Accuracy on Test data: 0.7801632285118103\n",
      "Step 50 | Training Loss: 0.355079 | Validation Accuracy: 0.972218\n",
      "Accuracy on Test data: 0.7794978618621826\n",
      "Step 51 | Training Loss: 0.346411 | Validation Accuracy: 0.970551\n",
      "Accuracy on Test data: 0.7775461077690125\n",
      "Step 52 | Training Loss: 0.356098 | Validation Accuracy: 0.972694\n",
      "Accuracy on Test data: 0.7757717967033386\n",
      "Step 53 | Training Loss: 0.344254 | Validation Accuracy: 0.976504\n",
      "Accuracy on Test data: 0.7748402953147888\n",
      "Step 54 | Training Loss: 0.352862 | Validation Accuracy: 0.971424\n",
      "Accuracy on Test data: 0.7740418910980225\n",
      "Step 55 | Training Loss: 0.356478 | Validation Accuracy: 0.974679\n",
      "Accuracy on Test data: 0.7733321785926819\n",
      "Step 56 | Training Loss: 0.339698 | Validation Accuracy: 0.972853\n",
      "Accuracy on Test data: 0.7728441953659058\n",
      "Step 57 | Training Loss: 0.347524 | Validation Accuracy: 0.971821\n",
      "Accuracy on Test data: 0.7722675800323486\n",
      "Step 58 | Training Loss: 0.347919 | Validation Accuracy: 0.973408\n",
      "Accuracy on Test data: 0.7721344828605652\n",
      "Step 59 | Training Loss: 0.350741 | Validation Accuracy: 0.974440\n",
      "Accuracy on Test data: 0.7711142897605896\n",
      "Step 60 | Training Loss: 0.339504 | Validation Accuracy: 0.974917\n",
      "Accuracy on Test data: 0.7704489231109619\n",
      "Step 61 | Training Loss: 0.340454 | Validation Accuracy: 0.974679\n",
      "Accuracy on Test data: 0.7706707119941711\n",
      "Step 62 | Training Loss: 0.336785 | Validation Accuracy: 0.972297\n",
      "Accuracy on Test data: 0.7703158259391785\n",
      "Step 63 | Training Loss: 0.348656 | Validation Accuracy: 0.973964\n",
      "Accuracy on Test data: 0.76987224817276\n",
      "Step 64 | Training Loss: 0.352935 | Validation Accuracy: 0.973012\n",
      "Accuracy on Test data: 0.7696504592895508\n",
      "Step 65 | Training Loss: 0.343084 | Validation Accuracy: 0.974758\n",
      "Accuracy on Test data: 0.7694730162620544\n",
      "Step 66 | Training Loss: 0.354475 | Validation Accuracy: 0.975314\n",
      "Accuracy on Test data: 0.7693399786949158\n",
      "Step 67 | Training Loss: 0.347457 | Validation Accuracy: 0.974599\n",
      "Accuracy on Test data: 0.7692068815231323\n",
      "Step 68 | Training Loss: 0.351940 | Validation Accuracy: 0.973805\n",
      "Accuracy on Test data: 0.7692068815231323\n",
      "Step 69 | Training Loss: 0.338883 | Validation Accuracy: 0.975075\n",
      "Accuracy on Test data: 0.7691181898117065\n",
      "Step 70 | Training Loss: 0.347245 | Validation Accuracy: 0.973250\n",
      "Accuracy on Test data: 0.7691625356674194\n",
      "Step 71 | Training Loss: 0.354618 | Validation Accuracy: 0.973647\n",
      "Accuracy on Test data: 0.7692068815231323\n",
      "Step 72 | Training Loss: 0.342115 | Validation Accuracy: 0.972932\n",
      "Accuracy on Test data: 0.7690737843513489\n",
      "Step 73 | Training Loss: 0.341929 | Validation Accuracy: 0.974043\n",
      "Accuracy on Test data: 0.769029438495636\n",
      "Step 74 | Training Loss: 0.345899 | Validation Accuracy: 0.975075\n",
      "Accuracy on Test data: 0.7691181898117065\n",
      "Step 75 | Training Loss: 0.349777 | Validation Accuracy: 0.973805\n",
      "Accuracy on Test data: 0.7690737843513489\n",
      "Step 76 | Training Loss: 0.334682 | Validation Accuracy: 0.973964\n",
      "Accuracy on Test data: 0.7691181898117065\n",
      "Step 77 | Training Loss: 0.347968 | Validation Accuracy: 0.977536\n",
      "Accuracy on Test data: 0.7687633037567139\n",
      "Step 78 | Training Loss: 0.338054 | Validation Accuracy: 0.974123\n",
      "Accuracy on Test data: 0.7681422829627991\n",
      "Step 79 | Training Loss: 0.341495 | Validation Accuracy: 0.972218\n",
      "Accuracy on Test data: 0.7678318023681641\n",
      "Step 80 | Training Loss: 0.330885 | Validation Accuracy: 0.972694\n",
      "Accuracy on Test data: 0.7677430510520935\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 81 | Training Loss: 0.356386 | Validation Accuracy: 0.973170\n",
      "Accuracy on Test data: 0.7658800482749939\n",
      "Step 82 | Training Loss: 0.332795 | Validation Accuracy: 0.975869\n",
      "Accuracy on Test data: 0.7635291218757629\n",
      "Step 83 | Training Loss: 0.349752 | Validation Accuracy: 0.976345\n",
      "Accuracy on Test data: 0.7635291218757629\n",
      "Step 84 | Training Loss: 0.338087 | Validation Accuracy: 0.976663\n",
      "Accuracy on Test data: 0.7635291218757629\n",
      "Step 85 | Training Loss: 0.343595 | Validation Accuracy: 0.972377\n",
      "Accuracy on Test data: 0.7635291218757629\n",
      "Step 86 | Training Loss: 0.356380 | Validation Accuracy: 0.974679\n",
      "Accuracy on Test data: 0.7634403705596924\n",
      "Step 87 | Training Loss: 0.347918 | Validation Accuracy: 0.975790\n",
      "Accuracy on Test data: 0.7633960247039795\n",
      "Step 88 | Training Loss: 0.349770 | Validation Accuracy: 0.973647\n",
      "Accuracy on Test data: 0.7633073329925537\n",
      "Step 89 | Training Loss: 0.347009 | Validation Accuracy: 0.976980\n",
      "Accuracy on Test data: 0.7633516788482666\n",
      "Step 90 | Training Loss: 0.350846 | Validation Accuracy: 0.977139\n",
      "Accuracy on Test data: 0.7633516788482666\n",
      "Step 91 | Training Loss: 0.345715 | Validation Accuracy: 0.976028\n",
      "Accuracy on Test data: 0.7635291218757629\n",
      "Step 92 | Training Loss: 0.343034 | Validation Accuracy: 0.975552\n",
      "Accuracy on Test data: 0.7634847164154053\n",
      "Step 93 | Training Loss: 0.345282 | Validation Accuracy: 0.977695\n",
      "Accuracy on Test data: 0.7634847164154053\n",
      "Step 94 | Training Loss: 0.343236 | Validation Accuracy: 0.975869\n",
      "Accuracy on Test data: 0.7634847164154053\n",
      "Step 95 | Training Loss: 0.342919 | Validation Accuracy: 0.976187\n",
      "Accuracy on Test data: 0.7632185816764832\n",
      "Step 96 | Training Loss: 0.346975 | Validation Accuracy: 0.978171\n",
      "Accuracy on Test data: 0.7633073329925537\n",
      "Step 97 | Training Loss: 0.341641 | Validation Accuracy: 0.974917\n",
      "Accuracy on Test data: 0.7633960247039795\n",
      "Step 98 | Training Loss: 0.337425 | Validation Accuracy: 0.977615\n",
      "Accuracy on Test data: 0.7625088691711426\n",
      "Step 99 | Training Loss: 0.351907 | Validation Accuracy: 0.975552\n",
      "Accuracy on Test data: 0.7625088691711426\n",
      "Step 100 | Training Loss: 0.342083 | Validation Accuracy: 0.974520\n",
      "Accuracy on Test data: 0.7615773677825928\n",
      "Current Layer Attributes - epochs:100 hidden layers:6 features count:4\n",
      "Step 1 | Training Loss: 0.702179 | Validation Accuracy: 0.535402\n",
      "Accuracy on Test data: 0.43075764179229736\n",
      "Step 2 | Training Loss: 0.700368 | Validation Accuracy: 0.535006\n",
      "Accuracy on Test data: 0.43075764179229736\n",
      "Step 3 | Training Loss: 0.697456 | Validation Accuracy: 0.535720\n",
      "Accuracy on Test data: 0.43075764179229736\n",
      "Step 4 | Training Loss: 0.685585 | Validation Accuracy: 0.528179\n",
      "Accuracy on Test data: 0.43075764179229736\n",
      "Step 5 | Training Loss: 0.698398 | Validation Accuracy: 0.538974\n",
      "Accuracy on Test data: 0.43075764179229736\n",
      "Step 6 | Training Loss: 0.695386 | Validation Accuracy: 0.536911\n",
      "Accuracy on Test data: 0.43075764179229736\n",
      "Step 7 | Training Loss: 0.695420 | Validation Accuracy: 0.533180\n",
      "Accuracy on Test data: 0.43075764179229736\n",
      "Step 8 | Training Loss: 0.697311 | Validation Accuracy: 0.533021\n",
      "Accuracy on Test data: 0.43075764179229736\n",
      "Step 9 | Training Loss: 0.696535 | Validation Accuracy: 0.536037\n",
      "Accuracy on Test data: 0.43075764179229736\n",
      "Step 10 | Training Loss: 0.682781 | Validation Accuracy: 0.535402\n",
      "Accuracy on Test data: 0.43075764179229736\n",
      "Step 11 | Training Loss: 0.692743 | Validation Accuracy: 0.538022\n",
      "Accuracy on Test data: 0.43075764179229736\n",
      "Step 12 | Training Loss: 0.693425 | Validation Accuracy: 0.531989\n",
      "Accuracy on Test data: 0.43075764179229736\n",
      "Step 13 | Training Loss: 0.690020 | Validation Accuracy: 0.534688\n",
      "Accuracy on Test data: 0.43075764179229736\n",
      "Step 14 | Training Loss: 0.690785 | Validation Accuracy: 0.542943\n",
      "Accuracy on Test data: 0.43075764179229736\n",
      "Step 15 | Training Loss: 0.696843 | Validation Accuracy: 0.532148\n",
      "Accuracy on Test data: 0.43075764179229736\n",
      "Step 16 | Training Loss: 0.693645 | Validation Accuracy: 0.535085\n",
      "Accuracy on Test data: 0.43075764179229736\n",
      "Step 17 | Training Loss: 0.694526 | Validation Accuracy: 0.535085\n",
      "Accuracy on Test data: 0.43075764179229736\n",
      "Step 18 | Training Loss: 0.693942 | Validation Accuracy: 0.540244\n",
      "Accuracy on Test data: 0.43075764179229736\n",
      "Step 19 | Training Loss: 0.689816 | Validation Accuracy: 0.535482\n",
      "Accuracy on Test data: 0.43075764179229736\n",
      "Step 20 | Training Loss: 0.686648 | Validation Accuracy: 0.533577\n",
      "Accuracy on Test data: 0.43075764179229736\n",
      "Step 21 | Training Loss: 0.695240 | Validation Accuracy: 0.538578\n",
      "Accuracy on Test data: 0.43075764179229736\n",
      "Step 22 | Training Loss: 0.692195 | Validation Accuracy: 0.533974\n",
      "Accuracy on Test data: 0.43075764179229736\n",
      "Step 23 | Training Loss: 0.694780 | Validation Accuracy: 0.536990\n",
      "Accuracy on Test data: 0.43075764179229736\n",
      "Step 24 | Training Loss: 0.685112 | Validation Accuracy: 0.535085\n",
      "Accuracy on Test data: 0.43075764179229736\n",
      "Step 25 | Training Loss: 0.689993 | Validation Accuracy: 0.537546\n",
      "Accuracy on Test data: 0.43075764179229736\n",
      "Step 26 | Training Loss: 0.692034 | Validation Accuracy: 0.535561\n",
      "Accuracy on Test data: 0.43075764179229736\n",
      "Step 27 | Training Loss: 0.696699 | Validation Accuracy: 0.528893\n",
      "Accuracy on Test data: 0.43075764179229736\n",
      "Step 28 | Training Loss: 0.694118 | Validation Accuracy: 0.529687\n",
      "Accuracy on Test data: 0.43075764179229736\n",
      "Step 29 | Training Loss: 0.689310 | Validation Accuracy: 0.537546\n",
      "Accuracy on Test data: 0.43075764179229736\n",
      "Step 30 | Training Loss: 0.686167 | Validation Accuracy: 0.532862\n",
      "Accuracy on Test data: 0.43075764179229736\n",
      "Step 31 | Training Loss: 0.689135 | Validation Accuracy: 0.524448\n",
      "Accuracy on Test data: 0.43075764179229736\n",
      "Step 32 | Training Loss: 0.690205 | Validation Accuracy: 0.529132\n",
      "Accuracy on Test data: 0.43075764179229736\n",
      "Step 33 | Training Loss: 0.688907 | Validation Accuracy: 0.527941\n",
      "Accuracy on Test data: 0.43075764179229736\n",
      "Step 34 | Training Loss: 0.684467 | Validation Accuracy: 0.531354\n",
      "Accuracy on Test data: 0.43075764179229736\n",
      "Step 35 | Training Loss: 0.690437 | Validation Accuracy: 0.539530\n",
      "Accuracy on Test data: 0.43075764179229736\n",
      "Step 36 | Training Loss: 0.692756 | Validation Accuracy: 0.537863\n",
      "Accuracy on Test data: 0.43075764179229736\n",
      "Step 37 | Training Loss: 0.687100 | Validation Accuracy: 0.535085\n",
      "Accuracy on Test data: 0.43075764179229736\n",
      "Step 38 | Training Loss: 0.692120 | Validation Accuracy: 0.540483\n",
      "Accuracy on Test data: 0.43075764179229736\n",
      "Step 39 | Training Loss: 0.681193 | Validation Accuracy: 0.538260\n",
      "Accuracy on Test data: 0.43075764179229736\n",
      "Step 40 | Training Loss: 0.687480 | Validation Accuracy: 0.537784\n",
      "Accuracy on Test data: 0.43075764179229736\n",
      "Step 41 | Training Loss: 0.683616 | Validation Accuracy: 0.538657\n",
      "Accuracy on Test data: 0.43075764179229736\n",
      "Step 42 | Training Loss: 0.686167 | Validation Accuracy: 0.531434\n",
      "Accuracy on Test data: 0.43075764179229736\n",
      "Step 43 | Training Loss: 0.679515 | Validation Accuracy: 0.540721\n",
      "Accuracy on Test data: 0.43075764179229736\n",
      "Step 44 | Training Loss: 0.679117 | Validation Accuracy: 0.535323\n",
      "Accuracy on Test data: 0.43075764179229736\n",
      "Step 45 | Training Loss: 0.683633 | Validation Accuracy: 0.536514\n",
      "Accuracy on Test data: 0.43075764179229736\n",
      "Step 46 | Training Loss: 0.691964 | Validation Accuracy: 0.532307\n",
      "Accuracy on Test data: 0.43075764179229736\n",
      "Step 47 | Training Loss: 0.689766 | Validation Accuracy: 0.526195\n",
      "Accuracy on Test data: 0.43075764179229736\n",
      "Step 48 | Training Loss: 0.688201 | Validation Accuracy: 0.526830\n",
      "Accuracy on Test data: 0.43075764179229736\n",
      "Step 49 | Training Loss: 0.689405 | Validation Accuracy: 0.533180\n",
      "Accuracy on Test data: 0.43075764179229736\n",
      "Step 50 | Training Loss: 0.680555 | Validation Accuracy: 0.537863\n",
      "Accuracy on Test data: 0.43075764179229736\n",
      "Step 51 | Training Loss: 0.681874 | Validation Accuracy: 0.535482\n",
      "Accuracy on Test data: 0.43075764179229736\n",
      "Step 52 | Training Loss: 0.675465 | Validation Accuracy: 0.535641\n",
      "Accuracy on Test data: 0.43075764179229736\n",
      "Step 53 | Training Loss: 0.682285 | Validation Accuracy: 0.532545\n",
      "Accuracy on Test data: 0.43075764179229736\n",
      "Step 54 | Training Loss: 0.685639 | Validation Accuracy: 0.532942\n",
      "Accuracy on Test data: 0.43075764179229736\n",
      "Step 55 | Training Loss: 0.669645 | Validation Accuracy: 0.536117\n",
      "Accuracy on Test data: 0.43075764179229736\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 56 | Training Loss: 0.680395 | Validation Accuracy: 0.533339\n",
      "Accuracy on Test data: 0.43075764179229736\n",
      "Step 57 | Training Loss: 0.687015 | Validation Accuracy: 0.533497\n",
      "Accuracy on Test data: 0.43075764179229736\n",
      "Step 58 | Training Loss: 0.677017 | Validation Accuracy: 0.534847\n",
      "Accuracy on Test data: 0.43075764179229736\n",
      "Step 59 | Training Loss: 0.681358 | Validation Accuracy: 0.536355\n",
      "Accuracy on Test data: 0.43075764179229736\n",
      "Step 60 | Training Loss: 0.678423 | Validation Accuracy: 0.537228\n",
      "Accuracy on Test data: 0.43075764179229736\n",
      "Step 61 | Training Loss: 0.668685 | Validation Accuracy: 0.532148\n",
      "Accuracy on Test data: 0.43075764179229736\n",
      "Step 62 | Training Loss: 0.684250 | Validation Accuracy: 0.532227\n",
      "Accuracy on Test data: 0.43075764179229736\n",
      "Step 63 | Training Loss: 0.686641 | Validation Accuracy: 0.529449\n",
      "Accuracy on Test data: 0.43075764179229736\n",
      "Step 64 | Training Loss: 0.670216 | Validation Accuracy: 0.526036\n",
      "Accuracy on Test data: 0.43075764179229736\n",
      "Step 65 | Training Loss: 0.678812 | Validation Accuracy: 0.534609\n",
      "Accuracy on Test data: 0.43075764179229736\n",
      "Step 66 | Training Loss: 0.666158 | Validation Accuracy: 0.535641\n",
      "Accuracy on Test data: 0.43075764179229736\n",
      "Step 67 | Training Loss: 0.674247 | Validation Accuracy: 0.536911\n",
      "Accuracy on Test data: 0.43075764179229736\n",
      "Step 68 | Training Loss: 0.685397 | Validation Accuracy: 0.539133\n",
      "Accuracy on Test data: 0.43075764179229736\n",
      "Step 69 | Training Loss: 0.666881 | Validation Accuracy: 0.534291\n",
      "Accuracy on Test data: 0.43075764179229736\n",
      "Step 70 | Training Loss: 0.677193 | Validation Accuracy: 0.541038\n",
      "Accuracy on Test data: 0.43075764179229736\n",
      "Step 71 | Training Loss: 0.671489 | Validation Accuracy: 0.538101\n",
      "Accuracy on Test data: 0.43075764179229736\n",
      "Step 72 | Training Loss: 0.668598 | Validation Accuracy: 0.528179\n",
      "Accuracy on Test data: 0.43075764179229736\n",
      "Step 73 | Training Loss: 0.675838 | Validation Accuracy: 0.523655\n",
      "Accuracy on Test data: 0.43075764179229736\n",
      "Step 74 | Training Loss: 0.666553 | Validation Accuracy: 0.526988\n",
      "Accuracy on Test data: 0.43075764179229736\n",
      "Step 75 | Training Loss: 0.679902 | Validation Accuracy: 0.532783\n",
      "Accuracy on Test data: 0.43075764179229736\n",
      "Step 76 | Training Loss: 0.674836 | Validation Accuracy: 0.534609\n",
      "Accuracy on Test data: 0.43075764179229736\n",
      "Step 77 | Training Loss: 0.678506 | Validation Accuracy: 0.527544\n",
      "Accuracy on Test data: 0.43075764179229736\n",
      "Step 78 | Training Loss: 0.669792 | Validation Accuracy: 0.539054\n",
      "Accuracy on Test data: 0.43075764179229736\n",
      "Step 79 | Training Loss: 0.674121 | Validation Accuracy: 0.533974\n",
      "Accuracy on Test data: 0.43075764179229736\n",
      "Step 80 | Training Loss: 0.674929 | Validation Accuracy: 0.541038\n",
      "Accuracy on Test data: 0.43075764179229736\n",
      "Step 81 | Training Loss: 0.685457 | Validation Accuracy: 0.533894\n",
      "Accuracy on Test data: 0.43075764179229736\n",
      "Step 82 | Training Loss: 0.669297 | Validation Accuracy: 0.533339\n",
      "Accuracy on Test data: 0.43075764179229736\n",
      "Step 83 | Training Loss: 0.669323 | Validation Accuracy: 0.531830\n",
      "Accuracy on Test data: 0.43075764179229736\n",
      "Step 84 | Training Loss: 0.665538 | Validation Accuracy: 0.537704\n",
      "Accuracy on Test data: 0.43075764179229736\n",
      "Step 85 | Training Loss: 0.663915 | Validation Accuracy: 0.536672\n",
      "Accuracy on Test data: 0.43075764179229736\n",
      "Step 86 | Training Loss: 0.678631 | Validation Accuracy: 0.535641\n",
      "Accuracy on Test data: 0.43075764179229736\n",
      "Step 87 | Training Loss: 0.665141 | Validation Accuracy: 0.535085\n",
      "Accuracy on Test data: 0.43075764179229736\n",
      "Step 88 | Training Loss: 0.672655 | Validation Accuracy: 0.540403\n",
      "Accuracy on Test data: 0.43075764179229736\n",
      "Step 89 | Training Loss: 0.666043 | Validation Accuracy: 0.535561\n",
      "Accuracy on Test data: 0.43075764179229736\n",
      "Step 90 | Training Loss: 0.660114 | Validation Accuracy: 0.536434\n",
      "Accuracy on Test data: 0.43075764179229736\n",
      "Step 91 | Training Loss: 0.667826 | Validation Accuracy: 0.535958\n",
      "Accuracy on Test data: 0.43075764179229736\n",
      "Step 92 | Training Loss: 0.667507 | Validation Accuracy: 0.537466\n",
      "Accuracy on Test data: 0.43075764179229736\n",
      "Step 93 | Training Loss: 0.670633 | Validation Accuracy: 0.539213\n",
      "Accuracy on Test data: 0.43075764179229736\n",
      "Step 94 | Training Loss: 0.664687 | Validation Accuracy: 0.543737\n",
      "Accuracy on Test data: 0.43075764179229736\n",
      "Step 95 | Training Loss: 0.665381 | Validation Accuracy: 0.532942\n",
      "Accuracy on Test data: 0.43075764179229736\n",
      "Step 96 | Training Loss: 0.658359 | Validation Accuracy: 0.533736\n",
      "Accuracy on Test data: 0.43075764179229736\n",
      "Step 97 | Training Loss: 0.666887 | Validation Accuracy: 0.538578\n",
      "Accuracy on Test data: 0.43075764179229736\n",
      "Step 98 | Training Loss: 0.664866 | Validation Accuracy: 0.530481\n",
      "Accuracy on Test data: 0.43075764179229736\n",
      "Step 99 | Training Loss: 0.663629 | Validation Accuracy: 0.536514\n",
      "Accuracy on Test data: 0.43075764179229736\n",
      "Step 100 | Training Loss: 0.668211 | Validation Accuracy: 0.536672\n",
      "Accuracy on Test data: 0.43075764179229736\n",
      "Current Layer Attributes - epochs:100 hidden layers:6 features count:8\n",
      "Step 1 | Training Loss: 0.719208 | Validation Accuracy: 0.466503\n",
      "Accuracy on Test data: 0.5148598551750183\n",
      "Step 2 | Training Loss: 0.699906 | Validation Accuracy: 0.464280\n",
      "Accuracy on Test data: 0.4496096670627594\n",
      "Step 3 | Training Loss: 0.700157 | Validation Accuracy: 0.532862\n",
      "Accuracy on Test data: 0.48496273159980774\n",
      "Step 4 | Training Loss: 0.709843 | Validation Accuracy: 0.599619\n",
      "Accuracy on Test data: 0.5479063391685486\n",
      "Step 5 | Training Loss: 0.702615 | Validation Accuracy: 0.645499\n",
      "Accuracy on Test data: 0.5725691914558411\n",
      "Step 6 | Training Loss: 0.690395 | Validation Accuracy: 0.594221\n",
      "Accuracy on Test data: 0.5571770668029785\n",
      "Step 7 | Training Loss: 0.694494 | Validation Accuracy: 0.601603\n",
      "Accuracy on Test data: 0.541474461555481\n",
      "Step 8 | Training Loss: 0.697992 | Validation Accuracy: 0.635339\n",
      "Accuracy on Test data: 0.5260823369026184\n",
      "Step 9 | Training Loss: 0.694990 | Validation Accuracy: 0.628830\n",
      "Accuracy on Test data: 0.5199609398841858\n",
      "Step 10 | Training Loss: 0.690271 | Validation Accuracy: 0.622242\n",
      "Accuracy on Test data: 0.5100248456001282\n",
      "Step 11 | Training Loss: 0.690260 | Validation Accuracy: 0.605731\n",
      "Accuracy on Test data: 0.5005766749382019\n",
      "Step 12 | Training Loss: 0.687449 | Validation Accuracy: 0.597952\n",
      "Accuracy on Test data: 0.49268096685409546\n",
      "Step 13 | Training Loss: 0.690885 | Validation Accuracy: 0.586363\n",
      "Accuracy on Test data: 0.4853619635105133\n",
      "Step 14 | Training Loss: 0.693883 | Validation Accuracy: 0.583982\n",
      "Accuracy on Test data: 0.47657912969589233\n",
      "Step 15 | Training Loss: 0.695157 | Validation Accuracy: 0.567789\n",
      "Accuracy on Test data: 0.46438077092170715\n",
      "Step 16 | Training Loss: 0.688539 | Validation Accuracy: 0.557390\n",
      "Accuracy on Test data: 0.45848119258880615\n",
      "Step 17 | Training Loss: 0.690134 | Validation Accuracy: 0.551040\n",
      "Accuracy on Test data: 0.44628283381462097\n",
      "Step 18 | Training Loss: 0.699549 | Validation Accuracy: 0.547230\n",
      "Accuracy on Test data: 0.44783535599708557\n",
      "Step 19 | Training Loss: 0.692953 | Validation Accuracy: 0.535482\n",
      "Accuracy on Test data: 0.45129525661468506\n",
      "Step 20 | Training Loss: 0.693518 | Validation Accuracy: 0.543181\n",
      "Accuracy on Test data: 0.4489886462688446\n",
      "Step 21 | Training Loss: 0.684066 | Validation Accuracy: 0.540244\n",
      "Accuracy on Test data: 0.44725868105888367\n",
      "Step 22 | Training Loss: 0.680195 | Validation Accuracy: 0.540721\n",
      "Accuracy on Test data: 0.44512951374053955\n",
      "Step 23 | Training Loss: 0.694903 | Validation Accuracy: 0.535006\n",
      "Accuracy on Test data: 0.44477465748786926\n",
      "Step 24 | Training Loss: 0.673186 | Validation Accuracy: 0.533418\n",
      "Accuracy on Test data: 0.44481903314590454\n",
      "Step 25 | Training Loss: 0.685340 | Validation Accuracy: 0.539133\n",
      "Accuracy on Test data: 0.44477465748786926\n",
      "Step 26 | Training Loss: 0.674674 | Validation Accuracy: 0.535879\n",
      "Accuracy on Test data: 0.44455286860466003\n",
      "Step 27 | Training Loss: 0.680558 | Validation Accuracy: 0.533021\n",
      "Accuracy on Test data: 0.4437100887298584\n",
      "Step 28 | Training Loss: 0.688352 | Validation Accuracy: 0.531989\n",
      "Accuracy on Test data: 0.44357699155807495\n",
      "Step 29 | Training Loss: 0.666903 | Validation Accuracy: 0.532069\n",
      "Accuracy on Test data: 0.44353264570236206\n",
      "Step 30 | Training Loss: 0.672738 | Validation Accuracy: 0.531592\n",
      "Accuracy on Test data: 0.44353264570236206\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 31 | Training Loss: 0.672543 | Validation Accuracy: 0.526830\n",
      "Accuracy on Test data: 0.4427785575389862\n",
      "Step 32 | Training Loss: 0.678040 | Validation Accuracy: 0.536117\n",
      "Accuracy on Test data: 0.442556768655777\n",
      "Step 33 | Training Loss: 0.669943 | Validation Accuracy: 0.528655\n",
      "Accuracy on Test data: 0.44224628806114197\n",
      "Step 34 | Training Loss: 0.670405 | Validation Accuracy: 0.538895\n",
      "Accuracy on Test data: 0.4422019124031067\n",
      "Step 35 | Training Loss: 0.662367 | Validation Accuracy: 0.535720\n",
      "Accuracy on Test data: 0.44198012351989746\n",
      "Step 36 | Training Loss: 0.658069 | Validation Accuracy: 0.538657\n",
      "Accuracy on Test data: 0.44171398878097534\n",
      "Step 37 | Training Loss: 0.667325 | Validation Accuracy: 0.535402\n",
      "Accuracy on Test data: 0.43115684390068054\n",
      "Step 38 | Training Loss: 0.657058 | Validation Accuracy: 0.535323\n",
      "Accuracy on Test data: 0.43075764179229736\n",
      "Step 39 | Training Loss: 0.662801 | Validation Accuracy: 0.539530\n",
      "Accuracy on Test data: 0.43075764179229736\n",
      "Step 40 | Training Loss: 0.658000 | Validation Accuracy: 0.533577\n",
      "Accuracy on Test data: 0.43075764179229736\n",
      "Step 41 | Training Loss: 0.647140 | Validation Accuracy: 0.536276\n",
      "Accuracy on Test data: 0.43075764179229736\n",
      "Step 42 | Training Loss: 0.652843 | Validation Accuracy: 0.536434\n",
      "Accuracy on Test data: 0.43075764179229736\n",
      "Step 43 | Training Loss: 0.648864 | Validation Accuracy: 0.536355\n",
      "Accuracy on Test data: 0.43075764179229736\n",
      "Step 44 | Training Loss: 0.651982 | Validation Accuracy: 0.535482\n",
      "Accuracy on Test data: 0.43075764179229736\n",
      "Step 45 | Training Loss: 0.653296 | Validation Accuracy: 0.528100\n",
      "Accuracy on Test data: 0.43075764179229736\n",
      "Step 46 | Training Loss: 0.631043 | Validation Accuracy: 0.899428\n",
      "Accuracy on Test data: 0.7144251465797424\n",
      "Step 47 | Training Loss: 0.625248 | Validation Accuracy: 0.929116\n",
      "Accuracy on Test data: 0.7299503087997437\n",
      "Step 48 | Training Loss: 0.622943 | Validation Accuracy: 0.948643\n",
      "Accuracy on Test data: 0.7427253127098083\n",
      "Step 49 | Training Loss: 0.639022 | Validation Accuracy: 0.949754\n",
      "Accuracy on Test data: 0.7578069567680359\n",
      "Step 50 | Training Loss: 0.630878 | Validation Accuracy: 0.954358\n",
      "Accuracy on Test data: 0.762641966342926\n",
      "Step 51 | Training Loss: 0.624016 | Validation Accuracy: 0.954913\n",
      "Accuracy on Test data: 0.7627750039100647\n",
      "Step 52 | Training Loss: 0.611422 | Validation Accuracy: 0.954834\n",
      "Accuracy on Test data: 0.7637065052986145\n",
      "Step 53 | Training Loss: 0.620263 | Validation Accuracy: 0.961819\n",
      "Accuracy on Test data: 0.7651259899139404\n",
      "Step 54 | Training Loss: 0.617125 | Validation Accuracy: 0.962851\n",
      "Accuracy on Test data: 0.764682412147522\n",
      "Step 55 | Training Loss: 0.608699 | Validation Accuracy: 0.965312\n",
      "Accuracy on Test data: 0.7639726996421814\n",
      "Step 56 | Training Loss: 0.614986 | Validation Accuracy: 0.967614\n",
      "Accuracy on Test data: 0.763262927532196\n",
      "Step 57 | Training Loss: 0.605999 | Validation Accuracy: 0.965629\n",
      "Accuracy on Test data: 0.7623757719993591\n",
      "Step 58 | Training Loss: 0.600702 | Validation Accuracy: 0.969201\n",
      "Accuracy on Test data: 0.7622427344322205\n",
      "Step 59 | Training Loss: 0.598489 | Validation Accuracy: 0.968963\n",
      "Accuracy on Test data: 0.7618435025215149\n",
      "Step 60 | Training Loss: 0.618243 | Validation Accuracy: 0.969440\n",
      "Accuracy on Test data: 0.7617548108100891\n",
      "Step 61 | Training Loss: 0.592543 | Validation Accuracy: 0.969519\n",
      "Accuracy on Test data: 0.7618878483772278\n",
      "Step 62 | Training Loss: 0.592904 | Validation Accuracy: 0.968566\n",
      "Accuracy on Test data: 0.761799156665802\n",
      "Step 63 | Training Loss: 0.599825 | Validation Accuracy: 0.969836\n",
      "Accuracy on Test data: 0.7617548108100891\n",
      "Step 64 | Training Loss: 0.598469 | Validation Accuracy: 0.971662\n",
      "Accuracy on Test data: 0.7615330219268799\n",
      "Step 65 | Training Loss: 0.604127 | Validation Accuracy: 0.970392\n",
      "Accuracy on Test data: 0.7614886164665222\n",
      "Step 66 | Training Loss: 0.581103 | Validation Accuracy: 0.969122\n",
      "Accuracy on Test data: 0.7616217136383057\n",
      "Step 67 | Training Loss: 0.591369 | Validation Accuracy: 0.970075\n",
      "Accuracy on Test data: 0.7617104053497314\n",
      "Step 68 | Training Loss: 0.595444 | Validation Accuracy: 0.970948\n",
      "Accuracy on Test data: 0.7613999247550964\n",
      "Step 69 | Training Loss: 0.578743 | Validation Accuracy: 0.966741\n",
      "Accuracy on Test data: 0.7608676552772522\n",
      "Step 70 | Training Loss: 0.594082 | Validation Accuracy: 0.968884\n",
      "Accuracy on Test data: 0.7606902122497559\n",
      "Step 71 | Training Loss: 0.571709 | Validation Accuracy: 0.970472\n",
      "Accuracy on Test data: 0.7605571150779724\n",
      "Step 72 | Training Loss: 0.574328 | Validation Accuracy: 0.970154\n",
      "Accuracy on Test data: 0.7602909803390503\n",
      "Step 73 | Training Loss: 0.564972 | Validation Accuracy: 0.972218\n",
      "Accuracy on Test data: 0.7599361538887024\n",
      "Step 74 | Training Loss: 0.570475 | Validation Accuracy: 0.973091\n",
      "Accuracy on Test data: 0.759758710861206\n",
      "Step 75 | Training Loss: 0.563703 | Validation Accuracy: 0.968725\n",
      "Accuracy on Test data: 0.7595812678337097\n",
      "Step 76 | Training Loss: 0.583050 | Validation Accuracy: 0.972059\n",
      "Accuracy on Test data: 0.7594925761222839\n",
      "Step 77 | Training Loss: 0.574678 | Validation Accuracy: 0.968011\n",
      "Accuracy on Test data: 0.7594038248062134\n",
      "Step 78 | Training Loss: 0.562589 | Validation Accuracy: 0.971662\n",
      "Accuracy on Test data: 0.7594925761222839\n",
      "Step 79 | Training Loss: 0.579002 | Validation Accuracy: 0.970710\n",
      "Accuracy on Test data: 0.7594925761222839\n",
      "Step 80 | Training Loss: 0.572585 | Validation Accuracy: 0.970948\n",
      "Accuracy on Test data: 0.7594038248062134\n",
      "Step 81 | Training Loss: 0.567517 | Validation Accuracy: 0.971503\n",
      "Accuracy on Test data: 0.7591820359230042\n",
      "Step 82 | Training Loss: 0.569083 | Validation Accuracy: 0.969757\n",
      "Accuracy on Test data: 0.7590489983558655\n",
      "Step 83 | Training Loss: 0.558237 | Validation Accuracy: 0.970313\n",
      "Accuracy on Test data: 0.758915901184082\n",
      "Step 84 | Training Loss: 0.559722 | Validation Accuracy: 0.972694\n",
      "Accuracy on Test data: 0.7588272094726562\n",
      "Step 85 | Training Loss: 0.561274 | Validation Accuracy: 0.968884\n",
      "Accuracy on Test data: 0.7585166692733765\n",
      "Step 86 | Training Loss: 0.554703 | Validation Accuracy: 0.969598\n",
      "Accuracy on Test data: 0.7583392262458801\n",
      "Step 87 | Training Loss: 0.552053 | Validation Accuracy: 0.972377\n",
      "Accuracy on Test data: 0.7581618428230286\n",
      "Step 88 | Training Loss: 0.557862 | Validation Accuracy: 0.971107\n",
      "Accuracy on Test data: 0.758073091506958\n",
      "Step 89 | Training Loss: 0.560819 | Validation Accuracy: 0.971662\n",
      "Accuracy on Test data: 0.7579400539398193\n",
      "Step 90 | Training Loss: 0.562917 | Validation Accuracy: 0.970233\n",
      "Accuracy on Test data: 0.7578513026237488\n",
      "Step 91 | Training Loss: 0.546815 | Validation Accuracy: 0.968963\n",
      "Accuracy on Test data: 0.7578513026237488\n",
      "Step 92 | Training Loss: 0.543098 | Validation Accuracy: 0.973170\n",
      "Accuracy on Test data: 0.757762610912323\n",
      "Step 93 | Training Loss: 0.552619 | Validation Accuracy: 0.972218\n",
      "Accuracy on Test data: 0.7576738595962524\n",
      "Step 94 | Training Loss: 0.553053 | Validation Accuracy: 0.969757\n",
      "Accuracy on Test data: 0.7577182650566101\n",
      "Step 95 | Training Loss: 0.544207 | Validation Accuracy: 0.970948\n",
      "Accuracy on Test data: 0.757762610912323\n",
      "Step 96 | Training Loss: 0.553843 | Validation Accuracy: 0.970789\n",
      "Accuracy on Test data: 0.757762610912323\n",
      "Step 97 | Training Loss: 0.556800 | Validation Accuracy: 0.970630\n",
      "Accuracy on Test data: 0.7577182650566101\n",
      "Step 98 | Training Loss: 0.543190 | Validation Accuracy: 0.970551\n",
      "Accuracy on Test data: 0.7577182650566101\n",
      "Step 99 | Training Loss: 0.529669 | Validation Accuracy: 0.970630\n",
      "Accuracy on Test data: 0.7577182650566101\n",
      "Step 100 | Training Loss: 0.542283 | Validation Accuracy: 0.971265\n",
      "Accuracy on Test data: 0.7576295137405396\n",
      "Current Layer Attributes - epochs:100 hidden layers:6 features count:32\n",
      "Step 1 | Training Loss: 0.704868 | Validation Accuracy: 0.763693\n",
      "Accuracy on Test data: 0.8228353261947632\n",
      "Step 2 | Training Loss: 0.681895 | Validation Accuracy: 0.788617\n",
      "Accuracy on Test data: 0.8253193497657776\n",
      "Step 3 | Training Loss: 0.699185 | Validation Accuracy: 0.819416\n",
      "Accuracy on Test data: 0.8273598551750183\n",
      "Step 4 | Training Loss: 0.687828 | Validation Accuracy: 0.856961\n",
      "Accuracy on Test data: 0.7932044267654419\n",
      "Step 5 | Training Loss: 0.676587 | Validation Accuracy: 0.882918\n",
      "Accuracy on Test data: 0.7971965670585632\n",
      "Step 6 | Training Loss: 0.671908 | Validation Accuracy: 0.886331\n",
      "Accuracy on Test data: 0.7982168197631836\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 7 | Training Loss: 0.665296 | Validation Accuracy: 0.902842\n",
      "Accuracy on Test data: 0.826339602470398\n",
      "Step 8 | Training Loss: 0.654973 | Validation Accuracy: 0.900460\n",
      "Accuracy on Test data: 0.8461231589317322\n",
      "Step 9 | Training Loss: 0.651225 | Validation Accuracy: 0.910065\n",
      "Accuracy on Test data: 0.8540631532669067\n",
      "Step 10 | Training Loss: 0.628961 | Validation Accuracy: 0.923718\n",
      "Accuracy on Test data: 0.8558374643325806\n",
      "Step 11 | Training Loss: 0.635476 | Validation Accuracy: 0.935069\n",
      "Accuracy on Test data: 0.8574787378311157\n",
      "Step 12 | Training Loss: 0.652570 | Validation Accuracy: 0.940705\n",
      "Accuracy on Test data: 0.8586763739585876\n",
      "Step 13 | Training Loss: 0.625304 | Validation Accuracy: 0.941261\n",
      "Accuracy on Test data: 0.862358033657074\n",
      "Step 14 | Training Loss: 0.605809 | Validation Accuracy: 0.943880\n",
      "Accuracy on Test data: 0.8645315766334534\n",
      "Step 15 | Training Loss: 0.603223 | Validation Accuracy: 0.942372\n",
      "Accuracy on Test data: 0.8674591779708862\n",
      "Step 16 | Training Loss: 0.594360 | Validation Accuracy: 0.943721\n",
      "Accuracy on Test data: 0.8681245446205139\n",
      "Step 17 | Training Loss: 0.585749 | Validation Accuracy: 0.946579\n",
      "Accuracy on Test data: 0.8682132959365845\n",
      "Step 18 | Training Loss: 0.589722 | Validation Accuracy: 0.951659\n",
      "Accuracy on Test data: 0.8674591779708862\n",
      "Step 19 | Training Loss: 0.574571 | Validation Accuracy: 0.946341\n",
      "Accuracy on Test data: 0.8684794306755066\n",
      "Step 20 | Training Loss: 0.575736 | Validation Accuracy: 0.949754\n",
      "Accuracy on Test data: 0.866926908493042\n",
      "Step 21 | Training Loss: 0.564957 | Validation Accuracy: 0.952453\n",
      "Accuracy on Test data: 0.8646646738052368\n",
      "Step 22 | Training Loss: 0.533655 | Validation Accuracy: 0.951262\n",
      "Accuracy on Test data: 0.8629347085952759\n",
      "Step 23 | Training Loss: 0.548235 | Validation Accuracy: 0.950389\n",
      "Accuracy on Test data: 0.862047553062439\n",
      "Step 24 | Training Loss: 0.526712 | Validation Accuracy: 0.951500\n",
      "Accuracy on Test data: 0.8605393767356873\n",
      "Step 25 | Training Loss: 0.540820 | Validation Accuracy: 0.952056\n",
      "Accuracy on Test data: 0.8589425086975098\n",
      "Step 26 | Training Loss: 0.540867 | Validation Accuracy: 0.951818\n",
      "Accuracy on Test data: 0.8580553531646729\n",
      "Step 27 | Training Loss: 0.524810 | Validation Accuracy: 0.951103\n",
      "Accuracy on Test data: 0.8579222559928894\n",
      "Step 28 | Training Loss: 0.534116 | Validation Accuracy: 0.955231\n",
      "Accuracy on Test data: 0.8574787378311157\n",
      "Step 29 | Training Loss: 0.517357 | Validation Accuracy: 0.952373\n",
      "Accuracy on Test data: 0.8570351600646973\n",
      "Step 30 | Training Loss: 0.515430 | Validation Accuracy: 0.950468\n",
      "Accuracy on Test data: 0.8567246198654175\n",
      "Step 31 | Training Loss: 0.497552 | Validation Accuracy: 0.959517\n",
      "Accuracy on Test data: 0.8563253879547119\n",
      "Step 32 | Training Loss: 0.507514 | Validation Accuracy: 0.958168\n",
      "Accuracy on Test data: 0.8552164435386658\n",
      "Step 33 | Training Loss: 0.484755 | Validation Accuracy: 0.952612\n",
      "Accuracy on Test data: 0.8546841740608215\n",
      "Step 34 | Training Loss: 0.473333 | Validation Accuracy: 0.956183\n",
      "Accuracy on Test data: 0.8532647490501404\n",
      "Step 35 | Training Loss: 0.496201 | Validation Accuracy: 0.955866\n",
      "Accuracy on Test data: 0.8513573408126831\n",
      "Step 36 | Training Loss: 0.475067 | Validation Accuracy: 0.958168\n",
      "Accuracy on Test data: 0.8512242436408997\n",
      "Step 37 | Training Loss: 0.469487 | Validation Accuracy: 0.956422\n",
      "Accuracy on Test data: 0.851091206073761\n",
      "Step 38 | Training Loss: 0.479693 | Validation Accuracy: 0.962851\n",
      "Accuracy on Test data: 0.8509137630462646\n",
      "Step 39 | Training Loss: 0.469619 | Validation Accuracy: 0.961026\n",
      "Accuracy on Test data: 0.8505589365959167\n",
      "Step 40 | Training Loss: 0.443229 | Validation Accuracy: 0.959517\n",
      "Accuracy on Test data: 0.8503814935684204\n",
      "Step 41 | Training Loss: 0.433681 | Validation Accuracy: 0.961661\n",
      "Accuracy on Test data: 0.8502927422523499\n",
      "Step 42 | Training Loss: 0.449443 | Validation Accuracy: 0.962057\n",
      "Accuracy on Test data: 0.8498935699462891\n",
      "Step 43 | Training Loss: 0.448468 | Validation Accuracy: 0.964836\n",
      "Accuracy on Test data: 0.8500266075134277\n",
      "Step 44 | Training Loss: 0.448976 | Validation Accuracy: 0.965550\n",
      "Accuracy on Test data: 0.8500709533691406\n",
      "Step 45 | Training Loss: 0.450149 | Validation Accuracy: 0.964598\n",
      "Accuracy on Test data: 0.849937915802002\n",
      "Step 46 | Training Loss: 0.425192 | Validation Accuracy: 0.964518\n",
      "Accuracy on Test data: 0.8499822616577148\n",
      "Step 47 | Training Loss: 0.423240 | Validation Accuracy: 0.961978\n",
      "Accuracy on Test data: 0.8498935699462891\n",
      "Step 48 | Training Loss: 0.437843 | Validation Accuracy: 0.962772\n",
      "Accuracy on Test data: 0.8501597046852112\n",
      "Step 49 | Training Loss: 0.420975 | Validation Accuracy: 0.967296\n",
      "Accuracy on Test data: 0.8502040505409241\n",
      "Step 50 | Training Loss: 0.434499 | Validation Accuracy: 0.965153\n",
      "Accuracy on Test data: 0.8501153588294983\n",
      "Step 51 | Training Loss: 0.414605 | Validation Accuracy: 0.965471\n",
      "Accuracy on Test data: 0.850248396396637\n",
      "Step 52 | Training Loss: 0.416922 | Validation Accuracy: 0.966106\n",
      "Accuracy on Test data: 0.8448367714881897\n",
      "Step 53 | Training Loss: 0.415975 | Validation Accuracy: 0.964280\n",
      "Accuracy on Test data: 0.843328595161438\n",
      "Step 54 | Training Loss: 0.405218 | Validation Accuracy: 0.964598\n",
      "Accuracy on Test data: 0.8419091701507568\n",
      "Step 55 | Training Loss: 0.414889 | Validation Accuracy: 0.969757\n",
      "Accuracy on Test data: 0.8356990814208984\n",
      "Step 56 | Training Loss: 0.411048 | Validation Accuracy: 0.968725\n",
      "Accuracy on Test data: 0.8309971690177917\n",
      "Step 57 | Training Loss: 0.395287 | Validation Accuracy: 0.965788\n",
      "Accuracy on Test data: 0.8247427344322205\n",
      "Step 58 | Training Loss: 0.399299 | Validation Accuracy: 0.966106\n",
      "Accuracy on Test data: 0.8217707872390747\n",
      "Step 59 | Training Loss: 0.417216 | Validation Accuracy: 0.967058\n",
      "Accuracy on Test data: 0.8200408220291138\n",
      "Step 60 | Training Loss: 0.404393 | Validation Accuracy: 0.966264\n",
      "Accuracy on Test data: 0.8192867040634155\n",
      "Step 61 | Training Loss: 0.394716 | Validation Accuracy: 0.969836\n",
      "Accuracy on Test data: 0.818576991558075\n",
      "Step 62 | Training Loss: 0.382291 | Validation Accuracy: 0.966979\n",
      "Accuracy on Test data: 0.818222165107727\n",
      "Step 63 | Training Loss: 0.399323 | Validation Accuracy: 0.968249\n",
      "Accuracy on Test data: 0.8179116249084473\n",
      "Step 64 | Training Loss: 0.386321 | Validation Accuracy: 0.967693\n",
      "Accuracy on Test data: 0.8174237012863159\n",
      "Step 65 | Training Loss: 0.376476 | Validation Accuracy: 0.966820\n",
      "Accuracy on Test data: 0.8160486221313477\n",
      "Step 66 | Training Loss: 0.366035 | Validation Accuracy: 0.969519\n",
      "Accuracy on Test data: 0.802741289138794\n",
      "Step 67 | Training Loss: 0.375491 | Validation Accuracy: 0.966979\n",
      "Accuracy on Test data: 0.7911195755004883\n",
      "Step 68 | Training Loss: 0.378870 | Validation Accuracy: 0.965153\n",
      "Accuracy on Test data: 0.7889460325241089\n",
      "Step 69 | Training Loss: 0.393256 | Validation Accuracy: 0.969360\n",
      "Accuracy on Test data: 0.7870386838912964\n",
      "Step 70 | Training Loss: 0.375829 | Validation Accuracy: 0.969678\n",
      "Accuracy on Test data: 0.7851312756538391\n",
      "Step 71 | Training Loss: 0.370271 | Validation Accuracy: 0.969360\n",
      "Accuracy on Test data: 0.7846433520317078\n",
      "Step 72 | Training Loss: 0.371166 | Validation Accuracy: 0.966026\n",
      "Accuracy on Test data: 0.7843328714370728\n",
      "Step 73 | Training Loss: 0.383413 | Validation Accuracy: 0.967614\n",
      "Accuracy on Test data: 0.7830908298492432\n",
      "Step 74 | Training Loss: 0.381235 | Validation Accuracy: 0.967614\n",
      "Accuracy on Test data: 0.7819375395774841\n",
      "Step 75 | Training Loss: 0.371097 | Validation Accuracy: 0.968487\n",
      "Accuracy on Test data: 0.7817157506942749\n",
      "Step 76 | Training Loss: 0.382800 | Validation Accuracy: 0.966106\n",
      "Accuracy on Test data: 0.7814052700996399\n",
      "Step 77 | Training Loss: 0.379503 | Validation Accuracy: 0.968725\n",
      "Accuracy on Test data: 0.7810947299003601\n",
      "Step 78 | Training Loss: 0.374783 | Validation Accuracy: 0.971424\n",
      "Accuracy on Test data: 0.7809173464775085\n",
      "Step 79 | Training Loss: 0.361300 | Validation Accuracy: 0.965947\n",
      "Accuracy on Test data: 0.7810503840446472\n",
      "Step 80 | Training Loss: 0.359350 | Validation Accuracy: 0.970313\n",
      "Accuracy on Test data: 0.780828595161438\n",
      "Step 81 | Training Loss: 0.368246 | Validation Accuracy: 0.968725\n",
      "Accuracy on Test data: 0.7806068062782288\n",
      "Step 82 | Training Loss: 0.359514 | Validation Accuracy: 0.966741\n",
      "Accuracy on Test data: 0.7802963256835938\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 83 | Training Loss: 0.361596 | Validation Accuracy: 0.969836\n",
      "Accuracy on Test data: 0.7801188826560974\n",
      "Step 84 | Training Loss: 0.368858 | Validation Accuracy: 0.969916\n",
      "Accuracy on Test data: 0.7801632285118103\n",
      "Step 85 | Training Loss: 0.360999 | Validation Accuracy: 0.972138\n",
      "Accuracy on Test data: 0.7801632285118103\n",
      "Step 86 | Training Loss: 0.366121 | Validation Accuracy: 0.970392\n",
      "Accuracy on Test data: 0.7797639966011047\n",
      "Step 87 | Training Loss: 0.350091 | Validation Accuracy: 0.970710\n",
      "Accuracy on Test data: 0.7795422077178955\n",
      "Step 88 | Training Loss: 0.360225 | Validation Accuracy: 0.971186\n",
      "Accuracy on Test data: 0.7795866131782532\n",
      "Step 89 | Training Loss: 0.364111 | Validation Accuracy: 0.974599\n",
      "Accuracy on Test data: 0.7792760729789734\n",
      "Step 90 | Training Loss: 0.374574 | Validation Accuracy: 0.972932\n",
      "Accuracy on Test data: 0.7792760729789734\n",
      "Step 91 | Training Loss: 0.357061 | Validation Accuracy: 0.973805\n",
      "Accuracy on Test data: 0.7790542840957642\n",
      "Step 92 | Training Loss: 0.362499 | Validation Accuracy: 0.972932\n",
      "Accuracy on Test data: 0.7789212465286255\n",
      "Step 93 | Training Loss: 0.346430 | Validation Accuracy: 0.971900\n",
      "Accuracy on Test data: 0.7788324952125549\n",
      "Step 94 | Training Loss: 0.360635 | Validation Accuracy: 0.971662\n",
      "Accuracy on Test data: 0.7786107063293457\n",
      "Step 95 | Training Loss: 0.364195 | Validation Accuracy: 0.972059\n",
      "Accuracy on Test data: 0.7785663604736328\n",
      "Step 96 | Training Loss: 0.370202 | Validation Accuracy: 0.970710\n",
      "Accuracy on Test data: 0.7785663604736328\n",
      "Step 97 | Training Loss: 0.359114 | Validation Accuracy: 0.971900\n",
      "Accuracy on Test data: 0.7786107063293457\n",
      "Step 98 | Training Loss: 0.366251 | Validation Accuracy: 0.972694\n",
      "Accuracy on Test data: 0.7783889174461365\n",
      "Step 99 | Training Loss: 0.351779 | Validation Accuracy: 0.971742\n",
      "Accuracy on Test data: 0.7784332633018494\n",
      "Step 100 | Training Loss: 0.357494 | Validation Accuracy: 0.971186\n",
      "Accuracy on Test data: 0.778477668762207\n",
      "Current Layer Attributes - epochs:100 hidden layers:6 features count:64\n",
      "Step 1 | Training Loss: 0.722754 | Validation Accuracy: 0.534132\n",
      "Accuracy on Test data: 0.43075764179229736\n",
      "Step 2 | Training Loss: 0.728326 | Validation Accuracy: 0.558501\n",
      "Accuracy on Test data: 0.4531139135360718\n",
      "Step 3 | Training Loss: 0.713446 | Validation Accuracy: 0.576203\n",
      "Accuracy on Test data: 0.4636266827583313\n",
      "Step 4 | Training Loss: 0.711794 | Validation Accuracy: 0.618908\n",
      "Accuracy on Test data: 0.4854063093662262\n",
      "Step 5 | Training Loss: 0.700227 | Validation Accuracy: 0.710827\n",
      "Accuracy on Test data: 0.6000266075134277\n",
      "Step 6 | Training Loss: 0.694707 | Validation Accuracy: 0.788220\n",
      "Accuracy on Test data: 0.6360450387001038\n",
      "Step 7 | Training Loss: 0.677660 | Validation Accuracy: 0.832751\n",
      "Accuracy on Test data: 0.6537438035011292\n",
      "Step 8 | Training Loss: 0.675236 | Validation Accuracy: 0.856009\n",
      "Accuracy on Test data: 0.6692246198654175\n",
      "Step 9 | Training Loss: 0.661763 | Validation Accuracy: 0.871170\n",
      "Accuracy on Test data: 0.6867459416389465\n",
      "Step 10 | Training Loss: 0.658608 | Validation Accuracy: 0.889347\n",
      "Accuracy on Test data: 0.7072391510009766\n",
      "Step 11 | Training Loss: 0.630583 | Validation Accuracy: 0.897523\n",
      "Accuracy on Test data: 0.727554976940155\n",
      "Step 12 | Training Loss: 0.607673 | Validation Accuracy: 0.899428\n",
      "Accuracy on Test data: 0.7408623099327087\n",
      "Step 13 | Training Loss: 0.590175 | Validation Accuracy: 0.903953\n",
      "Accuracy on Test data: 0.7529719471931458\n",
      "Step 14 | Training Loss: 0.591494 | Validation Accuracy: 0.920464\n",
      "Accuracy on Test data: 0.7589602470397949\n",
      "Step 15 | Training Loss: 0.553983 | Validation Accuracy: 0.930227\n",
      "Accuracy on Test data: 0.7645493149757385\n",
      "Step 16 | Training Loss: 0.534747 | Validation Accuracy: 0.940149\n",
      "Accuracy on Test data: 0.7665010690689087\n",
      "Step 17 | Training Loss: 0.519729 | Validation Accuracy: 0.946023\n",
      "Accuracy on Test data: 0.7676100134849548\n",
      "Step 18 | Training Loss: 0.508313 | Validation Accuracy: 0.950548\n",
      "Accuracy on Test data: 0.7708037495613098\n",
      "Step 19 | Training Loss: 0.487722 | Validation Accuracy: 0.951659\n",
      "Accuracy on Test data: 0.7734652161598206\n",
      "Step 20 | Training Loss: 0.481730 | Validation Accuracy: 0.952532\n",
      "Accuracy on Test data: 0.7727998495101929\n",
      "Step 21 | Training Loss: 0.451447 | Validation Accuracy: 0.956422\n",
      "Accuracy on Test data: 0.7712473273277283\n",
      "Step 22 | Training Loss: 0.435257 | Validation Accuracy: 0.952215\n",
      "Accuracy on Test data: 0.7704489231109619\n",
      "Step 23 | Training Loss: 0.465337 | Validation Accuracy: 0.953247\n",
      "Accuracy on Test data: 0.7670777440071106\n",
      "Step 24 | Training Loss: 0.420784 | Validation Accuracy: 0.956739\n",
      "Accuracy on Test data: 0.7660131454467773\n",
      "Step 25 | Training Loss: 0.411918 | Validation Accuracy: 0.954278\n",
      "Accuracy on Test data: 0.7649042010307312\n",
      "Step 26 | Training Loss: 0.409519 | Validation Accuracy: 0.954040\n",
      "Accuracy on Test data: 0.7644606232643127\n",
      "Step 27 | Training Loss: 0.400379 | Validation Accuracy: 0.955787\n",
      "Accuracy on Test data: 0.7633073329925537\n",
      "Step 28 | Training Loss: 0.395662 | Validation Accuracy: 0.957215\n",
      "Accuracy on Test data: 0.760956346988678\n",
      "Step 29 | Training Loss: 0.392040 | Validation Accuracy: 0.955390\n",
      "Accuracy on Test data: 0.7602909803390503\n",
      "Step 30 | Training Loss: 0.373414 | Validation Accuracy: 0.952850\n",
      "Accuracy on Test data: 0.7594925761222839\n",
      "Step 31 | Training Loss: 0.402619 | Validation Accuracy: 0.957295\n",
      "Accuracy on Test data: 0.7586941123008728\n",
      "Step 32 | Training Loss: 0.387434 | Validation Accuracy: 0.961581\n",
      "Accuracy on Test data: 0.7581618428230286\n",
      "Step 33 | Training Loss: 0.370985 | Validation Accuracy: 0.957057\n",
      "Accuracy on Test data: 0.7578069567680359\n",
      "Step 34 | Training Loss: 0.369703 | Validation Accuracy: 0.958724\n",
      "Accuracy on Test data: 0.7570084929466248\n",
      "Step 35 | Training Loss: 0.368139 | Validation Accuracy: 0.961026\n",
      "Accuracy on Test data: 0.7566980123519897\n",
      "Step 36 | Training Loss: 0.384244 | Validation Accuracy: 0.963169\n",
      "Accuracy on Test data: 0.7555447220802307\n",
      "Step 37 | Training Loss: 0.379892 | Validation Accuracy: 0.963963\n",
      "Accuracy on Test data: 0.7559439539909363\n",
      "Step 38 | Training Loss: 0.374395 | Validation Accuracy: 0.964598\n",
      "Accuracy on Test data: 0.7560326457023621\n",
      "Step 39 | Training Loss: 0.366213 | Validation Accuracy: 0.965868\n",
      "Accuracy on Test data: 0.756609320640564\n",
      "Step 40 | Training Loss: 0.358175 | Validation Accuracy: 0.964280\n",
      "Accuracy on Test data: 0.7566536664962769\n",
      "Step 41 | Training Loss: 0.355844 | Validation Accuracy: 0.967455\n",
      "Accuracy on Test data: 0.7567423582077026\n",
      "Step 42 | Training Loss: 0.358484 | Validation Accuracy: 0.969281\n",
      "Accuracy on Test data: 0.7570084929466248\n",
      "Step 43 | Training Loss: 0.373090 | Validation Accuracy: 0.967296\n",
      "Accuracy on Test data: 0.7565649151802063\n",
      "Step 44 | Training Loss: 0.358792 | Validation Accuracy: 0.969440\n",
      "Accuracy on Test data: 0.7559882998466492\n",
      "Step 45 | Training Loss: 0.367962 | Validation Accuracy: 0.968725\n",
      "Accuracy on Test data: 0.7562987804412842\n",
      "Step 46 | Training Loss: 0.361383 | Validation Accuracy: 0.966741\n",
      "Accuracy on Test data: 0.7566536664962769\n",
      "Step 47 | Training Loss: 0.355838 | Validation Accuracy: 0.968249\n",
      "Accuracy on Test data: 0.7564762234687805\n",
      "Step 48 | Training Loss: 0.358894 | Validation Accuracy: 0.967773\n",
      "Accuracy on Test data: 0.7561657428741455\n",
      "Step 49 | Training Loss: 0.351533 | Validation Accuracy: 0.968805\n",
      "Accuracy on Test data: 0.7561213374137878\n",
      "Step 50 | Training Loss: 0.355724 | Validation Accuracy: 0.969836\n",
      "Accuracy on Test data: 0.7558552026748657\n",
      "Step 51 | Training Loss: 0.359421 | Validation Accuracy: 0.968090\n",
      "Accuracy on Test data: 0.7550123929977417\n",
      "Step 52 | Training Loss: 0.353278 | Validation Accuracy: 0.972694\n",
      "Accuracy on Test data: 0.7545244693756104\n",
      "Step 53 | Training Loss: 0.356768 | Validation Accuracy: 0.971107\n",
      "Accuracy on Test data: 0.7543914318084717\n",
      "Step 54 | Training Loss: 0.368704 | Validation Accuracy: 0.969281\n",
      "Accuracy on Test data: 0.7524840235710144\n",
      "Step 55 | Training Loss: 0.361014 | Validation Accuracy: 0.970233\n",
      "Accuracy on Test data: 0.7495120763778687\n",
      "Step 56 | Training Loss: 0.373449 | Validation Accuracy: 0.970233\n",
      "Accuracy on Test data: 0.749689519405365\n",
      "Step 57 | Training Loss: 0.352037 | Validation Accuracy: 0.970075\n",
      "Accuracy on Test data: 0.7496451139450073\n",
      "Step 58 | Training Loss: 0.361216 | Validation Accuracy: 0.971107\n",
      "Accuracy on Test data: 0.7496451139450073\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 59 | Training Loss: 0.355818 | Validation Accuracy: 0.971107\n",
      "Accuracy on Test data: 0.7492015361785889\n",
      "Step 60 | Training Loss: 0.354364 | Validation Accuracy: 0.973329\n",
      "Accuracy on Test data: 0.7490241527557373\n",
      "Step 61 | Training Loss: 0.346438 | Validation Accuracy: 0.970948\n",
      "Accuracy on Test data: 0.749157190322876\n",
      "Step 62 | Training Loss: 0.346597 | Validation Accuracy: 0.972456\n",
      "Accuracy on Test data: 0.749157190322876\n",
      "Step 63 | Training Loss: 0.343278 | Validation Accuracy: 0.972694\n",
      "Accuracy on Test data: 0.7489354014396667\n",
      "Step 64 | Training Loss: 0.352981 | Validation Accuracy: 0.971742\n",
      "Accuracy on Test data: 0.748846709728241\n",
      "Step 65 | Training Loss: 0.347310 | Validation Accuracy: 0.974837\n",
      "Accuracy on Test data: 0.7487136125564575\n",
      "Step 66 | Training Loss: 0.340203 | Validation Accuracy: 0.974282\n",
      "Accuracy on Test data: 0.7488910555839539\n",
      "Step 67 | Training Loss: 0.349443 | Validation Accuracy: 0.976107\n",
      "Accuracy on Test data: 0.749157190322876\n",
      "Step 68 | Training Loss: 0.341467 | Validation Accuracy: 0.972615\n",
      "Accuracy on Test data: 0.7490684986114502\n",
      "Step 69 | Training Loss: 0.341655 | Validation Accuracy: 0.973726\n",
      "Accuracy on Test data: 0.7488023638725281\n",
      "Step 70 | Training Loss: 0.346610 | Validation Accuracy: 0.975631\n",
      "Accuracy on Test data: 0.7486249208450317\n",
      "Step 71 | Training Loss: 0.352774 | Validation Accuracy: 0.971186\n",
      "Accuracy on Test data: 0.7481369972229004\n",
      "Step 72 | Training Loss: 0.344850 | Validation Accuracy: 0.973170\n",
      "Accuracy on Test data: 0.7480039000511169\n",
      "Step 73 | Training Loss: 0.341895 | Validation Accuracy: 0.974599\n",
      "Accuracy on Test data: 0.748314380645752\n",
      "Step 74 | Training Loss: 0.354933 | Validation Accuracy: 0.973012\n",
      "Accuracy on Test data: 0.7477377653121948\n",
      "Step 75 | Training Loss: 0.343182 | Validation Accuracy: 0.972773\n",
      "Accuracy on Test data: 0.7455198764801025\n",
      "Step 76 | Training Loss: 0.343204 | Validation Accuracy: 0.975472\n",
      "Accuracy on Test data: 0.7451649904251099\n",
      "Step 77 | Training Loss: 0.338218 | Validation Accuracy: 0.974520\n",
      "Accuracy on Test data: 0.7443222403526306\n",
      "Step 78 | Training Loss: 0.349198 | Validation Accuracy: 0.976742\n",
      "Accuracy on Test data: 0.7436124682426453\n",
      "Step 79 | Training Loss: 0.353370 | Validation Accuracy: 0.974440\n",
      "Accuracy on Test data: 0.7452980875968933\n",
      "Step 80 | Training Loss: 0.367938 | Validation Accuracy: 0.977377\n",
      "Accuracy on Test data: 0.744277834892273\n",
      "Step 81 | Training Loss: 0.349807 | Validation Accuracy: 0.975472\n",
      "Accuracy on Test data: 0.7438786625862122\n",
      "Step 82 | Training Loss: 0.364709 | Validation Accuracy: 0.973250\n",
      "Accuracy on Test data: 0.7441004514694214\n",
      "Step 83 | Training Loss: 0.340667 | Validation Accuracy: 0.973091\n",
      "Accuracy on Test data: 0.7435681223869324\n",
      "Step 84 | Training Loss: 0.348137 | Validation Accuracy: 0.976028\n",
      "Accuracy on Test data: 0.743390679359436\n",
      "Step 85 | Training Loss: 0.346794 | Validation Accuracy: 0.974361\n",
      "Accuracy on Test data: 0.743080198764801\n",
      "Step 86 | Training Loss: 0.350840 | Validation Accuracy: 0.975234\n",
      "Accuracy on Test data: 0.7431245446205139\n",
      "Step 87 | Training Loss: 0.346815 | Validation Accuracy: 0.976266\n",
      "Accuracy on Test data: 0.743080198764801\n",
      "Step 88 | Training Loss: 0.335177 | Validation Accuracy: 0.972535\n",
      "Accuracy on Test data: 0.7428140640258789\n",
      "Step 89 | Training Loss: 0.341010 | Validation Accuracy: 0.977298\n",
      "Accuracy on Test data: 0.7429471015930176\n",
      "Step 90 | Training Loss: 0.350644 | Validation Accuracy: 0.977377\n",
      "Accuracy on Test data: 0.7428584098815918\n",
      "Step 91 | Training Loss: 0.342866 | Validation Accuracy: 0.975393\n",
      "Accuracy on Test data: 0.7424591779708862\n",
      "Step 92 | Training Loss: 0.356604 | Validation Accuracy: 0.974043\n",
      "Accuracy on Test data: 0.7424148321151733\n",
      "Step 93 | Training Loss: 0.353158 | Validation Accuracy: 0.976266\n",
      "Accuracy on Test data: 0.7426809668540955\n",
      "Step 94 | Training Loss: 0.348637 | Validation Accuracy: 0.975155\n",
      "Accuracy on Test data: 0.7425479292869568\n",
      "Step 95 | Training Loss: 0.353644 | Validation Accuracy: 0.974996\n",
      "Accuracy on Test data: 0.7423261404037476\n",
      "Step 96 | Training Loss: 0.338504 | Validation Accuracy: 0.976742\n",
      "Accuracy on Test data: 0.742237389087677\n",
      "Step 97 | Training Loss: 0.346452 | Validation Accuracy: 0.977298\n",
      "Accuracy on Test data: 0.7418825626373291\n",
      "Step 98 | Training Loss: 0.342122 | Validation Accuracy: 0.976901\n",
      "Accuracy on Test data: 0.7419712543487549\n",
      "Step 99 | Training Loss: 0.333055 | Validation Accuracy: 0.976822\n",
      "Accuracy on Test data: 0.7413058876991272\n",
      "Step 100 | Training Loss: 0.353813 | Validation Accuracy: 0.978409\n",
      "Accuracy on Test data: 0.7413058876991272\n"
     ]
    }
   ],
   "source": [
    "import itertools\n",
    "class Hyperparameters:\n",
    "#    features_arr = [2, 4, 8, 16, 32, 64, 128, 256]\n",
    "#    hidden_layers_arr = [2, 4, 6, 10]\n",
    "    features_arr = [4, 8, 32, 64]\n",
    "    hidden_layers_arr = [4, 6]\n",
    "\n",
    "    epochs = [100]\n",
    "    \n",
    "    for e, h, f in itertools.product(epochs, hidden_layers_arr, features_arr):\n",
    "        print(\"Current Layer Attributes - epochs:{} hidden layers:{} features count:{}\".format(e,h,f))\n",
    "        n = network(2,h,f)\n",
    "        n.build_layers()\n",
    "        Train.train(e, n, h,f)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-05-14T21:49:47.208692Z",
     "start_time": "2017-05-14T21:49:47.203960Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_results = pd.DataFrame(Train.results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-05-14T21:49:47.251731Z",
     "start_time": "2017-05-14T21:49:47.210242Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>epoch</th>\n",
       "      <th>no_of_features</th>\n",
       "      <th>hidden_layers</th>\n",
       "      <th>train_score</th>\n",
       "      <th>test_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>618</th>\n",
       "      <td>100</td>\n",
       "      <td>32</td>\n",
       "      <td>6</td>\n",
       "      <td>0.946341</td>\n",
       "      <td>0.868479</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>616</th>\n",
       "      <td>100</td>\n",
       "      <td>32</td>\n",
       "      <td>6</td>\n",
       "      <td>0.946579</td>\n",
       "      <td>0.868213</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>615</th>\n",
       "      <td>100</td>\n",
       "      <td>32</td>\n",
       "      <td>6</td>\n",
       "      <td>0.943721</td>\n",
       "      <td>0.868125</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>617</th>\n",
       "      <td>100</td>\n",
       "      <td>32</td>\n",
       "      <td>6</td>\n",
       "      <td>0.951659</td>\n",
       "      <td>0.867459</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>614</th>\n",
       "      <td>100</td>\n",
       "      <td>32</td>\n",
       "      <td>6</td>\n",
       "      <td>0.942372</td>\n",
       "      <td>0.867459</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>619</th>\n",
       "      <td>100</td>\n",
       "      <td>32</td>\n",
       "      <td>6</td>\n",
       "      <td>0.949754</td>\n",
       "      <td>0.866927</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>620</th>\n",
       "      <td>100</td>\n",
       "      <td>32</td>\n",
       "      <td>6</td>\n",
       "      <td>0.952453</td>\n",
       "      <td>0.864665</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>613</th>\n",
       "      <td>100</td>\n",
       "      <td>32</td>\n",
       "      <td>6</td>\n",
       "      <td>0.943880</td>\n",
       "      <td>0.864532</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>100</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>0.850452</td>\n",
       "      <td>0.864088</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>621</th>\n",
       "      <td>100</td>\n",
       "      <td>32</td>\n",
       "      <td>6</td>\n",
       "      <td>0.951262</td>\n",
       "      <td>0.862935</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>612</th>\n",
       "      <td>100</td>\n",
       "      <td>32</td>\n",
       "      <td>6</td>\n",
       "      <td>0.941261</td>\n",
       "      <td>0.862358</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>622</th>\n",
       "      <td>100</td>\n",
       "      <td>32</td>\n",
       "      <td>6</td>\n",
       "      <td>0.950389</td>\n",
       "      <td>0.862048</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>623</th>\n",
       "      <td>100</td>\n",
       "      <td>32</td>\n",
       "      <td>6</td>\n",
       "      <td>0.951500</td>\n",
       "      <td>0.860539</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>624</th>\n",
       "      <td>100</td>\n",
       "      <td>32</td>\n",
       "      <td>6</td>\n",
       "      <td>0.952056</td>\n",
       "      <td>0.858943</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>611</th>\n",
       "      <td>100</td>\n",
       "      <td>32</td>\n",
       "      <td>6</td>\n",
       "      <td>0.940705</td>\n",
       "      <td>0.858676</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>625</th>\n",
       "      <td>100</td>\n",
       "      <td>32</td>\n",
       "      <td>6</td>\n",
       "      <td>0.951818</td>\n",
       "      <td>0.858055</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>626</th>\n",
       "      <td>100</td>\n",
       "      <td>32</td>\n",
       "      <td>6</td>\n",
       "      <td>0.951103</td>\n",
       "      <td>0.857922</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>463</th>\n",
       "      <td>100</td>\n",
       "      <td>4</td>\n",
       "      <td>6</td>\n",
       "      <td>0.526036</td>\n",
       "      <td>0.430758</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>464</th>\n",
       "      <td>100</td>\n",
       "      <td>4</td>\n",
       "      <td>6</td>\n",
       "      <td>0.534609</td>\n",
       "      <td>0.430758</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>465</th>\n",
       "      <td>100</td>\n",
       "      <td>4</td>\n",
       "      <td>6</td>\n",
       "      <td>0.535641</td>\n",
       "      <td>0.430758</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>466</th>\n",
       "      <td>100</td>\n",
       "      <td>4</td>\n",
       "      <td>6</td>\n",
       "      <td>0.536911</td>\n",
       "      <td>0.430758</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>467</th>\n",
       "      <td>100</td>\n",
       "      <td>4</td>\n",
       "      <td>6</td>\n",
       "      <td>0.539133</td>\n",
       "      <td>0.430758</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>468</th>\n",
       "      <td>100</td>\n",
       "      <td>4</td>\n",
       "      <td>6</td>\n",
       "      <td>0.534291</td>\n",
       "      <td>0.430758</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>469</th>\n",
       "      <td>100</td>\n",
       "      <td>4</td>\n",
       "      <td>6</td>\n",
       "      <td>0.541038</td>\n",
       "      <td>0.430758</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>470</th>\n",
       "      <td>100</td>\n",
       "      <td>4</td>\n",
       "      <td>6</td>\n",
       "      <td>0.538101</td>\n",
       "      <td>0.430758</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>471</th>\n",
       "      <td>100</td>\n",
       "      <td>4</td>\n",
       "      <td>6</td>\n",
       "      <td>0.528179</td>\n",
       "      <td>0.430758</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>472</th>\n",
       "      <td>100</td>\n",
       "      <td>4</td>\n",
       "      <td>6</td>\n",
       "      <td>0.523655</td>\n",
       "      <td>0.430758</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>473</th>\n",
       "      <td>100</td>\n",
       "      <td>4</td>\n",
       "      <td>6</td>\n",
       "      <td>0.526988</td>\n",
       "      <td>0.430758</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>474</th>\n",
       "      <td>100</td>\n",
       "      <td>4</td>\n",
       "      <td>6</td>\n",
       "      <td>0.532783</td>\n",
       "      <td>0.430758</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>475</th>\n",
       "      <td>100</td>\n",
       "      <td>4</td>\n",
       "      <td>6</td>\n",
       "      <td>0.534609</td>\n",
       "      <td>0.430758</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>477</th>\n",
       "      <td>100</td>\n",
       "      <td>4</td>\n",
       "      <td>6</td>\n",
       "      <td>0.539054</td>\n",
       "      <td>0.430758</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>478</th>\n",
       "      <td>100</td>\n",
       "      <td>4</td>\n",
       "      <td>6</td>\n",
       "      <td>0.533974</td>\n",
       "      <td>0.430758</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>479</th>\n",
       "      <td>100</td>\n",
       "      <td>4</td>\n",
       "      <td>6</td>\n",
       "      <td>0.541038</td>\n",
       "      <td>0.430758</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>400</th>\n",
       "      <td>100</td>\n",
       "      <td>4</td>\n",
       "      <td>6</td>\n",
       "      <td>0.535402</td>\n",
       "      <td>0.430758</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>800 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     epoch  no_of_features  hidden_layers  train_score  test_score\n",
       "618    100              32              6     0.946341    0.868479\n",
       "616    100              32              6     0.946579    0.868213\n",
       "615    100              32              6     0.943721    0.868125\n",
       "617    100              32              6     0.951659    0.867459\n",
       "614    100              32              6     0.942372    0.867459\n",
       "619    100              32              6     0.949754    0.866927\n",
       "620    100              32              6     0.952453    0.864665\n",
       "613    100              32              6     0.943880    0.864532\n",
       "3      100               4              4     0.850452    0.864088\n",
       "621    100              32              6     0.951262    0.862935\n",
       "612    100              32              6     0.941261    0.862358\n",
       "622    100              32              6     0.950389    0.862048\n",
       "623    100              32              6     0.951500    0.860539\n",
       "624    100              32              6     0.952056    0.858943\n",
       "611    100              32              6     0.940705    0.858676\n",
       "625    100              32              6     0.951818    0.858055\n",
       "626    100              32              6     0.951103    0.857922\n",
       "..     ...             ...            ...          ...         ...\n",
       "463    100               4              6     0.526036    0.430758\n",
       "464    100               4              6     0.534609    0.430758\n",
       "465    100               4              6     0.535641    0.430758\n",
       "466    100               4              6     0.536911    0.430758\n",
       "467    100               4              6     0.539133    0.430758\n",
       "468    100               4              6     0.534291    0.430758\n",
       "469    100               4              6     0.541038    0.430758\n",
       "470    100               4              6     0.538101    0.430758\n",
       "471    100               4              6     0.528179    0.430758\n",
       "472    100               4              6     0.523655    0.430758\n",
       "473    100               4              6     0.526988    0.430758\n",
       "474    100               4              6     0.532783    0.430758\n",
       "475    100               4              6     0.534609    0.430758\n",
       "477    100               4              6     0.539054    0.430758\n",
       "478    100               4              6     0.533974    0.430758\n",
       "479    100               4              6     0.541038    0.430758\n",
       "400    100               4              6     0.535402    0.430758\n",
       "\n",
       "[800 rows x 5 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_results.sort_values(by = 'test_score', ascending = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-05-14T21:49:47.262074Z",
     "start_time": "2017-05-14T21:49:47.253216Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pd.Panel(Train.predictions).to_pickle(\"dataset/tf_dense_only_nsl_kdd_predictions.pkl\")\n",
    "df_results.to_pickle(\"dataset/tf_dense_only_nsl_kdd_scores.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-05-14T21:49:47.325723Z",
     "start_time": "2017-05-14T21:49:47.263585Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import itertools\n",
    "\n",
    "def plot_confusion_matrix(cm, classes,\n",
    "                          normalize=False,\n",
    "                          title='Confusion matrix',\n",
    "                          cmap=plt.cm.Blues):\n",
    "    \"\"\"\n",
    "    This function prints and plots the confusion matrix.\n",
    "    Normalization can be applied by setting `normalize=True`.\n",
    "    \"\"\"\n",
    "    np.set_printoptions(precision=4)\n",
    "\n",
    "    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n",
    "    plt.title(title)\n",
    "    plt.colorbar()\n",
    "    tick_marks = np.arange(len(classes))\n",
    "    plt.xticks(tick_marks, classes, rotation=45)\n",
    "    plt.yticks(tick_marks, classes)\n",
    "\n",
    "    if normalize:\n",
    "        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "        print(\"Normalized confusion matrix\")\n",
    "    else:\n",
    "        print('Confusion matrix, without normalization')\n",
    "\n",
    "    print(cm)\n",
    "\n",
    "    thresh = cm.max() / 2.\n",
    "    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
    "        plt.text(j, i, cm[i, j].round(4),\n",
    "                 horizontalalignment=\"center\",\n",
    "                 color=\"white\" if cm[i, j] > thresh else \"black\")\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.ylabel('True label')\n",
    "    plt.xlabel('Predicted label')\n",
    "\n",
    "def plot(actual_value, pred_value):\n",
    "    from sklearn.metrics import confusion_matrix\n",
    "    cm_2labels = confusion_matrix(y_pred = pred_value, y_true = actual_value)\n",
    "    plt.figure(figsize=[6,6])\n",
    "    plot_confusion_matrix(cm_2labels, preprocess.output_columns_2labels, normalize = True,\n",
    "                         title = Train.best_parameters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-05-14T21:49:47.621094Z",
     "start_time": "2017-05-14T21:49:47.327197Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Normalized confusion matrix\n",
      "[[ 0.799   0.201 ]\n",
      " [ 0.0396  0.9604]]\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAbcAAAGeCAYAAAAXNE8VAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAAIABJREFUeJzt3XecVOXZxvHfRVVAig0RUVRUFDsWNMaQ2LBiYsNYsMSe\n19iSmGI076uJMRqNGrsG7KJGxYpKYhcUFASsWAFBQRBURGG53z/Os2RYWXZZZsucub5+zoc5/Tmz\n49xz3+c55ygiMDMzy5Nmjd0AMzOzYnNwMzOz3HFwMzOz3HFwMzOz3HFwMzOz3HFwMzOz3HFwMzOz\n3HFwMzOz3HFwMzOz3GnR2A0wM7Piat5+nYgFXxdte/H19GER0a9oG2wADm5mZjkTC76m9UYHF217\n88b8Y9WibayBOLiZmeWOQOV91qm8j97MzHLJmZuZWd4IkBq7FY3Kwc3MLI9cljQzM8sXBzczszyS\nijfUuCvdJOlTSeMLpq0s6QlJ76R/OxXM+42kiZLekrRHwfTeksaleZdL2c4ltZZ0V5o+UlL3mtrk\n4GZmljupt2SxhpoNAqpeB3c2MDwiNgCGp3EkbQIMAHqlda6S1DytczVwHLBBGiq3eSwwKyJ6AJcC\nf6mpQQ5uZma2XCLiGWBmlcn9gcHp9WBg/4Lpd0bENxHxPjAR2E5SF6B9RIyIiABurrJO5bbuAXap\nzOqq4w4lZmZ5VNzekqtKGlUwfl1EXFfDOp0jYmp6PQ3onF53BUYULDc5TZufXledXrnOJICIWCBp\nNrAKMKO6nTu4mZnljSh2b8kZEbFNXVeOiJAUxWxQTVyWNDOz+vBJKjWS/v00TZ8CdCtYbq00bUp6\nXXX6YutIagF0AD5b2s4d3MzMcqeIPSXrXt4cCgxMrwcCDxRMH5B6QK5L1nHkpVTCnCOpTzqfdmSV\ndSq3dSDw73RerlouS5qZ5VEDXsQt6Q6gL9m5ucnAucCFwBBJxwIfAgcDRMQESUOA14EFwCkRUZE2\ndTJZz8sVgUfTAHAjcIukiWQdVwbU2KYagp+ZmZWYZu26ROvNjy7a9ua9+OfRy3POrTE4czMzyyPf\nW9LMzPLFj7wp76M3M7NccuZmZpY3fuSNg5uZWS65LGlmZpYvztzMzHLHHUoc3MzM8qhZeZ9zK+/Q\nbmZmueTMzcwsb4r/VICS4+BmZpZHZX4pQHmHdjMzyyVnbmZmuePekuV99GZmlkvO3MzM8qjMz7k5\nuJmZ5ZHLkmZmZvnizM3MLG8klyUbuwFmZlYPXJY0MzPLF2duZmZ55LKkmZnliy/iLu+jzzlJEyT1\nrWZeX0mTl7LuIEnn11vjzMzqkYNbiZL0gaRdq0w7StJzleMR0Ssinmrwxi1F1TaWAkmrSbpd0mxJ\nsyTdVsv1uksKSV8WDGOL0J7zJN26vNspFkkbSrpb0oz0Hr0m6QxJzet5vzX+AJN0q6RpkuZIelvS\nzwrm9ZH0hKSZkqanY+hSn21uUJU9JosxlCAHNysryizr5/5fwDRgbWB14OJlXL9jRLRLwxbLuG7R\nSSra6QhJ6wMjgUnAZhHRATgI6A2sVKz9LIcLgfUioj2wH3C+pN5pXifgOqA7sA7wBfDPxmhk0VU+\n8qZYQwkqzVZbrRRmd5JWTL90Z0l6Hdi2yrJbSXpF0heS7gJWqDJ/H0ljJH0u6QVJm1fZz1npF/ts\nSXdJWmz9Wrb3aElvpDa8J+mEgnnjJe1bMN4yZQpbpfE+qV2fSxpbWI6V9JSkCyQ9D8wF1ksZ5Htp\nX+9LOqyaNu0OdAN+GRGzI2J+RLy6rMdWzbaPScc7S9IwSesUzPu7pEkp4xgt6ftpej/gt8AhhZlg\n1Uy+MLsryCCPlfQR8O9avGe1en+APwIvRMQZETEVICLeiojDIuLztK39lJXIP09/i40L9hOSehSM\nL8rGlErnks6U9KmkqZKOTvOOBw4DfpXehweX1LiIGB8RcytH07B+mvdoRNwdEXPSMlcC31vKn8xK\niINb+TiX7H/q9YE9gIGVMyS1Au4HbgFWBu4GDiiYvxVwE3ACsApwLTBUUuuC7R8M9APWBTYHjqpD\nGz8F9gHaA0cDl0raOs27GTi8YNm9gKkR8aqkrsDDwPmp/WcB90parWD5I4DjybKJ6cDlwJ4RsRKw\nIzAmHeva6Ut47bReH+AtYLCkzyS9LOkHdTi2xUjqTxakfgKsBjwL3FGwyMvAlul4bgfulrRCRDwG\n/Am4qw6Z4A+AjYE9lvaeSWpLNe/PEuwK3LOU49wwHddp6TgfAR5Mn7naWAPoAHQFjgX+IalTRFwH\n3AZclN6HfdP+rpJ0VZU2XCVpLvAmMDW1YUl2BibUsl1NnJy5NXYDbLncn76IP5f0OXDVUpY9GLgg\nImZGxCSyL69KfYCWwGUpM7mH7Mu10vHAtRExMiIqImIw8E1ar9LlEfFxRMwEHiT7Yl4mEfFwRLwb\nmaeBx4Hvp9m3AntJap/GjyALxpAFvUci4pGIWBgRTwCjyAJgpUERMSEiFgALgIXAppJWjIipETEh\nteGjiOgYER+l9dYCdgf+Q/ZFewnwgKRVl+HQZhT8nc5K004E/hwRb6Q2/QnYsjJ7i4hbI+KziFgQ\nEZcArYGNlmGfS3JeRHwVEV9T83u2xPdnCVYhCxjVOQR4OCKeiIj5ZCXdFckCZm3MB/43fS4fAb5k\nKe9DRJwcESdXnUb2o+b7ZCXmb6qulyoRfwB+Wct2NX0+52YlbP/0RdwxIjoCJy9l2TXJzotU+rDK\nvCkREdXMXwc4s0og7ZbWqzSt4PVcoN2yHAiApD0ljVB2gv9zsi/aVQEi4mPgeeAASR2BPcl+uVe2\n76Aq7dsJKOwcsOjYI+Irsi/dE4Gpkh6W1LOaZn0NfBARN6Yv2DvTtpalfLVqwd+p8nzdOsDfC9o7\nk+xMSdf0XpyVSpaz0/wOle/Fcij8+1f7ni3j+/MZi7/PVa1JwWcpIhamdnStZZs/S8G/Up0+W+lH\n2XNkP1ZOKpyXyqKPAr+IiGeXddvWNDm4lY+pZAGp0tpV5nWVFvuJVjh/ElnW17FgaBMRhWW05ZJK\nnPeS/bLvnIL1I2Rf+JUGk2UcBwEvRsSUgvbdUqV9bSPiwoJ1CwM3ETEsInYj+2J+E7i+mqa9VnXd\nJYzXxSTghCptXjEiXkjn135Flm13Su/FbP77Xixp/18BbQrG11jCMoXrLfU9W4b350kKSthL8DFZ\nIAWyDj1kn8PKv93cWrS7OnX5O7QgnXNL7VmH7Bj+LyJuqXatUuSypJWJIcBvJHWStBbwPwXzXiQr\n1Z2qrKPGT4DtCuZfD5woaXtl2kraW1Jde8NJ0gqFA9CKrPQ2HVggaU+ycmCh+4GtgV+QnYOrdCuw\nr6Q9JDVP2+ybjnNJO+8sqX86t/QNWalrYTVtvQ/oJGlg2vaBZL/+n0/bOk/SU3V4D64h+3v0Stvp\nIOmgNG8lsr/HdKCFpD+QnYes9AnQXYv3+hwDDEh/v22AA2vYf7Xv2TK+P+cCO0r6q6Q10rH0UNYF\nvyPZ525vSbtIagmcmbb5QkG7f5ra0I/svGBtfQKsV91MSatLGiCpXdr+HsChwPA0vytZ55orI+Ka\nZdhvaXBZ0srEH8nKQ++Tncta9Cs1Ir4l69hwFFl57BCycxOV80cBx5H1JpsFTKRuHUYq7UhW7qs6\nnEr2ZTgL+CkwtHCldK7oXrJOK4XtmwRUdtCYTpaV/JLqP9/NgDPIsoqZZF+oJ8GiDiVfVnYoSecQ\n9yPrcDEbOBvoHxEz0ra6kQLdsoiI+4C/AHdKmgOMJyu1AgwDHgPeJvubzWPxkuLd6d/PJL2SXp9D\nlpHMIvtb317D/pf2nlX7/ixhO+8CO5B1p58gaTbZ32gU8EVEvEWWbV8BzAD2BfZNnznIfqjsC3xO\n1vvx/qW1u4obgU1SWfV+AEnXSKoMVJHaPZnsfbkYOC0iKj9XPyMLjuep4FrEZdi/NWFa/DSLWdOW\nspgNI+LwGhduAJLGALtExGeN3RazSs06dY/WfX9ftO3Nu/+40RGxTdE22AB8b0krGZJWJusOfkRj\nt6VSRCxzr1CzBlGi5cRicVnSSoKk48hKZ49GxDON3R4za9qcuVlJiIjrqb7HnplVoTLP3BzczMxy\nRji4uSxpZma548ytjtRixVCrpnDTcysFPdev7Q05rNx9POUjPp/52fKlXWLx2x+UIQe3OlKrlWi9\n0cGN3QwrETf/64LGboKViCP361uErchlycZugJmZWbE5czMzy6Fyz9wc3MzMcqjcg5vLkmZmljvO\n3MzMcqjcMzcHNzOzvPGlAC5LmplZ/jhzMzPLGfk6Nwc3M7M8Kvfg5rKkmZnljjM3M7McKvfMzcHN\nzCyHyj24uSxpZma548zNzCxvfJ2bg5uZWR65LGlmZpYzztzMzHLGF3E7uJmZ5VK5BzeXJc3MLHec\nuZmZ5VF5J24ObmZmuSOXJV2WNDOz3HHmZmaWQ+WeuTm4mZnlULkHN5clzcwsd5y5mZnljC/idnAz\nM8un8o5tLkuamVn+OHMzM8sbX+fmzM3MLI8kFW2oxb5OlzRB0nhJd0haQdLKkp6Q9E76t1PB8r+R\nNFHSW5L2KJjeW9K4NO9yLUeEdnAzM7M6k9QVOBXYJiI2BZoDA4CzgeERsQEwPI0jaZM0vxfQD7hK\nUvO0uauB44AN0tCvru1ycDMzy6GGzNzITnGtKKkF0Ab4GOgPDE7zBwP7p9f9gTsj4puIeB+YCGwn\nqQvQPiJGREQANxess8wc3MzM8khFHJYiIqYAFwMfAVOB2RHxONA5IqamxaYBndPrrsCkgk1MTtO6\nptdVp9eJg5uZmdVkVUmjCobjK2ekc2n9gXWBNYG2kg4vXDllYtGQDXZvSTOzHCpyb8kZEbFNNfN2\nBd6PiOlpv/8CdgQ+kdQlIqamkuOnafkpQLeC9ddK06ak11Wn14kzNzOznCnm+bZaBMmPgD6S2qTe\njbsAbwBDgYFpmYHAA+n1UGCApNaS1iXrOPJSKmHOkdQnbefIgnWWmTM3MzOrs4gYKeke4BVgAfAq\ncB3QDhgi6VjgQ+DgtPwESUOA19Pyp0RERdrcycAgYEXg0TTUiYObmVkONeRF3BFxLnBulcnfkGVx\nS1r+AuCCJUwfBWxajDY5uJmZ5ZDvUGJmZpYzztzMzPKovBM3BzczszxyWdLMzCxnnLmZmeWNH3nj\n4GZmljcCyjy2uSxpZmb548zNzCx3av2omtxycDMzy6Eyj20uS5qZWf44czMzyyGXJc3MLF/ksqTL\nkmZmljvO3MzMckZAs2blnbo5czMzs9xx5mZmlkPlfs7Nwc3MLIfKvbeky5JmZpY7ztzMzPLGlwI4\nuJmZ5U32VIDyjm4uS5qZWe44uFm1dttxY8bedw7jHziXs47e7TvzTz9yF0bceTYj7jybUXf/li9H\nXU6n9m0AOOXQvoy6+7eMvud3/PynfRets9mGXXlq8Jm8POS33HPZCazUdoWGOhyrRy88/SQH7LIN\nP/7hVgy6+tLvzH/0/iEcuueODOi3I8ccuDtvvzGuxnWffOR+Dt6jD9ut34nXX3u1QY4jP7KnAhRr\nKEUObrZEzZqJy84+mP4/v4qtDjifg/r1pud6ayy2zKU3D6fPgAvpM+BC/nDFUJ4d/Q6z5sxlk/W7\ncPRPduT7R/yV7Q75M3vuvCnrdVsVgKv/8FN+f/kDbHvwnxj6n7GcPnCXxjg8K6KKigouOvcs/v7P\nexgybCSPP3gP773z5mLLrNltHa698xHufOwFjv35L/nTb0+rcd31N9yYi66+ha2227HBjykPpOIN\npcjBzZZo20278+6kGXww5TPmL6jg7mGvsE/fzatd/uB+2zDksdEA9Fx3DV4e/wFfz5tPRcVCnh09\nkf1/tCUAPdZenedGTwTg3yPeZP9dtqz/g7F6NWHsaLqtsx5rrd2dlq1asds+B/D0E48stswWvben\nfYeOAGy21bZ8Ou3jGtddt8dGdF9vg4Y9GMsNBzdbojVX78DkT2YtGp/yySy6rtZhicuuuEJLdttx\nY+4fPgaACe9+zPe26sHKHdqy4got6bdTL9ZaoxMAb7w3lX1TkPzJbluzVudO9XwkVt+mT5tK5y5d\nF4137rIm0z+ZWu3yDwy5hR1/sGud1rXaK/eypHtL2nLbe+fNeHHMe8yaMxeAt97/hEsGPcGDV53C\n3HnfMvatyVRULATghPNu45JfHcjZx/Xj4afH8e38isZsujWwUS8+w9Aht3D9kMcauyn5VsLlxGJp\nsMxN0gt1XG9LSSGpX8G0jpJOLhjvLumny9G2pyRtU9f18+jjT2cvllV17dyJKdNnL3HZg/bozd2p\nJFlp8P0v8r3DLmK3Yy/j8zlzeefDTwF4+4NP2Pfkf/C9wy5iyGOjeX/y9Po7CGsQq63RhU+mTlk0\n/snUj1mtc5fvLPfOG+M5/zencvG1t9Ox08rLtK7Zsmqw4BYRdT0rfCjwXPq3Ukfg5ILx7kCdg5t9\n16gJH9Jj7dVYZ81VaNmiOQftsTUPP/Xad5Zr324FdurdgwerzFutUzsAuq3Rif4/2oK7Hh212HRJ\nnH3cHlx/z3P1fCRW3zbZfGs++uBdpkz6gPnffssTD93Lzrvuudgy06ZM4lcnH8EfL7mWddbrsUzr\n2rKrvM7NZckGIOnLiGgnqQtwF9A+7f+kiHi2mnUEHATsBjwraYWImAdcCKwvaQzwBPB9YOM0Phi4\nD7gFaJs29fOIeCFt89fA4cBC4NGIOLtgf82Am4DJEfH74r4DpaWiYiGn/2UID151Cs2bicEPjOCN\n96bxswN3AuCGFJT2++EWDB/xJnPnfbvY+ndc/DNW7tiW+QsqOO3CIcz+8msg63hywiE7A/DAv8dw\n8wMjGvCorD60aNGCX533V04deAAVCyvY76DDWX/Djbn3tpsAOOCwY7jhiouYPWsmf/nDmdk6zVtw\n89Cnql0X4D/DHuTiP/6aWTNncPqxB7PhJptxxeB/NdpxlpoSjUlFo4homB39N7idCawQERdIag60\niYgvqlnne8D/RsQukm4H7o2IeyV1Bx6KiE3Tcn2BsyJinzTeBlgYEfMkbQDcERHbSNoTOAfYNSLm\nSlo5ImZKego4G/gFMD4iLqimPccDxwPQsl3vFXoNLMp7Y/n37L+W+JEy+44j9+vL6+NeXa7Q1Lbr\nRrHxSdcUq0mMPudHoyOipE7dNEaHkpeBmyS1BO6PiDFLWfZQ4M70+k7gSODeWuyjJXClpC2BCmDD\nNH1X4J8RMRcgImYWrHMtMKS6wJaWvw64DqBZm9Ub5leBmVkdlGo5sVga/FKAiHgG2BmYAgySdOSS\nlktZ3QHAHyR9AFwB9JO0Ui12czrwCbAFsA3QqhbrvAD8UJJvmWFmJc8XcTcwSesAn0TE9cANwNbV\nLLoL8FpEdIuI7hGxDlnW9mPgC6AwyFUd7wBMjYiFwBFA8zT9CeDoVLZE0soF69wIPAIMkeRLJMzM\nSlhjXMTdFxgr6VXgEODv1Sx3KFnHkEL3AodGxGfA85LGS/or8BpQIWmspNOBq4CBksYCPYGvACLi\nMWAoMCp1PjmrcOMR8TfgVeCW1LnEzKz0yL0lGyxDiYh26d/BZD0aa1r+6CVMG0oWnIiIql3/f1Rl\nvPBeUb8u2MaFZL0tC7fbt+D1uTW1zcysKcsuBWjsVjQuZydmZpY7TeLckqSRQOsqk4+IiHFLWt7M\nzJamdMuJxdIkgltEbN/YbTAzy5Myj20uS5qZWf40iczNzMyKy2VJMzPLlxK++LpYXJY0M7PcceZm\nZpYzlY+8KWcObmZmOVTuwc1lSTMzyx1nbmZmOVTmiZuDm5lZHrksaWZmljPO3MzM8sbXuTm4mZnl\njXzjZJclzcwsf5y5mZnlUJknbg5uZmZ51KzMo5vLkmZmljvO3MzMcqjMEzcHNzOzvJF8EbfLkmZm\nljvO3MzMcqhZeSduDm5mZnnksqSZmVnOOHMzM8uhMk/cHNzMzPJGZPeXLGcuS5qZWe44czMzyyH3\nljQzs3yRH3njsqSZmeWOMzczsxwq88TNwc3MLG+EH3njsqSZmS0XSR0l3SPpTUlvSNpB0sqSnpD0\nTvq3U8Hyv5E0UdJbkvYomN5b0rg073Itx4lDBzczsxzKngxQnKEW/g48FhE9gS2AN4CzgeERsQEw\nPI0jaRNgANAL6AdcJal52s7VwHHABmnoV9fjd3AzM8shpR6TxRhq2E8HYGfgRoCI+DYiPgf6A4PT\nYoOB/dPr/sCdEfFNRLwPTAS2k9QFaB8RIyIigJsL1llmDm5mZrY81gWmA/+U9KqkGyS1BTpHxNS0\nzDSgc3rdFZhUsP7kNK1rel11ep04uJmZ5UwxS5IpcVtV0qiC4fiC3bUAtgaujoitgK9IJchKKROL\nBjr8RY0yM7OcKXJvyRkRsU018yYDkyNiZBq/hyy4fSKpS0RMTSXHT9P8KUC3gvXXStOmpNdVp9eJ\nMzczM6uziJgGTJK0UZq0C/A6MBQYmKYNBB5Ir4cCAyS1lrQuWceRl1IJc46kPqmX5JEF6yyzajM3\nSe1rOKA5dd2pmZnVrwa+yu1/gNsktQLeA44mS56GSDoW+BA4GCAiJkgaQhYAFwCnRERF2s7JwCBg\nReDRNNTJ0sqSE8hqpIXvUeV4AGvXdadmZla/GvLekhExBlhS2XKXapa/ALhgCdNHAZsWo03VBreI\n6FbdPDMzs6asVufcJA2Q9Nv0ei1Jveu3WWZmVlfZ7beKN5SiGoObpCuBHwJHpElzgWvqs1FmZrYc\ningBd6k+Oqc2lwLsGBFbS3oVICJmppOGZmZmTVJtgtt8Sc1IF+BJWgVYWK+tMjOz5VKiCVfR1Ca4\n/QO4F1hN0h/JunP+sV5bZWZmy6VUy4nFUmNwi4ibJY0Gdk2TDoqI8fXbLDMzs7qr7e23mgPzyUqT\nvquJmVkTVtlbspzVprfk74A7gDXJ7vV1u6Tf1HfDzMys7txbsmZHAltFxFwASRcArwJ/rs+GmZmZ\n1VVtgtvUKsu1SNPMzKyJKs18q3iWduPkS8nOsc0EJkgalsZ3B15umOaZmdmykor+yJuSs7TMrbJH\n5ATg4YLpI+qvOWZmZstvaTdOvrEhG2JmZsVT5olbzefcJK1P9miCTYAVKqdHxIb12C4zM7M6q801\na4OAf5Kdn9wTGALcVY9tMjOz5VTulwLUJri1iYhhABHxbkT8nizImZlZEyUVbyhFtbkU4Jt04+R3\nJZ0ITAFWqt9mmZmZ1V1tgtvpQFvgVLJzbx2AY+qzUWZmVndCvhSgpgUiYmR6+QX/fWCpmZk1VSVc\nTiyWpV3EfR/pGW5LEhE/qZcWmZmZLaelZW5XNlgrStBWG6/N8yP9FlntdNr3ssZugpWIbz6aUZTt\nlGovx2JZ2kXcwxuyIWZmVjzl/myycj9+MzPLodo+rNTMzEqEcFmy1sFNUuuI+KY+G2NmZsXhJ3HX\nQNJ2ksYB76TxLSRdUe8tMzMzq6PanHO7HNgH+AwgIsYCP6zPRpmZ2fJppuINpag2ZclmEfFhlfpt\nRT21x8zMllN2T8gSjUpFUpvgNknSdkBIag78D/B2/TbLzMys7moT3E4iK02uDXwCPJmmmZlZE1Wq\n5cRiqc29JT8FBjRAW8zMrEjKvCpZqydxX88S7jEZEcfXS4vMzMyWU23Kkk8WvF4B+DEwqX6aY2Zm\ny0vgR97UtEBE3FU4LukW4Ll6a5GZmS23cr+3Yl2Of12gc7EbYmZmViy1Oec2i/+ec2sGzATOrs9G\nmZnZ8inzquTSg5uyqwC3AKakSQsjotoHmJqZWeOTVPbn3JZalkyB7JGIqEiDA5uZmTV5tTnnNkbS\nVvXeEjMzK5rsFlzFGUpRtWVJSS0iYgGwFfCypHeBr8h6mUZEbN1AbTQzs2XkO5RU7yVga2C/BmqL\nmZlZUSwtuAkgIt5toLaYmVkR+CLupQe31SSdUd3MiPhbPbTHzMyKoMxj21KDW3OgHSmDMzMzKxVL\nC25TI+J/G6wlZmZWHCX8BO1iqfGcm5mZlR6V+Vf40q5z26XBWmFmZlZE1WZuETGzIRtiZmbFkfWW\nbOxWNK7aPM/NzMxKTLkHt3J/5I+ZmeWQMzczsxxSmV/o5uBmZpYzPufmsqSZmeWQMzczs7wp4UfV\nFIuDm5lZDpX7jZNdljQzs9xx5mZmljPuUOLgZmaWS2VelXRZ0szM8seZm5lZ7ohmZf5UAAc3M7Oc\nES5LuixpZma548zNzCxv/CRuBzczszzyRdxmZmY548zNzCxn3KHEwc3MLJdcljQzM8sZZ25mZjlU\n5ombMzczs7wR2Zd7sYZa7VNqLulVSQ+l8ZUlPSHpnfRvp4JlfyNpoqS3JO1RML23pHFp3uVS3UO0\ng5uZmRXDL4A3CsbPBoZHxAbA8DSOpE2AAUAvoB9wlaTmaZ2rgeOADdLQr66NcXAzM8sbgaSiDTXu\nTloL2Bu4oWByf2Bwej0Y2L9g+p0R8U1EvA9MBLaT1AVoHxEjIiKAmwvWWWY+52ZmlkNFPuW2qqRR\nBePXRcR1BeOXAb8CViqY1jkipqbX04DO6XVXYETBcpPTtPnpddXpdeLgZmZmNZkREdssaYakfYBP\nI2K0pL5LWiYiQlLUZwOrcnAzM8uZ7EncDdZd8nvAfpL2AlYA2ku6FfhEUpeImJpKjp+m5acA3QrW\nXytNm5JeV51eJz7nZmaWQyrisDQR8ZuIWCsiupN1FPl3RBwODAUGpsUGAg+k10OBAZJaS1qXrOPI\nS6mEOUdSn9RL8siCdZaZMzczM6sPFwJDJB0LfAgcDBAREyQNAV4HFgCnRERFWudkYBCwIvBoGurE\nwc3MLIca4yLuiHgKeCq9/gzYpZrlLgAuWML0UcCmxWiLg5uZWe7Urgt/nvmcm5mZ5Y4zNzOznKm8\n/VY5c3AzM8shlyXNzMxyxsHNFnl82GNs3msjevXswV8vuvA78yOCM047lV49e7DtVpvz6iuvADBv\n3jx22mE7ttt6C7beohf/98dzF63z2tix/GCnHdhmy804YP99mTNnzqJ54157jR/stANbb9GLbbbc\njHnz5tUGOTxuAAAYH0lEQVT/QVrR7NZ7HcZefyTjbzyKsw767s0rOrZrzV3n7MNLVx3Gs5cNYJN1\nVlk0r0Pb1tz+u70Zc92RvHrtkWzfswsAndq15qELfsy4Gwby0AU/pmO71otts9tqKzH9Xydz2gFb\n1+/B5UBDXefWVDm4GQAVFRWcduopPPDgo7z62uvcfecdvPH664stM+yxR3l34juMf+Mdrrz6Ok79\n+UkAtG7dmsee+DcvvTKWkaPG8Piwxxg5Irt13Ekn/Izz/3Qho8aMY7/+P+bSS/4KwIIFCzhm4OFc\n8Y9reGXsBIYNf4qWLVs27EFbnTVrJi475Yf0P+d+tjrhZg7quxE91155sWV+dci2jH13OtudfBvH\nXjyMi0/8waJ5F5/4Ax4f9QFbHn8z251yK29OmgnAWQdvy1NjJrHZzwbz1JhJnHXwtott8y/H78zj\noz6o9+MreQ184+SmyMHNAHj5pZdYf/0erLveerRq1YqDDhnAQw8ufnOAh4Y+wE8PPxJJbN+nD7Nn\nf87UqVORRLt27QCYP38+C+bPX/Q/xMR33man7+8MwI923Y3777sXgCefeJxNN9uczbfYAoBVVlmF\n5s2bY6Vh2w3X4N2PZ/PBtDnMX7CQu59+m336rL/YMj3XXoWnx04C4O3Js1inc3tW79iG9m1asdOm\nXRk0bAIA8xcsZPZX3wCwzw7rceuT2Y+qW598nX13WG/R9vbdYX0+mDab1z+c2RCHaCXOwc0A+Pjj\nKay11n9v99a161pMmTKlxmU+TstUVFSwfe8tWXvN1fnRrrux3fbbA7DxJr14cGgWJP91z91MnpR9\n2b3z9ttIYt+99mCHbbfmkosvqtfjs+Jac9W2TJ7+xaLxKTO+oOsqbRdbZtx70+n/vR4AbLNhZ9Ze\nvT1dV21H9zU6MGP211x3xu68eOVPueoXu9Kmdda3bfWObZk2ay4A02bNZfWO2TbbrtCSMw/ahgtu\nG9kQh1fyGuNhpU1NqbbbmpjmzZszcvQYJn4wmVEvv8SE8eMBuPb6m7jumqvYcbvefPnlF7Rq1QqA\nBRULeOGF5/jnzbcx/OnnGHr/ffzn38Mb8xCsyC6+exQd2rZmxJWHcdJ+WzL23U+pWBi0aC627LE6\n1z/8Gjv8/Hbmzpv/nfJjpeyxXvD7w/twxX2v8NW8+Q15CCWt3MuS9XYpgKQXImLHZVznA2B0RByQ\nxg8E9omIo4rfwmrbcB7wZURc3FD7bArWXLMrkydPWjQ+ZcpkunbtWuMya1ZZpmPHjvyg7w95/PHH\n6LXppmzUsycPPfo4kGVrjz7yMJBlfTvttDOrrroqAP323ItXX32FH/5oiXfrsSbm4xlfsdZq/310\nV9dVV2LKZ18ttswXc7/lhEufWDT+5qBjeH/abNq0bsGUGV/y8lvTALjvuXc4MwW3Tz//ijU6tWHa\nrLms0akN02dnWdy2G63Bj3fagAuO/T4d2rZmYQTzvq3gmgfH1vehWomqt8xtWQNbgd7pMeTLTJKv\n26ujbbbdlokT3+GD99/n22+/5e677mTvffZbbJm9992P22+9mYhg5IgRtG/fgS5dujB9+nQ+//xz\nAL7++muGP/kEG23UE4BPP82ecrFw4UIu/NP5HHf8iQDstvseTBg/jrlz57JgwQKefeZpNt64Tn92\nawSj3p5GjzU7sk7n9rRs0YyDfrAhD494d7FlOrRtTcsW2VfM0f025blxk/li7rd8Mmsuk6d/wQZd\nOwHQd8u1efOjzwB4eMR7HL5r9jk4fNdNeOjF9wDY9Zd30/Oom+h51E1cef+r/PWulxzYalDuvSXr\nM3P7MiLapef43AW0T/s7KSKeXcqqlwC/Aw6rsr2VgZuA9YC5wPER8VrKtNZP0z+SNIzs0eRtyR6l\ncDHQCjgC+AbYKyJmSjoOOD7NmwgcERFzazim49M6dFt77dq+FSWhRYsWXPr3K9l37z2oqKhg4FHH\nsEmvXlx/7TUAHHfCifTbcy+GPfoIvXr2oM2Kbbj2hn8CMG3qVI47ZiAVFRUsjIUccODB7LX3PgAM\nufMOrr3mHwD03/8nHHnU0QB06tSJU087g5122BZJ7NFvL/bca+9GOHKri4qFwelX/4cHz/8xzZuL\nwY9P4I2PZvKzvTYD4IZHxtGz28pcf+buBMEbH87kxMv+m8WdcfVT/PNX/WjVshkfTJ3D8Zdm2f3F\nQ0Zx62/3YuAevfjo0y84/E8PN8rx5UGJVhOLRpU17aJv+L/B7UxghYi4QFJzoE1EfFHNOh8A25Pd\nVXpfYEtSWVLSFWRPg/2jpB8Bf4uILVNw2xfYKSK+lnQU8HtgK7IH500Efh0R10i6FPgwIi6TtEq6\nazWSzgc+iYgraluW7N17m3h+5KilLWK2SKd9L2vsJliJ+OaFS1g4e9JyhaYevbaIS+4cVqwmsf/m\nXUZX9yTupqohyngvAzdJagncHxFjali+Avgr8BsWf5bPTsABABHxb0mrSGqf5g2NiK8Llv1PCqBf\nSJoNPJimjwM2T683TUGtI9AOKN4nwcysEWW9Jcs7dav33pIR8QywM9njwgdJOrIWq92S1ulW04LJ\nV1XGvyl4vbBgfCH/DeiDgJ9HxGbAH8myPDMzy4F6D26S1iEr+V0P3ADUeN+ciJgPXAqcXjD5WdJ5\nOEl9yUqUc767dq2tBExNGeVhNS1sZlZKpOINpaghypJ9gV9Kmg98CdQmcwO4kezcWaXzyMqbr5F1\nKBm4nO06BxgJTE//rrT0xc3MSoVQmZcl6y24RUS79O9gYHAt1+le8PobYM2C8ZlkvSCrrnNelfFB\nZCXHJW1z0byIuBq4uqbtmZlZ6fF1YWZmOVSq5cRiaZTgJmkk0LrK5CMiYlxjtMfMLE/cW7KRgltE\nbN8Y+zUzs/LgsqSZWd6UcC/HYnFwMzPLoXIPbn7kjZmZ5Y4zNzOzHPJ1bmZmlisCmpV3bHNZ0szM\n8seZm5lZDrksaWZmuePekmZmZjnjzM3MLIdcljQzs1xxb0mXJc3MLIecuZmZ5Y4fVurgZmaWN75x\nssuSZmaWP87czMxyqMwTNwc3M7O8yXpLlnd4c1nSzMxyx5mbmVkOlXfe5uBmZpZPZR7dXJY0M7Pc\nceZmZpZDvojbzMxyp8w7S7osaWZm+ePMzcwsh8o8cXNwMzPLpTKPbi5LmplZ7jhzMzPLGeHekg5u\nZmZ540feuCxpZmb548zNzCyHyjxxc3AzM8ulMo9uLkuamVnuOHMzM8sdubdkYzfAzMyKz70lzczM\ncsaZm5lZzoiy70/i4GZmlktlHt1cljQzs9xx5mZmlkPuLWlmZrnj3pJmZmY548zNzCyHyjxxc3Az\nM8sdXwvgsqSZmeWPMzczsxxyb0kzM8sV4d6SLkuamVmdSeom6T+SXpc0QdIv0vSVJT0h6Z30b6eC\ndX4jaaKktyTtUTC9t6Rxad7lUt1DtIObmVkOqYhDDRYAZ0bEJkAf4BRJmwBnA8MjYgNgeBonzRsA\n9AL6AVdJap62dTVwHLBBGvrV9fgd3MzM8qiBoltETI2IV9LrL4A3gK5Af2BwWmwwsH963R+4MyK+\niYj3gYnAdpK6AO0jYkREBHBzwTrLzMHNzMyKQlJ3YCtgJNA5IqamWdOAzul1V2BSwWqT07Su6XXV\n6XXiDiVmZjlU5N6Sq0oaVTB+XURct9j+pHbAvcBpETGn8HRZRISkKGaDauLgZmaWQ0XuLTkjIrap\nfl9qSRbYbouIf6XJn0jqEhFTU8nx0zR9CtCtYPW10rQp6XXV6XXisqSZmdVZ6tF4I/BGRPytYNZQ\nYGB6PRB4oGD6AEmtJa1L1nHkpVTCnCOpT9rmkQXrLDNnbmZmOdSAl7l9DzgCGCdpTJr2W+BCYIik\nY4EPgYMBImKCpCHA62Q9LU+JiIq03snAIGBF4NE01ImDm5lZHjVQdIuI55ayt12qWecC4IIlTB8F\nbFqMdrksaWZmuePMzcwsZ7LL08r7/lsObmZmeSPfW9JlSTMzyx1nbnX0yiujZ6zYUh82djuamFWB\nGY3dCCsZ/rws2TrF2EiZJ24ObnUVEas1dhuaGkmjlnahp1khf17qWZlHN5clzcwsd5y5mZnljtxb\nsrEbYLlyXc2LmC3iz0s9cm9JsyKpepdws6Xx58XqkzM3M7OcqeUTtHPNwc3MLI/KPLq5LGlmZrnj\nzM2aBEmKiAZ9Uq+VFkkrA6tGxNuN3ZZSUO69JZ25WaOS1A2yx9A3dlus6ZK0AnAqcIykjRu7PaVA\nKt5QihzcrEFJaiepVXq9MXCRpJUauVnWxEXEPODJNHqQpE0asz3W9Dm4WYOR1Ba4DTgoTZqbhi8l\ntUzLlOjvRKsvlZ+J9FDMoUB74EAHuKVTEYdS5OBmDSYivgLuAo6WdAjQHfg6MvPTMi5P2iKV52Il\nrSupRUS8APwT6EAW4FyitCVyhxJrEJKaR0RFRNwuaTrwa2A0sK6kvwOTgW+AFhHxt8ZsqzUdKbDt\nDZwDPCvpS+AysrubHAscLum2iHi9MdvZ5JTwubJiceZm9S79+q6QtJukiyLiCeDvwC7At8BH6d92\nwMhGbKo1MZL6AH8CDiH7Mb4/cBEwHRgMtCX77Nh3lHdh0pmb1bv063sX4CrghDTtQUkLgDOAtyPi\nwcZsozUtkpoBQfbMtyOBnsDOwNnA8cDFZNn/71K522wxztysXinTAugHnBMR/67sLRkRjwLXAL+W\n1LUx22lNQ0GHonbpXOxDETGWLGP7WUQMAz4l+2He2YFtyYQvBXBws3qVvqAWAPOAPpJWiIhvASRt\nCzwC7BcRUxqzndY0FJxjGy7pPEk/SbNWB46XtD2wHXBxRIxvtIaWgPIuSjq4WT2o/PUtaW1Ja6XJ\njwItgR+keVsAlwIbRsTMRmmoNTmSugCHkZUdZwJ7pGB3DNAN+APw54h4rfFaaaXA59ys6Ap+ff8Z\neEHSyhFxcOq2fYSkX5N15T4/lZzMkLQNsAUwJSLukrQasAfwY6BlROwjqU1EzPXt2mpWquXEYnFw\ns6IpuCapD1mPtn3IMrWbJD0ZEbtKGkT2BTY7It71l5QBSOpL1vtxGFn3/jsi4hVJjwKtgP6SXoqI\nj8HXQ9ZGud9b0sHNllu679/81N2/M/AZcDCwAVnvyA7AU5JeiIgdgVcq1/WXlElaF/gtcEREPCNp\nInCrpMMi4lVJDwCPVQY2s9rwOTdbLqnL9o7AaZL2ITsn8gXwOrA3cFNEfEH2q3zt1InEylzBedlt\nybL7DmQ9IomIi4AbgaGSekfEZw5sdVDmPUoc3KwYXgN2B24B7omIaWT/S0wF1pd0HFmJcreIeLnx\nmmlNRSpf70xWvh5HdqF2G0k/T/MvAf5BdmG/1UGZxzYHN6sbSW0lrRURC4F10uT/AHum7v4Lye7i\nPpcssF0TEW80UnOtiZG0EXASMCgiRgNPAcOBnpLOBIiICyPiad9M2+rC59ysrroD50saBWwKnAnM\nIrsH4N+Ak4H3yALenyJigTuPWIHNgM7ArpIeiYjpkh4ju1ykr6R1IuJD8HnZuijli6+LxZmb1UlE\nTAAmknUEGJkuqJ1Odout1pKGk/0an58u4vaXVBkrOMe2lqQOEXEP2Q+hOWR3918lnZt9EPhDZWCz\nulMR/ytFDm5Wa5I6SmpTMGk8cAlwpKRdIuLbdHHt74BBwOkRMaIRmmpNiKRm6RzbnmQX898o6Rng\nDeAhoPL6x1Ui4ot0ztZsubgsabUiaWXgbeBJSc9GxD8iYnCaNwn4m6SBwOfATyofW+NSZPmStGJE\nfB0RCyX1AP4POCEiXpB0OXA/2UXaLdO/bckuI7FiKM2Eq2gc3Ky2ZgGPk/WAPEzSdsBzwN0Rcb2k\nb4F7gQXAaZUrObCVJ0kdgAsl3RcRj5P96HmT7AcSEXGqpDuAsyPiXEkvR8TURmxy7pR5bHNZ0mon\nBalXyDoB7ExWdtwZeFrSD8k6jmwPHJDu9m/lrT3ZOdmfpscdzQFWAXYtWOYR0rPYHNis2Jy5Wa1F\nxMWSHiH7ghoPbEn2a3wA0AM4xHdqL2+SVkrnzSZJupnss3EMWWej3wKDJPUEZqfpv2q81uZbufeW\ndHCzWpHUPCIqyDK2H5Pd0f/GFPBWJ7ux7YzGbKM1LkndgXskjQaGAO8A/wS+IbtU5C/AQcCewJpk\nHY6e9HnZ+lC6vRyLxcHNaiUFNoCRwHnAixFxcZo23V9OBqwAdAH6Ax+Q3WHkGqAT8AJZ1/8LIuLv\nhSv5s2P1wefcrNbSL+wPgTOAdpVPz/aXk6Xu/m+SlaxnAx8BhwAfk9078sA0flG6pMTfPfXIT+J2\n5mZVFDy2plm6hdYiBUFsMrDwu2tbuUrd/ZtFxBuSDgfuJLszzY2S7iF7QkR/YExEfN6ojbWy4OBm\nixQEtl3IMrNhETGv6nIRMV7SryNiSiM005qoggD3sqQBwB3pPqP/AN4iu0myr320BuHSgAGLOoyE\npH7A1cCsJQU2ZZpFxIeS2khapeFba01VYYAjK0OeI+mUKss4sDWAci9LOriVOUk9UvftCkmdyE76\nn5geGvl9SQPTBduVmqUvsI5k17at3CgNt0ZVcK/I73yHFAS40cC+wISGbp/53pIuS1pnYHVJIyJi\nlqT/AMemZ7A1A+aTnS95SVKLdHf/DsDdwC8j4p3Ga7o1htqUr6tkcC5FWoNz5lbmIuJ5sodFviep\nPdl1bC8BV0TEIWTXK/WS1CoFtk7AfcD/RsQzjdVuaxy1LV9XLp7WWZHscgBrKEUsSbosaSUrPWrk\nF2TXIs2IiL+nm9t+n+xmtzdExLdp8UOB8yPi2UZqrjWCZS1fV170n8rXT5HdessaSDGfwl2isc1l\nSctExAOS5gOjJfUG5pFdm/T7iHi4sqwUEVc1bkutkbh8bSXFwc0WiYhHJC0ke87WRsCvI2JewTkW\nnzcpUxHxvKSVyMrXm5OVr/cGXk5Z/n7A0al8/W3K7u4FznWW30hKNeUqEpclbTER8RjwM2CrynMp\nlQHNga28uXxdWtxb0qyKiHgY3MPNvsvlaysVDm5WLQc2WxKXr0tDqfZyLBaXJc1smbl83fS5t6SZ\nWR24fG1NmYObmS0XB7YmqlRTriJxcDMzy6FS7eVYLD7nZmZmuePMzcwsZyqfxF3O5HK55Y2kCrKb\nQbcg664+MCLm1nFbfYGzImKfdBeOTSLiwmqW7Qj8dFmv8ZJ0HvBlRFxcm+lVlhkEPBQR99RyX93T\n8psuSxuttEh6DFi1iJucERH9iri9eufMzfLo64jYEkDSbcCJwN8qZ6ZnkSkiFi7LRiNiKDB0KYt0\nBE4GfAGzNapSC0T1wefcLO+eBXpI6i7pLUk3A+OBbpJ2l/SipFck3S2pHYCkfpLelPQK8JPKDUk6\nStKV6XVnSfdJGpuGHYELgfUljZH017TcLyW9LOk1SX8s2NbvJL0t6TmyC6GXStJxaTtjJd0rqU3B\n7F0ljUrb2yct31zSXwv2fcLyvpFmpcTBzXJLUgtgT7ISJWR3rb8qInoBXwG/B3aNiK2BUcAZklYA\nrid7gnRvYI1qNn858HREbAFsTfa06bOBdyNiy4j4paTd0z63A7YEekvaOd22akCathewbS0O518R\nsW3a3xvAsQXzuqd97A1ck47hWGB2RGybtn+cpHVrsR+zXHBZ0vJoRUlj0utngRuBNYEPI2JEmt4H\n2AR4PqtS0gp4EegJvF/5iBZJtwLHL2EfPwKOBIiICmB2uhN+od3T8Goab0cW7FYC7qs8DyhpaaXO\nSptKOp+s9NkOGFYwb0gqsb4j6b10DLsDm0s6MC3TIe377Vrsy6zkObhZHi0651YpBbCvCicBT0TE\noVWWW2y95STgzxFxbZV9nFaHbQ0C9o+IsZKOAvoWzKvaKyzSvv8nIgqDYGWHErPcc1nSytUI4HuS\negBIaitpQ+BNoLuk9dNyh1az/nDgpLRu8/Rgzi/IsrJKw4BjCs7ldZW0OvAMsL+kFdMz0vatRXtX\nAqZKagkcVmXeQZKapTavB7yV9n1SWh5JG0pqW4v9mOWCMzcrSxExPWVAd0hqnSb/PiLelnQ88LCk\nuWRlzZWWsIlfANdJOhaoAE6KiBclPS9pPPBoOu+2MfBiyhy/BA6PiFck3QWMBT4FXq5Fk88BRgLT\n07+FbfoIeAloD5yY7tB/A9m5uFdS79DpwP61e3fMSp+vczMzs9xxWdLMzHLHwc3MzHLHwc3MzHLH\nwc3MzHLHwc3MzHLHwc3MzHLHwc3MzHLHwc3MzHLn/wG0ZlAHNfz5awAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7fb30f5cb0b8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot(actual_value = Train.actual_value, pred_value = Train.pred_value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "_draft": {
   "nbviewer_url": "https://gist.github.com/7d1ace18a82178e15ece8fc5252fce88"
  },
  "anaconda-cloud": {},
  "gist": {
   "data": {
    "description": "Hyper parameter tuning",
    "public": false
   },
   "id": "7d1ace18a82178e15ece8fc5252fce88"
  },
  "kernelspec": {
   "display_name": "Python [conda env:p3]",
   "language": "python",
   "name": "conda-env-p3-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
