{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Read Data Sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-05-13T02:09:06.402604Z",
     "start_time": "2017-05-13T02:09:06.000108Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from collections import namedtuple\n",
    "pd.set_option(\"display.max_rows\",35)\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-05-13T02:09:06.489077Z",
     "start_time": "2017-05-13T02:09:06.404550Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class dataset:\n",
    "    kdd_train_2labels = pd.read_pickle(\"dataset/kdd_train_2labels.pkl\")\n",
    "    kdd_test_2labels = pd.read_pickle(\"dataset/kdd_test_2labels.pkl\")\n",
    "    \n",
    "    kdd_train_5labels = pd.read_pickle(\"dataset/kdd_train_5labels.pkl\")\n",
    "    kdd_test_5labels = pd.read_pickle(\"dataset/kdd_test_5labels.pkl\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-05-13T02:09:06.495889Z",
     "start_time": "2017-05-13T02:09:06.490869Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(125973, 124)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.kdd_train_2labels.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-05-13T02:09:06.501859Z",
     "start_time": "2017-05-13T02:09:06.497453Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(22544, 124)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.kdd_test_2labels.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-05-13T02:09:07.220976Z",
     "start_time": "2017-05-13T02:09:06.503519Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(125973, 122)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn import model_selection as ms\n",
    "from sklearn import preprocessing as pp\n",
    "\n",
    "class preprocess:\n",
    "    \n",
    "    output_columns_2labels = ['is_Attack','is_Normal']\n",
    "    \n",
    "    x_input = dataset.kdd_train_2labels.drop(output_columns_2labels, axis = 1)\n",
    "    y_output = dataset.kdd_train_2labels.loc[:,output_columns_2labels]\n",
    "\n",
    "    x_test_input = dataset.kdd_test_2labels.drop(output_columns_2labels, axis = 1)\n",
    "    y_test = dataset.kdd_test_2labels.loc[:,output_columns_2labels]\n",
    "\n",
    "    ss = pp.StandardScaler()\n",
    "\n",
    "    x_train = ss.fit_transform(x_input)\n",
    "    x_test = ss.transform(x_test_input)\n",
    "\n",
    "    y_train = y_output.values\n",
    "    y_test = y_test.values\n",
    "\n",
    "preprocess.x_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-05-13T02:09:08.253636Z",
     "start_time": "2017-05-13T02:09:07.222862Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-05-13T02:09:08.428084Z",
     "start_time": "2017-05-13T02:09:08.255267Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class network(object):\n",
    "    \n",
    "    input_dim = 122\n",
    "    classes = 2\n",
    "    hidden_encoder_dim = 122\n",
    "    hidden_layers = 1\n",
    "    latent_dim = 18\n",
    "\n",
    "    def __init__(self, classes, hidden_layers, num_of_features):\n",
    "        self.classes = classes\n",
    "        self.hidden_layers = hidden_layers\n",
    "        self.latent_dim = num_of_features\n",
    "            \n",
    "    def build_layers(self):\n",
    "        tf.reset_default_graph()\n",
    "        #learning_rate = tf.Variable(initial_value=0.001)\n",
    "\n",
    "        input_dim = self.input_dim\n",
    "        classes = self.classes\n",
    "        hidden_encoder_dim = self.hidden_encoder_dim\n",
    "        hidden_layers = self.hidden_layers\n",
    "        latent_dim = self.latent_dim\n",
    "        \n",
    "        with tf.variable_scope(\"Input\"):\n",
    "            self.x = tf.placeholder(\"float\", shape=[None, input_dim])\n",
    "            self.y_ = tf.placeholder(\"float\", shape=[None, classes])\n",
    "            self.keep_prob = tf.placeholder(\"float\")\n",
    "        \n",
    "        with tf.variable_scope(\"Layer_Encoder\"):\n",
    "\n",
    "            hidden_encoder = tf.layers.dense(self.x, hidden_encoder_dim, activation = tf.nn.relu) #, kernel_regularizer=tf.nn.l2_loss)\n",
    "            hidden_encoder = tf.nn.dropout(hidden_encoder, self.keep_prob)\n",
    "            for h in range(hidden_layers - 1):\n",
    "                hidden_encoder = tf.layers.dense(hidden_encoder, latent_dim, activation = tf.nn.relu) #, kernel_regularizer=tf.nn.l2_loss)\n",
    "                hidden_encoder = tf.nn.dropout(hidden_encoder, self.keep_prob)\n",
    "            \n",
    "            #hidden_encoder = tf.layers.dense(self.x, latent_dim, activation = tf.nn.relu) #, kernel_regularizer=tf.nn.l2_loss)\n",
    "            #hidden_encoder = tf.nn.dropout(hidden_encoder, self.keep_prob)\n",
    "            \n",
    "        with tf.variable_scope(\"Layer_Dense_Softmax\"):\n",
    "            self.y = tf.layers.dense(hidden_encoder, classes, activation=tf.nn.softmax)\n",
    "            \n",
    "        with tf.variable_scope(\"Loss\"):\n",
    "            \n",
    "            loss = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(labels = self.y_, logits = self.y))\n",
    "\n",
    "            #loss = tf.clip_by_value(loss, -1e-1, 1e-1)\n",
    "            #loss = tf.where(tf.is_nan(loss), 1e-1, loss)\n",
    "            #loss = tf.where(tf.equal(loss, -1e-1), tf.random_normal(loss.shape), loss)\n",
    "            #loss = tf.where(tf.equal(loss, 1e-1), tf.random_normal(loss.shape), loss)\n",
    "            \n",
    "            self.regularized_loss = loss\n",
    "            correct_prediction = tf.equal(tf.argmax(self.y_, 1), tf.argmax(self.y, 1))\n",
    "            self.tf_accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32), name = \"Accuracy\")\n",
    "\n",
    "        with tf.variable_scope(\"Optimizer\"):\n",
    "            learning_rate=1e-4\n",
    "            optimizer = tf.train.AdamOptimizer(learning_rate)\n",
    "            gradients, variables = zip(*optimizer.compute_gradients(self.regularized_loss))\n",
    "            gradients = [\n",
    "                None if gradient is None else tf.clip_by_value(gradient, -1, 1)\n",
    "                for gradient in gradients]\n",
    "            self.train_op = optimizer.apply_gradients(zip(gradients, variables))\n",
    "            #self.train_op = optimizer.minimize(self.regularized_loss)\n",
    "            \n",
    "        # add op for merging summary\n",
    "        #self.summary_op = tf.summary.merge_all()\n",
    "        self.pred = tf.argmax(self.y, axis = 1)\n",
    "        self.actual = tf.argmax(self.y_, axis = 1)\n",
    "\n",
    "        # add Saver ops\n",
    "        self.saver = tf.train.Saver()\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-05-13T02:09:08.551011Z",
     "start_time": "2017-05-13T02:09:08.430089Z"
    },
    "collapsed": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import collections\n",
    "\n",
    "class Train:    \n",
    "    \n",
    "    result = namedtuple(\"score\", ['epoch', 'no_of_features','hidden_layers','train_score', 'test_score'])\n",
    "\n",
    "    predictions = {}\n",
    "\n",
    "    results = []\n",
    "    best_acc = 0\n",
    "    \n",
    "    def train(epochs, net, h,f):\n",
    "        batch_iterations = 200\n",
    "    \n",
    "        with tf.Session() as sess:\n",
    "            #summary_writer_train = tf.summary.FileWriter('./logs/kdd/VAE/training', graph=sess.graph)\n",
    "            #summary_writer_valid = tf.summary.FileWriter('./logs/kdd/VAE/validation')\n",
    "\n",
    "            sess.run(tf.global_variables_initializer())\n",
    "\n",
    "            for epoch in range(1, (epochs+1)):\n",
    "                x_train, x_valid, y_train, y_valid, = ms.train_test_split(preprocess.x_train, \n",
    "                                                                          preprocess.y_train, \n",
    "                                                                          test_size=0.1)\n",
    "                batch_indices = np.array_split(np.arange(x_train.shape[0]), \n",
    "                                           batch_iterations)\n",
    "                                                                          \n",
    "                for i in batch_indices:\n",
    "                    _, train_loss = sess.run([net.train_op, \n",
    "                                                           net.regularized_loss, \n",
    "                                                           ], #net.summary_op\n",
    "                                                          feed_dict={net.x: x_train[i,:], \n",
    "                                                                     net.y_: y_train[i,:], \n",
    "                                                                     net.keep_prob:1})\n",
    "                    \n",
    "                    #summary_writer_train.add_summary(summary_str, epoch)\n",
    "                    if(train_loss > 1e9):\n",
    "                        print(\"Step {} | Training Loss: {:.6f}\".format(epoch, train_loss))\n",
    "                    \n",
    "\n",
    "                valid_accuracy = sess.run(net.tf_accuracy, #net.summary_op \n",
    "                                                      feed_dict={net.x: preprocess.x_test, \n",
    "                                                                 net.y_: preprocess.y_test, \n",
    "                                                                 net.keep_prob:1})\n",
    "                #summary_writer_valid.add_summary(summary_str, epoch)\n",
    "\n",
    "                if epoch % 1 == 0:\n",
    "                    print(\"Step {} | Training Loss: {:.6f} | Validation Accuracy: {:.6f}\".format(epoch, train_loss, valid_accuracy))\n",
    "\n",
    "            accuracy, pred_value, actual_value, y_pred = sess.run([net.tf_accuracy, \n",
    "                                                           net.pred, \n",
    "                                                           net.actual, net.y], \n",
    "                                                          feed_dict={net.x: preprocess.x_test, \n",
    "                                                                     net.y_: preprocess.y_test, \n",
    "                                                                     net.keep_prob:1})\n",
    "\n",
    "\n",
    "            print(\"Accuracy on Test data: {}\".format(accuracy))\n",
    "            \n",
    "            curr_pred = pd.DataFrame({\"Attack_prob\":y_pred[:,-2], \"Normal_prob\":y_pred[:, -1]})\n",
    "            Train.predictions.update({\"{}_{}_{}\".format(epochs,f,h):curr_pred})\n",
    "            \n",
    "            if accuracy > Train.best_acc:\n",
    "                Train.best_acc = accuracy\n",
    "                Train.pred_value = pred_value\n",
    "                Train.actual_value = actual_value\n",
    "                Train.best_parameters = \"Hidden Layers:{}, Features Count:{}\".format(h, f)\n",
    "                #net.saver.save(sess, \"dataset/epochs_{}_hidden layers_{}_features count_{}\".format(epochs,h,f))\n",
    "            Train.results.append(Train.result(epochs, f, h,valid_accuracy, accuracy))\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-05-13T02:25:29.493031Z",
     "start_time": "2017-05-13T02:09:08.552762Z"
    },
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current Layer Attributes - epochs:100 hidden layers:4 features count:4\n",
      "Step 1 | Training Loss: 0.528424 | Validation Accuracy: 0.574831\n",
      "Step 2 | Training Loss: 0.509805 | Validation Accuracy: 0.713582\n",
      "Step 3 | Training Loss: 0.483057 | Validation Accuracy: 0.724051\n",
      "Step 4 | Training Loss: 0.488333 | Validation Accuracy: 0.734608\n",
      "Step 5 | Training Loss: 0.472584 | Validation Accuracy: 0.752706\n",
      "Step 6 | Training Loss: 0.470036 | Validation Accuracy: 0.753903\n",
      "Step 7 | Training Loss: 0.448185 | Validation Accuracy: 0.754702\n",
      "Step 8 | Training Loss: 0.456574 | Validation Accuracy: 0.759138\n",
      "Step 9 | Training Loss: 0.446128 | Validation Accuracy: 0.768054\n",
      "Step 10 | Training Loss: 0.424114 | Validation Accuracy: 0.773066\n",
      "Step 11 | Training Loss: 0.413871 | Validation Accuracy: 0.781627\n",
      "Step 12 | Training Loss: 0.340858 | Validation Accuracy: 0.790055\n",
      "Step 13 | Training Loss: 0.324988 | Validation Accuracy: 0.778256\n",
      "Step 14 | Training Loss: 0.340924 | Validation Accuracy: 0.767433\n",
      "Step 15 | Training Loss: 0.327862 | Validation Accuracy: 0.766412\n",
      "Step 16 | Training Loss: 0.328272 | Validation Accuracy: 0.769828\n",
      "Step 17 | Training Loss: 0.333007 | Validation Accuracy: 0.768675\n",
      "Step 18 | Training Loss: 0.331417 | Validation Accuracy: 0.766235\n",
      "Step 19 | Training Loss: 0.327215 | Validation Accuracy: 0.770671\n",
      "Step 20 | Training Loss: 0.331799 | Validation Accuracy: 0.769251\n",
      "Step 21 | Training Loss: 0.323516 | Validation Accuracy: 0.771203\n",
      "Step 22 | Training Loss: 0.324322 | Validation Accuracy: 0.769739\n",
      "Step 23 | Training Loss: 0.326729 | Validation Accuracy: 0.773332\n",
      "Step 24 | Training Loss: 0.325261 | Validation Accuracy: 0.772223\n",
      "Step 25 | Training Loss: 0.324110 | Validation Accuracy: 0.772800\n",
      "Step 26 | Training Loss: 0.325846 | Validation Accuracy: 0.772046\n",
      "Step 27 | Training Loss: 0.329493 | Validation Accuracy: 0.773155\n",
      "Step 28 | Training Loss: 0.325181 | Validation Accuracy: 0.773510\n",
      "Step 29 | Training Loss: 0.320088 | Validation Accuracy: 0.773598\n",
      "Step 30 | Training Loss: 0.321884 | Validation Accuracy: 0.774574\n",
      "Step 31 | Training Loss: 0.323196 | Validation Accuracy: 0.772800\n",
      "Step 32 | Training Loss: 0.322073 | Validation Accuracy: 0.771957\n",
      "Step 33 | Training Loss: 0.320496 | Validation Accuracy: 0.773909\n",
      "Step 34 | Training Loss: 0.324161 | Validation Accuracy: 0.775417\n",
      "Step 35 | Training Loss: 0.322445 | Validation Accuracy: 0.775994\n",
      "Step 36 | Training Loss: 0.319675 | Validation Accuracy: 0.773066\n",
      "Step 37 | Training Loss: 0.320853 | Validation Accuracy: 0.777413\n",
      "Step 38 | Training Loss: 0.319776 | Validation Accuracy: 0.775594\n",
      "Step 39 | Training Loss: 0.335482 | Validation Accuracy: 0.777014\n",
      "Step 40 | Training Loss: 0.318457 | Validation Accuracy: 0.776526\n",
      "Step 41 | Training Loss: 0.322824 | Validation Accuracy: 0.776304\n",
      "Step 42 | Training Loss: 0.331573 | Validation Accuracy: 0.775861\n",
      "Step 43 | Training Loss: 0.322969 | Validation Accuracy: 0.776570\n",
      "Step 44 | Training Loss: 0.324848 | Validation Accuracy: 0.775949\n",
      "Step 45 | Training Loss: 0.335535 | Validation Accuracy: 0.777857\n",
      "Step 46 | Training Loss: 0.324862 | Validation Accuracy: 0.774485\n",
      "Step 47 | Training Loss: 0.323816 | Validation Accuracy: 0.776570\n",
      "Step 48 | Training Loss: 0.324901 | Validation Accuracy: 0.775417\n",
      "Step 49 | Training Loss: 0.322441 | Validation Accuracy: 0.775905\n",
      "Step 50 | Training Loss: 0.321207 | Validation Accuracy: 0.777058\n",
      "Step 51 | Training Loss: 0.327730 | Validation Accuracy: 0.774175\n",
      "Step 52 | Training Loss: 0.324467 | Validation Accuracy: 0.775417\n",
      "Step 53 | Training Loss: 0.325088 | Validation Accuracy: 0.776082\n",
      "Step 54 | Training Loss: 0.315181 | Validation Accuracy: 0.774973\n",
      "Step 55 | Training Loss: 0.328612 | Validation Accuracy: 0.776171\n",
      "Step 56 | Training Loss: 0.326021 | Validation Accuracy: 0.775816\n",
      "Step 57 | Training Loss: 0.327626 | Validation Accuracy: 0.772977\n",
      "Step 58 | Training Loss: 0.324497 | Validation Accuracy: 0.775062\n",
      "Step 59 | Training Loss: 0.330577 | Validation Accuracy: 0.775949\n",
      "Step 60 | Training Loss: 0.322039 | Validation Accuracy: 0.773953\n",
      "Step 61 | Training Loss: 0.322570 | Validation Accuracy: 0.774840\n",
      "Step 62 | Training Loss: 0.324688 | Validation Accuracy: 0.774663\n",
      "Step 63 | Training Loss: 0.323535 | Validation Accuracy: 0.774308\n",
      "Step 64 | Training Loss: 0.324141 | Validation Accuracy: 0.773731\n",
      "Step 65 | Training Loss: 0.325906 | Validation Accuracy: 0.774131\n",
      "Step 66 | Training Loss: 0.332610 | Validation Accuracy: 0.773554\n",
      "Step 67 | Training Loss: 0.319239 | Validation Accuracy: 0.775816\n",
      "Step 68 | Training Loss: 0.318829 | Validation Accuracy: 0.774352\n",
      "Step 69 | Training Loss: 0.330616 | Validation Accuracy: 0.775151\n",
      "Step 70 | Training Loss: 0.322163 | Validation Accuracy: 0.774619\n",
      "Step 71 | Training Loss: 0.326655 | Validation Accuracy: 0.775727\n",
      "Step 72 | Training Loss: 0.319103 | Validation Accuracy: 0.778788\n",
      "Step 73 | Training Loss: 0.320895 | Validation Accuracy: 0.777679\n",
      "Step 74 | Training Loss: 0.321948 | Validation Accuracy: 0.776792\n",
      "Step 75 | Training Loss: 0.323872 | Validation Accuracy: 0.776482\n",
      "Step 76 | Training Loss: 0.322275 | Validation Accuracy: 0.778034\n",
      "Step 77 | Training Loss: 0.331443 | Validation Accuracy: 0.775994\n",
      "Step 78 | Training Loss: 0.329607 | Validation Accuracy: 0.777191\n",
      "Step 79 | Training Loss: 0.326456 | Validation Accuracy: 0.777280\n",
      "Step 80 | Training Loss: 0.318578 | Validation Accuracy: 0.778699\n",
      "Step 81 | Training Loss: 0.320637 | Validation Accuracy: 0.777324\n",
      "Step 82 | Training Loss: 0.327639 | Validation Accuracy: 0.777945\n",
      "Step 83 | Training Loss: 0.324473 | Validation Accuracy: 0.776215\n",
      "Step 84 | Training Loss: 0.331398 | Validation Accuracy: 0.779454\n",
      "Step 85 | Training Loss: 0.326005 | Validation Accuracy: 0.780208\n",
      "Step 86 | Training Loss: 0.328277 | Validation Accuracy: 0.778389\n",
      "Step 87 | Training Loss: 0.321109 | Validation Accuracy: 0.778522\n",
      "Step 88 | Training Loss: 0.329964 | Validation Accuracy: 0.778832\n",
      "Step 89 | Training Loss: 0.331708 | Validation Accuracy: 0.779897\n",
      "Step 90 | Training Loss: 0.337524 | Validation Accuracy: 0.777724\n",
      "Step 91 | Training Loss: 0.318676 | Validation Accuracy: 0.778167\n",
      "Step 92 | Training Loss: 0.322062 | Validation Accuracy: 0.779808\n",
      "Step 93 | Training Loss: 0.339043 | Validation Accuracy: 0.778345\n",
      "Step 94 | Training Loss: 0.316263 | Validation Accuracy: 0.778921\n",
      "Step 95 | Training Loss: 0.327354 | Validation Accuracy: 0.779764\n",
      "Step 96 | Training Loss: 0.321260 | Validation Accuracy: 0.778966\n",
      "Step 97 | Training Loss: 0.328906 | Validation Accuracy: 0.779720\n",
      "Step 98 | Training Loss: 0.318306 | Validation Accuracy: 0.779587\n",
      "Step 99 | Training Loss: 0.319043 | Validation Accuracy: 0.779764\n",
      "Step 100 | Training Loss: 0.325591 | Validation Accuracy: 0.779808\n",
      "Accuracy on Test data: 0.7798084020614624\n",
      "Current Layer Attributes - epochs:100 hidden layers:4 features count:8\n",
      "Step 1 | Training Loss: 0.608541 | Validation Accuracy: 0.862402\n",
      "Step 2 | Training Loss: 0.520668 | Validation Accuracy: 0.855172\n",
      "Step 3 | Training Loss: 0.498745 | Validation Accuracy: 0.839736\n",
      "Step 4 | Training Loss: 0.505219 | Validation Accuracy: 0.825186\n",
      "Step 5 | Training Loss: 0.505607 | Validation Accuracy: 0.792983\n",
      "Step 6 | Training Loss: 0.486532 | Validation Accuracy: 0.786684\n",
      "Step 7 | Training Loss: 0.477228 | Validation Accuracy: 0.784732\n",
      "Step 8 | Training Loss: 0.472133 | Validation Accuracy: 0.782425\n",
      "Step 9 | Training Loss: 0.446887 | Validation Accuracy: 0.769872\n",
      "Step 10 | Training Loss: 0.408832 | Validation Accuracy: 0.763352\n",
      "Step 11 | Training Loss: 0.351027 | Validation Accuracy: 0.763307\n",
      "Step 12 | Training Loss: 0.333979 | Validation Accuracy: 0.774086\n",
      "Step 13 | Training Loss: 0.325120 | Validation Accuracy: 0.774397\n",
      "Step 14 | Training Loss: 0.330714 | Validation Accuracy: 0.776836\n",
      "Step 15 | Training Loss: 0.322379 | Validation Accuracy: 0.781405\n",
      "Step 16 | Training Loss: 0.329819 | Validation Accuracy: 0.783135\n",
      "Step 17 | Training Loss: 0.326161 | Validation Accuracy: 0.784022\n",
      "Step 18 | Training Loss: 0.326850 | Validation Accuracy: 0.785043\n",
      "Step 19 | Training Loss: 0.330622 | Validation Accuracy: 0.786107\n",
      "Step 20 | Training Loss: 0.325752 | Validation Accuracy: 0.786018\n",
      "Step 21 | Training Loss: 0.321787 | Validation Accuracy: 0.786107\n",
      "Step 22 | Training Loss: 0.322568 | Validation Accuracy: 0.786152\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 23 | Training Loss: 0.324293 | Validation Accuracy: 0.786817\n",
      "Step 24 | Training Loss: 0.338261 | Validation Accuracy: 0.787482\n",
      "Step 25 | Training Loss: 0.332444 | Validation Accuracy: 0.786595\n",
      "Step 26 | Training Loss: 0.325635 | Validation Accuracy: 0.786684\n",
      "Step 27 | Training Loss: 0.324902 | Validation Accuracy: 0.787127\n",
      "Step 28 | Training Loss: 0.322234 | Validation Accuracy: 0.786728\n",
      "Step 29 | Training Loss: 0.325591 | Validation Accuracy: 0.786595\n",
      "Step 30 | Training Loss: 0.324101 | Validation Accuracy: 0.786595\n",
      "Step 31 | Training Loss: 0.321616 | Validation Accuracy: 0.786595\n",
      "Step 32 | Training Loss: 0.320471 | Validation Accuracy: 0.785397\n",
      "Step 33 | Training Loss: 0.328288 | Validation Accuracy: 0.784643\n",
      "Step 34 | Training Loss: 0.331906 | Validation Accuracy: 0.785531\n",
      "Step 35 | Training Loss: 0.324096 | Validation Accuracy: 0.785176\n",
      "Step 36 | Training Loss: 0.323658 | Validation Accuracy: 0.784688\n",
      "Step 37 | Training Loss: 0.321389 | Validation Accuracy: 0.783534\n",
      "Step 38 | Training Loss: 0.332288 | Validation Accuracy: 0.784466\n",
      "Step 39 | Training Loss: 0.324631 | Validation Accuracy: 0.783889\n",
      "Step 40 | Training Loss: 0.329639 | Validation Accuracy: 0.785043\n",
      "Step 41 | Training Loss: 0.326445 | Validation Accuracy: 0.784022\n",
      "Step 42 | Training Loss: 0.322776 | Validation Accuracy: 0.783845\n",
      "Step 43 | Training Loss: 0.325800 | Validation Accuracy: 0.783224\n",
      "Step 44 | Training Loss: 0.329383 | Validation Accuracy: 0.782559\n",
      "Step 45 | Training Loss: 0.320382 | Validation Accuracy: 0.783668\n",
      "Step 46 | Training Loss: 0.325453 | Validation Accuracy: 0.783534\n",
      "Step 47 | Training Loss: 0.327057 | Validation Accuracy: 0.783668\n",
      "Step 48 | Training Loss: 0.322280 | Validation Accuracy: 0.785043\n",
      "Step 49 | Training Loss: 0.333056 | Validation Accuracy: 0.783668\n",
      "Step 50 | Training Loss: 0.323869 | Validation Accuracy: 0.783801\n",
      "Step 51 | Training Loss: 0.326296 | Validation Accuracy: 0.782470\n",
      "Step 52 | Training Loss: 0.322644 | Validation Accuracy: 0.783490\n",
      "Step 53 | Training Loss: 0.325591 | Validation Accuracy: 0.783579\n",
      "Step 54 | Training Loss: 0.324458 | Validation Accuracy: 0.782337\n",
      "Step 55 | Training Loss: 0.324582 | Validation Accuracy: 0.783889\n",
      "Step 56 | Training Loss: 0.320484 | Validation Accuracy: 0.784732\n",
      "Step 57 | Training Loss: 0.318622 | Validation Accuracy: 0.782913\n",
      "Step 58 | Training Loss: 0.320882 | Validation Accuracy: 0.784599\n",
      "Step 59 | Training Loss: 0.326645 | Validation Accuracy: 0.783534\n",
      "Step 60 | Training Loss: 0.328145 | Validation Accuracy: 0.785575\n",
      "Step 61 | Training Loss: 0.323002 | Validation Accuracy: 0.784022\n",
      "Step 62 | Training Loss: 0.322502 | Validation Accuracy: 0.784333\n",
      "Step 63 | Training Loss: 0.328231 | Validation Accuracy: 0.786240\n",
      "Step 64 | Training Loss: 0.327995 | Validation Accuracy: 0.785043\n",
      "Step 65 | Training Loss: 0.318941 | Validation Accuracy: 0.784909\n",
      "Step 66 | Training Loss: 0.317462 | Validation Accuracy: 0.783046\n",
      "Step 67 | Training Loss: 0.320093 | Validation Accuracy: 0.785176\n",
      "Step 68 | Training Loss: 0.326203 | Validation Accuracy: 0.784776\n",
      "Step 69 | Training Loss: 0.323714 | Validation Accuracy: 0.783934\n",
      "Step 70 | Training Loss: 0.322323 | Validation Accuracy: 0.784599\n",
      "Step 71 | Training Loss: 0.323238 | Validation Accuracy: 0.784067\n",
      "Step 72 | Training Loss: 0.317779 | Validation Accuracy: 0.785752\n",
      "Step 73 | Training Loss: 0.322878 | Validation Accuracy: 0.783623\n",
      "Step 74 | Training Loss: 0.325741 | Validation Accuracy: 0.785974\n",
      "Step 75 | Training Loss: 0.335542 | Validation Accuracy: 0.783046\n",
      "Step 76 | Training Loss: 0.327256 | Validation Accuracy: 0.784954\n",
      "Step 77 | Training Loss: 0.320828 | Validation Accuracy: 0.783845\n",
      "Step 78 | Training Loss: 0.322698 | Validation Accuracy: 0.784466\n",
      "Step 79 | Training Loss: 0.324399 | Validation Accuracy: 0.785220\n",
      "Step 80 | Training Loss: 0.326046 | Validation Accuracy: 0.785442\n",
      "Step 81 | Training Loss: 0.320246 | Validation Accuracy: 0.784422\n",
      "Step 82 | Training Loss: 0.324221 | Validation Accuracy: 0.784643\n",
      "Step 83 | Training Loss: 0.324052 | Validation Accuracy: 0.785176\n",
      "Step 84 | Training Loss: 0.328275 | Validation Accuracy: 0.786018\n",
      "Step 85 | Training Loss: 0.328259 | Validation Accuracy: 0.785841\n",
      "Step 86 | Training Loss: 0.324814 | Validation Accuracy: 0.784022\n",
      "Step 87 | Training Loss: 0.320900 | Validation Accuracy: 0.784244\n",
      "Step 88 | Training Loss: 0.324329 | Validation Accuracy: 0.783446\n",
      "Step 89 | Training Loss: 0.326391 | Validation Accuracy: 0.784555\n",
      "Step 90 | Training Loss: 0.320110 | Validation Accuracy: 0.784865\n",
      "Step 91 | Training Loss: 0.322842 | Validation Accuracy: 0.786639\n",
      "Step 92 | Training Loss: 0.324623 | Validation Accuracy: 0.784998\n",
      "Step 93 | Training Loss: 0.323836 | Validation Accuracy: 0.784289\n",
      "Step 94 | Training Loss: 0.322209 | Validation Accuracy: 0.784289\n",
      "Step 95 | Training Loss: 0.329926 | Validation Accuracy: 0.784422\n",
      "Step 96 | Training Loss: 0.323678 | Validation Accuracy: 0.784289\n",
      "Step 97 | Training Loss: 0.324897 | Validation Accuracy: 0.785043\n",
      "Step 98 | Training Loss: 0.325905 | Validation Accuracy: 0.785974\n",
      "Step 99 | Training Loss: 0.322434 | Validation Accuracy: 0.783889\n",
      "Step 100 | Training Loss: 0.327211 | Validation Accuracy: 0.788369\n",
      "Accuracy on Test data: 0.7883694171905518\n",
      "Current Layer Attributes - epochs:100 hidden layers:4 features count:32\n",
      "Step 1 | Training Loss: 0.388697 | Validation Accuracy: 0.754214\n",
      "Step 2 | Training Loss: 0.354796 | Validation Accuracy: 0.738511\n",
      "Step 3 | Training Loss: 0.334849 | Validation Accuracy: 0.756875\n",
      "Step 4 | Training Loss: 0.339839 | Validation Accuracy: 0.747693\n",
      "Step 5 | Training Loss: 0.336608 | Validation Accuracy: 0.758916\n",
      "Step 6 | Training Loss: 0.340143 | Validation Accuracy: 0.757674\n",
      "Step 7 | Training Loss: 0.324199 | Validation Accuracy: 0.759892\n",
      "Step 8 | Training Loss: 0.329739 | Validation Accuracy: 0.760513\n",
      "Step 9 | Training Loss: 0.327787 | Validation Accuracy: 0.758694\n",
      "Step 10 | Training Loss: 0.322837 | Validation Accuracy: 0.760646\n",
      "Step 11 | Training Loss: 0.332223 | Validation Accuracy: 0.759626\n",
      "Step 12 | Training Loss: 0.327145 | Validation Accuracy: 0.762021\n",
      "Step 13 | Training Loss: 0.321850 | Validation Accuracy: 0.763884\n",
      "Step 14 | Training Loss: 0.336511 | Validation Accuracy: 0.761134\n",
      "Step 15 | Training Loss: 0.329089 | Validation Accuracy: 0.766324\n",
      "Step 16 | Training Loss: 0.327483 | Validation Accuracy: 0.763307\n",
      "Step 17 | Training Loss: 0.331291 | Validation Accuracy: 0.770005\n",
      "Step 18 | Training Loss: 0.331269 | Validation Accuracy: 0.765348\n",
      "Step 19 | Training Loss: 0.329335 | Validation Accuracy: 0.769429\n",
      "Step 20 | Training Loss: 0.321959 | Validation Accuracy: 0.764372\n",
      "Step 21 | Training Loss: 0.327357 | Validation Accuracy: 0.768098\n",
      "Step 22 | Training Loss: 0.324773 | Validation Accuracy: 0.764993\n",
      "Step 23 | Training Loss: 0.328916 | Validation Accuracy: 0.765082\n",
      "Step 24 | Training Loss: 0.331709 | Validation Accuracy: 0.769517\n",
      "Step 25 | Training Loss: 0.325279 | Validation Accuracy: 0.772889\n",
      "Step 26 | Training Loss: 0.328333 | Validation Accuracy: 0.774175\n",
      "Step 27 | Training Loss: 0.320776 | Validation Accuracy: 0.770005\n",
      "Step 28 | Training Loss: 0.328145 | Validation Accuracy: 0.771425\n",
      "Step 29 | Training Loss: 0.330733 | Validation Accuracy: 0.771114\n",
      "Step 30 | Training Loss: 0.320796 | Validation Accuracy: 0.772578\n",
      "Step 31 | Training Loss: 0.326372 | Validation Accuracy: 0.768852\n",
      "Step 32 | Training Loss: 0.325452 | Validation Accuracy: 0.770138\n",
      "Step 33 | Training Loss: 0.327056 | Validation Accuracy: 0.773377\n",
      "Step 34 | Training Loss: 0.328183 | Validation Accuracy: 0.774752\n",
      "Step 35 | Training Loss: 0.325388 | Validation Accuracy: 0.775240\n",
      "Step 36 | Training Loss: 0.322451 | Validation Accuracy: 0.770981\n",
      "Step 37 | Training Loss: 0.326223 | Validation Accuracy: 0.771647\n",
      "Step 38 | Training Loss: 0.322779 | Validation Accuracy: 0.775151\n",
      "Step 39 | Training Loss: 0.332241 | Validation Accuracy: 0.767033\n",
      "Step 40 | Training Loss: 0.339092 | Validation Accuracy: 0.764727\n",
      "Step 41 | Training Loss: 0.320315 | Validation Accuracy: 0.771913\n",
      "Step 42 | Training Loss: 0.323089 | Validation Accuracy: 0.764150\n",
      "Step 43 | Training Loss: 0.328044 | Validation Accuracy: 0.768187\n",
      "Step 44 | Training Loss: 0.320391 | Validation Accuracy: 0.771159\n",
      "Step 45 | Training Loss: 0.322685 | Validation Accuracy: 0.764416\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 46 | Training Loss: 0.327553 | Validation Accuracy: 0.763263\n",
      "Step 47 | Training Loss: 0.329097 | Validation Accuracy: 0.766279\n",
      "Step 48 | Training Loss: 0.326059 | Validation Accuracy: 0.769384\n",
      "Step 49 | Training Loss: 0.326215 | Validation Accuracy: 0.770005\n",
      "Step 50 | Training Loss: 0.322354 | Validation Accuracy: 0.764771\n",
      "Step 51 | Training Loss: 0.322948 | Validation Accuracy: 0.764904\n",
      "Step 52 | Training Loss: 0.320776 | Validation Accuracy: 0.766945\n",
      "Step 53 | Training Loss: 0.319091 | Validation Accuracy: 0.765836\n",
      "Step 54 | Training Loss: 0.326438 | Validation Accuracy: 0.768231\n",
      "Step 55 | Training Loss: 0.330119 | Validation Accuracy: 0.770804\n",
      "Step 56 | Training Loss: 0.321621 | Validation Accuracy: 0.764815\n",
      "Step 57 | Training Loss: 0.322082 | Validation Accuracy: 0.766279\n",
      "Step 58 | Training Loss: 0.325788 | Validation Accuracy: 0.767654\n",
      "Step 59 | Training Loss: 0.323731 | Validation Accuracy: 0.771070\n",
      "Step 60 | Training Loss: 0.324359 | Validation Accuracy: 0.765924\n",
      "Step 61 | Training Loss: 0.324279 | Validation Accuracy: 0.768408\n",
      "Step 62 | Training Loss: 0.331689 | Validation Accuracy: 0.769296\n",
      "Step 63 | Training Loss: 0.315125 | Validation Accuracy: 0.768009\n",
      "Step 64 | Training Loss: 0.321181 | Validation Accuracy: 0.768231\n",
      "Step 65 | Training Loss: 0.329467 | Validation Accuracy: 0.767033\n",
      "Step 66 | Training Loss: 0.325734 | Validation Accuracy: 0.767521\n",
      "Step 67 | Training Loss: 0.321670 | Validation Accuracy: 0.767610\n",
      "Step 68 | Training Loss: 0.322259 | Validation Accuracy: 0.766856\n",
      "Step 69 | Training Loss: 0.324073 | Validation Accuracy: 0.763928\n",
      "Step 70 | Training Loss: 0.334164 | Validation Accuracy: 0.770094\n",
      "Step 71 | Training Loss: 0.325528 | Validation Accuracy: 0.767699\n",
      "Step 72 | Training Loss: 0.322909 | Validation Accuracy: 0.768808\n",
      "Step 73 | Training Loss: 0.334578 | Validation Accuracy: 0.769207\n",
      "Step 74 | Training Loss: 0.323967 | Validation Accuracy: 0.767743\n",
      "Step 75 | Training Loss: 0.317153 | Validation Accuracy: 0.765747\n",
      "Step 76 | Training Loss: 0.324570 | Validation Accuracy: 0.768542\n",
      "Step 77 | Training Loss: 0.323951 | Validation Accuracy: 0.769296\n",
      "Step 78 | Training Loss: 0.323053 | Validation Accuracy: 0.772179\n",
      "Step 79 | Training Loss: 0.328708 | Validation Accuracy: 0.774485\n",
      "Step 80 | Training Loss: 0.327912 | Validation Accuracy: 0.770759\n",
      "Step 81 | Training Loss: 0.323871 | Validation Accuracy: 0.765791\n",
      "Step 82 | Training Loss: 0.317132 | Validation Accuracy: 0.764061\n",
      "Step 83 | Training Loss: 0.316834 | Validation Accuracy: 0.767965\n",
      "Step 84 | Training Loss: 0.320669 | Validation Accuracy: 0.768985\n",
      "Step 85 | Training Loss: 0.329814 | Validation Accuracy: 0.768453\n",
      "Step 86 | Training Loss: 0.327436 | Validation Accuracy: 0.768586\n",
      "Step 87 | Training Loss: 0.325671 | Validation Accuracy: 0.769562\n",
      "Step 88 | Training Loss: 0.322267 | Validation Accuracy: 0.771336\n",
      "Step 89 | Training Loss: 0.323826 | Validation Accuracy: 0.770050\n",
      "Step 90 | Training Loss: 0.327405 | Validation Accuracy: 0.766856\n",
      "Step 91 | Training Loss: 0.322979 | Validation Accuracy: 0.771913\n",
      "Step 92 | Training Loss: 0.323745 | Validation Accuracy: 0.766945\n",
      "Step 93 | Training Loss: 0.318647 | Validation Accuracy: 0.769163\n",
      "Step 94 | Training Loss: 0.323914 | Validation Accuracy: 0.766102\n",
      "Step 95 | Training Loss: 0.329375 | Validation Accuracy: 0.765969\n",
      "Step 96 | Training Loss: 0.315038 | Validation Accuracy: 0.768009\n",
      "Step 97 | Training Loss: 0.322463 | Validation Accuracy: 0.769029\n",
      "Step 98 | Training Loss: 0.325922 | Validation Accuracy: 0.768187\n",
      "Step 99 | Training Loss: 0.324395 | Validation Accuracy: 0.771114\n",
      "Step 100 | Training Loss: 0.320413 | Validation Accuracy: 0.767211\n",
      "Accuracy on Test data: 0.7672107815742493\n",
      "Current Layer Attributes - epochs:100 hidden layers:4 features count:64\n",
      "Step 1 | Training Loss: 0.345736 | Validation Accuracy: 0.786329\n",
      "Step 2 | Training Loss: 0.341967 | Validation Accuracy: 0.769118\n",
      "Step 3 | Training Loss: 0.346000 | Validation Accuracy: 0.764949\n",
      "Step 4 | Training Loss: 0.334646 | Validation Accuracy: 0.773066\n",
      "Step 5 | Training Loss: 0.334343 | Validation Accuracy: 0.783180\n",
      "Step 6 | Training Loss: 0.318031 | Validation Accuracy: 0.783401\n",
      "Step 7 | Training Loss: 0.333791 | Validation Accuracy: 0.779941\n",
      "Step 8 | Training Loss: 0.334059 | Validation Accuracy: 0.776393\n",
      "Step 9 | Training Loss: 0.316696 | Validation Accuracy: 0.778744\n",
      "Step 10 | Training Loss: 0.323681 | Validation Accuracy: 0.777768\n",
      "Step 11 | Training Loss: 0.327303 | Validation Accuracy: 0.778921\n",
      "Step 12 | Training Loss: 0.326245 | Validation Accuracy: 0.775240\n",
      "Step 13 | Training Loss: 0.329652 | Validation Accuracy: 0.776748\n",
      "Step 14 | Training Loss: 0.329414 | Validation Accuracy: 0.774663\n",
      "Step 15 | Training Loss: 0.324256 | Validation Accuracy: 0.773022\n",
      "Step 16 | Training Loss: 0.324139 | Validation Accuracy: 0.767876\n",
      "Step 17 | Training Loss: 0.332295 | Validation Accuracy: 0.771070\n",
      "Step 18 | Training Loss: 0.324831 | Validation Accuracy: 0.775151\n",
      "Step 19 | Training Loss: 0.324821 | Validation Accuracy: 0.772001\n",
      "Step 20 | Training Loss: 0.316292 | Validation Accuracy: 0.775284\n",
      "Step 21 | Training Loss: 0.333824 | Validation Accuracy: 0.774485\n",
      "Step 22 | Training Loss: 0.324478 | Validation Accuracy: 0.771602\n",
      "Step 23 | Training Loss: 0.321019 | Validation Accuracy: 0.771913\n",
      "Step 24 | Training Loss: 0.331345 | Validation Accuracy: 0.772046\n",
      "Step 25 | Training Loss: 0.324454 | Validation Accuracy: 0.771203\n",
      "Step 26 | Training Loss: 0.324856 | Validation Accuracy: 0.772179\n",
      "Step 27 | Training Loss: 0.326795 | Validation Accuracy: 0.770316\n",
      "Step 28 | Training Loss: 0.335344 | Validation Accuracy: 0.773377\n",
      "Step 29 | Training Loss: 0.329266 | Validation Accuracy: 0.773022\n",
      "Step 30 | Training Loss: 0.322195 | Validation Accuracy: 0.773554\n",
      "Step 31 | Training Loss: 0.331378 | Validation Accuracy: 0.771513\n",
      "Step 32 | Training Loss: 0.323896 | Validation Accuracy: 0.774796\n",
      "Step 33 | Training Loss: 0.317556 | Validation Accuracy: 0.772800\n",
      "Step 34 | Training Loss: 0.331502 | Validation Accuracy: 0.769074\n",
      "Step 35 | Training Loss: 0.329628 | Validation Accuracy: 0.772977\n",
      "Step 36 | Training Loss: 0.315514 | Validation Accuracy: 0.773598\n",
      "Step 37 | Training Loss: 0.323443 | Validation Accuracy: 0.771913\n",
      "Step 38 | Training Loss: 0.326986 | Validation Accuracy: 0.771913\n",
      "Step 39 | Training Loss: 0.322283 | Validation Accuracy: 0.772756\n",
      "Step 40 | Training Loss: 0.322265 | Validation Accuracy: 0.773909\n",
      "Step 41 | Training Loss: 0.324015 | Validation Accuracy: 0.773022\n",
      "Step 42 | Training Loss: 0.323900 | Validation Accuracy: 0.773776\n",
      "Step 43 | Training Loss: 0.325679 | Validation Accuracy: 0.773909\n",
      "Step 44 | Training Loss: 0.322164 | Validation Accuracy: 0.773421\n",
      "Step 45 | Training Loss: 0.324216 | Validation Accuracy: 0.777502\n",
      "Step 46 | Training Loss: 0.327547 | Validation Accuracy: 0.775373\n",
      "Step 47 | Training Loss: 0.324541 | Validation Accuracy: 0.775062\n",
      "Step 48 | Training Loss: 0.322254 | Validation Accuracy: 0.781272\n",
      "Step 49 | Training Loss: 0.320833 | Validation Accuracy: 0.777014\n",
      "Step 50 | Training Loss: 0.322826 | Validation Accuracy: 0.780163\n",
      "Step 51 | Training Loss: 0.316818 | Validation Accuracy: 0.780873\n",
      "Step 52 | Training Loss: 0.320491 | Validation Accuracy: 0.778300\n",
      "Step 53 | Training Loss: 0.325573 | Validation Accuracy: 0.779099\n",
      "Step 54 | Training Loss: 0.323920 | Validation Accuracy: 0.778788\n",
      "Step 55 | Training Loss: 0.325853 | Validation Accuracy: 0.779099\n",
      "Step 56 | Training Loss: 0.319035 | Validation Accuracy: 0.778699\n",
      "Step 57 | Training Loss: 0.322134 | Validation Accuracy: 0.777945\n",
      "Step 58 | Training Loss: 0.333499 | Validation Accuracy: 0.768453\n",
      "Step 59 | Training Loss: 0.324029 | Validation Accuracy: 0.772134\n",
      "Step 60 | Training Loss: 0.320431 | Validation Accuracy: 0.777103\n",
      "Step 61 | Training Loss: 0.327776 | Validation Accuracy: 0.775106\n",
      "Step 62 | Training Loss: 0.320381 | Validation Accuracy: 0.780385\n",
      "Step 63 | Training Loss: 0.323546 | Validation Accuracy: 0.783579\n",
      "Step 64 | Training Loss: 0.322411 | Validation Accuracy: 0.776659\n",
      "Step 65 | Training Loss: 0.318572 | Validation Accuracy: 0.785664\n",
      "Step 66 | Training Loss: 0.322897 | Validation Accuracy: 0.775018\n",
      "Step 67 | Training Loss: 0.324115 | Validation Accuracy: 0.774663\n",
      "Step 68 | Training Loss: 0.318724 | Validation Accuracy: 0.774707\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 69 | Training Loss: 0.324984 | Validation Accuracy: 0.773998\n",
      "Step 70 | Training Loss: 0.324201 | Validation Accuracy: 0.775683\n",
      "Step 71 | Training Loss: 0.316926 | Validation Accuracy: 0.776659\n",
      "Step 72 | Training Loss: 0.324930 | Validation Accuracy: 0.774619\n",
      "Step 73 | Training Loss: 0.325752 | Validation Accuracy: 0.774042\n",
      "Step 74 | Training Loss: 0.324356 | Validation Accuracy: 0.782115\n",
      "Step 75 | Training Loss: 0.318600 | Validation Accuracy: 0.776615\n",
      "Step 76 | Training Loss: 0.323614 | Validation Accuracy: 0.779897\n",
      "Step 77 | Training Loss: 0.325645 | Validation Accuracy: 0.779498\n",
      "Step 78 | Training Loss: 0.319134 | Validation Accuracy: 0.779587\n",
      "Step 79 | Training Loss: 0.320403 | Validation Accuracy: 0.778522\n",
      "Step 80 | Training Loss: 0.327434 | Validation Accuracy: 0.779941\n",
      "Step 81 | Training Loss: 0.327335 | Validation Accuracy: 0.779187\n",
      "Step 82 | Training Loss: 0.329323 | Validation Accuracy: 0.779720\n",
      "Step 83 | Training Loss: 0.318584 | Validation Accuracy: 0.777591\n",
      "Step 84 | Training Loss: 0.316837 | Validation Accuracy: 0.777857\n",
      "Step 85 | Training Loss: 0.332710 | Validation Accuracy: 0.775949\n",
      "Step 86 | Training Loss: 0.316858 | Validation Accuracy: 0.779675\n",
      "Step 87 | Training Loss: 0.320345 | Validation Accuracy: 0.774352\n",
      "Step 88 | Training Loss: 0.322103 | Validation Accuracy: 0.770138\n",
      "Step 89 | Training Loss: 0.321841 | Validation Accuracy: 0.777812\n",
      "Step 90 | Training Loss: 0.322399 | Validation Accuracy: 0.774219\n",
      "Step 91 | Training Loss: 0.316801 | Validation Accuracy: 0.768009\n",
      "Step 92 | Training Loss: 0.324615 | Validation Accuracy: 0.780740\n",
      "Step 93 | Training Loss: 0.318575 | Validation Accuracy: 0.781982\n",
      "Step 94 | Training Loss: 0.323942 | Validation Accuracy: 0.779454\n",
      "Step 95 | Training Loss: 0.322084 | Validation Accuracy: 0.778921\n",
      "Step 96 | Training Loss: 0.325632 | Validation Accuracy: 0.779143\n",
      "Step 97 | Training Loss: 0.320336 | Validation Accuracy: 0.781583\n",
      "Step 98 | Training Loss: 0.322097 | Validation Accuracy: 0.782780\n",
      "Step 99 | Training Loss: 0.325759 | Validation Accuracy: 0.781361\n",
      "Step 100 | Training Loss: 0.324176 | Validation Accuracy: 0.778167\n",
      "Accuracy on Test data: 0.7781671285629272\n",
      "Current Layer Attributes - epochs:100 hidden layers:6 features count:4\n",
      "Step 1 | Training Loss: 0.566578 | Validation Accuracy: 0.795023\n",
      "Step 2 | Training Loss: 0.534502 | Validation Accuracy: 0.793337\n",
      "Step 3 | Training Loss: 0.516075 | Validation Accuracy: 0.762243\n",
      "Step 4 | Training Loss: 0.466499 | Validation Accuracy: 0.757408\n",
      "Step 5 | Training Loss: 0.392875 | Validation Accuracy: 0.755279\n",
      "Step 6 | Training Loss: 0.361274 | Validation Accuracy: 0.748581\n",
      "Step 7 | Training Loss: 0.364021 | Validation Accuracy: 0.747117\n",
      "Step 8 | Training Loss: 0.343809 | Validation Accuracy: 0.747161\n",
      "Step 9 | Training Loss: 0.346064 | Validation Accuracy: 0.746984\n",
      "Step 10 | Training Loss: 0.341159 | Validation Accuracy: 0.747915\n",
      "Step 11 | Training Loss: 0.336835 | Validation Accuracy: 0.757541\n",
      "Step 12 | Training Loss: 0.334002 | Validation Accuracy: 0.757541\n",
      "Step 13 | Training Loss: 0.335022 | Validation Accuracy: 0.757408\n",
      "Step 14 | Training Loss: 0.331476 | Validation Accuracy: 0.759936\n",
      "Step 15 | Training Loss: 0.329534 | Validation Accuracy: 0.761932\n",
      "Step 16 | Training Loss: 0.328316 | Validation Accuracy: 0.761622\n",
      "Step 17 | Training Loss: 0.331143 | Validation Accuracy: 0.762420\n",
      "Step 18 | Training Loss: 0.329826 | Validation Accuracy: 0.763485\n",
      "Step 19 | Training Loss: 0.327653 | Validation Accuracy: 0.763440\n",
      "Step 20 | Training Loss: 0.329845 | Validation Accuracy: 0.764061\n",
      "Step 21 | Training Loss: 0.341713 | Validation Accuracy: 0.765215\n",
      "Step 22 | Training Loss: 0.326546 | Validation Accuracy: 0.765836\n",
      "Step 23 | Training Loss: 0.322455 | Validation Accuracy: 0.765126\n",
      "Step 24 | Training Loss: 0.332435 | Validation Accuracy: 0.766013\n",
      "Step 25 | Training Loss: 0.330643 | Validation Accuracy: 0.766723\n",
      "Step 26 | Training Loss: 0.328951 | Validation Accuracy: 0.766057\n",
      "Step 27 | Training Loss: 0.328399 | Validation Accuracy: 0.766679\n",
      "Step 28 | Training Loss: 0.324701 | Validation Accuracy: 0.771735\n",
      "Step 29 | Training Loss: 0.329785 | Validation Accuracy: 0.772090\n",
      "Step 30 | Training Loss: 0.331590 | Validation Accuracy: 0.772001\n",
      "Step 31 | Training Loss: 0.319103 | Validation Accuracy: 0.772134\n",
      "Step 32 | Training Loss: 0.330180 | Validation Accuracy: 0.772578\n",
      "Step 33 | Training Loss: 0.333924 | Validation Accuracy: 0.772977\n",
      "Step 34 | Training Loss: 0.324940 | Validation Accuracy: 0.773465\n",
      "Step 35 | Training Loss: 0.326725 | Validation Accuracy: 0.774131\n",
      "Step 36 | Training Loss: 0.326808 | Validation Accuracy: 0.774574\n",
      "Step 37 | Training Loss: 0.325538 | Validation Accuracy: 0.774707\n",
      "Step 38 | Training Loss: 0.325966 | Validation Accuracy: 0.775062\n",
      "Step 39 | Training Loss: 0.327121 | Validation Accuracy: 0.774929\n",
      "Step 40 | Training Loss: 0.333937 | Validation Accuracy: 0.773820\n",
      "Step 41 | Training Loss: 0.326087 | Validation Accuracy: 0.775151\n",
      "Step 42 | Training Loss: 0.333152 | Validation Accuracy: 0.774530\n",
      "Step 43 | Training Loss: 0.330884 | Validation Accuracy: 0.775018\n",
      "Step 44 | Training Loss: 0.328932 | Validation Accuracy: 0.774663\n",
      "Step 45 | Training Loss: 0.324659 | Validation Accuracy: 0.774308\n",
      "Step 46 | Training Loss: 0.329340 | Validation Accuracy: 0.775195\n",
      "Step 47 | Training Loss: 0.333967 | Validation Accuracy: 0.775240\n",
      "Step 48 | Training Loss: 0.327320 | Validation Accuracy: 0.774752\n",
      "Step 49 | Training Loss: 0.323776 | Validation Accuracy: 0.775594\n",
      "Step 50 | Training Loss: 0.330178 | Validation Accuracy: 0.775949\n",
      "Step 51 | Training Loss: 0.325095 | Validation Accuracy: 0.774619\n",
      "Step 52 | Training Loss: 0.322586 | Validation Accuracy: 0.775506\n",
      "Step 53 | Training Loss: 0.322775 | Validation Accuracy: 0.775417\n",
      "Step 54 | Training Loss: 0.330797 | Validation Accuracy: 0.776437\n",
      "Step 55 | Training Loss: 0.323097 | Validation Accuracy: 0.776082\n",
      "Step 56 | Training Loss: 0.333438 | Validation Accuracy: 0.776393\n",
      "Step 57 | Training Loss: 0.324146 | Validation Accuracy: 0.775639\n",
      "Step 58 | Training Loss: 0.321094 | Validation Accuracy: 0.776215\n",
      "Step 59 | Training Loss: 0.325973 | Validation Accuracy: 0.777147\n",
      "Step 60 | Training Loss: 0.343499 | Validation Accuracy: 0.777635\n",
      "Step 61 | Training Loss: 0.337504 | Validation Accuracy: 0.777990\n",
      "Step 62 | Training Loss: 0.325722 | Validation Accuracy: 0.776570\n",
      "Step 63 | Training Loss: 0.331297 | Validation Accuracy: 0.776792\n",
      "Step 64 | Training Loss: 0.328089 | Validation Accuracy: 0.777280\n",
      "Step 65 | Training Loss: 0.330008 | Validation Accuracy: 0.776659\n",
      "Step 66 | Training Loss: 0.333102 | Validation Accuracy: 0.777103\n",
      "Step 67 | Training Loss: 0.328317 | Validation Accuracy: 0.777280\n",
      "Step 68 | Training Loss: 0.340128 | Validation Accuracy: 0.777324\n",
      "Step 69 | Training Loss: 0.318679 | Validation Accuracy: 0.777147\n",
      "Step 70 | Training Loss: 0.335231 | Validation Accuracy: 0.776969\n",
      "Step 71 | Training Loss: 0.326781 | Validation Accuracy: 0.777679\n",
      "Step 72 | Training Loss: 0.340614 | Validation Accuracy: 0.776792\n",
      "Step 73 | Training Loss: 0.324198 | Validation Accuracy: 0.776969\n",
      "Step 74 | Training Loss: 0.325173 | Validation Accuracy: 0.776792\n",
      "Step 75 | Training Loss: 0.322896 | Validation Accuracy: 0.777058\n",
      "Step 76 | Training Loss: 0.332530 | Validation Accuracy: 0.776969\n",
      "Step 77 | Training Loss: 0.323925 | Validation Accuracy: 0.776881\n",
      "Step 78 | Training Loss: 0.324733 | Validation Accuracy: 0.777591\n",
      "Step 79 | Training Loss: 0.322702 | Validation Accuracy: 0.776881\n",
      "Step 80 | Training Loss: 0.327844 | Validation Accuracy: 0.777058\n",
      "Step 81 | Training Loss: 0.326076 | Validation Accuracy: 0.777014\n",
      "Step 82 | Training Loss: 0.319892 | Validation Accuracy: 0.776836\n",
      "Step 83 | Training Loss: 0.325751 | Validation Accuracy: 0.777324\n",
      "Step 84 | Training Loss: 0.333781 | Validation Accuracy: 0.777591\n",
      "Step 85 | Training Loss: 0.331328 | Validation Accuracy: 0.777236\n",
      "Step 86 | Training Loss: 0.327526 | Validation Accuracy: 0.777369\n",
      "Step 87 | Training Loss: 0.321324 | Validation Accuracy: 0.777457\n",
      "Step 88 | Training Loss: 0.327752 | Validation Accuracy: 0.777191\n",
      "Step 89 | Training Loss: 0.333813 | Validation Accuracy: 0.777990\n",
      "Step 90 | Training Loss: 0.324104 | Validation Accuracy: 0.777014\n",
      "Step 91 | Training Loss: 0.322250 | Validation Accuracy: 0.776969\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 92 | Training Loss: 0.333496 | Validation Accuracy: 0.776925\n",
      "Step 93 | Training Loss: 0.324076 | Validation Accuracy: 0.777103\n",
      "Step 94 | Training Loss: 0.325730 | Validation Accuracy: 0.777635\n",
      "Step 95 | Training Loss: 0.320513 | Validation Accuracy: 0.777768\n",
      "Step 96 | Training Loss: 0.334719 | Validation Accuracy: 0.777103\n",
      "Step 97 | Training Loss: 0.324064 | Validation Accuracy: 0.777457\n",
      "Step 98 | Training Loss: 0.334592 | Validation Accuracy: 0.778167\n",
      "Step 99 | Training Loss: 0.325685 | Validation Accuracy: 0.777546\n",
      "Step 100 | Training Loss: 0.329460 | Validation Accuracy: 0.777280\n",
      "Accuracy on Test data: 0.7772799730300903\n",
      "Current Layer Attributes - epochs:100 hidden layers:6 features count:8\n",
      "Step 1 | Training Loss: 0.533019 | Validation Accuracy: 0.897489\n",
      "Step 2 | Training Loss: 0.512365 | Validation Accuracy: 0.797596\n",
      "Step 3 | Training Loss: 0.483961 | Validation Accuracy: 0.780784\n",
      "Step 4 | Training Loss: 0.472232 | Validation Accuracy: 0.769340\n",
      "Step 5 | Training Loss: 0.438500 | Validation Accuracy: 0.767122\n",
      "Step 6 | Training Loss: 0.403803 | Validation Accuracy: 0.764594\n",
      "Step 7 | Training Loss: 0.394563 | Validation Accuracy: 0.759537\n",
      "Step 8 | Training Loss: 0.360111 | Validation Accuracy: 0.760114\n",
      "Step 9 | Training Loss: 0.352020 | Validation Accuracy: 0.759581\n",
      "Step 10 | Training Loss: 0.337652 | Validation Accuracy: 0.759581\n",
      "Step 11 | Training Loss: 0.330997 | Validation Accuracy: 0.759182\n",
      "Step 12 | Training Loss: 0.344834 | Validation Accuracy: 0.758827\n",
      "Step 13 | Training Loss: 0.334185 | Validation Accuracy: 0.759537\n",
      "Step 14 | Training Loss: 0.324778 | Validation Accuracy: 0.760468\n",
      "Step 15 | Training Loss: 0.334031 | Validation Accuracy: 0.760779\n",
      "Step 16 | Training Loss: 0.319279 | Validation Accuracy: 0.760202\n",
      "Step 17 | Training Loss: 0.327470 | Validation Accuracy: 0.760513\n",
      "Step 18 | Training Loss: 0.329197 | Validation Accuracy: 0.760735\n",
      "Step 19 | Training Loss: 0.319760 | Validation Accuracy: 0.761356\n",
      "Step 20 | Training Loss: 0.335145 | Validation Accuracy: 0.761045\n",
      "Step 21 | Training Loss: 0.330932 | Validation Accuracy: 0.761577\n",
      "Step 22 | Training Loss: 0.332838 | Validation Accuracy: 0.762465\n",
      "Step 23 | Training Loss: 0.321425 | Validation Accuracy: 0.762154\n",
      "Step 24 | Training Loss: 0.330201 | Validation Accuracy: 0.761755\n",
      "Step 25 | Training Loss: 0.328605 | Validation Accuracy: 0.762642\n",
      "Step 26 | Training Loss: 0.328246 | Validation Accuracy: 0.762154\n",
      "Step 27 | Training Loss: 0.331629 | Validation Accuracy: 0.762642\n",
      "Step 28 | Training Loss: 0.321952 | Validation Accuracy: 0.762819\n",
      "Step 29 | Training Loss: 0.332931 | Validation Accuracy: 0.762997\n",
      "Step 30 | Training Loss: 0.333121 | Validation Accuracy: 0.762731\n",
      "Step 31 | Training Loss: 0.333125 | Validation Accuracy: 0.763130\n",
      "Step 32 | Training Loss: 0.328463 | Validation Accuracy: 0.763352\n",
      "Step 33 | Training Loss: 0.322182 | Validation Accuracy: 0.762908\n",
      "Step 34 | Training Loss: 0.337317 | Validation Accuracy: 0.763440\n",
      "Step 35 | Training Loss: 0.322536 | Validation Accuracy: 0.763307\n",
      "Step 36 | Training Loss: 0.326984 | Validation Accuracy: 0.763973\n",
      "Step 37 | Training Loss: 0.327538 | Validation Accuracy: 0.763707\n",
      "Step 38 | Training Loss: 0.328708 | Validation Accuracy: 0.764150\n",
      "Step 39 | Training Loss: 0.330703 | Validation Accuracy: 0.764106\n",
      "Step 40 | Training Loss: 0.336283 | Validation Accuracy: 0.763840\n",
      "Step 41 | Training Loss: 0.323116 | Validation Accuracy: 0.764239\n",
      "Step 42 | Training Loss: 0.334697 | Validation Accuracy: 0.764416\n",
      "Step 43 | Training Loss: 0.328325 | Validation Accuracy: 0.763573\n",
      "Step 44 | Training Loss: 0.328127 | Validation Accuracy: 0.764904\n",
      "Step 45 | Training Loss: 0.331116 | Validation Accuracy: 0.764815\n",
      "Step 46 | Training Loss: 0.326152 | Validation Accuracy: 0.764150\n",
      "Step 47 | Training Loss: 0.336943 | Validation Accuracy: 0.764461\n",
      "Step 48 | Training Loss: 0.331293 | Validation Accuracy: 0.764993\n",
      "Step 49 | Training Loss: 0.330945 | Validation Accuracy: 0.763884\n",
      "Step 50 | Training Loss: 0.334495 | Validation Accuracy: 0.764505\n",
      "Step 51 | Training Loss: 0.322348 | Validation Accuracy: 0.764106\n",
      "Step 52 | Training Loss: 0.325651 | Validation Accuracy: 0.764727\n",
      "Step 53 | Training Loss: 0.323918 | Validation Accuracy: 0.763884\n",
      "Step 54 | Training Loss: 0.320655 | Validation Accuracy: 0.764949\n",
      "Step 55 | Training Loss: 0.335082 | Validation Accuracy: 0.764239\n",
      "Step 56 | Training Loss: 0.327419 | Validation Accuracy: 0.764461\n",
      "Step 57 | Training Loss: 0.327509 | Validation Accuracy: 0.764682\n",
      "Step 58 | Training Loss: 0.326928 | Validation Accuracy: 0.764638\n",
      "Step 59 | Training Loss: 0.329187 | Validation Accuracy: 0.764416\n",
      "Step 60 | Training Loss: 0.327624 | Validation Accuracy: 0.764416\n",
      "Step 61 | Training Loss: 0.327413 | Validation Accuracy: 0.764061\n",
      "Step 62 | Training Loss: 0.327049 | Validation Accuracy: 0.763928\n",
      "Step 63 | Training Loss: 0.327254 | Validation Accuracy: 0.764638\n",
      "Step 64 | Training Loss: 0.334533 | Validation Accuracy: 0.764239\n",
      "Step 65 | Training Loss: 0.336482 | Validation Accuracy: 0.764461\n",
      "Step 66 | Training Loss: 0.336396 | Validation Accuracy: 0.763928\n",
      "Step 67 | Training Loss: 0.341676 | Validation Accuracy: 0.764239\n",
      "Step 68 | Training Loss: 0.325646 | Validation Accuracy: 0.764061\n",
      "Step 69 | Training Loss: 0.330784 | Validation Accuracy: 0.764239\n",
      "Step 70 | Training Loss: 0.329210 | Validation Accuracy: 0.764461\n",
      "Step 71 | Training Loss: 0.324162 | Validation Accuracy: 0.764150\n",
      "Step 72 | Training Loss: 0.326273 | Validation Accuracy: 0.764061\n",
      "Step 73 | Training Loss: 0.328188 | Validation Accuracy: 0.764150\n",
      "Step 74 | Training Loss: 0.333540 | Validation Accuracy: 0.764461\n",
      "Step 75 | Training Loss: 0.339858 | Validation Accuracy: 0.763618\n",
      "Step 76 | Training Loss: 0.331246 | Validation Accuracy: 0.763396\n",
      "Step 77 | Training Loss: 0.329239 | Validation Accuracy: 0.763928\n",
      "Step 78 | Training Loss: 0.335292 | Validation Accuracy: 0.764017\n",
      "Step 79 | Training Loss: 0.327596 | Validation Accuracy: 0.764194\n",
      "Step 80 | Training Loss: 0.333211 | Validation Accuracy: 0.763618\n",
      "Step 81 | Training Loss: 0.319567 | Validation Accuracy: 0.763884\n",
      "Step 82 | Training Loss: 0.326044 | Validation Accuracy: 0.763618\n",
      "Step 83 | Training Loss: 0.334491 | Validation Accuracy: 0.763840\n",
      "Step 84 | Training Loss: 0.330936 | Validation Accuracy: 0.763707\n",
      "Step 85 | Training Loss: 0.327414 | Validation Accuracy: 0.763751\n",
      "Step 86 | Training Loss: 0.319757 | Validation Accuracy: 0.763352\n",
      "Step 87 | Training Loss: 0.324442 | Validation Accuracy: 0.763352\n",
      "Step 88 | Training Loss: 0.325725 | Validation Accuracy: 0.763485\n",
      "Step 89 | Training Loss: 0.330123 | Validation Accuracy: 0.763396\n",
      "Step 90 | Training Loss: 0.324686 | Validation Accuracy: 0.763485\n",
      "Step 91 | Training Loss: 0.325642 | Validation Accuracy: 0.763307\n",
      "Step 92 | Training Loss: 0.320566 | Validation Accuracy: 0.763352\n",
      "Step 93 | Training Loss: 0.330310 | Validation Accuracy: 0.763529\n",
      "Step 94 | Training Loss: 0.323965 | Validation Accuracy: 0.763840\n",
      "Step 95 | Training Loss: 0.325638 | Validation Accuracy: 0.763928\n",
      "Step 96 | Training Loss: 0.316855 | Validation Accuracy: 0.763840\n",
      "Step 97 | Training Loss: 0.330932 | Validation Accuracy: 0.763884\n",
      "Step 98 | Training Loss: 0.335245 | Validation Accuracy: 0.763707\n",
      "Step 99 | Training Loss: 0.330946 | Validation Accuracy: 0.763485\n",
      "Step 100 | Training Loss: 0.334627 | Validation Accuracy: 0.763263\n",
      "Accuracy on Test data: 0.763262927532196\n",
      "Current Layer Attributes - epochs:100 hidden layers:6 features count:32\n",
      "Step 1 | Training Loss: 0.375359 | Validation Accuracy: 0.775727\n",
      "Step 2 | Training Loss: 0.341045 | Validation Accuracy: 0.773510\n",
      "Step 3 | Training Loss: 0.335465 | Validation Accuracy: 0.773155\n",
      "Step 4 | Training Loss: 0.326772 | Validation Accuracy: 0.772001\n",
      "Step 5 | Training Loss: 0.331024 | Validation Accuracy: 0.772578\n",
      "Step 6 | Training Loss: 0.329889 | Validation Accuracy: 0.774397\n",
      "Step 7 | Training Loss: 0.329887 | Validation Accuracy: 0.775639\n",
      "Step 8 | Training Loss: 0.331718 | Validation Accuracy: 0.771292\n",
      "Step 9 | Training Loss: 0.326286 | Validation Accuracy: 0.772401\n",
      "Step 10 | Training Loss: 0.324433 | Validation Accuracy: 0.767965\n",
      "Step 11 | Training Loss: 0.331568 | Validation Accuracy: 0.755722\n",
      "Step 12 | Training Loss: 0.332305 | Validation Accuracy: 0.753593\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 13 | Training Loss: 0.332453 | Validation Accuracy: 0.751464\n",
      "Step 14 | Training Loss: 0.332685 | Validation Accuracy: 0.754258\n",
      "Step 15 | Training Loss: 0.332550 | Validation Accuracy: 0.754391\n",
      "Step 16 | Training Loss: 0.326513 | Validation Accuracy: 0.753105\n",
      "Step 17 | Training Loss: 0.328566 | Validation Accuracy: 0.751863\n",
      "Step 18 | Training Loss: 0.331710 | Validation Accuracy: 0.750266\n",
      "Step 19 | Training Loss: 0.330521 | Validation Accuracy: 0.751508\n",
      "Step 20 | Training Loss: 0.328630 | Validation Accuracy: 0.750754\n",
      "Step 21 | Training Loss: 0.333067 | Validation Accuracy: 0.751153\n",
      "Step 22 | Training Loss: 0.325796 | Validation Accuracy: 0.752351\n",
      "Step 23 | Training Loss: 0.334373 | Validation Accuracy: 0.751242\n",
      "Step 24 | Training Loss: 0.322312 | Validation Accuracy: 0.750843\n",
      "Step 25 | Training Loss: 0.331492 | Validation Accuracy: 0.752617\n",
      "Step 26 | Training Loss: 0.322334 | Validation Accuracy: 0.751996\n",
      "Step 27 | Training Loss: 0.325306 | Validation Accuracy: 0.751819\n",
      "Step 28 | Training Loss: 0.325730 | Validation Accuracy: 0.752883\n",
      "Step 29 | Training Loss: 0.322373 | Validation Accuracy: 0.751508\n",
      "Step 30 | Training Loss: 0.338166 | Validation Accuracy: 0.752351\n",
      "Step 31 | Training Loss: 0.335661 | Validation Accuracy: 0.752528\n",
      "Step 32 | Training Loss: 0.334959 | Validation Accuracy: 0.751863\n",
      "Step 33 | Training Loss: 0.318532 | Validation Accuracy: 0.751375\n",
      "Step 34 | Training Loss: 0.324045 | Validation Accuracy: 0.751907\n",
      "Step 35 | Training Loss: 0.326334 | Validation Accuracy: 0.751109\n",
      "Step 36 | Training Loss: 0.338724 | Validation Accuracy: 0.751375\n",
      "Step 37 | Training Loss: 0.327459 | Validation Accuracy: 0.751553\n",
      "Step 38 | Training Loss: 0.327412 | Validation Accuracy: 0.751819\n",
      "Step 39 | Training Loss: 0.325684 | Validation Accuracy: 0.751774\n",
      "Step 40 | Training Loss: 0.329940 | Validation Accuracy: 0.750843\n",
      "Step 41 | Training Loss: 0.329855 | Validation Accuracy: 0.751508\n",
      "Step 42 | Training Loss: 0.332853 | Validation Accuracy: 0.751109\n",
      "Step 43 | Training Loss: 0.323815 | Validation Accuracy: 0.751331\n",
      "Step 44 | Training Loss: 0.335533 | Validation Accuracy: 0.750310\n",
      "Step 45 | Training Loss: 0.332429 | Validation Accuracy: 0.751375\n",
      "Step 46 | Training Loss: 0.327397 | Validation Accuracy: 0.752040\n",
      "Step 47 | Training Loss: 0.337627 | Validation Accuracy: 0.751553\n",
      "Step 48 | Training Loss: 0.325589 | Validation Accuracy: 0.750665\n",
      "Step 49 | Training Loss: 0.334710 | Validation Accuracy: 0.752262\n",
      "Step 50 | Training Loss: 0.316730 | Validation Accuracy: 0.751375\n",
      "Step 51 | Training Loss: 0.323783 | Validation Accuracy: 0.751730\n",
      "Step 52 | Training Loss: 0.329713 | Validation Accuracy: 0.750754\n",
      "Step 53 | Training Loss: 0.322533 | Validation Accuracy: 0.749823\n",
      "Step 54 | Training Loss: 0.328983 | Validation Accuracy: 0.750222\n",
      "Step 55 | Training Loss: 0.327554 | Validation Accuracy: 0.751508\n",
      "Step 56 | Training Loss: 0.322196 | Validation Accuracy: 0.750710\n",
      "Step 57 | Training Loss: 0.326407 | Validation Accuracy: 0.750710\n",
      "Step 58 | Training Loss: 0.336245 | Validation Accuracy: 0.750000\n",
      "Step 59 | Training Loss: 0.332654 | Validation Accuracy: 0.750577\n",
      "Step 60 | Training Loss: 0.336100 | Validation Accuracy: 0.748935\n",
      "Step 61 | Training Loss: 0.330664 | Validation Accuracy: 0.749778\n",
      "Step 62 | Training Loss: 0.330956 | Validation Accuracy: 0.750754\n",
      "Step 63 | Training Loss: 0.341551 | Validation Accuracy: 0.751198\n",
      "Step 64 | Training Loss: 0.338222 | Validation Accuracy: 0.750266\n",
      "Step 65 | Training Loss: 0.336335 | Validation Accuracy: 0.749911\n",
      "Step 66 | Training Loss: 0.334381 | Validation Accuracy: 0.750798\n",
      "Step 67 | Training Loss: 0.331473 | Validation Accuracy: 0.750488\n",
      "Step 68 | Training Loss: 0.318643 | Validation Accuracy: 0.750089\n",
      "Step 69 | Training Loss: 0.325632 | Validation Accuracy: 0.750976\n",
      "Step 70 | Training Loss: 0.327371 | Validation Accuracy: 0.750089\n",
      "Step 71 | Training Loss: 0.332268 | Validation Accuracy: 0.750798\n",
      "Step 72 | Training Loss: 0.334697 | Validation Accuracy: 0.750177\n",
      "Step 73 | Training Loss: 0.333560 | Validation Accuracy: 0.750310\n",
      "Step 74 | Training Loss: 0.330075 | Validation Accuracy: 0.750044\n",
      "Step 75 | Training Loss: 0.330934 | Validation Accuracy: 0.750621\n",
      "Step 76 | Training Loss: 0.330965 | Validation Accuracy: 0.750798\n",
      "Step 77 | Training Loss: 0.331296 | Validation Accuracy: 0.750133\n",
      "Step 78 | Training Loss: 0.339075 | Validation Accuracy: 0.749778\n",
      "Step 79 | Training Loss: 0.331263 | Validation Accuracy: 0.750754\n",
      "Step 80 | Training Loss: 0.341498 | Validation Accuracy: 0.750222\n",
      "Step 81 | Training Loss: 0.330935 | Validation Accuracy: 0.749335\n",
      "Step 82 | Training Loss: 0.331573 | Validation Accuracy: 0.749556\n",
      "Step 83 | Training Loss: 0.334065 | Validation Accuracy: 0.749290\n",
      "Step 84 | Training Loss: 0.325647 | Validation Accuracy: 0.749423\n",
      "Step 85 | Training Loss: 0.331335 | Validation Accuracy: 0.748980\n",
      "Step 86 | Training Loss: 0.323865 | Validation Accuracy: 0.749601\n",
      "Step 87 | Training Loss: 0.325631 | Validation Accuracy: 0.750976\n",
      "Step 88 | Training Loss: 0.327668 | Validation Accuracy: 0.750532\n",
      "Step 89 | Training Loss: 0.322160 | Validation Accuracy: 0.750133\n",
      "Step 90 | Training Loss: 0.320327 | Validation Accuracy: 0.750798\n",
      "Step 91 | Training Loss: 0.336230 | Validation Accuracy: 0.750577\n",
      "Step 92 | Training Loss: 0.324114 | Validation Accuracy: 0.751375\n",
      "Step 93 | Training Loss: 0.334552 | Validation Accuracy: 0.750222\n",
      "Step 94 | Training Loss: 0.334465 | Validation Accuracy: 0.750798\n",
      "Step 95 | Training Loss: 0.326782 | Validation Accuracy: 0.750355\n",
      "Step 96 | Training Loss: 0.334348 | Validation Accuracy: 0.750532\n",
      "Step 97 | Training Loss: 0.337933 | Validation Accuracy: 0.749024\n",
      "Step 98 | Training Loss: 0.329729 | Validation Accuracy: 0.748492\n",
      "Step 99 | Training Loss: 0.328857 | Validation Accuracy: 0.749911\n",
      "Step 100 | Training Loss: 0.336334 | Validation Accuracy: 0.750000\n",
      "Accuracy on Test data: 0.75\n",
      "Current Layer Attributes - epochs:100 hidden layers:6 features count:64\n",
      "Step 1 | Training Loss: 0.352716 | Validation Accuracy: 0.738290\n",
      "Step 2 | Training Loss: 0.337924 | Validation Accuracy: 0.736160\n",
      "Step 3 | Training Loss: 0.331551 | Validation Accuracy: 0.734918\n",
      "Step 4 | Training Loss: 0.329154 | Validation Accuracy: 0.772711\n",
      "Step 5 | Training Loss: 0.330539 | Validation Accuracy: 0.768320\n",
      "Step 6 | Training Loss: 0.330056 | Validation Accuracy: 0.767699\n",
      "Step 7 | Training Loss: 0.328940 | Validation Accuracy: 0.769074\n",
      "Step 8 | Training Loss: 0.325492 | Validation Accuracy: 0.769695\n",
      "Step 9 | Training Loss: 0.322673 | Validation Accuracy: 0.769650\n",
      "Step 10 | Training Loss: 0.319021 | Validation Accuracy: 0.766457\n",
      "Step 11 | Training Loss: 0.327416 | Validation Accuracy: 0.769872\n",
      "Step 12 | Training Loss: 0.327041 | Validation Accuracy: 0.772268\n",
      "Step 13 | Training Loss: 0.326278 | Validation Accuracy: 0.773554\n",
      "Step 14 | Training Loss: 0.326720 | Validation Accuracy: 0.771380\n",
      "Step 15 | Training Loss: 0.320757 | Validation Accuracy: 0.771691\n",
      "Step 16 | Training Loss: 0.324086 | Validation Accuracy: 0.774796\n",
      "Step 17 | Training Loss: 0.328652 | Validation Accuracy: 0.772800\n",
      "Step 18 | Training Loss: 0.319962 | Validation Accuracy: 0.771203\n",
      "Step 19 | Training Loss: 0.330280 | Validation Accuracy: 0.769251\n",
      "Step 20 | Training Loss: 0.325810 | Validation Accuracy: 0.770715\n",
      "Step 21 | Training Loss: 0.327906 | Validation Accuracy: 0.771114\n",
      "Step 22 | Training Loss: 0.318712 | Validation Accuracy: 0.766723\n",
      "Step 23 | Training Loss: 0.323400 | Validation Accuracy: 0.768320\n",
      "Step 24 | Training Loss: 0.318743 | Validation Accuracy: 0.766812\n",
      "Step 25 | Training Loss: 0.327166 | Validation Accuracy: 0.770493\n",
      "Step 26 | Training Loss: 0.326072 | Validation Accuracy: 0.765791\n",
      "Step 27 | Training Loss: 0.324757 | Validation Accuracy: 0.765791\n",
      "Step 28 | Training Loss: 0.320178 | Validation Accuracy: 0.767166\n",
      "Step 29 | Training Loss: 0.320534 | Validation Accuracy: 0.766900\n",
      "Step 30 | Training Loss: 0.328543 | Validation Accuracy: 0.765082\n",
      "Step 31 | Training Loss: 0.318703 | Validation Accuracy: 0.766900\n",
      "Step 32 | Training Loss: 0.323234 | Validation Accuracy: 0.760468\n",
      "Step 33 | Training Loss: 0.320775 | Validation Accuracy: 0.768985\n",
      "Step 34 | Training Loss: 0.315088 | Validation Accuracy: 0.760735\n",
      "Step 35 | Training Loss: 0.332785 | Validation Accuracy: 0.765436\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 36 | Training Loss: 0.318737 | Validation Accuracy: 0.768408\n",
      "Step 37 | Training Loss: 0.323644 | Validation Accuracy: 0.764860\n",
      "Step 38 | Training Loss: 0.326714 | Validation Accuracy: 0.767832\n",
      "Step 39 | Training Loss: 0.323866 | Validation Accuracy: 0.762731\n",
      "Step 40 | Training Loss: 0.318597 | Validation Accuracy: 0.767876\n",
      "Step 41 | Training Loss: 0.320391 | Validation Accuracy: 0.768985\n",
      "Step 42 | Training Loss: 0.322098 | Validation Accuracy: 0.769429\n",
      "Step 43 | Training Loss: 0.318774 | Validation Accuracy: 0.769473\n",
      "Step 44 | Training Loss: 0.323888 | Validation Accuracy: 0.769562\n",
      "Step 45 | Training Loss: 0.318554 | Validation Accuracy: 0.766945\n",
      "Step 46 | Training Loss: 0.319191 | Validation Accuracy: 0.764372\n",
      "Step 47 | Training Loss: 0.325632 | Validation Accuracy: 0.769828\n",
      "Step 48 | Training Loss: 0.315972 | Validation Accuracy: 0.768275\n",
      "Step 49 | Training Loss: 0.323896 | Validation Accuracy: 0.764949\n",
      "Step 50 | Training Loss: 0.324402 | Validation Accuracy: 0.773643\n",
      "Step 51 | Training Loss: 0.322615 | Validation Accuracy: 0.772001\n",
      "Step 52 | Training Loss: 0.323864 | Validation Accuracy: 0.770005\n",
      "Step 53 | Training Loss: 0.323865 | Validation Accuracy: 0.773155\n",
      "Step 54 | Training Loss: 0.330992 | Validation Accuracy: 0.763662\n",
      "Step 55 | Training Loss: 0.322104 | Validation Accuracy: 0.763307\n",
      "Step 56 | Training Loss: 0.318567 | Validation Accuracy: 0.762243\n",
      "Step 57 | Training Loss: 0.325634 | Validation Accuracy: 0.764150\n",
      "Step 58 | Training Loss: 0.316849 | Validation Accuracy: 0.765303\n",
      "Step 59 | Training Loss: 0.325629 | Validation Accuracy: 0.769296\n",
      "Step 60 | Training Loss: 0.322102 | Validation Accuracy: 0.770538\n",
      "Step 61 | Training Loss: 0.320354 | Validation Accuracy: 0.770538\n",
      "Step 62 | Training Loss: 0.324176 | Validation Accuracy: 0.768630\n",
      "Step 63 | Training Loss: 0.330996 | Validation Accuracy: 0.764061\n",
      "Step 64 | Training Loss: 0.318562 | Validation Accuracy: 0.771292\n",
      "Step 65 | Training Loss: 0.320507 | Validation Accuracy: 0.776127\n",
      "Step 66 | Training Loss: 0.321939 | Validation Accuracy: 0.769650\n",
      "Step 67 | Training Loss: 0.323890 | Validation Accuracy: 0.768630\n",
      "Step 68 | Training Loss: 0.327396 | Validation Accuracy: 0.772578\n",
      "Step 69 | Training Loss: 0.322117 | Validation Accuracy: 0.766057\n",
      "Step 70 | Training Loss: 0.325721 | Validation Accuracy: 0.768763\n",
      "Step 71 | Training Loss: 0.322724 | Validation Accuracy: 0.765348\n",
      "Step 72 | Training Loss: 0.336277 | Validation Accuracy: 0.769784\n",
      "Step 73 | Training Loss: 0.326798 | Validation Accuracy: 0.763352\n",
      "Step 74 | Training Loss: 0.320375 | Validation Accuracy: 0.769296\n",
      "Step 75 | Training Loss: 0.318627 | Validation Accuracy: 0.772578\n",
      "Step 76 | Training Loss: 0.324834 | Validation Accuracy: 0.763795\n",
      "Step 77 | Training Loss: 0.325631 | Validation Accuracy: 0.774840\n",
      "Step 78 | Training Loss: 0.322096 | Validation Accuracy: 0.767300\n",
      "Step 79 | Training Loss: 0.323865 | Validation Accuracy: 0.766945\n",
      "Step 80 | Training Loss: 0.323969 | Validation Accuracy: 0.768187\n",
      "Step 81 | Training Loss: 0.321989 | Validation Accuracy: 0.773155\n",
      "Step 82 | Training Loss: 0.330381 | Validation Accuracy: 0.769473\n",
      "Step 83 | Training Loss: 0.328829 | Validation Accuracy: 0.773820\n",
      "Step 84 | Training Loss: 0.323864 | Validation Accuracy: 0.773776\n",
      "Step 85 | Training Loss: 0.329217 | Validation Accuracy: 0.774219\n",
      "Step 86 | Training Loss: 0.318564 | Validation Accuracy: 0.771026\n",
      "Step 87 | Training Loss: 0.327397 | Validation Accuracy: 0.766723\n",
      "Step 88 | Training Loss: 0.318564 | Validation Accuracy: 0.772667\n",
      "Step 89 | Training Loss: 0.329183 | Validation Accuracy: 0.770582\n",
      "Step 90 | Training Loss: 0.323869 | Validation Accuracy: 0.769650\n",
      "Step 91 | Training Loss: 0.323868 | Validation Accuracy: 0.768852\n",
      "Step 92 | Training Loss: 0.323858 | Validation Accuracy: 0.769118\n",
      "Step 93 | Training Loss: 0.316265 | Validation Accuracy: 0.772445\n",
      "Step 94 | Training Loss: 0.325633 | Validation Accuracy: 0.772401\n",
      "Step 95 | Training Loss: 0.316970 | Validation Accuracy: 0.770981\n",
      "Step 96 | Training Loss: 0.332705 | Validation Accuracy: 0.762065\n",
      "Step 97 | Training Loss: 0.320335 | Validation Accuracy: 0.762287\n",
      "Step 98 | Training Loss: 0.321885 | Validation Accuracy: 0.772046\n",
      "Step 99 | Training Loss: 0.320329 | Validation Accuracy: 0.764638\n",
      "Step 100 | Training Loss: 0.315030 | Validation Accuracy: 0.770538\n",
      "Accuracy on Test data: 0.7705376148223877\n"
     ]
    }
   ],
   "source": [
    "import itertools\n",
    "class Hyperparameters:\n",
    "#    features_arr = [2, 4, 8, 16, 32, 64, 128, 256]\n",
    "#    hidden_layers_arr = [2, 4, 6, 10]\n",
    "    features_arr = [4, 8, 32, 64]\n",
    "    hidden_layers_arr = [4, 6]\n",
    "\n",
    "    epochs = [100]\n",
    "    \n",
    "    for e, h, f in itertools.product(epochs, hidden_layers_arr, features_arr):\n",
    "        print(\"Current Layer Attributes - epochs:{} hidden layers:{} features count:{}\".format(e,h,f))\n",
    "        n = network(2,h,f)\n",
    "        n.build_layers()\n",
    "        Train.train(e, n, h,f)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-05-13T02:25:29.498894Z",
     "start_time": "2017-05-13T02:25:29.495213Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_results = pd.DataFrame(Train.results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-05-13T02:25:29.554169Z",
     "start_time": "2017-05-13T02:25:29.500602Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>epoch</th>\n",
       "      <th>no_of_features</th>\n",
       "      <th>hidden_layers</th>\n",
       "      <th>train_score</th>\n",
       "      <th>test_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>100</td>\n",
       "      <td>8</td>\n",
       "      <td>4</td>\n",
       "      <td>0.788369</td>\n",
       "      <td>0.788369</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>100</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>0.779808</td>\n",
       "      <td>0.779808</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>100</td>\n",
       "      <td>64</td>\n",
       "      <td>4</td>\n",
       "      <td>0.778167</td>\n",
       "      <td>0.778167</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>100</td>\n",
       "      <td>4</td>\n",
       "      <td>6</td>\n",
       "      <td>0.777280</td>\n",
       "      <td>0.777280</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>100</td>\n",
       "      <td>64</td>\n",
       "      <td>6</td>\n",
       "      <td>0.770538</td>\n",
       "      <td>0.770538</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>100</td>\n",
       "      <td>32</td>\n",
       "      <td>4</td>\n",
       "      <td>0.767211</td>\n",
       "      <td>0.767211</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>100</td>\n",
       "      <td>8</td>\n",
       "      <td>6</td>\n",
       "      <td>0.763263</td>\n",
       "      <td>0.763263</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>100</td>\n",
       "      <td>32</td>\n",
       "      <td>6</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>0.750000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   epoch  no_of_features  hidden_layers  train_score  test_score\n",
       "1    100               8              4     0.788369    0.788369\n",
       "0    100               4              4     0.779808    0.779808\n",
       "3    100              64              4     0.778167    0.778167\n",
       "4    100               4              6     0.777280    0.777280\n",
       "7    100              64              6     0.770538    0.770538\n",
       "2    100              32              4     0.767211    0.767211\n",
       "5    100               8              6     0.763263    0.763263\n",
       "6    100              32              6     0.750000    0.750000"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_results.sort_values(by = 'test_score', ascending = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-05-13T02:25:29.569104Z",
     "start_time": "2017-05-13T02:25:29.555645Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pd.Panel(Train.predictions).to_pickle(\"dataset/tf_dense_only_nsl_kdd_predictions.pkl\")\n",
    "df_results.to_pickle(\"dataset/tf_dense_only_nsl_kdd_scores.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-05-13T02:25:29.633626Z",
     "start_time": "2017-05-13T02:25:29.570791Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import itertools\n",
    "\n",
    "def plot_confusion_matrix(cm, classes,\n",
    "                          normalize=False,\n",
    "                          title='Confusion matrix',\n",
    "                          cmap=plt.cm.Blues):\n",
    "    \"\"\"\n",
    "    This function prints and plots the confusion matrix.\n",
    "    Normalization can be applied by setting `normalize=True`.\n",
    "    \"\"\"\n",
    "    np.set_printoptions(precision=4)\n",
    "\n",
    "    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n",
    "    plt.title(title)\n",
    "    plt.colorbar()\n",
    "    tick_marks = np.arange(len(classes))\n",
    "    plt.xticks(tick_marks, classes, rotation=45)\n",
    "    plt.yticks(tick_marks, classes)\n",
    "\n",
    "    if normalize:\n",
    "        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "        print(\"Normalized confusion matrix\")\n",
    "    else:\n",
    "        print('Confusion matrix, without normalization')\n",
    "\n",
    "    print(cm)\n",
    "\n",
    "    thresh = cm.max() / 2.\n",
    "    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
    "        plt.text(j, i, cm[i, j].round(4),\n",
    "                 horizontalalignment=\"center\",\n",
    "                 color=\"white\" if cm[i, j] > thresh else \"black\")\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.ylabel('True label')\n",
    "    plt.xlabel('Predicted label')\n",
    "\n",
    "def plot(actual_value, pred_value):\n",
    "    from sklearn.metrics import confusion_matrix\n",
    "    cm_2labels = confusion_matrix(y_pred = pred_value, y_true = actual_value)\n",
    "    plt.figure(figsize=[6,6])\n",
    "    plot_confusion_matrix(cm_2labels, preprocess.output_columns_2labels, normalize = True,\n",
    "                         title = Train.best_parameters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-05-13T02:25:29.945549Z",
     "start_time": "2017-05-13T02:25:29.635202Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Normalized confusion matrix\n",
      "[[ 0.6823  0.3177]\n",
      " [ 0.0715  0.9285]]\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAbUAAAGgCAYAAAAtsfn1AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAAIABJREFUeJzs3Xm8FmX9//HXmx1FNhdEQHHBBcwNVH5mZamJimKLSpmi\nmZq75YaVqX2jrMzcUtM0UFNETcUFCTHNJUBwQ0QURQVkV8EV4fD5/THXwZvjOYcD3Ge75/3kMY97\n5pprZq65z839ua9rrrlGEYGZmVkpaFLfBTAzMysWBzUzMysZDmpmZlYyHNTMzKxkOKiZmVnJcFAz\nM7OS4aBmZmZFJelMSS9LmiLprJTWUdIYSa+n1w4F+S+QNF3SNEkHFKT3ljQ5rbtKklZ3bAc1MzMr\nGkk7AicAewA7A/0lbQMMBsZGRA9gbFpGUk9gINAL6AdcK6lp2t11aV890tRvdcd3UDMzs2LaARgf\nEZ9ExHLgCeC7wABgWMozDDgszQ8AhkfE0oiYAUwH9pDUGWgbEeMiGyXkloJtqtSsuOdiZmYNTdO2\nW0Qs/7Ro+4tPF4yOiKpqTS8DQyRtCHwKHARMBDpFxJyUZy7QKc13AcYVbD8rpS1L8xXTq+WgZmZW\n4mL5p7Tc7oii7e+zF/66vaSJBUk3RMQNABExVdIfgH8DHwMvAGWrlCciJNXKGI0OamZmJU+gol5t\nWhgRfapaGRE3ATcBSPodWS1rnqTOETEnNS3OT9lnA90KNu+a0man+Yrp1fI1NTMzKypJm6TXzcmu\np90OjAQGpSyDgPvT/EhgoKSWkrYk6xAyITVVLpHUN/V6PKZgmyq5pmZmVuoErL43fDHdk66pLQNO\njYgPJF0KjJB0PPA2cARAREyRNAJ4BVie8pc3V54CDAVaA6PSVC350TNmZqWtyfqdouUOPyza/j6b\ndMWk6pof65ObH83MrGS4+dHMLA/qtvmx3jiomZmVvKL3fmyw8nGWZmaWC66pmZnlgZsfzcysJAg3\nP5qZmTU2rqmZmZU8ufnRzMxKiJsfzczMGhfX1MzM8sDNj2ZmVhp887WZmVmj45qamVmpq/tHz9Qb\nBzUzszxw86OZmVnj4pqamVnJy09HEQc1M7M8aJKPa2r5CN1mZpYLrqmZmZU6j9JvZmbW+LimZmaW\nB75PzczMSkN+ej/m4yzNzCwXXFMzM8sDNz+amVnJcPOjmZlZ4+KamplZqZPc/GhmZiXEzY9mZmaN\ni4NazkiaImmfKtbtI2lWNdsOlfTbWiucmdWe8ibIYkwNmINaCZH0lqT9KqQdK+mp8uWI6BURj9d5\n4apRsYyNiaSbJYWkbWqYv3vK/1HB9GIRynGxpNvWdT/FImlbSXdJWihpsaSXJP1cUtNaPu5qf3il\nv8HDkt6XNFfSNZJK/FJMuvm6WFMD1rBLZ1YHlFnj/wuS9ga2XsvDto+INmnaeS33UTTF/FKXtDUw\nHpgJfCUi2gGHA72BDYp1nHVwLbAA6AzsAnwDOKVeS2RF46CWM4W1OUmt0y/b9yW9AuxeIe+ukp6T\n9KGkO4FWFdb3l/SCpA8kPSNppwrHOSf9Ql8s6U5Jq2xfw/IeJ2lqKsObkk4qWPeypEMKlpunmsGu\nablvKtcHkl4sbHaV9LikIZKeBj4Btko1xjfTsWZIOqqacjUDrgZOX9NzWs35/jid7/uSRkvaomDd\nlZJmSloiaZKkr6X0fsAvgCMLa34Va+6FtbmCGuPxkt4BHkvp1b1nNX1/LgGeiYifR8QcgIiYFhFH\nRcQHaV+HpqbwD9LfYoeC46xS8y2sfSk1kUs6W9J8SXMkHZfWnQgcBZyX3ocHqijflsCdEfFZRMwF\nHgF6re5v0+i5+dFy4CKymsbWwAHAoPIVkloA9wG3Ah2Bu4DvFazfFbgZOAnYEPgbMFJSy4L9HwH0\nI/sS2Qk4di3KOB/oD7QFjgP+Imm3tO4W4EcFeQ8C5kTE85K6AA8Bv03lPwe4R9LGBfmPBk4kqz0s\nAK4CDoyIDYC9gBfSuW6evnw3L9j2Z8B/I+KltTinSkkaQBacvgtsDDwJ3FGQ5VmymkVH4HbgLkmt\nIuIR4HdkX9RrWvP7BrADcEB175mk9ani/anEfsDd1Zzntum8zkrn+TDwQPrM1cSmQDugC3A88FdJ\nHSLiBuCfwB/T+3BIOt61kq4t2P4Ksh8A66VzPpAssJWu8kfPuPnRGqH70hfwB5I+IGtqqcoRwJCI\neC8iZpJ9aZXrCzQHroiIZRFxN9mXarkTgb9FxPiIKIuIYcDStF25qyLi3Yh4D3iA7At5jUTEQxHx\nRmSeAP4NfC2tvg04SFLbtHw0WRCGLNg9HBEPR8SKiBgDTCQLfOWGRsSUiFgOLAdWADtKah0RcyJi\nSirDOxHRPiLeAZDUjSyY/3pNz6fAwoK/0zkp7afA7yNiairT74BdymtrEXFbRCyKiOUR8WegJbDd\nOpQB4OKI+DgiPmX171ml708lNgTmVHPMI4GHImJMRCwDLgNakwXKmlgG/CZ9Lh8GPqKa9yEiTomI\nwubF/wI7AkuAWWTneF8Nj20NnINa6TksfQG3j4j2VH+tYDOy6x7l3q6wbnZERBXrtwDOrhBAu6Xt\nys0tmP8EaLMmJwIg6UBJ4yS9l45xELARQES8CzwNfE9Se7Jf3P8sKN/hFcq3N9l1lHIrzz0iPib7\nsv0pMEfSQ5K2r6JYV5B9qS5e0/MpsFHB3+mygjJfWVDe98h+Y3dJ78U5qWlycVrfrvy9WAeFf/8q\n37M1fH8Wser7XNFmFHyWImJFKkeXGpZ5UQr65Wr82VJ27fQR4F/A+mTvXwfgDzU8diPljiKWD3PI\nAlG5zSus6yKt0oBeuH4mWS2vfcG0XkQUNpetk9SUeQ/ZL/lOKUg/TPZFX24YWQ3jcOB/ETG7oHy3\nVijf+hFxacG2hQGbiBgdEfuTfSG/CtxYRdH2Bf6krOdceeD+n6Qfrv3ZrizzSRXK3DoinknXz84j\nq113SO/FYr54L6KS/X0MrFewvGkleQq3q/Y9W4P351EKmqor8S5ZAAWyjjpkn8Pyv90nNSh3VSp7\nHwp1JPscXxMRSyNiEfAPVq3BlyZfU7McGAFcIKmDpK6s2unhf2RNcmco64DxXWCPgvU3Aj+VtKcy\n60s6WNLa9m6TpFaFE9CCrIltAbBc0oHAtytsdx+wG3Am2TW2crcBh0g6QFLTtM990nlWdvBOkgak\na0dLyZq0VlRR1m2BncmaU8ubVA8B7k37uljS42t09pnryf4evdJ+2kk6PK3bgOzvsQBoJunXZNcZ\ny80DumvVXpwvAAPT368P8P3VHL/K92wN35+LgL0k/UnSpulctpF0W6pRjwAOlrSvpObA2WmfzxSU\n+4epDP3IrvvV1Dxgq6pWRsRCYAbZZ7dZKs8goGjXRg0k/UxZR6CXJd2RPksdJY2R9Hp67VCQ/wJJ\n0yVNk3RAQXpvSZPTuqsq/MiulINavl1C1gw0g+xaVfn1KCLic7IOC8eSNYMdSdZkU75+InACcA3w\nPjCdtesIUm4v4NNKpjPIvgTfB34IjCzcKF0LuoesM0ph+WYC5R0vFpDVQs6l6s98E+DnZLWI98i+\nSE+GlR1FPlLqKBIR8yNibvmUtl+YygJZrePpNX0DIuJesmaw4ZKWAC+TNakCjCZrNnuN7G/2Gas2\nHd6VXhdJei7NX0jWCeh9sr/17as5fnXvWZXvTyX7eQP4f0B3YIqkxWR/o4nAhxExjax2fTWwkOwH\nwSHpMwfZD5RDgA/IejOuyfWum4Ceqfn0PgBJ10u6viDPd8ne1wVkn9tlZB1/SlsdNT8q63xzBtAn\nInYEmgIDgcHA2IjoAYxNy0jqmdb3IutYdq2+uJ/xOrLvmR5p6rfa01z1kolZ45NqLdtGxI9Wm7kO\nSHoB2Dc1bZnVuybtt4iW+/yyaPv77P6TJkVEn8rWpaA2jqw1YwnZj5KryH7E7BMRcyR1Bh6PiO0k\nXQAQEb9P248GLgbeAv4TEdun9B+k7U+iGq6pWaMmqSNZt+4b6rss5SJiFwc0y6t0Xfsy4B2ya/OL\nI+LfZNfFy3vFzgU6pfkurNrqMCuldUnzFdOr5aBmjZakE8j+M4yKiP/Wd3nMGiwVvffjRpImFkwn\nfnEodSBrxt6SrKfr+pJWaUVJvaprpZmwxMc7s1IWETdSdQ88MytU3F6LC6tqfiS7+X5GRCzIDqt/\nkV0znyepc0Hz4/yUfzar9sLumtJmp/mK6dVyTc3MzIrpHaCvshFbRHYLzFSyTl7loxYNAu5P8yPJ\neum2lLQlWYeQCampcomyodsEHFOwTZVcUzMzy4Ea9IYviogYL+lu4Dmy21CeJ7vm3QYYIel4sh68\nR6T8UySNAF5J+U+NiLK0u1OAoWQjzoxKU7Xc+3Etqfl6oZbt6rsY1sh07bquA4BY3rw3dzYfffDe\nOkWkph26R6t9LypWkfjknh9X2fuxvrmmtpbUsh0tvzJo9RnNCpz9x2p7I5t9yZ9POLS+i9CoOKiZ\nmZU6sergciXMQc3MrOSpzq6p1Tf3fjQzs5LhmpqZWQ7kpabmoGZmlgN5CWpufjQzs5LhmpqZWQ7k\npabmoGZmVupy1KXfzY9mZlYyXFMzMytxytF9ag5qZmY5kJeg5uZHMzMrGa6pmZnlQF5qag5qZmY5\nkJeg5uZHMzMrGa6pmZmVuhzdp+agZmaWA25+NDMza2RcUzMzK3G++drMzEpKXoKamx/NzKxkuKZm\nZpYH+aioOaiZmZU8ufnRzMys0XFNzcwsB/JSU3NQMzPLgbwENTc/mplZyXBNzcysxPnmazMzKy35\niGlufjQzs9LhmpqZWanL0X1qDmpmZjmQl6Dm5kczMysZrqmZmeVAXmpqDmpmZnmQj5jm5kczMysd\nDmpmZjkgqWhTDY61naQXCqYlks6S1FHSGEmvp9cOBdtcIGm6pGmSDihI7y1pclp3lVZTAAc1M7MS\nV8yAVpOgFhHTImKXiNgF6A18AtwLDAbGRkQPYGxaRlJPYCDQC+gHXCupadrddcAJQI809avu2A5q\nZmZWm/YF3oiIt4EBwLCUPgw4LM0PAIZHxNKImAFMB/aQ1BloGxHjIiKAWwq2qZQ7ipiZ5UA99n4c\nCNyR5jtFxJw0PxfolOa7AOMKtpmV0pal+YrpVXJQMzPLgSIHtY0kTSxYviEibqjkmC2AQ4ELKq6L\niJAUxSwUOKiZmdmaWxgRfWqQ70DguYiYl5bnSeocEXNS0+L8lD4b6FawXdeUNjvNV0yvkq+pmZnl\ngYo41dwP+KLpEWAkMCjNDwLuL0gfKKmlpC3JOoRMSE2VSyT1Tb0ejynYplKuqZmZ5UBdX1OTtD6w\nP3BSQfKlwAhJxwNvA0cARMQUSSOAV4DlwKkRUZa2OQUYCrQGRqWpSg5qZmZWdBHxMbBhhbRFZL0h\nK8s/BBhSSfpEYMeaHtdBzcys1PnRM2ZmVioE5CSmuaOImZmVDtfUzMxKXs2GtyoFDmpmZjmQk5jm\n5kczMysdrqmZmeVAXpofXVMzM7OS4ZqamVmpU36uqTmomZmVOAFNmuQjqrn50czMSoZramZmOeDm\nRzMzKxnu/WhmZtbIuKZmZlbq3PvRzMxKRTZKfz6imoOarWL/vtty2VmH0LSpGDryWS679Ykv5fna\nrlvxp7P607xZUxYt/phvn3IDAKcP3JtjD9mdiGDKG3M5ccjdLP18Ob877UAO2nsHPl9WxozZ73Hi\nb+9i8Uef0adnV645/7tA9h9uyE2PMvKJKXV6vlYcU8c/wb+u+g2xYgV9Dz6C/X508irrJz85hodv\nuhw1aULTpk35zukXstVOuwNw+6Xn8coz/6FNhw0ZPOyRldsMveh05s98E4BPP1pC6zZtOe/mh5j4\n7/t4bPiNK/PNeeNVzv77A3Tt0bMOztQaOgc1W6lJE3HF2QM4+MybmD1/MU/dfBoPPjmVV9+avzJP\nuzatuPLcAQz42c3MnLeYjTusD8BmG7fllMP3YtcfXs5nS5dz229/yOH77cxtD09i7ITpXHjdaMrK\nVvDbU/px7jH78KtrH2HKG/P46o+voaxsBZtuuAHjbzmTh56aSlnZivp6C2wtrCgr4+6/XMTJl99C\n+4035fITD2PHvfdj0+49VubZtvde7Lj3fkji3TemMvSi0/nFbY8CsGe/7/O17xzDP393zir7PfaS\nq1fO33fNEFq12QCAPt8+jD7fPgyAd994lZt++VMHtNXKzyj97ihiK+3esxtvzFrEW+++x7LlZdz1\n6Iv0//qqXxZHfnsX7n98CjPnLQZgwfsfr1zXrGkTWrdsTtOmTWjdqjlzFi4BYOyE11cGqglTZtJl\nk3YAfLp02cr0li2aEUStn6MV39tTX2SjLluw0Wab06x5C3bdtz+TnxqzSp6W662/8kt16aefkjWI\nZbbeZQ/Wa9u+yv1HBC/852F673vIl9Y9N/YBdtu3f3FOpMRJxZsaMtfUbKXNNm7LrPmLVy7Pnr+Y\nPXp1WyVPj803olmzpoz+64m0Wa8Ffx3xDLePeo53Fyzhituf5LV7B/Pp0mWMnfA6Yye8/qVjHNO/\nD3c/+uLK5d17duP6X36fzTdtz/G/GeFaWiO0eOFcOmzSeeVy+4078/YrL3wp30v/Hc2DN/yJj95f\nxAl/uKnG+3/zxWfZoOOGbNxtyy+te/6xh/jJ7/62dgW3kuSamq2RZk2bsNt2XfjO2f/g0LNu5oLj\nvsU23Tai/Qat6f+1nuzwvT+y1SG/Y/1WLRh4wC6rbHveoG9SVraC4aO/+MJ79pWZ9D7qL+z942s4\n95h9aNnCv7NK1U5fP4Bf3PYoxw/5G6NuurzG200aO5Ld9j30S+lvvfICLVq2ovNW2xWzmCVLUtGm\nhqzOgpqkZ9Zyu10khaR+BWntJZ1SsNxd0g/XoWyPS+qzttuXincXLKFrahoE6LJJO2YvWLJKntnz\nFzNm/Gt88tkyFi3+hKdemMFOPTrzrd234a0577Hwg49ZXraC+56YQt+vbLFyux8d1JuDvro9x140\nvNJjT3t7AR998jm9tupUOydntabdRpvy/vw5K5c/WDCHdhtX/Xfcepc9WPTuTD764L3V7rts+XJe\n+u9odv3WwV9a9/zYB9htvy83SVolitj02MBjWt0FtYjYay03/QHwVHot1x44pWC5O7DWQc0yE6fO\nYptuG7JF5w40b9aUw/fbmYeefGWVPA/89xX22rl7dt2sZXN279mNV9+az8y5H7BHr81p3bI5AN/s\nszXT3loAZD0qf/6jr/P9827h06XLVu5ri84daNo0+whuvml7tttiY96e834dna0Vy+bb78TCWW+x\n6N2ZLF/2Oc+PfZAdv7rfKnkWzHqLiOya6cxpL7N82ees367Davf92qSn6bT51rQvaN4EWLFiBS/8\n52F2reQ6m+VbnbX1SPooItpI6gzcCbRNxz85Ip6sYhsBhwP7A09KahURnwGXAltLegEYA3wN2CEt\nDwPuBW4F1k+7Oi0inkn7PB/4EbACGBURgwuO1wS4GZgVEb8q7jvQ8JWVreBnfx7JA1f8mKZNmjDs\nwYlMnTGfn3xnTwD+fu94pr29gDHjXuPZW89kxYpg6APP8sqb8wC49z+T+d+w01m+fAUvvvYuN90/\nHoC/nH0oLZs348ErjwdgwpR3OOOP97HXzt055+h9WLa8jBURnHnZfSxa/En9nLyttabNmvG9sy7m\n+nMGsWLFCvY86HA6b7ktT9//TwC+OuAoXnziESaOvpcmzZrRvGUrBl181cpmrGGXnMEbz4/no8Xv\nc9H39uLA486kb/8jAXhu7IOV1sbeeHEC7TfpzEabbV53J9qI5ek+NZX/eqr1A30R1M4GWkXEEElN\ngfUi4sMqtvkq8JuI2FfS7cA9EXGPpO7AgxGxY8q3D3BORPRPy+sBKyLiM0k9gDsioo+kA4ELgf0i\n4hNJHSPiPUmPA4OBM4GXI2JIFeU5ETgRgBZte7fa7eTKsplV6dI/nlTfRbBG5s8nHMo7r05ep4i0\nfpftYoeTry9WkZh04bcmRUSDvGRTHx1FngWOk3Qx8JWqAlryA6D8IsxwVm2CrE5z4EZJk4G7gPJ+\n6fsB/4iITwAiorBR/29UE9BS/hsiok9E9FHz9WpYFDMzqyt1HtQi4r/A14HZwFBJx1SWL9Xivgf8\nWtJbwNVAP0kb1OAwPwPmATsDfYAWNdjmGeCbklrVIK+ZWaPi3o+1RNIWwLyIuBH4O7BbFVn3BV6K\niG4R0T0itgDuAb4DfAgUBreKy+2AORGxAjgaaJrSx5DVEtdLZelYsM1NwMPACEnuV25mJcW9H2vP\nPsCLkp4HjgSurCLfD8g6fBS6B/hBRCwCnpb0sqQ/AS8BZZJelPQz4FpgkKQXge2BjwEi4hFgJDAx\ndSpZZVyeiLgceB64NXUaMTOzRqTOaiQR0Sa9DiProbi6/MdVkjaSLCgRERW78H+rwvJOBfPnF+zj\nUrLek4X73adg/qLVlc3MrFFRfno/upnNzKzEZV3667sUdaNBBDVJ44GWFZKPjojJ9VEeMzNrnBpE\nUIuIPeu7DGZmpavh91oslgYR1MzMrHblJKZ5lH4zMysdrqmZmeWAmx/NzKw0NIKbpovFzY9mZlYy\nHNTMzEpc+aNn6nLsx/Qw57slvSppqqT/J6mjpDGSXk+vHQryXyBpuqRpkg4oSO8taXJad5VWUwAH\nNTOzHKiHAY2vBB6JiO3JBpefSvaIr7ER0QMYm5aR1BMYCPQC+gHXpkHtAa4DTgB6pKlfdQd1UDMz\ns6KS1I7saSw3AUTE5xHxATCAL4ZJHAYcluYHAMMjYmlEzACmA3soe6h024gYF9nDP28p2KZSDmpm\nZjlQ5FH6N5I0sWA6scLhtgQWAP+Q9Lykv0taH+gUEXNSnrlApzTfBZhZsP2slNYlzVdMr5J7P5qZ\n5UCRu/QvXM2Tr5uRPVbs9IgYL+lKUlNjuYgISVHMQoFramZmVnyzgFkRMT4t300W5OalJkXS6/y0\nfjbQrWD7riltdpqvmF4lBzUzs1JXxKbHmlT4ImIuMFPSdilpX+AVskeHDUppg4D70/xIYKCklpK2\nJOsQMiE1VS6R1Df1ejymYJtKufnRzKzEqX4GND4d+KekFsCbwHFkFakRko4H3gaOAIiIKZJGkAW+\n5cCpEVGW9nMKMBRoDYxKU5Uc1MzMrOgi4gWgsutu+1aRfwgwpJL0icCONT2ug5qZWQ7kZZgsBzUz\nsxxokpOo5o4iZmZWMlxTMzPLgZxU1BzUzMxKXdYVPx9Rzc2PZmZWMlxTMzPLgSb5qKg5qJmZ5YGb\nH83MzBoZ19TMzHIgJxU1BzUzs1InsvEf88DNj2ZmVjJcUzMzywH3fjQzs9Kgenn0TL1w86OZmZUM\n19TMzHIgJxU1BzUzs1In/OgZMzOzRsc1NTOzHMhJRc1BzcwsD9z70czMrJFxTc3MrMRlDwmt71LU\nDQc1M7MccO9HMzOzRqbKmpqkttVtGBFLil8cMzOrDfmop1Xf/DgFCFZ9L8qXA9i8FstlZmZFlJfe\nj1UGtYjoVpcFMTMzW1c1uqYmaaCkX6T5rpJ6126xzMysWLJhsoo3NWSrDWqSrgG+CRydkj4Brq/N\nQpmZWRGlR88Ua2rIatKlf6+I2E3S8wAR8Z6kFrVcLjMzszVWk6C2TFITss4hSNoQWFGrpTIzs6Jq\n4BWsoqlJUPsrcA+wsaRLgCOAS2q1VGZmVlQNvdmwWFYb1CLiFkmTgP1S0uER8XLtFsvMzGzN1XSY\nrKbAMrImSI9CYmbWiJT3fsyDmvR+/CVwB7AZ0BW4XdIFtV0wMzMrHvd+/MIxwK4R8QmApCHA88Dv\na7NgZmZma6omQW1OhXzNUpqZmTUSDbt+VTzVDWj8F7JraO8BUySNTsvfBp6tm+KZmdm6kur+0TOS\n3gI+BMqA5RHRR1JH4E6gO/AWcEREvJ/yXwAcn/KfERGjU3pvYCjQGngYODMioqrjVldTK+/hOAV4\nqCB93JqdmpmZ5dQ3I2JhwfJgYGxEXCppcFo+X1JPYCDQi6z/xqOSto2IMuA64ARgPFlQ6weMquqA\n1Q1ofNO6no2ZmTUMDaR/xwBgnzQ/DHgcOD+lD4+IpcAMSdOBPVJtr21EjAOQdAtwGNUEtZr0ftxa\n0nBJL0l6rXxa+3MyM7McCLIa1yRJJ6a0ThFR3idjLtApzXcBZhZsOyuldUnzFdOrVJOOIkOB3wKX\nAQcCx6XCmplZI1HkrvgbSZpYsHxDRNxQIc/eETFb0ibAGEmvFq6MiJBU9FhSkxup1yu/YBcRb0TE\nr8iCm5mZNRJS8SZgYUT0KZgqBjQiYnZ6nQ/cC+wBzJPUOSuPOgPzU/bZQOEzPLumtNlpvmJ6lWoS\n1JamAY3fkPRTSYcAG9RgOzMzyyFJ60vaoHyerNf8y8BIYFDKNgi4P82PBAZKailpS6AHMCE1VS6R\n1FdZVfOYgm0qVZPmx58B6wNnAEOAdsCP1+D8zMysHgnVdZf+TsC9qcmzGXB7RDwi6VlghKTjgbfJ\nBsgnIqZIGgG8AiwHTk09HwFO4Ysu/aOoppNI+cGqFRHj0+yHfPGgUDMzayxUt70fI+JNYOdK0hcB\n+1axzRCyilPF9InAjjU9dnU3X99LNR1CIuK7NT2ImZlZXaiupnZNnZWiEdp1uy48/eSl9V0Ma2Q6\n7H5afRfBGpml78wryn4a+kDExVLdzddj67IgZmZWe/LyzLC8nKeZmeVATR8SamZmjZRw8+OXSGqZ\nxuUyM7NGxk++TiTtIWky8Hpa3lnS1bVeMjMzszVUk2tqVwH9gUUAEfEi8M3aLJSZmRVXExVvashq\n0vzYJCLertAeW1ZVZjMza1iyMRsbeDQqkpoEtZmS9gBCUlPgdMCPnjEzswanJkHtZLImyM2BecCj\nKc3MzBqJht5sWCw1GftxPtljts3MrJHKSevj6oOapBupZAzIiDixkuxmZmb1pibNj48WzLcCvsOq\nj902M7MGTFDXj56pNzVpfryzcFnSrcBTtVYiMzMruryMibg257kl2QPgzMzMGpSaXFN7ny+uqTUB\n3gMG12Yhph0SAAAeeUlEQVShzMysuHLS+lh9UFN2t97OwOyUtCIiqnxwqJmZNTyScnNNrdrmxxTA\nHo6IsjQ5oJmZWYNVk2tqL0jatdZLYmZmtSYbKqs4U0NWZfOjpGYRsRzYFXhW0hvAx2S9QyMidquj\nMpqZ2TryiCIwAdgNOLSOymJmZrZOqgtqAoiIN+qoLGZmVgt883VmY0k/r2plRFxeC+UxM7NakJOY\nVm1Qawq0IdXYzMzMGrrqgtqciPhNnZXEzMxqRyN4YnWxrPaampmZNX7KyVd6dfep7VtnpTAzMyuC\nKmtqEfFeXRbEzMxqR9b7sb5LUTdq8jw1MzNr5PIS1PLyiB0zM8sB19TMzHJAOblRzUHNzKzE5ema\nmpsfzcysZLimZmZW6hrBI2OKxUHNzCwH8jKgsZsfzcysZLimZmZW4txRxMzMSopUvKlmx1NTSc9L\nejAtd5Q0RtLr6bVDQd4LJE2XNE3SAQXpvSVNTuuuUg3uS3BQMzOz2nAmMLVgeTAwNiJ6AGPTMpJ6\nAgOBXkA/4FpJTdM21wEnAD3S1G91B3VQMzMreaJJEafVHk3qChwM/L0geQAwLM0PAw4rSB8eEUsj\nYgYwHdhDUmegbUSMi4gAbinYpkq+pmZmVuJE0bv0byRpYsHyDRFxQ8HyFcB5wAYFaZ0iYk6anwt0\nSvNdgHEF+WaltGVpvmJ6tRzUzMxsTS2MiD6VrZDUH5gfEZMk7VNZnogISVEbBXNQMzMrdXX75Ouv\nAodKOghoBbSVdBswT1LniJiTmhbnp/yzgW4F23dNabPTfMX0avmamplZDjSRijZVJyIuiIiuEdGd\nrAPIYxHxI2AkMChlGwTcn+ZHAgMltZS0JVmHkAmpqXKJpL6p1+MxBdtUyTU1MzOrC5cCIyQdD7wN\nHAEQEVMkjQBeAZYDp0ZEWdrmFGAo0BoYlaZqOaiZmZW4WugoUiMR8TjweJpfBOxbRb4hwJBK0icC\nO67JMR3UzMxywGM/mpmZNTKuqZmZ5UBOKmoOamZmpU7kp1kuL+dpZmY54JqamVmpE9RggPuS4KBm\nZpYD+Qhpbn40M7MS4pqamVmJy558nY+6moOamVkO5COkufnRzMxKiGtqZmY5kJPWRwc1M7PSp9x0\n6Xfzo5mZlQzX1MzMSlyehslyUDMzywE3P5qZmTUyrqmZmeVAPupprqlZBf8e/Qg79dqOXttvw5/+\neOmX1kcEPz/rDHptvw2777oTzz/3HACvTZvGnr13WTlt0rEtV195BQD33H0Xu+3ci/VaNGHSxIkr\n9/X2W2/RYYPWK7c5/ZSf1s1JWtHtv9cOvHjvhbx8/0Wcc9z+X1rffoPW3PnnE5hw5wU8ees59Ny6\nMwBdO7XnkRvO4Ll7fsmku3/JqT/YZ+U2O23bhSeGnc244YN56p/n0afXFgBs3rkj7/3vcsYNH8y4\n4YO56pcD6+QcG7U0oHGxpobMNTVbqaysjLPOOJWHRo2hS9eu7N13d/r3P5QdevZcmWf0I6N4Y/rr\nvDz1dSaMH88Zp53Mk8+MZ9vttmP8pBdW7mfrLbpw6GHfAaBXrx0ZPuJfnHbKSV865lZbb71yO2uc\nmjQRVww+goNPvobZ8z7gqX+ey4NPTObVN+euzHPe8Qfw4rRZHHn2jWzbvRNXDD6Cg356NcvLVjD4\n8n/xwquzaLNeS565/XzGjn+VV9+cy5CzDmPIDaP499OvcMDePRly1mEccMKVALw5ayF9B375R5eZ\na2q20rMTJrD11tuw5VZb0aJFCw4/ciAPPnD/KnkeHHk/P/zRMUhiz759Wbz4A+bMmbNKnv88NpYt\nt9qaLbbIfllvv8MObLvddnV2Hla3dt+xO2/MXMhbsxexbHkZd41+jv777LRKnu232pQnnn0NgNfe\nmscWm3Vkk44bMHfhEl54dRYAH32ylFdnzGWzjdsDEAFt128FQLs2rZmzYHEdnlVpKe/9WKypIWvo\n5bM69O67s+natdvK5S5dujJ79uzV5nm3Qp677hzOEUf+oEbHfGvGDPbsvQv7f+sbPPXUk+tQeqsv\nm23Sjlnz3l+5PHve+3TZuN0qeSa/NpsB39oZgD69tmDzzh3p0qn9Knk279yRXbbryrMvvwXAuZfd\nze/OOozXR/0fv//Zd/j11V/8wOreZUPGDR/Mv/9+Jl/ddetaOrPSkpfmRwc1K6rPP/+chx4cyXe/\nf/hq827auTOvvfkO4ye9wB/+dDnHHv1DlixZUgeltLp22T/G0G6D9Rg3fDAnD/wGL06bRVnZipXr\n12/dgjsu+wnnXnYPH378GQAnHv41zvvzv+hx4IWcd9k9XHfRUQDMXbiEbQ/8NX0HXsr5f/4XQ393\nLBukGp1ZrQU1Sc+sxTZvSbqnYPn7koYWtWCrL8PFks6py2M2FJtt1oVZs2auXJ49exZdunRZbZ7N\nCvKMfmQUu+y6G506dVrt8Vq2bMmGG24IwG69e7PVVlvz+muvretpWB17d/5iunbqsHK5S6cOzK7Q\nVPjhx59x0sW30XfgpRx/4S1s1KENM2YvAqBZsybccdkJ3DlqIvc/9uLKbY7qvyf3jc2ut94z5vmV\nHUU+X7ac9xZ/DMDzU2fy5qyF9Nhik1o9x1KgIk4NWa0FtYjYay037S2p5+qzfZkkd3xZB312353p\n01/nrRkz+Pzzz7nrzuEc3P/QVfIcfMih3H7bLUQE48eNo23bdnTu3Hnl+hF33lHjpscFCxZQVlYG\nwIw332T69NfZcqutindCVicmTnmbbTbfmC0225DmzZpy+AG78dDjL62Sp12b1jRv1hSA476zF089\nN31ljez6i45i2oy5XHXbY6tsM2fBYr7WuwcA++yxLdPfWQDARh3a0KRJ9tXavcuGbLP5xsyYtbBW\nz9Eaj1oLApI+iog2kjoDdwJt0/FOjojqLp78GfglcFSF/XUEbga2Aj4BToyIlyRdDGyd0t+RNBo4\nDFgf6AFcBrQAjgaWAgdFxHuSTgBOTOumA0dHxCerOacT0zZ023zzmr4VjUazZs34y5XXcMjBB1BW\nVsagY39Mz169uPFv1wNwwkk/pd+BBzF61MP02n4b1mu9Hn/7+z9Wbv/xxx/z2KNjuObav62y3/vv\nu5efn3U6Cxcs4LsDDmannXfhgYdH89ST/+X/Lvk1zZs1p0mTJlz91+vp2LFjnZ6zrbuyshX87A8j\neODaU2naRAy7fxxT35zLT76/NwB/v/sptt9qU278zdFEBFPfmMNPL/knAHvtshVH9d+Tya/NZtzw\nwQBcdM1IRj/1Cqf+3+386dzv06xZE5YuXc5pv70DgL1324YLTz6YZcvLWLEiOH3IcN5fUu1/XSM/\no/QrImpnx18EtbOBVhExRFJTYL2I+LCKbd4C9gQeBw4BdgH6R8Sxkq4GFkbEJZK+BVweEbukoHYI\nsHdEfCrpWOBXwK5AK7KAdX5EXC/pL8DbEXGFpA0jYlE67m+BeRFxddrfRxFxWXXn17t3n3h6/MTq\nsph9SYfdT6vvIlgjs3TaCFZ8Mn+dQlKPXjvH5cP/XawicehOm06KiD5F22ER1UVHkWeB41Kw+EpV\nAa1AGfAn4IIK6XsDtwJExGPAhpLapnUjI+LTgrz/iYgPI2IBsBh4IKVPBrqn+R0lPSlpMlmtsNca\nn5mZmTUotR7UIuK/wNeB2cBQScfUYLNb0zbdVpcx+bjC8tKC+RUFyyv4osl1KHBaRHwFuISsVmdm\nVpKk4k0NWa0HNUlbkDXt3Qj8HdhtddtExDLgL8DPCpKfJF1nk7QPWVPkuvT/3gCYI6k5Fa7fmZmV\nFhX1X0NWF70F9wHOlbQM+AioSU0N4Caya2PlLgZulvQSWUeRQetYrguB8cCC9LrBOu7PzMzqWa0F\ntYhok16HAcNquE33gvmlwGYFy++R9WqsuM3FFZaHkjUtVrbPlesi4jrgutXtz8ysFDT0ZsNi8X1d\nZmYlLhv7MR9RrV6CmqTxQMsKyUdHxOT6KI+ZmZWGeglqEbFnfRzXzCyXGkGvxWJx86OZWQ7kJah5\nlH4zMysZDmpmZjlQl/epSWolaYKkFyVNkXRJSu8oaYyk19Nrh4JtLpA0XdI0SQcUpPeWNDmtu0qr\neaCbg5qZWYkT0ETFm2pgKfCtiNiZbAzffpL6AoOBsRHRAxiblklPZhlINlxhP+DaNFYwZLdenUA2\nQH2PtL5KDmpmZlZUkfkoLTZPUwAD+OK+5WF8ce/xAGB4RCyNiBlkA9HvkZ7y0jYixkU2+v4tVHK/\nciEHNTOzHKjrYbIkNZX0AjAfGBMR44FOETEnZZkLlD9NuAsws2DzWSmtS5qvmF4l9340M8uBIvd+\n3EhS4bO3boiIGwozREQZsIuk9sC9knassD4kFf3ZZw5qZma2phbW9HlqEfGBpP+QXQubJ6lzRMxJ\nTYvzU7bZrPpUlq4pbXaar5heJTc/mpnlQB33ftw41dCQ1BrYH3gVGMkXg9EPAu5P8yOBgZJaStqS\nrEPIhNRUuURS39Tr8ZiCbSrlmpqZWYkr7/1YhzoDw1IPxibAiIh4UNL/gBGSjgfeBo4AiIgpkkYA\nrwDLgVNT8yXAKWQD0bcGRqWpSg5qZmZWVBHxErBrJemLgH2r2GYIMKSS9InAjl/eonIOamZmJa/h\nP9yzWBzUzMxKXY4GNHZHETMzKxmuqZmZ5UBOKmoOamZmpS7r/ZiPsObmRzMzKxmuqZmZ5UA+6mkO\namZm+ZCTqObmRzMzKxmuqZmZ5YBvvjYzs5KRk86Pbn40M7PS4ZqamVkO5KSi5qBmZpYLOYlqbn40\nM7OS4ZqamVmJE+79aGZmpcKPnjEzM2t8XFMzM8uBnFTUHNTMzHIhJ1HNzY9mZlYyXFMzMyt5cu9H\nMzMrHe79aGZm1si4pmZmVuJEbvqJOKiZmeVCTqKamx/NzKxkuKZmZpYD7v1oZmYlw70fzczMGhnX\n1MzMciAnFTUHNTOzkpejPv1ufjQzs5LhmpqZWQ6496OZmZUE4d6PZmZmjY5ramZmOZCTippramZm\nuaAiTqs7lNRN0n8kvSJpiqQzU3pHSWMkvZ5eOxRsc4Gk6ZKmSTqgIL23pMlp3VVS9Q2pDmpmZlZs\ny4GzI6In0Bc4VVJPYDAwNiJ6AGPTMmndQKAX0A+4VlLTtK/rgBOAHmnqV92BHdTMzHJARfy3OhEx\nJyKeS/MfAlOBLsAAYFjKNgw4LM0PAIZHxNKImAFMB/aQ1BloGxHjIiKAWwq2qZSvqZmZ5UB99X6U\n1B3YFRgPdIqIOWnVXKBTmu8CjCvYbFZKW5bmK6ZXyUHNzMzW1EaSJhYs3xARN1TMJKkNcA9wVkQs\nKbwcFhEhKYpdMAc1M7McKHJFbWFE9Kn2eFJzsoD2z4j4V0qeJ6lzRMxJTYvzU/psoFvB5l1T2uw0\nXzG9Sr6mZmaWB3Xb+1HATcDUiLi8YNVIYFCaHwTcX5A+UFJLSVuSdQiZkJoql0jqm/Z5TME2lXJN\nzczMiu2rwNHAZEkvpLRfAJcCIyQdD7wNHAEQEVMkjQBeIes5eWpElKXtTgGGAq2BUWmqkoOamVmJ\nyypYdddTJCKeouo63b5VbDMEGFJJ+kRgx5oe20HNzKzUyWM/mpmZNTquqZmZ5UBOKmoOamZmuZCT\nqOagtpaee27SwtbN9XZ9l6MB2ghYWN+FsEbHn5uqbVHfBWhMHNTWUkRsXN9laIgkTVzdTZlmFflz\nU9tqNmZjKXBQMzPLAfd+NDMza2RcU7Ni+9KgpmY14M9NLarh6FYlwUHNiqqykbrNVsefmzqQk6jm\n5kczMysZrqmZmeVAXno/uqZmZmYlwzU1azAkKSKK/iRcKz2SOgIbRcRr9V2WxsJd+s3qiKRukD3e\nvb7LYg2fpFbAGcCPJe1Q3+VpLOrwGaH1ykHN6pykNpJapPkdgD9K2qCei2WNRER8BjyaFg+X1LM+\ny2MNi4Oa1SlJ6wP/BA5PSZ+k6SNJzVOehv5j0OpJ+WcjPYRyJNAW+L4D22qk56kVa2rIHNSsTkXE\nx8CdwHGSjgS6A59GZlnK42ZI+5Lya66StpTULCKeAf4BtCMLbG6KrFY+GiDdUcTqjKSmEVEWEbdL\nWgCcD0wCtpR0JTALWAo0i4jL67Os1vCkgHYwcCHwpKSPgCvIRiM5HviRpH9GxCv1WU6rX66pWZ1I\nv7LLJO0v6Y8RMQa4EtgX+Bx4J722AcbXY1GtgZLUF/gdcCTZD/LDgD8CC4BhwPpknyGrQOSn+dE1\nNasT6Vf2vsC1wEkp7QFJy4GfA69FxAP1WUZrmCQ1AYLsmWvHANsDXwcGAycCl5HV+n+ZmretEg08\nFhWNa2pW65RpBvQDLoyIx8p7P0bEKOB64HxJXeqznNawFHQYapOuuT4YES+S1dB+EhGjgflkP847\nOaAZOKhZHUhfSMuBz4C+klpFxOcAknYHHgYOjYjZ9VlOa1gKrqGNlXSxpO+mVZsAJ0raE9gDuCwi\nXq63gjYSeWl+dFCzWlH+K1vS5pK6puRRQHPgG2ndzsBfgG0j4r16Kag1WJI6A0eRNS++BxyQgtyP\ngW7Ar4HfR8RL9VfKxkNF/NeQ+Zqa1YqCX9m/B56R1DEijkjdro+WdD5ZV+zfpiYls5Uk9QF2BmZH\nxJ2SNgYOAL4DNI+I/pLWi4hPPLyaFXJQs6IquJeoL1nPtP5kNbObJT0aEftJGkr2hbU4It7wl5IV\nkrQPWW/G0WTd9O+IiOckjQJaAAMkTYiId8H3NdZYw65gFY2DmhVFGo9vWeq23wlYBBwB9CDr7dgO\neFzSMxGxF/Bc+bb+UrJykrYEfgEcHRH/lTQduE3SURHxvKT7gUfKA5rVXE5imq+p2bpLXa73As6S\n1J/sWseHwCvAwcDNEfEh2a/vzVPnEDNgleuvu5PV6tuR9XAkIv4I3ASMlNQ7IhY5oFl1HNSsWF4C\nvg3cCtwdEXPJfhzOAbaWdAJZU+T+EfFs/RXTGprUXP11subqyWQ3WK8n6bS0/s/AX8luzLe1UMye\nj+79aCVL0vqSukbECmCLlPwf4MDUbX8F2Wjqn5AFtOsjYmo9FdcaKEnbAScDQyNiEvA4MBbYXtLZ\nABFxaUQ84cGu115eej86qNm66A5cLemXwDnA2cDpZCOnl4/d+CZZoPteRPzLX0pWia8AnYD9JG0c\nEYuBR4BngO0klf9g8vVXWy0HNVtrETEFmE52YX98ugF2AdlQWC0ljSX71b0s3XztLyUrvIbWVVK7\niLibbJDiJWSj7W+YrsE+APw6It6ux+KWjnwM0u/ej7ZmJLUHPo+IT1LSy8CfgWMkTY6IscBLqfa2\nP/BuRIyrp+JaAyOpSUSskHQg2TW0aZI2IesY8iBwINl9jLdGxCKyDkdWBA08FhWNg5rVmKSOwGvA\no5KejIi/RsSwtG4mcLmkQcAHwHfLHx/j+9BMUuuI+DQFtG2A/wNOiohnJF0F3Ed2c3Xz9Lo+2W0h\nZmvEQc3WxPvAv8l6NB4laQ/gKeCuiLhR0ufAPcBy4KzyjRzQ8k1SO+BSSfdGxL/JfvS8SvYDiYg4\nQ9IdwOCIuEjSsxExpx6LXJLycjXb19SsxlJweo7sov7XgaHp9QlJ3yTrELInWaeQUfVVTmtw2pJd\ne/1hevzQEmBDYL+CPA+TnoXmgFYbitn3sWFHR9fUbI1ExGWSHib7QnoZ2IXsV/dAYBvgSI+YbgCS\nNoiIDyNipqRbyD4jPybrTPQLYKik7YHFKf28+iutlQoHNasxSU0jooyshvYdshH2b0qBbhOygWYX\n1mcZrWGQ1B24W9IkYATwOvAPYCnZrR9/AA4n6xiyGfCziHjU119rR/mTr/PAzY9WYymgAYwHvgb8\nLyIuS2kL/Dw0K9AK6AwMIHvm2b+BnwBdyO4/uxBoERFXRsT5EfEo+PprqZB0s6T5kl4uSOsoaYyk\n19Nrh4J1F0iaLmmapAMK0ntLmpzWXVWT+1wd1GyNpF/SbwM/B9qUP63aX0ZWLnXbf5WsiXox8A5w\nJPAu2diO30/Lf5TUPo0daqVlKNmT7gsNBsZGRA+yEWMGA0jqSdY03Sttc62kpmmb64ATyAZG71HJ\nPr/EHyb7koKbY7/0+SgIXrOAFXVZLmscUrf9JmlItB8BvwH6RMQI4FvAaWRfaFdExAdpODWrZXU5\n9mNE/Jfswa6FBpANak56PawgfXhELI2IGWSdivZID4ltGxHj0vfOLQXbVMnX1GwVBc9D25esJjY6\nIj6rmC8iXpZ0vpscrTIFge1ZSQOBO9J4oH8FppHdeO17GOtQA+i12KmgZ+tcsl7UkDVJFw7QMCul\nLUvzFdOr5ZqarZQ6goSkfmTV/vcrC2jKNImItyWtJ2nDui+tNXSFgY2sufFCSadWyOOA1jhtJGli\nwXTimmyc/u618rd3Tc1IIzzMi4gP08XbC4Gfpoc0fg3YCpgaERPSJk3Sw0Dbk55OjEd/yK2C2n2T\nik2JBYFtkqRDyEYKsbpW/EfGLIyIPmu4zTxJnSNiTmpanJ/SZwPdCvJ1TWmz03zF9Gq5pmaQNQN8\nJX35vE92E/XxaZSH08jGcDwUQFKzFNDaAXcB50bE6/VVcKtfFZqrD1H2BPRVFNbYIuJxP6mh7hVz\nLON1+OONBAal+UHA/QXpAyW1VPbk8x7AhNRUuURS3/SZOaZgmyo5qBkR8TTZwxnflNSWrOfSBODq\niDiS7D6jXpJaRMTyVJu7F/hNuiBsOVTT5ury7Gmb1kCHKvJYiUg/iP9H9uigWZKOBy4F9pf0OlnP\n2Eth5dM+RgCvkD1y6NSC24dOAf5O1nnkDWC1IxXJTdpWTtIAYAiwd0R8kNK+BlwD/CIiHkpppwCv\nRsRj9VZYqzeVNFc/CFwYEY9V1lxdftN+YXO1a/d1a7fefeKJZyasPmMNtW3VdNJaND/WCV9Ts5Ui\n4n5Jy4BJknoDn5HdU/SriHiovKkpIq6t35JaPesEbCJpXES8L6m8ufoEstafZaQmpNRcvdzN1fWv\nAfR+rBMOaraKiHhY0gpgKrAdcH5EfFZw7cRdsHMuIp6WtAFZc/VOZM3VBwPPpkfJHAocl5qrP0+1\nuXuAiyLiyforueWBr6nZl0TEI2RDGu1afo2kPJA5oBlAZE+mPpNsyKuFabirZ1Lz4/8Bf4+Iz1P2\nHwC/dUCrX3V583V9ck3NKlVw/cw1M6uUm6sblwYei4rGQc2q5YBm1XFztTU0bn40s3Xi5upGogHc\nqFYXXFMzs3Xm5uqGLy+9H11TM7OicUCz+uaamplZicvTk689ooiZWYmT9AiwURF3uTAiVvvAzvrg\noGZmZiXD19SsZEkqk/SCpJcl3SVpvXXY1z6SHkzzh0oaXE3e9ml8zDU9xsWSzqlpeoU8QyV9fw2O\n1V3Sy2taRrOGzkHNStmnEbFLROwIfA78tHBl+cNO13SnETEyIi6tJkt7stHFzayOOahZXjwJbJNq\nKNMk3QK8DHST9G1J/5P0XKrRtQGQ1E/Sq5KeA75bviNJx0q6Js13knSvpBfTtBfZIzW2TrXEP6V8\n50p6VtJLki4p2NcvJb0m6Smym5erJemEtJ8XJd1Tofa5n7KnEL8mqX/K31TSnwqOfdK6vpFmDZmD\nmpU8Sc2AA8meGQfZCPLXRkQv4GPgV8B+EbEbMBH4eXrY5Y3AIUBvYNMqdn8V8ERE7AzsBkwBBgNv\npFriuZK+nY65B7AL0FvS19PQUgNT2kHA7jU4nX9FxO7peFOB4wvWdU/HOBi4Pp3D8cDiiNg97f+E\n9CBGs5LkLv1WylpLeiHNPwncBGwGvB0R41J6X6An8HT2cF1akD3ccHtgRvljUiTdBpxYyTG+RfZE\nXtKDDRenUekLfTtNz6flNmRBbgPg3oj4JB1jZA3OaUdJvyVr4mxD9nyyciMiYgXwuqQ30zl8G9ip\n4Hpbu3Ts12pwLLNGx0HNStmnEbFLYUIKXB8XJgFjIuIHFfKtst06EvD7/9/e3as0EERhGH4/RURC\nLG1sgkLAa7DxBoQ0FqKFKIgpRC9AL0SxsBMvQMTCRpD4A4F0amkjmFKxk2OxIyxBIaQy4/c0Czsz\ne4ZtDvOzOxFx0BNjd4BnHQONiOhIWgMWSmW9W5kjxd6OiHLyQ1JtgNhmf56nH+2/uwHm02nOSKpI\nqgMPQE3SbKq3/Ev7S6CZ2o6mwzDfKEZh3y6A9dJa3bSkKeAKaEiaSOeTLfbR3yrwImkMWOkpW5I0\nkvo8Azym2M1UH0l1SZU+4pgNJY/U7F+LiG4a8ZxIGk+39yLiSdImcCbpg2L6svrDI3aAQ0kbwCfQ\njIiWpOu0Zf48ravNAa00UnwHViOiLekU6ACvwH0fXd4HboFuupb79AzcAZPAVvpb/hHFWltbRfAu\n0Ojv7ZgNH398bWZm2fD0o5mZZcNJzczMsuGkZmZm2XBSMzOzbDipmZlZNpzUzMwsG05qZmaWDSc1\nMzPLxhes/38W6ai3vAAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7feb473d4b38>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot(actual_value = Train.actual_value, pred_value = Train.pred_value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "_draft": {
   "nbviewer_url": "https://gist.github.com/7d1ace18a82178e15ece8fc5252fce88"
  },
  "anaconda-cloud": {},
  "gist": {
   "data": {
    "description": "Hyper parameter tuning",
    "public": false
   },
   "id": "7d1ace18a82178e15ece8fc5252fce88"
  },
  "kernelspec": {
   "display_name": "Python [conda env:p3]",
   "language": "python",
   "name": "conda-env-p3-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
