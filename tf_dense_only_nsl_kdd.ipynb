{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Read Data Sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-05-31T00:34:19.501455Z",
     "start_time": "2017-05-31T00:34:18.908469Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "from collections import namedtuple\n",
    "pd.set_option(\"display.max_rows\",35)\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-05-31T00:34:19.610865Z",
     "start_time": "2017-05-31T00:34:19.503656Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class dataset:\n",
    "    kdd_train_2labels = pd.read_pickle(\"dataset/kdd_train_2labels.pkl\")\n",
    "    kdd_test_2labels = pd.read_pickle(\"dataset/kdd_test_2labels.pkl\")\n",
    "    \n",
    "    kdd_train_5labels = pd.read_pickle(\"dataset/kdd_train_5labels.pkl\")\n",
    "    kdd_test_5labels = pd.read_pickle(\"dataset/kdd_test_5labels.pkl\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-05-31T00:34:19.619349Z",
     "start_time": "2017-05-31T00:34:19.613192Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(125973, 124)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.kdd_train_2labels.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-05-31T00:34:19.628720Z",
     "start_time": "2017-05-31T00:34:19.621461Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(22544, 124)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.kdd_test_2labels.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-05-31T00:34:20.518511Z",
     "start_time": "2017-05-31T00:34:19.630763Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(125973, 122)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn import model_selection as ms\n",
    "from sklearn import preprocessing as pp\n",
    "\n",
    "class preprocess:\n",
    "    \n",
    "    output_columns_2labels = ['is_Attack','is_Normal']\n",
    "    \n",
    "    x_input = dataset.kdd_train_2labels.drop(output_columns_2labels, axis = 1)\n",
    "    y_output = dataset.kdd_train_2labels.loc[:,output_columns_2labels]\n",
    "\n",
    "    x_test_input = dataset.kdd_test_2labels.drop(output_columns_2labels, axis = 1)\n",
    "    y_test = dataset.kdd_test_2labels.loc[:,output_columns_2labels]\n",
    "\n",
    "    ss = pp.StandardScaler()\n",
    "\n",
    "    x_train = ss.fit_transform(x_input)\n",
    "    x_test = ss.transform(x_test_input)\n",
    "\n",
    "    y_train = y_output.values\n",
    "    y_test = y_test.values\n",
    "\n",
    "preprocess.x_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-05-31T00:34:22.042986Z",
     "start_time": "2017-05-31T00:34:20.521163Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-05-31T00:34:22.228056Z",
     "start_time": "2017-05-31T00:34:22.044999Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class network(object):\n",
    "    \n",
    "    input_dim = 122\n",
    "    classes = 2\n",
    "    hidden_encoder_dim = 122\n",
    "    hidden_layers = 1\n",
    "    latent_dim = 18\n",
    "\n",
    "    def __init__(self, classes, hidden_layers, num_of_features):\n",
    "        self.classes = classes\n",
    "        self.hidden_layers = hidden_layers\n",
    "        self.latent_dim = num_of_features\n",
    "            \n",
    "    def build_layers(self):\n",
    "        tf.reset_default_graph()\n",
    "        #learning_rate = tf.Variable(initial_value=0.001)\n",
    "\n",
    "        input_dim = self.input_dim\n",
    "        classes = self.classes\n",
    "        hidden_encoder_dim = self.hidden_encoder_dim\n",
    "        hidden_layers = self.hidden_layers\n",
    "        latent_dim = self.latent_dim\n",
    "        \n",
    "        with tf.variable_scope(\"Input\"):\n",
    "            self.x = tf.placeholder(\"float\", shape=[None, input_dim])\n",
    "            self.y_ = tf.placeholder(\"float\", shape=[None, classes])\n",
    "            self.keep_prob = tf.placeholder(\"float\")\n",
    "        \n",
    "        with tf.variable_scope(\"Layer_Encoder\"):\n",
    "\n",
    "            hidden_encoder = tf.layers.dense(self.x, hidden_encoder_dim, activation = tf.nn.relu, kernel_regularizer=tf.nn.l2_loss)\n",
    "            hidden_encoder = tf.nn.dropout(hidden_encoder, self.keep_prob)\n",
    "            for h in range(hidden_layers - 1):\n",
    "                hidden_encoder = tf.layers.dense(hidden_encoder, latent_dim, activation = tf.nn.relu, kernel_regularizer=tf.nn.l2_loss)\n",
    "                hidden_encoder = tf.nn.dropout(hidden_encoder, self.keep_prob)\n",
    "            \n",
    "            #hidden_encoder = tf.layers.dense(self.x, latent_dim, activation = tf.nn.relu, kernel_regularizer=tf.nn.l2_loss)\n",
    "            #hidden_encoder = tf.nn.dropout(hidden_encoder, self.keep_prob)\n",
    "            \n",
    "        with tf.variable_scope(\"Layer_Dense_Softmax\"):\n",
    "            self.y = tf.layers.dense(hidden_encoder, classes, activation=tf.nn.softmax)\n",
    "            \n",
    "        with tf.variable_scope(\"Loss\"):\n",
    "            \n",
    "            loss = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(labels = self.y_, logits = self.y))\n",
    "\n",
    "            #loss = tf.clip_by_value(loss, -1e-1, 1e-1)\n",
    "            #loss = tf.where(tf.is_nan(loss), 1e-1, loss)\n",
    "            #loss = tf.where(tf.equal(loss, -1e-1), tf.random_normal(loss.shape), loss)\n",
    "            #loss = tf.where(tf.equal(loss, 1e-1), tf.random_normal(loss.shape), loss)\n",
    "            \n",
    "            self.regularized_loss = loss\n",
    "            correct_prediction = tf.equal(tf.argmax(self.y_, 1), tf.argmax(self.y, 1))\n",
    "            self.tf_accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32), name = \"Accuracy\")\n",
    "\n",
    "        with tf.variable_scope(\"Optimizer\"):\n",
    "            learning_rate=1e-5\n",
    "            optimizer = tf.train.AdamOptimizer(learning_rate)\n",
    "            gradients, variables = zip(*optimizer.compute_gradients(self.regularized_loss))\n",
    "            gradients = [\n",
    "                None if gradient is None else tf.clip_by_value(gradient, -1, 1)\n",
    "                for gradient in gradients]\n",
    "            self.train_op = optimizer.apply_gradients(zip(gradients, variables))\n",
    "            #self.train_op = optimizer.minimize(self.regularized_loss)\n",
    "            \n",
    "        # add op for merging summary\n",
    "        #self.summary_op = tf.summary.merge_all()\n",
    "        self.pred = tf.argmax(self.y, axis = 1)\n",
    "        self.actual = tf.argmax(self.y_, axis = 1)\n",
    "\n",
    "        # add Saver ops\n",
    "        self.saver = tf.train.Saver()\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-05-31T00:35:00.038920Z",
     "start_time": "2017-05-31T00:34:59.764866Z"
    },
    "collapsed": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import collections\n",
    "import time\n",
    "\n",
    "class Train:    \n",
    "    \n",
    "    result = namedtuple(\"score\", ['epoch', 'no_of_features','hidden_layers','train_score', 'test_score', 'time_taken'])\n",
    "\n",
    "    predictions = {}\n",
    "\n",
    "    results = []\n",
    "    best_acc = 0\n",
    "    best_acc_global = 0\n",
    "    \n",
    "    def train(epochs, net, h,f):\n",
    "        batch_iterations = 200\n",
    "        train_loss = None\n",
    "        Train.best_acc = 0\n",
    "        os.makedirs(\"dataset/tf_dense_only_nsl_kdd/hidden layers_{}_features count_{}\".format(epochs,h,f),\n",
    "                    exist_ok = True)\n",
    "        with tf.Session() as sess:\n",
    "            #summary_writer_train = tf.summary.FileWriter('./logs/kdd/VAE/training', graph=sess.graph)\n",
    "            #summary_writer_valid = tf.summary.FileWriter('./logs/kdd/VAE/validation')\n",
    "\n",
    "            sess.run(tf.global_variables_initializer())\n",
    "            start_time = time.perf_counter()\n",
    "\n",
    "            for epoch in range(1, (epochs+1)):\n",
    "                x_train, x_valid, y_train, y_valid, = ms.train_test_split(preprocess.x_train, \n",
    "                                                                          preprocess.y_train, \n",
    "                                                                          test_size=0.1)\n",
    "                batch_indices = np.array_split(np.arange(x_train.shape[0]), \n",
    "                                           batch_iterations)\n",
    "                                                                          \n",
    "                for i in batch_indices:\n",
    "                    \n",
    "                    def train_batch():\n",
    "                        nonlocal train_loss\n",
    "                        _, train_loss = sess.run([net.train_op, \n",
    "                                                           net.regularized_loss, \n",
    "                                                           ], #net.summary_op\n",
    "                                                          feed_dict={net.x: x_train[i,:], \n",
    "                                                                     net.y_: y_train[i,:], \n",
    "                                                                     net.keep_prob:0.5})\n",
    "                    \n",
    "                    train_batch()\n",
    "                    #summary_writer_train.add_summary(summary_str, epoch)\n",
    "                    while((train_loss > 1e4 or np.isnan(train_loss)) and epoch > 1):\n",
    "                        print(\"Step {} | Training Loss: {:.6f}\".format(epoch, train_loss))\n",
    "                        net.saver.restore(sess, \n",
    "                                          tf.train.latest_checkpoint('dataset/tf_dense_only_nsl_kdd/hidden_layers_{}_features_count_{}'\n",
    "                                                                     .format(epochs,h,f)))\n",
    "                        train_batch()\n",
    "                    \n",
    "\n",
    "                valid_accuracy = sess.run(net.tf_accuracy, #net.summary_op \n",
    "                                                      feed_dict={net.x: x_valid, \n",
    "                                                                 net.y_: y_valid, \n",
    "                                                                 net.keep_prob:1})\n",
    "                #summary_writer_valid.add_summary(summary_str, epoch)\n",
    "\n",
    "                \n",
    "                accuracy, pred_value, actual_value, y_pred = sess.run([net.tf_accuracy, \n",
    "                                                               net.pred, \n",
    "                                                               net.actual, net.y], \n",
    "                                                              feed_dict={net.x: preprocess.x_test, \n",
    "                                                                         net.y_: preprocess.y_test, \n",
    "                                                                         net.keep_prob:1})\n",
    "\n",
    "                print(\"Step {} | Training Loss: {:.6f} | Validation Accuracy: {:.6f}\".format(epoch, train_loss, valid_accuracy))\n",
    "                print(\"Accuracy on Test data: {}\".format(accuracy))\n",
    "\n",
    "                if accuracy > Train.best_acc_global:\n",
    "                    Train.best_acc_global = accuracy\n",
    "                    Train.pred_value = pred_value\n",
    "                    Train.actual_value = actual_value\n",
    "                    Train.best_parameters = \"Hidden Layers:{}, Features Count:{}\".format(h, f)\n",
    "\n",
    "                if accuracy > Train.best_acc:\n",
    "                    Train.best_acc = accuracy\n",
    "                    \n",
    "                    if not (np.isnan(train_loss)):\n",
    "                        net.saver.save(sess, \n",
    "                                   \"dataset/tf_dense_only_nsl_kdd/hidden_layers_{}_features_count_{}\".format(h,f),\n",
    "                                    global_step = epochs)\n",
    "                    curr_pred = pd.DataFrame({\"Attack_prob\":y_pred[:,-2], \"Normal_prob\":y_pred[:, -1], \"Prediction\":pred_value})\n",
    "                    Train.predictions.update({\"{}_{}_{}\".format(epochs,f,h):(curr_pred, \n",
    "                                               Train.result(epochs, f, h,valid_accuracy, accuracy, time.perf_counter() - start_time))})\n",
    "\n",
    "                    #Train.results.append(Train.result(epochs, f, h,valid_accuracy, accuracy))\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-05-31T00:45:27.766049Z",
     "start_time": "2017-05-31T00:35:01.475542Z"
    },
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current Layer Attributes - epochs:20 hidden layers:2 features count:4\n",
      "Step 1 | Training Loss: 0.663410 | Validation Accuracy: 0.696460\n",
      "Accuracy on Test data: 0.7773243188858032\n",
      "Step 2 | Training Loss: 0.661624 | Validation Accuracy: 0.823940\n",
      "Accuracy on Test data: 0.8376951813697815\n",
      "Step 3 | Training Loss: 0.648470 | Validation Accuracy: 0.835371\n",
      "Accuracy on Test data: 0.8266057372093201\n",
      "Step 4 | Training Loss: 0.641668 | Validation Accuracy: 0.848150\n",
      "Accuracy on Test data: 0.8240330219268799\n",
      "Step 5 | Training Loss: 0.638921 | Validation Accuracy: 0.864344\n",
      "Accuracy on Test data: 0.8204400539398193\n",
      "Step 6 | Training Loss: 0.631525 | Validation Accuracy: 0.881648\n",
      "Accuracy on Test data: 0.8215933442115784\n",
      "Step 7 | Training Loss: 0.635580 | Validation Accuracy: 0.896888\n",
      "Accuracy on Test data: 0.820262610912323\n",
      "Step 8 | Training Loss: 0.620816 | Validation Accuracy: 0.913161\n",
      "Accuracy on Test data: 0.8203513026237488\n",
      "Step 9 | Training Loss: 0.610219 | Validation Accuracy: 0.919035\n",
      "Accuracy on Test data: 0.8196859359741211\n",
      "Step 10 | Training Loss: 0.606855 | Validation Accuracy: 0.933005\n",
      "Accuracy on Test data: 0.8309971690177917\n",
      "Step 11 | Training Loss: 0.596579 | Validation Accuracy: 0.943007\n",
      "Accuracy on Test data: 0.8453690409660339\n",
      "Step 12 | Training Loss: 0.570848 | Validation Accuracy: 0.942769\n",
      "Accuracy on Test data: 0.8428406715393066\n",
      "Step 13 | Training Loss: 0.549260 | Validation Accuracy: 0.950071\n",
      "Accuracy on Test data: 0.8408002257347107\n",
      "Step 14 | Training Loss: 0.551201 | Validation Accuracy: 0.950389\n",
      "Accuracy on Test data: 0.8369854688644409\n",
      "Step 15 | Training Loss: 0.537496 | Validation Accuracy: 0.946103\n",
      "Accuracy on Test data: 0.8329045176506042\n",
      "Step 16 | Training Loss: 0.532359 | Validation Accuracy: 0.952294\n",
      "Accuracy on Test data: 0.8296664357185364\n",
      "Step 17 | Training Loss: 0.520304 | Validation Accuracy: 0.954675\n",
      "Accuracy on Test data: 0.8273598551750183\n",
      "Step 18 | Training Loss: 0.511969 | Validation Accuracy: 0.956977\n",
      "Accuracy on Test data: 0.8227909803390503\n",
      "Step 19 | Training Loss: 0.506777 | Validation Accuracy: 0.959041\n",
      "Accuracy on Test data: 0.8206174373626709\n",
      "Step 20 | Training Loss: 0.518148 | Validation Accuracy: 0.957374\n",
      "Accuracy on Test data: 0.8173350095748901\n",
      "Current Layer Attributes - epochs:20 hidden layers:2 features count:8\n",
      "Step 1 | Training Loss: 0.676237 | Validation Accuracy: 0.690665\n",
      "Accuracy on Test data: 0.752040445804596\n",
      "Step 2 | Training Loss: 0.650823 | Validation Accuracy: 0.812669\n",
      "Accuracy on Test data: 0.8548616170883179\n",
      "Step 3 | Training Loss: 0.631384 | Validation Accuracy: 0.830211\n",
      "Accuracy on Test data: 0.8578335642814636\n",
      "Step 4 | Training Loss: 0.604308 | Validation Accuracy: 0.841800\n",
      "Accuracy on Test data: 0.8614708781242371\n",
      "Step 5 | Training Loss: 0.587198 | Validation Accuracy: 0.870218\n",
      "Accuracy on Test data: 0.8708303570747375\n",
      "Step 6 | Training Loss: 0.550313 | Validation Accuracy: 0.884426\n",
      "Accuracy on Test data: 0.8757097125053406\n",
      "Step 7 | Training Loss: 0.548728 | Validation Accuracy: 0.901095\n",
      "Accuracy on Test data: 0.8799237012863159\n",
      "Step 8 | Training Loss: 0.530177 | Validation Accuracy: 0.909113\n",
      "Accuracy on Test data: 0.880189836025238\n",
      "Step 9 | Training Loss: 0.550194 | Validation Accuracy: 0.905382\n",
      "Accuracy on Test data: 0.8812544345855713\n",
      "Step 10 | Training Loss: 0.511557 | Validation Accuracy: 0.915701\n",
      "Accuracy on Test data: 0.8702980875968933\n",
      "Step 11 | Training Loss: 0.521685 | Validation Accuracy: 0.916098\n",
      "Accuracy on Test data: 0.8671930432319641\n",
      "Step 12 | Training Loss: 0.505091 | Validation Accuracy: 0.919273\n",
      "Accuracy on Test data: 0.8678584098815918\n",
      "Step 13 | Training Loss: 0.500709 | Validation Accuracy: 0.921972\n",
      "Accuracy on Test data: 0.8684794306755066\n",
      "Step 14 | Training Loss: 0.486474 | Validation Accuracy: 0.927052\n",
      "Accuracy on Test data: 0.8687899112701416\n",
      "Step 15 | Training Loss: 0.485319 | Validation Accuracy: 0.929513\n",
      "Accuracy on Test data: 0.8656405210494995\n",
      "Step 16 | Training Loss: 0.471713 | Validation Accuracy: 0.932132\n",
      "Accuracy on Test data: 0.865773618221283\n",
      "Step 17 | Training Loss: 0.471900 | Validation Accuracy: 0.936498\n",
      "Accuracy on Test data: 0.8659954071044922\n",
      "Step 18 | Training Loss: 0.477098 | Validation Accuracy: 0.943880\n",
      "Accuracy on Test data: 0.8655961751937866\n",
      "Step 19 | Training Loss: 0.464195 | Validation Accuracy: 0.942927\n",
      "Accuracy on Test data: 0.8620032072067261\n",
      "Step 20 | Training Loss: 0.461200 | Validation Accuracy: 0.950468\n",
      "Accuracy on Test data: 0.8581440448760986\n",
      "Current Layer Attributes - epochs:20 hidden layers:2 features count:32\n",
      "Step 1 | Training Loss: 0.633035 | Validation Accuracy: 0.771313\n",
      "Accuracy on Test data: 0.6057487726211548\n",
      "Step 2 | Training Loss: 0.609447 | Validation Accuracy: 0.873075\n",
      "Accuracy on Test data: 0.7281316518783569\n",
      "Step 3 | Training Loss: 0.572744 | Validation Accuracy: 0.927290\n",
      "Accuracy on Test data: 0.7538591027259827\n",
      "Step 4 | Training Loss: 0.534767 | Validation Accuracy: 0.931894\n",
      "Accuracy on Test data: 0.7652590274810791\n",
      "Step 5 | Training Loss: 0.518815 | Validation Accuracy: 0.941578\n",
      "Accuracy on Test data: 0.7823367714881897\n",
      "Step 6 | Training Loss: 0.494927 | Validation Accuracy: 0.946579\n",
      "Accuracy on Test data: 0.7839779853820801\n",
      "Step 7 | Training Loss: 0.480089 | Validation Accuracy: 0.945309\n",
      "Accuracy on Test data: 0.7857966423034668\n",
      "Step 8 | Training Loss: 0.467299 | Validation Accuracy: 0.949119\n",
      "Accuracy on Test data: 0.7869055867195129\n",
      "Step 9 | Training Loss: 0.437375 | Validation Accuracy: 0.950389\n",
      "Accuracy on Test data: 0.7877040505409241\n",
      "Step 10 | Training Loss: 0.434450 | Validation Accuracy: 0.951818\n",
      "Accuracy on Test data: 0.7881919741630554\n",
      "Step 11 | Training Loss: 0.430218 | Validation Accuracy: 0.956342\n",
      "Accuracy on Test data: 0.7887686491012573\n",
      "Step 12 | Training Loss: 0.423998 | Validation Accuracy: 0.955469\n",
      "Accuracy on Test data: 0.7819375395774841\n",
      "Step 13 | Training Loss: 0.415360 | Validation Accuracy: 0.957215\n",
      "Accuracy on Test data: 0.7778566479682922\n",
      "Step 14 | Training Loss: 0.394238 | Validation Accuracy: 0.960152\n",
      "Accuracy on Test data: 0.7739975452423096\n",
      "Step 15 | Training Loss: 0.397852 | Validation Accuracy: 0.957374\n",
      "Accuracy on Test data: 0.7699165940284729\n",
      "Step 16 | Training Loss: 0.404238 | Validation Accuracy: 0.960708\n",
      "Accuracy on Test data: 0.7676543593406677\n",
      "Step 17 | Training Loss: 0.382315 | Validation Accuracy: 0.961422\n",
      "Accuracy on Test data: 0.766678512096405\n",
      "Step 18 | Training Loss: 0.381178 | Validation Accuracy: 0.960470\n",
      "Accuracy on Test data: 0.7653921246528625\n",
      "Step 19 | Training Loss: 0.376345 | Validation Accuracy: 0.961184\n",
      "Accuracy on Test data: 0.7639282941818237\n",
      "Step 20 | Training Loss: 0.370136 | Validation Accuracy: 0.964836\n",
      "Accuracy on Test data: 0.762641966342926\n",
      "Current Layer Attributes - epochs:20 hidden layers:2 features count:64\n",
      "Step 1 | Training Loss: 0.675024 | Validation Accuracy: 0.821559\n",
      "Accuracy on Test data: 0.8102821111679077\n",
      "Step 2 | Training Loss: 0.619737 | Validation Accuracy: 0.898635\n",
      "Accuracy on Test data: 0.8459457159042358\n",
      "Step 3 | Training Loss: 0.573276 | Validation Accuracy: 0.915463\n",
      "Accuracy on Test data: 0.8582327961921692\n",
      "Step 4 | Training Loss: 0.543095 | Validation Accuracy: 0.919432\n",
      "Accuracy on Test data: 0.8627572655677795\n",
      "Step 5 | Training Loss: 0.523262 | Validation Accuracy: 0.924909\n",
      "Accuracy on Test data: 0.853087306022644\n",
      "Step 6 | Training Loss: 0.487861 | Validation Accuracy: 0.929433\n",
      "Accuracy on Test data: 0.8446593284606934\n",
      "Step 7 | Training Loss: 0.478453 | Validation Accuracy: 0.927211\n",
      "Accuracy on Test data: 0.8427075743675232\n",
      "Step 8 | Training Loss: 0.459370 | Validation Accuracy: 0.935704\n",
      "Accuracy on Test data: 0.8413768410682678\n",
      "Step 9 | Training Loss: 0.416927 | Validation Accuracy: 0.934831\n",
      "Accuracy on Test data: 0.8407558798789978\n",
      "Step 10 | Training Loss: 0.404714 | Validation Accuracy: 0.947452\n",
      "Accuracy on Test data: 0.8336586356163025\n",
      "Step 11 | Training Loss: 0.419809 | Validation Accuracy: 0.954755\n",
      "Accuracy on Test data: 0.8292672038078308\n",
      "Step 12 | Training Loss: 0.412296 | Validation Accuracy: 0.956739\n",
      "Accuracy on Test data: 0.8226579427719116\n",
      "Step 13 | Training Loss: 0.406383 | Validation Accuracy: 0.959597\n",
      "Accuracy on Test data: 0.8134315013885498\n",
      "Step 14 | Training Loss: 0.398701 | Validation Accuracy: 0.962375\n",
      "Accuracy on Test data: 0.8093949556350708\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 15 | Training Loss: 0.387070 | Validation Accuracy: 0.963169\n",
      "Accuracy on Test data: 0.8036284446716309\n",
      "Step 16 | Training Loss: 0.381044 | Validation Accuracy: 0.967296\n",
      "Accuracy on Test data: 0.7928495407104492\n",
      "Step 17 | Training Loss: 0.382578 | Validation Accuracy: 0.965868\n",
      "Accuracy on Test data: 0.7841110825538635\n",
      "Step 18 | Training Loss: 0.368834 | Validation Accuracy: 0.966661\n",
      "Accuracy on Test data: 0.7803406715393066\n",
      "Step 19 | Training Loss: 0.368596 | Validation Accuracy: 0.966185\n",
      "Accuracy on Test data: 0.7758162021636963\n",
      "Step 20 | Training Loss: 0.381695 | Validation Accuracy: 0.966106\n",
      "Accuracy on Test data: 0.7737313508987427\n",
      "Current Layer Attributes - epochs:20 hidden layers:4 features count:4\n",
      "Step 1 | Training Loss: 0.675782 | Validation Accuracy: 0.466423\n",
      "Accuracy on Test data: 0.5479063391685486\n",
      "Step 2 | Training Loss: 0.677014 | Validation Accuracy: 0.587871\n",
      "Accuracy on Test data: 0.6271735429763794\n",
      "Step 3 | Training Loss: 0.669848 | Validation Accuracy: 0.798857\n",
      "Accuracy on Test data: 0.8169357776641846\n",
      "Step 4 | Training Loss: 0.676850 | Validation Accuracy: 0.850294\n",
      "Accuracy on Test data: 0.8357877731323242\n",
      "Step 5 | Training Loss: 0.676876 | Validation Accuracy: 0.867677\n",
      "Accuracy on Test data: 0.8301543593406677\n",
      "Step 6 | Training Loss: 0.666864 | Validation Accuracy: 0.874028\n",
      "Accuracy on Test data: 0.8196415901184082\n",
      "Step 7 | Training Loss: 0.660230 | Validation Accuracy: 0.878314\n",
      "Accuracy on Test data: 0.806423008441925\n",
      "Step 8 | Training Loss: 0.653415 | Validation Accuracy: 0.890379\n",
      "Accuracy on Test data: 0.8011000752449036\n",
      "Step 9 | Training Loss: 0.647761 | Validation Accuracy: 0.897047\n",
      "Accuracy on Test data: 0.8030074238777161\n",
      "Step 10 | Training Loss: 0.653617 | Validation Accuracy: 0.905937\n",
      "Accuracy on Test data: 0.8074432015419006\n",
      "Step 11 | Training Loss: 0.650242 | Validation Accuracy: 0.911732\n",
      "Accuracy on Test data: 0.8077093958854675\n",
      "Step 12 | Training Loss: 0.641262 | Validation Accuracy: 0.915225\n",
      "Accuracy on Test data: 0.8051809668540955\n",
      "Step 13 | Training Loss: 0.658552 | Validation Accuracy: 0.923480\n",
      "Accuracy on Test data: 0.8039833307266235\n",
      "Step 14 | Training Loss: 0.652955 | Validation Accuracy: 0.916415\n",
      "Accuracy on Test data: 0.8022977113723755\n",
      "Step 15 | Training Loss: 0.645158 | Validation Accuracy: 0.921019\n",
      "Accuracy on Test data: 0.8006121516227722\n",
      "Step 16 | Training Loss: 0.656684 | Validation Accuracy: 0.924591\n",
      "Accuracy on Test data: 0.7980837225914001\n",
      "Step 17 | Training Loss: 0.649354 | Validation Accuracy: 0.925306\n",
      "Accuracy on Test data: 0.7952892184257507\n",
      "Step 18 | Training Loss: 0.638876 | Validation Accuracy: 0.931656\n",
      "Accuracy on Test data: 0.793470561504364\n",
      "Step 19 | Training Loss: 0.642985 | Validation Accuracy: 0.933164\n",
      "Accuracy on Test data: 0.7921398282051086\n",
      "Step 20 | Training Loss: 0.630837 | Validation Accuracy: 0.934117\n",
      "Accuracy on Test data: 0.7893009185791016\n",
      "Current Layer Attributes - epochs:20 hidden layers:4 features count:8\n",
      "Step 1 | Training Loss: 0.714698 | Validation Accuracy: 0.468884\n",
      "Accuracy on Test data: 0.5693311095237732\n",
      "Step 2 | Training Loss: 0.715106 | Validation Accuracy: 0.594221\n",
      "Accuracy on Test data: 0.6835965514183044\n",
      "Step 3 | Training Loss: 0.682287 | Validation Accuracy: 0.693126\n",
      "Accuracy on Test data: 0.7473385334014893\n",
      "Step 4 | Training Loss: 0.676185 | Validation Accuracy: 0.806001\n",
      "Accuracy on Test data: 0.8449698090553284\n",
      "Step 5 | Training Loss: 0.660362 | Validation Accuracy: 0.837831\n",
      "Accuracy on Test data: 0.8690560460090637\n",
      "Step 6 | Training Loss: 0.662361 | Validation Accuracy: 0.853707\n",
      "Accuracy on Test data: 0.8797019124031067\n",
      "Step 7 | Training Loss: 0.644314 | Validation Accuracy: 0.861803\n",
      "Accuracy on Test data: 0.8853353261947632\n",
      "Step 8 | Training Loss: 0.647476 | Validation Accuracy: 0.869027\n",
      "Accuracy on Test data: 0.8858232498168945\n",
      "Step 9 | Training Loss: 0.650424 | Validation Accuracy: 0.876568\n",
      "Accuracy on Test data: 0.8773953318595886\n",
      "Step 10 | Training Loss: 0.638316 | Validation Accuracy: 0.898476\n",
      "Accuracy on Test data: 0.8789478540420532\n",
      "Step 11 | Training Loss: 0.628807 | Validation Accuracy: 0.903953\n",
      "Accuracy on Test data: 0.8754879236221313\n",
      "Step 12 | Training Loss: 0.628743 | Validation Accuracy: 0.909033\n",
      "Accuracy on Test data: 0.868923008441925\n",
      "Step 13 | Training Loss: 0.635774 | Validation Accuracy: 0.912764\n",
      "Accuracy on Test data: 0.8656405210494995\n",
      "Step 14 | Training Loss: 0.619805 | Validation Accuracy: 0.914669\n",
      "Accuracy on Test data: 0.8598296642303467\n",
      "Step 15 | Training Loss: 0.620362 | Validation Accuracy: 0.915383\n",
      "Accuracy on Test data: 0.8571681976318359\n",
      "Step 16 | Training Loss: 0.607293 | Validation Accuracy: 0.916971\n",
      "Accuracy on Test data: 0.8557931184768677\n",
      "Step 17 | Training Loss: 0.621469 | Validation Accuracy: 0.917606\n",
      "Accuracy on Test data: 0.854817271232605\n",
      "Step 18 | Training Loss: 0.616798 | Validation Accuracy: 0.921813\n",
      "Accuracy on Test data: 0.8525993824005127\n",
      "Step 19 | Training Loss: 0.602739 | Validation Accuracy: 0.920146\n",
      "Accuracy on Test data: 0.8487846255302429\n",
      "Step 20 | Training Loss: 0.612469 | Validation Accuracy: 0.922607\n",
      "Accuracy on Test data: 0.8435947299003601\n",
      "Current Layer Attributes - epochs:20 hidden layers:4 features count:32\n",
      "Step 1 | Training Loss: 0.712758 | Validation Accuracy: 0.705191\n",
      "Accuracy on Test data: 0.8085965514183044\n",
      "Step 2 | Training Loss: 0.692542 | Validation Accuracy: 0.761629\n",
      "Accuracy on Test data: 0.838981568813324\n",
      "Step 3 | Training Loss: 0.686735 | Validation Accuracy: 0.811716\n",
      "Accuracy on Test data: 0.8636444211006165\n",
      "Step 4 | Training Loss: 0.664369 | Validation Accuracy: 0.840133\n",
      "Accuracy on Test data: 0.8793914318084717\n",
      "Step 5 | Training Loss: 0.671826 | Validation Accuracy: 0.871249\n",
      "Accuracy on Test data: 0.8914123773574829\n",
      "Step 6 | Training Loss: 0.657363 | Validation Accuracy: 0.892046\n",
      "Accuracy on Test data: 0.8979329466819763\n",
      "Step 7 | Training Loss: 0.636290 | Validation Accuracy: 0.906652\n",
      "Accuracy on Test data: 0.8942512273788452\n",
      "Step 8 | Training Loss: 0.609326 | Validation Accuracy: 0.915860\n",
      "Accuracy on Test data: 0.8897267580032349\n",
      "Step 9 | Training Loss: 0.617989 | Validation Accuracy: 0.926973\n",
      "Accuracy on Test data: 0.8732256889343262\n",
      "Step 10 | Training Loss: 0.588251 | Validation Accuracy: 0.928639\n",
      "Accuracy on Test data: 0.8647977113723755\n",
      "Step 11 | Training Loss: 0.569031 | Validation Accuracy: 0.939832\n",
      "Accuracy on Test data: 0.8616926670074463\n",
      "Step 12 | Training Loss: 0.558439 | Validation Accuracy: 0.941975\n",
      "Accuracy on Test data: 0.8603619337081909\n",
      "Step 13 | Training Loss: 0.570000 | Validation Accuracy: 0.942451\n",
      "Accuracy on Test data: 0.8581884503364563\n",
      "Step 14 | Training Loss: 0.556164 | Validation Accuracy: 0.944118\n",
      "Accuracy on Test data: 0.8556600213050842\n",
      "Step 15 | Training Loss: 0.559291 | Validation Accuracy: 0.949913\n",
      "Accuracy on Test data: 0.8531316518783569\n",
      "Step 16 | Training Loss: 0.520005 | Validation Accuracy: 0.953167\n",
      "Accuracy on Test data: 0.8491394519805908\n",
      "Step 17 | Training Loss: 0.515203 | Validation Accuracy: 0.951818\n",
      "Accuracy on Test data: 0.8459457159042358\n",
      "Step 18 | Training Loss: 0.489769 | Validation Accuracy: 0.953247\n",
      "Accuracy on Test data: 0.8425745368003845\n",
      "Step 19 | Training Loss: 0.500702 | Validation Accuracy: 0.953008\n",
      "Accuracy on Test data: 0.8402678966522217\n",
      "Step 20 | Training Loss: 0.482854 | Validation Accuracy: 0.953723\n",
      "Accuracy on Test data: 0.8395581841468811\n",
      "Current Layer Attributes - epochs:20 hidden layers:4 features count:64\n",
      "Step 1 | Training Loss: 0.724805 | Validation Accuracy: 0.614939\n",
      "Accuracy on Test data: 0.461408793926239\n",
      "Step 2 | Training Loss: 0.720065 | Validation Accuracy: 0.676060\n",
      "Accuracy on Test data: 0.4736515283584595\n",
      "Step 3 | Training Loss: 0.674624 | Validation Accuracy: 0.748770\n",
      "Accuracy on Test data: 0.5989176630973816\n",
      "Step 4 | Training Loss: 0.687041 | Validation Accuracy: 0.846880\n",
      "Accuracy on Test data: 0.7097232341766357\n",
      "Step 5 | Training Loss: 0.649572 | Validation Accuracy: 0.896730\n",
      "Accuracy on Test data: 0.7755500078201294\n",
      "Step 6 | Training Loss: 0.625903 | Validation Accuracy: 0.933164\n",
      "Accuracy on Test data: 0.7984829545021057\n",
      "Step 7 | Training Loss: 0.585498 | Validation Accuracy: 0.936974\n",
      "Accuracy on Test data: 0.8109918236732483\n",
      "Step 8 | Training Loss: 0.548753 | Validation Accuracy: 0.940467\n",
      "Accuracy on Test data: 0.8157381415367126\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 9 | Training Loss: 0.525209 | Validation Accuracy: 0.944991\n",
      "Accuracy on Test data: 0.8164034485816956\n",
      "Step 10 | Training Loss: 0.497437 | Validation Accuracy: 0.948166\n",
      "Accuracy on Test data: 0.8171575665473938\n",
      "Step 11 | Training Loss: 0.467538 | Validation Accuracy: 0.951897\n",
      "Accuracy on Test data: 0.8167583346366882\n",
      "Step 12 | Training Loss: 0.457477 | Validation Accuracy: 0.951976\n",
      "Accuracy on Test data: 0.8168026804924011\n",
      "Step 13 | Training Loss: 0.457929 | Validation Accuracy: 0.955866\n",
      "Accuracy on Test data: 0.8162704110145569\n",
      "Step 14 | Training Loss: 0.446968 | Validation Accuracy: 0.956898\n",
      "Accuracy on Test data: 0.815693736076355\n",
      "Step 15 | Training Loss: 0.418268 | Validation Accuracy: 0.958089\n",
      "Accuracy on Test data: 0.8140968680381775\n",
      "Step 16 | Training Loss: 0.433654 | Validation Accuracy: 0.962772\n",
      "Accuracy on Test data: 0.8129435777664185\n",
      "Step 17 | Training Loss: 0.416211 | Validation Accuracy: 0.960787\n",
      "Accuracy on Test data: 0.8115241527557373\n",
      "Step 18 | Training Loss: 0.402026 | Validation Accuracy: 0.962772\n",
      "Accuracy on Test data: 0.8102821111679077\n",
      "Step 19 | Training Loss: 0.387475 | Validation Accuracy: 0.966344\n",
      "Accuracy on Test data: 0.8094393014907837\n",
      "Step 20 | Training Loss: 0.386661 | Validation Accuracy: 0.968487\n",
      "Accuracy on Test data: 0.8091288208961487\n",
      "Current Layer Attributes - epochs:20 hidden layers:6 features count:4\n",
      "Step 1 | Training Loss: 0.688856 | Validation Accuracy: 0.529846\n",
      "Accuracy on Test data: 0.43075764179229736\n",
      "Step 2 | Training Loss: 0.685390 | Validation Accuracy: 0.534926\n",
      "Accuracy on Test data: 0.43075764179229736\n",
      "Step 3 | Training Loss: 0.688772 | Validation Accuracy: 0.531989\n",
      "Accuracy on Test data: 0.43075764179229736\n",
      "Step 4 | Training Loss: 0.685721 | Validation Accuracy: 0.531989\n",
      "Accuracy on Test data: 0.43075764179229736\n",
      "Step 5 | Training Loss: 0.687415 | Validation Accuracy: 0.535720\n",
      "Accuracy on Test data: 0.43075764179229736\n",
      "Step 6 | Training Loss: 0.686172 | Validation Accuracy: 0.535006\n",
      "Accuracy on Test data: 0.43075764179229736\n",
      "Step 7 | Training Loss: 0.686554 | Validation Accuracy: 0.542229\n",
      "Accuracy on Test data: 0.43075764179229736\n",
      "Step 8 | Training Loss: 0.682080 | Validation Accuracy: 0.525401\n",
      "Accuracy on Test data: 0.43075764179229736\n",
      "Step 9 | Training Loss: 0.688917 | Validation Accuracy: 0.529528\n",
      "Accuracy on Test data: 0.43075764179229736\n",
      "Step 10 | Training Loss: 0.683327 | Validation Accuracy: 0.530005\n",
      "Accuracy on Test data: 0.43075764179229736\n",
      "Step 11 | Training Loss: 0.682924 | Validation Accuracy: 0.541038\n",
      "Accuracy on Test data: 0.43075764179229736\n",
      "Step 12 | Training Loss: 0.686806 | Validation Accuracy: 0.531672\n",
      "Accuracy on Test data: 0.43075764179229736\n",
      "Step 13 | Training Loss: 0.680339 | Validation Accuracy: 0.531830\n",
      "Accuracy on Test data: 0.43075764179229736\n",
      "Step 14 | Training Loss: 0.679881 | Validation Accuracy: 0.540800\n",
      "Accuracy on Test data: 0.43075764179229736\n",
      "Step 15 | Training Loss: 0.679555 | Validation Accuracy: 0.537784\n",
      "Accuracy on Test data: 0.43075764179229736\n",
      "Step 16 | Training Loss: 0.677603 | Validation Accuracy: 0.533259\n",
      "Accuracy on Test data: 0.43075764179229736\n",
      "Step 17 | Training Loss: 0.680360 | Validation Accuracy: 0.531989\n",
      "Accuracy on Test data: 0.43075764179229736\n",
      "Step 18 | Training Loss: 0.676395 | Validation Accuracy: 0.536831\n",
      "Accuracy on Test data: 0.43075764179229736\n",
      "Step 19 | Training Loss: 0.677244 | Validation Accuracy: 0.535164\n",
      "Accuracy on Test data: 0.43075764179229736\n",
      "Step 20 | Training Loss: 0.683439 | Validation Accuracy: 0.545960\n",
      "Accuracy on Test data: 0.4309794306755066\n",
      "Current Layer Attributes - epochs:20 hidden layers:6 features count:8\n",
      "Step 1 | Training Loss: 0.692747 | Validation Accuracy: 0.447055\n",
      "Accuracy on Test data: 0.35778921842575073\n",
      "Step 2 | Training Loss: 0.687479 | Validation Accuracy: 0.546912\n",
      "Accuracy on Test data: 0.472054660320282\n",
      "Step 3 | Training Loss: 0.688641 | Validation Accuracy: 0.583664\n",
      "Accuracy on Test data: 0.5165454149246216\n",
      "Step 4 | Training Loss: 0.685111 | Validation Accuracy: 0.581442\n",
      "Accuracy on Test data: 0.4885113537311554\n",
      "Step 5 | Training Loss: 0.692069 | Validation Accuracy: 0.601603\n",
      "Accuracy on Test data: 0.48589426279067993\n",
      "Step 6 | Training Loss: 0.688393 | Validation Accuracy: 0.604620\n",
      "Accuracy on Test data: 0.4894872307777405\n",
      "Step 7 | Training Loss: 0.691908 | Validation Accuracy: 0.622639\n",
      "Accuracy on Test data: 0.4916163980960846\n",
      "Step 8 | Training Loss: 0.671737 | Validation Accuracy: 0.632164\n",
      "Accuracy on Test data: 0.5035486221313477\n",
      "Step 9 | Training Loss: 0.679452 | Validation Accuracy: 0.649627\n",
      "Accuracy on Test data: 0.5122870802879333\n",
      "Step 10 | Training Loss: 0.668687 | Validation Accuracy: 0.656771\n",
      "Accuracy on Test data: 0.5173882246017456\n",
      "Step 11 | Training Loss: 0.679612 | Validation Accuracy: 0.679076\n",
      "Accuracy on Test data: 0.537437915802002\n",
      "Step 12 | Training Loss: 0.670981 | Validation Accuracy: 0.697254\n",
      "Accuracy on Test data: 0.5498136878013611\n",
      "Step 13 | Training Loss: 0.668245 | Validation Accuracy: 0.750278\n",
      "Accuracy on Test data: 0.5868523716926575\n",
      "Step 14 | Training Loss: 0.664908 | Validation Accuracy: 0.822511\n",
      "Accuracy on Test data: 0.6096965670585632\n",
      "Step 15 | Training Loss: 0.667072 | Validation Accuracy: 0.831481\n",
      "Accuracy on Test data: 0.6230039000511169\n",
      "Step 16 | Training Loss: 0.657779 | Validation Accuracy: 0.844817\n",
      "Accuracy on Test data: 0.6352022886276245\n",
      "Step 17 | Training Loss: 0.651432 | Validation Accuracy: 0.853628\n",
      "Accuracy on Test data: 0.645715057849884\n",
      "Step 18 | Training Loss: 0.651498 | Validation Accuracy: 0.859740\n",
      "Accuracy on Test data: 0.6520138382911682\n",
      "Step 19 | Training Loss: 0.647221 | Validation Accuracy: 0.862438\n",
      "Accuracy on Test data: 0.6572480201721191\n",
      "Step 20 | Training Loss: 0.658487 | Validation Accuracy: 0.870773\n",
      "Accuracy on Test data: 0.6686035990715027\n",
      "Current Layer Attributes - epochs:20 hidden layers:6 features count:32\n",
      "Step 1 | Training Loss: 0.698169 | Validation Accuracy: 0.537546\n",
      "Accuracy on Test data: 0.4539123475551605\n",
      "Step 2 | Training Loss: 0.702659 | Validation Accuracy: 0.585093\n",
      "Accuracy on Test data: 0.5317157506942749\n",
      "Step 3 | Training Loss: 0.689324 | Validation Accuracy: 0.640816\n",
      "Accuracy on Test data: 0.5736337900161743\n",
      "Step 4 | Training Loss: 0.679286 | Validation Accuracy: 0.748690\n",
      "Accuracy on Test data: 0.626685619354248\n",
      "Step 5 | Training Loss: 0.694335 | Validation Accuracy: 0.783775\n",
      "Accuracy on Test data: 0.6461142897605896\n",
      "Step 6 | Training Loss: 0.662961 | Validation Accuracy: 0.815685\n",
      "Accuracy on Test data: 0.6813786625862122\n",
      "Step 7 | Training Loss: 0.652676 | Validation Accuracy: 0.841562\n",
      "Accuracy on Test data: 0.6949964761734009\n",
      "Step 8 | Training Loss: 0.636920 | Validation Accuracy: 0.865852\n",
      "Accuracy on Test data: 0.7221876978874207\n",
      "Step 9 | Training Loss: 0.641161 | Validation Accuracy: 0.886966\n",
      "Accuracy on Test data: 0.7713360786437988\n",
      "Step 10 | Training Loss: 0.630132 | Validation Accuracy: 0.897523\n",
      "Accuracy on Test data: 0.7841554284095764\n",
      "Step 11 | Training Loss: 0.617563 | Validation Accuracy: 0.911176\n",
      "Accuracy on Test data: 0.7885024547576904\n",
      "Step 12 | Training Loss: 0.627620 | Validation Accuracy: 0.921654\n",
      "Accuracy on Test data: 0.7951561212539673\n",
      "Step 13 | Training Loss: 0.617746 | Validation Accuracy: 0.928163\n",
      "Accuracy on Test data: 0.8144960999488831\n",
      "Step 14 | Training Loss: 0.600141 | Validation Accuracy: 0.934831\n",
      "Accuracy on Test data: 0.8194641470909119\n",
      "Step 15 | Training Loss: 0.597292 | Validation Accuracy: 0.938562\n",
      "Accuracy on Test data: 0.8258516788482666\n",
      "Step 16 | Training Loss: 0.577696 | Validation Accuracy: 0.940229\n",
      "Accuracy on Test data: 0.8272267580032349\n",
      "Step 17 | Training Loss: 0.585011 | Validation Accuracy: 0.940625\n",
      "Accuracy on Test data: 0.828025221824646\n",
      "Step 18 | Training Loss: 0.587456 | Validation Accuracy: 0.941181\n",
      "Accuracy on Test data: 0.8287349343299866\n",
      "Step 19 | Training Loss: 0.566966 | Validation Accuracy: 0.945309\n",
      "Accuracy on Test data: 0.8297551274299622\n",
      "Step 20 | Training Loss: 0.571830 | Validation Accuracy: 0.944753\n",
      "Accuracy on Test data: 0.8297107815742493\n",
      "Current Layer Attributes - epochs:20 hidden layers:6 features count:64\n",
      "Step 1 | Training Loss: 0.718032 | Validation Accuracy: 0.724083\n",
      "Accuracy on Test data: 0.7330996990203857\n",
      "Step 2 | Training Loss: 0.698232 | Validation Accuracy: 0.763454\n",
      "Accuracy on Test data: 0.8078424334526062\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 3 | Training Loss: 0.689343 | Validation Accuracy: 0.792427\n",
      "Accuracy on Test data: 0.8211941123008728\n",
      "Step 4 | Training Loss: 0.707720 | Validation Accuracy: 0.820686\n",
      "Accuracy on Test data: 0.8281582593917847\n",
      "Step 5 | Training Loss: 0.679009 | Validation Accuracy: 0.843070\n",
      "Accuracy on Test data: 0.8416873812675476\n",
      "Step 6 | Training Loss: 0.669693 | Validation Accuracy: 0.853548\n",
      "Accuracy on Test data: 0.8496717810630798\n",
      "Step 7 | Training Loss: 0.641692 | Validation Accuracy: 0.882918\n",
      "Accuracy on Test data: 0.8736249208450317\n",
      "Step 8 | Training Loss: 0.636748 | Validation Accuracy: 0.901334\n",
      "Accuracy on Test data: 0.8810326457023621\n",
      "Step 9 | Training Loss: 0.623175 | Validation Accuracy: 0.906096\n",
      "Accuracy on Test data: 0.8808995485305786\n",
      "Step 10 | Training Loss: 0.625877 | Validation Accuracy: 0.918638\n",
      "Accuracy on Test data: 0.8755766749382019\n",
      "Step 11 | Training Loss: 0.606653 | Validation Accuracy: 0.928719\n",
      "Accuracy on Test data: 0.8745120763778687\n",
      "Step 12 | Training Loss: 0.625711 | Validation Accuracy: 0.932688\n",
      "Accuracy on Test data: 0.8734031319618225\n",
      "Step 13 | Training Loss: 0.580455 | Validation Accuracy: 0.934434\n",
      "Accuracy on Test data: 0.8679471015930176\n",
      "Step 14 | Training Loss: 0.558955 | Validation Accuracy: 0.939435\n",
      "Accuracy on Test data: 0.8643985390663147\n",
      "Step 15 | Training Loss: 0.574197 | Validation Accuracy: 0.938720\n",
      "Accuracy on Test data: 0.8615596294403076\n",
      "Step 16 | Training Loss: 0.567613 | Validation Accuracy: 0.938641\n",
      "Accuracy on Test data: 0.8589868545532227\n",
      "Step 17 | Training Loss: 0.545844 | Validation Accuracy: 0.937609\n",
      "Accuracy on Test data: 0.8529542088508606\n",
      "Step 18 | Training Loss: 0.540073 | Validation Accuracy: 0.936022\n",
      "Accuracy on Test data: 0.8338804244995117\n",
      "Step 19 | Training Loss: 0.511364 | Validation Accuracy: 0.939355\n",
      "Accuracy on Test data: 0.8296664357185364\n",
      "Step 20 | Training Loss: 0.509388 | Validation Accuracy: 0.942848\n",
      "Accuracy on Test data: 0.8258073329925537\n"
     ]
    }
   ],
   "source": [
    "import itertools\n",
    "class Hyperparameters:\n",
    "#    features_arr = [2, 4, 8, 16, 32, 64, 128, 256]\n",
    "#    hidden_layers_arr = [2, 4, 6, 10]\n",
    "    features_arr = [4, 8, 32, 64]\n",
    "    hidden_layers_arr = [2, 4, 6]\n",
    "\n",
    "    epochs = [20]\n",
    "    \n",
    "    for e, h, f in itertools.product(epochs, hidden_layers_arr, features_arr):\n",
    "        print(\"Current Layer Attributes - epochs:{} hidden layers:{} features count:{}\".format(e,h,f))\n",
    "        n = network(2,h,f)\n",
    "        n.build_layers()\n",
    "        Train.train(e, n, h,f)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-05-31T00:45:27.775959Z",
     "start_time": "2017-05-31T00:45:27.768661Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dict1 = {}\n",
    "dict2 = []\n",
    "for k, (v1, v2) in Train.predictions.items():\n",
    "    dict1.update({k: v1})\n",
    "    dict2.append(v2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-05-31T00:45:27.784643Z",
     "start_time": "2017-05-31T00:45:27.778047Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Train.predictions = dict1\n",
    "Train.results = dict2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-05-31T00:45:27.797137Z",
     "start_time": "2017-05-31T00:45:27.791234Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_results = pd.DataFrame(Train.results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-05-31T00:45:27.825000Z",
     "start_time": "2017-05-31T00:45:27.799731Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>epoch</th>\n",
       "      <th>no_of_features</th>\n",
       "      <th>hidden_layers</th>\n",
       "      <th>train_score</th>\n",
       "      <th>test_score</th>\n",
       "      <th>time_taken</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>20</td>\n",
       "      <td>32</td>\n",
       "      <td>4</td>\n",
       "      <td>0.892046</td>\n",
       "      <td>0.897933</td>\n",
       "      <td>19.431615</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>20</td>\n",
       "      <td>8</td>\n",
       "      <td>4</td>\n",
       "      <td>0.869027</td>\n",
       "      <td>0.885823</td>\n",
       "      <td>22.556436</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>20</td>\n",
       "      <td>8</td>\n",
       "      <td>2</td>\n",
       "      <td>0.905382</td>\n",
       "      <td>0.881254</td>\n",
       "      <td>17.043705</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>20</td>\n",
       "      <td>64</td>\n",
       "      <td>6</td>\n",
       "      <td>0.901334</td>\n",
       "      <td>0.881033</td>\n",
       "      <td>39.989143</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>20</td>\n",
       "      <td>64</td>\n",
       "      <td>2</td>\n",
       "      <td>0.919432</td>\n",
       "      <td>0.862757</td>\n",
       "      <td>8.935693</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>20</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>0.943007</td>\n",
       "      <td>0.845369</td>\n",
       "      <td>16.299912</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>20</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>0.850294</td>\n",
       "      <td>0.835788</td>\n",
       "      <td>9.173420</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>20</td>\n",
       "      <td>32</td>\n",
       "      <td>6</td>\n",
       "      <td>0.945309</td>\n",
       "      <td>0.829755</td>\n",
       "      <td>78.154274</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>20</td>\n",
       "      <td>64</td>\n",
       "      <td>4</td>\n",
       "      <td>0.948166</td>\n",
       "      <td>0.817158</td>\n",
       "      <td>39.293368</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>20</td>\n",
       "      <td>32</td>\n",
       "      <td>2</td>\n",
       "      <td>0.956342</td>\n",
       "      <td>0.788769</td>\n",
       "      <td>21.211315</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>20</td>\n",
       "      <td>8</td>\n",
       "      <td>6</td>\n",
       "      <td>0.870773</td>\n",
       "      <td>0.668604</td>\n",
       "      <td>58.356642</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>20</td>\n",
       "      <td>4</td>\n",
       "      <td>6</td>\n",
       "      <td>0.545960</td>\n",
       "      <td>0.430979</td>\n",
       "      <td>41.594095</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    epoch  no_of_features  hidden_layers  train_score  test_score  time_taken\n",
       "6      20              32              4     0.892046    0.897933   19.431615\n",
       "5      20               8              4     0.869027    0.885823   22.556436\n",
       "1      20               8              2     0.905382    0.881254   17.043705\n",
       "11     20              64              6     0.901334    0.881033   39.989143\n",
       "3      20              64              2     0.919432    0.862757    8.935693\n",
       "0      20               4              2     0.943007    0.845369   16.299912\n",
       "4      20               4              4     0.850294    0.835788    9.173420\n",
       "10     20              32              6     0.945309    0.829755   78.154274\n",
       "7      20              64              4     0.948166    0.817158   39.293368\n",
       "2      20              32              2     0.956342    0.788769   21.211315\n",
       "9      20               8              6     0.870773    0.668604   58.356642\n",
       "8      20               4              6     0.545960    0.430979   41.594095"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_results.sort_values(by = 'test_score', ascending = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-05-31T00:45:27.849107Z",
     "start_time": "2017-05-31T00:45:27.828933Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pd.Panel(Train.predictions).to_pickle(\"dataset/tf_dense_only_nsl_kdd_predictions.pkl\")\n",
    "df_results.to_pickle(\"dataset/tf_dense_only_nsl_kdd_scores.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-05-31T00:45:27.954957Z",
     "start_time": "2017-05-31T00:45:27.853363Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import itertools\n",
    "\n",
    "def plot_confusion_matrix(cm, classes,\n",
    "                          normalize=False,\n",
    "                          title='Confusion matrix',\n",
    "                          cmap=plt.cm.Blues):\n",
    "    \"\"\"\n",
    "    This function prints and plots the confusion matrix.\n",
    "    Normalization can be applied by setting `normalize=True`.\n",
    "    \"\"\"\n",
    "    np.set_printoptions(precision=4)\n",
    "\n",
    "    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n",
    "    plt.title(title)\n",
    "    plt.colorbar()\n",
    "    tick_marks = np.arange(len(classes))\n",
    "    plt.xticks(tick_marks, classes, rotation=45)\n",
    "    plt.yticks(tick_marks, classes)\n",
    "\n",
    "    if normalize:\n",
    "        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "        print(\"Normalized confusion matrix\")\n",
    "    else:\n",
    "        print('Confusion matrix, without normalization')\n",
    "\n",
    "    print(cm)\n",
    "\n",
    "    thresh = cm.max() / 2.\n",
    "    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
    "        plt.text(j, i, cm[i, j].round(4),\n",
    "                 horizontalalignment=\"center\",\n",
    "                 color=\"white\" if cm[i, j] > thresh else \"black\")\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.ylabel('True label')\n",
    "    plt.xlabel('Predicted label')\n",
    "\n",
    "def plot(actual_value, pred_value):\n",
    "    from sklearn.metrics import confusion_matrix\n",
    "    cm_2labels = confusion_matrix(y_pred = pred_value, y_true = actual_value)\n",
    "    plt.figure(figsize=[6,6])\n",
    "    plot_confusion_matrix(cm_2labels, preprocess.output_columns_2labels, normalize = True,\n",
    "                         title = Train.best_parameters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-05-31T00:45:28.449288Z",
     "start_time": "2017-05-31T00:45:27.959529Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Normalized confusion matrix\n",
      "[[ 0.9312  0.0688]\n",
      " [ 0.146   0.854 ]]\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAbcAAAGeCAYAAAAXNE8VAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nljbAq4uQRQAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f425d9650b8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot(actual_value = Train.actual_value, pred_value = Train.pred_value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "_draft": {
   "nbviewer_url": "https://gist.github.com/7d1ace18a82178e15ece8fc5252fce88"
  },
  "anaconda-cloud": {},
  "gist": {
   "data": {
    "description": "Hyper parameter tuning",
    "public": false
   },
   "id": "7d1ace18a82178e15ece8fc5252fce88"
  },
  "kernelspec": {
   "display_name": "Python [conda env:p3]",
   "language": "python",
   "name": "conda-env-p3-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
