{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Read Data Sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-05-15T11:47:51.703202Z",
     "start_time": "2017-05-15T11:47:45.191997Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from collections import namedtuple\n",
    "pd.set_option(\"display.max_rows\",35)\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-05-15T11:47:53.767555Z",
     "start_time": "2017-05-15T11:47:51.704834Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class dataset:\n",
    "    kdd_train_2labels = pd.read_pickle(\"dataset/kdd_train_2labels.pkl\")\n",
    "    kdd_test_2labels = pd.read_pickle(\"dataset/kdd_test_2labels.pkl\")\n",
    "    \n",
    "    kdd_train_5labels = pd.read_pickle(\"dataset/kdd_train_5labels.pkl\")\n",
    "    kdd_test_5labels = pd.read_pickle(\"dataset/kdd_test_5labels.pkl\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-05-15T11:47:53.773685Z",
     "start_time": "2017-05-15T11:47:53.769058Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(125973, 124)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.kdd_train_2labels.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-05-15T11:47:53.808972Z",
     "start_time": "2017-05-15T11:47:53.774960Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(22544, 124)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.kdd_test_2labels.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-05-15T11:47:58.874421Z",
     "start_time": "2017-05-15T11:47:53.810530Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(125973, 122)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn import model_selection as ms\n",
    "from sklearn import preprocessing as pp\n",
    "\n",
    "class preprocess:\n",
    "    \n",
    "    output_columns_2labels = ['is_Attack','is_Normal']\n",
    "    \n",
    "    x_input = dataset.kdd_train_2labels.drop(output_columns_2labels, axis = 1)\n",
    "    y_output = dataset.kdd_train_2labels.loc[:,output_columns_2labels]\n",
    "\n",
    "    x_test_input = dataset.kdd_test_2labels.drop(output_columns_2labels, axis = 1)\n",
    "    y_test = dataset.kdd_test_2labels.loc[:,output_columns_2labels]\n",
    "\n",
    "    ss = pp.StandardScaler()\n",
    "\n",
    "    x_train = ss.fit_transform(x_input)\n",
    "    x_test = ss.transform(x_test_input)\n",
    "\n",
    "    y_train = y_output.values\n",
    "    y_test = y_test.values\n",
    "\n",
    "preprocess.x_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-05-15T11:48:05.885477Z",
     "start_time": "2017-05-15T11:47:58.876047Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-05-15T11:48:06.070694Z",
     "start_time": "2017-05-15T11:48:05.887248Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class network(object):\n",
    "    \n",
    "    input_dim = 122\n",
    "    classes = 2\n",
    "    hidden_encoder_dim = 122\n",
    "    hidden_layers = 1\n",
    "    latent_dim = 18\n",
    "\n",
    "    def __init__(self, classes, hidden_layers, num_of_features):\n",
    "        self.classes = classes\n",
    "        self.hidden_layers = hidden_layers\n",
    "        self.latent_dim = num_of_features\n",
    "            \n",
    "    def build_layers(self):\n",
    "        tf.reset_default_graph()\n",
    "        #learning_rate = tf.Variable(initial_value=0.001)\n",
    "\n",
    "        input_dim = self.input_dim\n",
    "        classes = self.classes\n",
    "        hidden_encoder_dim = self.hidden_encoder_dim\n",
    "        hidden_layers = self.hidden_layers\n",
    "        latent_dim = self.latent_dim\n",
    "        \n",
    "        with tf.variable_scope(\"Input\"):\n",
    "            self.x = tf.placeholder(\"float\", shape=[None, input_dim])\n",
    "            self.y_ = tf.placeholder(\"float\", shape=[None, classes])\n",
    "            self.keep_prob = tf.placeholder(\"float\")\n",
    "        \n",
    "        with tf.variable_scope(\"Layer_Encoder\"):\n",
    "\n",
    "            hidden_encoder = tf.layers.dense(self.x, hidden_encoder_dim, activation = tf.nn.relu, kernel_regularizer=tf.nn.l2_loss)\n",
    "            hidden_encoder = tf.nn.dropout(hidden_encoder, self.keep_prob)\n",
    "            for h in range(hidden_layers - 1):\n",
    "                hidden_encoder = tf.layers.dense(hidden_encoder, latent_dim, activation = tf.nn.relu, kernel_regularizer=tf.nn.l2_loss)\n",
    "                hidden_encoder = tf.nn.dropout(hidden_encoder, self.keep_prob)\n",
    "            \n",
    "            #hidden_encoder = tf.layers.dense(self.x, latent_dim, activation = tf.nn.relu, kernel_regularizer=tf.nn.l2_loss)\n",
    "            #hidden_encoder = tf.nn.dropout(hidden_encoder, self.keep_prob)\n",
    "            \n",
    "        with tf.variable_scope(\"Layer_Dense_Softmax\"):\n",
    "            self.y = tf.layers.dense(hidden_encoder, classes, activation=tf.nn.softmax)\n",
    "            \n",
    "        with tf.variable_scope(\"Loss\"):\n",
    "            \n",
    "            loss = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(labels = self.y_, logits = self.y))\n",
    "\n",
    "            #loss = tf.clip_by_value(loss, -1e-1, 1e-1)\n",
    "            #loss = tf.where(tf.is_nan(loss), 1e-1, loss)\n",
    "            #loss = tf.where(tf.equal(loss, -1e-1), tf.random_normal(loss.shape), loss)\n",
    "            #loss = tf.where(tf.equal(loss, 1e-1), tf.random_normal(loss.shape), loss)\n",
    "            \n",
    "            self.regularized_loss = loss\n",
    "            correct_prediction = tf.equal(tf.argmax(self.y_, 1), tf.argmax(self.y, 1))\n",
    "            self.tf_accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32), name = \"Accuracy\")\n",
    "\n",
    "        with tf.variable_scope(\"Optimizer\"):\n",
    "            learning_rate=1e-5\n",
    "            optimizer = tf.train.AdamOptimizer(learning_rate)\n",
    "            gradients, variables = zip(*optimizer.compute_gradients(self.regularized_loss))\n",
    "            gradients = [\n",
    "                None if gradient is None else tf.clip_by_value(gradient, -1, 1)\n",
    "                for gradient in gradients]\n",
    "            self.train_op = optimizer.apply_gradients(zip(gradients, variables))\n",
    "            #self.train_op = optimizer.minimize(self.regularized_loss)\n",
    "            \n",
    "        # add op for merging summary\n",
    "        #self.summary_op = tf.summary.merge_all()\n",
    "        self.pred = tf.argmax(self.y, axis = 1)\n",
    "        self.actual = tf.argmax(self.y_, axis = 1)\n",
    "\n",
    "        # add Saver ops\n",
    "        self.saver = tf.train.Saver()\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-05-15T11:48:06.187777Z",
     "start_time": "2017-05-15T11:48:06.072323Z"
    },
    "collapsed": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import collections\n",
    "\n",
    "class Train:    \n",
    "    \n",
    "    result = namedtuple(\"score\", ['epoch', 'no_of_features','hidden_layers','train_score', 'test_score'])\n",
    "\n",
    "    predictions = {}\n",
    "\n",
    "    results = []\n",
    "    best_acc = 0\n",
    "    \n",
    "    def train(epochs, net, h,f):\n",
    "        batch_iterations = 200\n",
    "    \n",
    "        with tf.Session() as sess:\n",
    "            #summary_writer_train = tf.summary.FileWriter('./logs/kdd/VAE/training', graph=sess.graph)\n",
    "            #summary_writer_valid = tf.summary.FileWriter('./logs/kdd/VAE/validation')\n",
    "\n",
    "            sess.run(tf.global_variables_initializer())\n",
    "\n",
    "            for epoch in range(1, (epochs+1)):\n",
    "                x_train, x_valid, y_train, y_valid, = ms.train_test_split(preprocess.x_train, \n",
    "                                                                          preprocess.y_train, \n",
    "                                                                          test_size=0.1)\n",
    "                batch_indices = np.array_split(np.arange(x_train.shape[0]), \n",
    "                                           batch_iterations)\n",
    "                                                                          \n",
    "                for i in batch_indices:\n",
    "                    _, train_loss = sess.run([net.train_op, \n",
    "                                                           net.regularized_loss, \n",
    "                                                           ], #net.summary_op\n",
    "                                                          feed_dict={net.x: x_train[i,:], \n",
    "                                                                     net.y_: y_train[i,:], \n",
    "                                                                     net.keep_prob:0.5})\n",
    "                    \n",
    "                    #summary_writer_train.add_summary(summary_str, epoch)\n",
    "                    if(train_loss > 1e9):\n",
    "                        print(\"Step {} | Training Loss: {:.6f}\".format(epoch, train_loss))\n",
    "                    \n",
    "\n",
    "                valid_accuracy = sess.run(net.tf_accuracy, #net.summary_op \n",
    "                                                      feed_dict={net.x: x_valid, \n",
    "                                                                 net.y_: y_valid, \n",
    "                                                                 net.keep_prob:1})\n",
    "                #summary_writer_valid.add_summary(summary_str, epoch)\n",
    "\n",
    "                \n",
    "                accuracy, pred_value, actual_value, y_pred = sess.run([net.tf_accuracy, \n",
    "                                                               net.pred, \n",
    "                                                               net.actual, net.y], \n",
    "                                                              feed_dict={net.x: preprocess.x_test, \n",
    "                                                                         net.y_: preprocess.y_test, \n",
    "                                                                         net.keep_prob:1})\n",
    "\n",
    "                print(\"Step {} | Training Loss: {:.6f} | Validation Accuracy: {:.6f}\".format(epoch, train_loss, valid_accuracy))\n",
    "                print(\"Accuracy on Test data: {}\".format(accuracy))\n",
    "\n",
    "                if accuracy > Train.best_acc:\n",
    "                    Train.best_acc = accuracy\n",
    "                    Train.pred_value = pred_value\n",
    "                    Train.actual_value = actual_value\n",
    "                    Train.best_parameters = \"Hidden Layers:{}, Features Count:{}\".format(h, f)\n",
    "                    net.saver.save(sess, \n",
    "                                   \"dataset/tf_dense_only_nsl_kdd_hidden layers_{}_features count_{}\".format(h,f),\n",
    "                                    global_step = epochs)\n",
    "                    curr_pred = pd.DataFrame({\"Attack_prob\":y_pred[:,-2], \"Normal_prob\":y_pred[:, -1]})\n",
    "                    Train.predictions.update({\"{}_{}_{}\".format(epochs,f,h):curr_pred})\n",
    "\n",
    "                    Train.results.append(Train.result(epochs, f, h,valid_accuracy, accuracy))\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-05-15T12:09:44.229406Z",
     "start_time": "2017-05-15T11:48:06.189381Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current Layer Attributes - epochs:100 hidden layers:4 features count:4\n",
      "Step 1 | Training Loss: 0.681097 | Validation Accuracy: 0.718844\n",
      "Accuracy on Test data: 0.5996273756027222\n",
      "Step 2 | Training Loss: 0.683299 | Validation Accuracy: 0.801080\n",
      "Accuracy on Test data: 0.6605748534202576\n",
      "Step 3 | Training Loss: 0.682867 | Validation Accuracy: 0.815764\n",
      "Accuracy on Test data: 0.6569375395774841\n",
      "Step 4 | Training Loss: 0.682487 | Validation Accuracy: 0.819971\n",
      "Accuracy on Test data: 0.6472232341766357\n",
      "Step 5 | Training Loss: 0.675851 | Validation Accuracy: 0.844261\n",
      "Accuracy on Test data: 0.6533445715904236\n",
      "Step 6 | Training Loss: 0.674450 | Validation Accuracy: 0.872916\n",
      "Accuracy on Test data: 0.7317246198654175\n",
      "Step 7 | Training Loss: 0.664040 | Validation Accuracy: 0.896015\n",
      "Accuracy on Test data: 0.7506210207939148\n",
      "Step 8 | Training Loss: 0.658958 | Validation Accuracy: 0.913558\n",
      "Accuracy on Test data: 0.7605571150779724\n",
      "Step 9 | Training Loss: 0.661027 | Validation Accuracy: 0.924988\n",
      "Accuracy on Test data: 0.7892122268676758\n",
      "Step 10 | Training Loss: 0.655260 | Validation Accuracy: 0.929989\n",
      "Accuracy on Test data: 0.798660397529602\n",
      "Step 11 | Training Loss: 0.646944 | Validation Accuracy: 0.936657\n",
      "Accuracy on Test data: 0.8040720224380493\n",
      "Step 12 | Training Loss: 0.656950 | Validation Accuracy: 0.941022\n",
      "Accuracy on Test data: 0.8115241527557373\n",
      "Step 13 | Training Loss: 0.654473 | Validation Accuracy: 0.945706\n",
      "Accuracy on Test data: 0.8148065805435181\n",
      "Step 14 | Training Loss: 0.648320 | Validation Accuracy: 0.947769\n",
      "Accuracy on Test data: 0.8183995485305786\n",
      "Step 15 | Training Loss: 0.645020 | Validation Accuracy: 0.946341\n",
      "Accuracy on Test data: 0.8212828040122986\n",
      "Step 16 | Training Loss: 0.638427 | Validation Accuracy: 0.942927\n",
      "Accuracy on Test data: 0.8249201774597168\n",
      "Step 17 | Training Loss: 0.649948 | Validation Accuracy: 0.943880\n",
      "Accuracy on Test data: 0.8286905884742737\n",
      "Step 18 | Training Loss: 0.639798 | Validation Accuracy: 0.944515\n",
      "Accuracy on Test data: 0.8300656676292419\n",
      "Step 19 | Training Loss: 0.642450 | Validation Accuracy: 0.947928\n",
      "Accuracy on Test data: 0.8317068815231323\n",
      "Step 20 | Training Loss: 0.636850 | Validation Accuracy: 0.948087\n",
      "Accuracy on Test data: 0.8325053453445435\n",
      "Step 21 | Training Loss: 0.635516 | Validation Accuracy: 0.949119\n",
      "Accuracy on Test data: 0.8331707119941711\n",
      "Step 22 | Training Loss: 0.641402 | Validation Accuracy: 0.948484\n",
      "Accuracy on Test data: 0.8344570398330688\n",
      "Step 23 | Training Loss: 0.643167 | Validation Accuracy: 0.952770\n",
      "Accuracy on Test data: 0.8340578675270081\n",
      "Step 24 | Training Loss: 0.629359 | Validation Accuracy: 0.952850\n",
      "Accuracy on Test data: 0.8344570398330688\n",
      "Step 25 | Training Loss: 0.644035 | Validation Accuracy: 0.954437\n",
      "Accuracy on Test data: 0.8349893689155579\n",
      "Step 26 | Training Loss: 0.623842 | Validation Accuracy: 0.954517\n",
      "Accuracy on Test data: 0.835565984249115\n",
      "Step 27 | Training Loss: 0.625845 | Validation Accuracy: 0.954120\n",
      "Accuracy on Test data: 0.8355216383934021\n",
      "Step 28 | Training Loss: 0.630280 | Validation Accuracy: 0.958724\n",
      "Accuracy on Test data: 0.8353441953659058\n",
      "Step 29 | Training Loss: 0.635440 | Validation Accuracy: 0.956660\n",
      "Accuracy on Test data: 0.8358321785926819\n",
      "Step 30 | Training Loss: 0.628218 | Validation Accuracy: 0.957850\n",
      "Accuracy on Test data: 0.834412693977356\n",
      "Step 31 | Training Loss: 0.628671 | Validation Accuracy: 0.960073\n",
      "Accuracy on Test data: 0.8318399786949158\n",
      "Step 32 | Training Loss: 0.635727 | Validation Accuracy: 0.957850\n",
      "Accuracy on Test data: 0.8292228579521179\n",
      "Step 33 | Training Loss: 0.625891 | Validation Accuracy: 0.960232\n",
      "Accuracy on Test data: 0.825141966342926\n",
      "Step 34 | Training Loss: 0.626494 | Validation Accuracy: 0.959835\n",
      "Accuracy on Test data: 0.8215489983558655\n",
      "Step 35 | Training Loss: 0.629807 | Validation Accuracy: 0.961264\n",
      "Accuracy on Test data: 0.815693736076355\n",
      "Step 36 | Training Loss: 0.626320 | Validation Accuracy: 0.960629\n",
      "Accuracy on Test data: 0.8144517540931702\n",
      "Step 37 | Training Loss: 0.612646 | Validation Accuracy: 0.960470\n",
      "Accuracy on Test data: 0.8122338652610779\n",
      "Step 38 | Training Loss: 0.629800 | Validation Accuracy: 0.962057\n",
      "Accuracy on Test data: 0.8105482459068298\n",
      "Step 39 | Training Loss: 0.608567 | Validation Accuracy: 0.961899\n",
      "Accuracy on Test data: 0.8089513778686523\n",
      "Step 40 | Training Loss: 0.612430 | Validation Accuracy: 0.959676\n",
      "Accuracy on Test data: 0.8069552779197693\n",
      "Step 41 | Training Loss: 0.609179 | Validation Accuracy: 0.962772\n",
      "Accuracy on Test data: 0.8061124682426453\n",
      "Step 42 | Training Loss: 0.618575 | Validation Accuracy: 0.960787\n",
      "Accuracy on Test data: 0.8046486973762512\n",
      "Step 43 | Training Loss: 0.609825 | Validation Accuracy: 0.962454\n",
      "Accuracy on Test data: 0.803584098815918\n",
      "Step 44 | Training Loss: 0.613553 | Validation Accuracy: 0.962851\n",
      "Accuracy on Test data: 0.8030074238777161\n",
      "Step 45 | Training Loss: 0.613654 | Validation Accuracy: 0.958089\n",
      "Accuracy on Test data: 0.8011444211006165\n",
      "Step 46 | Training Loss: 0.606301 | Validation Accuracy: 0.962375\n",
      "Accuracy on Test data: 0.8000354766845703\n",
      "Step 47 | Training Loss: 0.619221 | Validation Accuracy: 0.964677\n",
      "Accuracy on Test data: 0.7993257641792297\n",
      "Step 48 | Training Loss: 0.610669 | Validation Accuracy: 0.963963\n",
      "Accuracy on Test data: 0.7983942627906799\n",
      "Step 49 | Training Loss: 0.604621 | Validation Accuracy: 0.966423\n",
      "Accuracy on Test data: 0.7975514531135559\n",
      "Step 50 | Training Loss: 0.605133 | Validation Accuracy: 0.963963\n",
      "Accuracy on Test data: 0.7972853183746338\n",
      "Step 51 | Training Loss: 0.603846 | Validation Accuracy: 0.963407\n",
      "Accuracy on Test data: 0.7963094115257263\n",
      "Step 52 | Training Loss: 0.605877 | Validation Accuracy: 0.964280\n",
      "Accuracy on Test data: 0.7948012948036194\n",
      "Step 53 | Training Loss: 0.599270 | Validation Accuracy: 0.965074\n",
      "Accuracy on Test data: 0.7940471768379211\n",
      "Step 54 | Training Loss: 0.594875 | Validation Accuracy: 0.962692\n",
      "Accuracy on Test data: 0.7940471768379211\n",
      "Step 55 | Training Loss: 0.611186 | Validation Accuracy: 0.962851\n",
      "Accuracy on Test data: 0.7927608489990234\n",
      "Step 56 | Training Loss: 0.605575 | Validation Accuracy: 0.963645\n",
      "Accuracy on Test data: 0.7924059629440308\n",
      "Step 57 | Training Loss: 0.596471 | Validation Accuracy: 0.963963\n",
      "Accuracy on Test data: 0.7914301156997681\n",
      "Step 58 | Training Loss: 0.613068 | Validation Accuracy: 0.966106\n",
      "Accuracy on Test data: 0.7909421324729919\n",
      "Step 59 | Training Loss: 0.589552 | Validation Accuracy: 0.964280\n",
      "Accuracy on Test data: 0.7906759977340698\n",
      "Step 60 | Training Loss: 0.614376 | Validation Accuracy: 0.964280\n",
      "Accuracy on Test data: 0.7899219393730164\n",
      "Step 61 | Training Loss: 0.589586 | Validation Accuracy: 0.965312\n",
      "Accuracy on Test data: 0.7888573408126831\n",
      "Step 62 | Training Loss: 0.603394 | Validation Accuracy: 0.964359\n",
      "Accuracy on Test data: 0.7883250713348389\n",
      "Step 63 | Training Loss: 0.606880 | Validation Accuracy: 0.967931\n",
      "Accuracy on Test data: 0.7875709533691406\n",
      "Step 64 | Training Loss: 0.595870 | Validation Accuracy: 0.963010\n",
      "Accuracy on Test data: 0.7876597046852112\n",
      "Step 65 | Training Loss: 0.592734 | Validation Accuracy: 0.966185\n",
      "Accuracy on Test data: 0.7865951061248779\n",
      "Step 66 | Training Loss: 0.595177 | Validation Accuracy: 0.965947\n",
      "Accuracy on Test data: 0.7859740853309631\n",
      "Step 67 | Training Loss: 0.609326 | Validation Accuracy: 0.966582\n",
      "Accuracy on Test data: 0.7850425839424133\n",
      "Step 68 | Training Loss: 0.591404 | Validation Accuracy: 0.967455\n",
      "Accuracy on Test data: 0.7843772172927856\n",
      "Step 69 | Training Loss: 0.586945 | Validation Accuracy: 0.965471\n",
      "Accuracy on Test data: 0.7838449478149414\n",
      "Step 70 | Training Loss: 0.593812 | Validation Accuracy: 0.967296\n",
      "Accuracy on Test data: 0.7832239270210266\n",
      "Step 71 | Training Loss: 0.584492 | Validation Accuracy: 0.967058\n",
      "Accuracy on Test data: 0.7830021381378174\n",
      "Step 72 | Training Loss: 0.600942 | Validation Accuracy: 0.965471\n",
      "Accuracy on Test data: 0.7827803492546082\n",
      "Step 73 | Training Loss: 0.596024 | Validation Accuracy: 0.963089\n",
      "Accuracy on Test data: 0.7827803492546082\n",
      "Step 74 | Training Loss: 0.599458 | Validation Accuracy: 0.967376\n",
      "Accuracy on Test data: 0.7824254631996155\n",
      "Step 75 | Training Loss: 0.586483 | Validation Accuracy: 0.967455\n",
      "Accuracy on Test data: 0.7819375395774841\n",
      "Step 76 | Training Loss: 0.583833 | Validation Accuracy: 0.966503\n",
      "Accuracy on Test data: 0.7814496159553528\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 77 | Training Loss: 0.597299 | Validation Accuracy: 0.967138\n",
      "Accuracy on Test data: 0.7810947299003601\n",
      "Step 78 | Training Loss: 0.582857 | Validation Accuracy: 0.966185\n",
      "Accuracy on Test data: 0.7808729410171509\n",
      "Step 79 | Training Loss: 0.584016 | Validation Accuracy: 0.968408\n",
      "Accuracy on Test data: 0.7809616923332214\n",
      "Step 80 | Training Loss: 0.588315 | Validation Accuracy: 0.968646\n",
      "Accuracy on Test data: 0.7810060381889343\n",
      "Step 81 | Training Loss: 0.591915 | Validation Accuracy: 0.966026\n",
      "Accuracy on Test data: 0.7809173464775085\n",
      "Step 82 | Training Loss: 0.578645 | Validation Accuracy: 0.968011\n",
      "Accuracy on Test data: 0.7806068062782288\n",
      "Step 83 | Training Loss: 0.581369 | Validation Accuracy: 0.968884\n",
      "Accuracy on Test data: 0.7806511521339417\n",
      "Step 84 | Training Loss: 0.596540 | Validation Accuracy: 0.967058\n",
      "Accuracy on Test data: 0.7802963256835938\n",
      "Step 85 | Training Loss: 0.580330 | Validation Accuracy: 0.966185\n",
      "Accuracy on Test data: 0.779985785484314\n",
      "Step 86 | Training Loss: 0.580009 | Validation Accuracy: 0.970948\n",
      "Accuracy on Test data: 0.7798527479171753\n",
      "Step 87 | Training Loss: 0.587018 | Validation Accuracy: 0.969360\n",
      "Accuracy on Test data: 0.7795422077178955\n",
      "Step 88 | Training Loss: 0.575871 | Validation Accuracy: 0.969122\n",
      "Accuracy on Test data: 0.7792317271232605\n",
      "Step 89 | Training Loss: 0.581275 | Validation Accuracy: 0.969201\n",
      "Accuracy on Test data: 0.7788768410682678\n",
      "Step 90 | Training Loss: 0.577392 | Validation Accuracy: 0.967931\n",
      "Accuracy on Test data: 0.7787438035011292\n",
      "Step 91 | Training Loss: 0.570933 | Validation Accuracy: 0.971107\n",
      "Accuracy on Test data: 0.7785220146179199\n",
      "Step 92 | Training Loss: 0.584936 | Validation Accuracy: 0.967931\n",
      "Accuracy on Test data: 0.7783445715904236\n",
      "Step 93 | Training Loss: 0.581953 | Validation Accuracy: 0.968963\n",
      "Accuracy on Test data: 0.7781671285629272\n",
      "Step 94 | Training Loss: 0.587972 | Validation Accuracy: 0.967931\n",
      "Accuracy on Test data: 0.7778566479682922\n",
      "Step 95 | Training Loss: 0.588031 | Validation Accuracy: 0.970075\n",
      "Accuracy on Test data: 0.7777678966522217\n",
      "Step 96 | Training Loss: 0.560039 | Validation Accuracy: 0.966264\n",
      "Accuracy on Test data: 0.7774574160575867\n",
      "Step 97 | Training Loss: 0.588354 | Validation Accuracy: 0.966741\n",
      "Accuracy on Test data: 0.7771469354629517\n",
      "Step 98 | Training Loss: 0.567476 | Validation Accuracy: 0.970789\n",
      "Accuracy on Test data: 0.7767033576965332\n",
      "Step 99 | Training Loss: 0.565769 | Validation Accuracy: 0.970472\n",
      "Accuracy on Test data: 0.7764371633529663\n",
      "Step 100 | Training Loss: 0.581246 | Validation Accuracy: 0.966264\n",
      "Accuracy on Test data: 0.7763928174972534\n",
      "Current Layer Attributes - epochs:100 hidden layers:4 features count:8\n",
      "Step 1 | Training Loss: 0.745057 | Validation Accuracy: 0.344420\n",
      "Accuracy on Test data: 0.4144339859485626\n",
      "Step 2 | Training Loss: 0.732998 | Validation Accuracy: 0.537387\n",
      "Accuracy on Test data: 0.6076117753982544\n",
      "Step 3 | Training Loss: 0.708152 | Validation Accuracy: 0.613510\n",
      "Accuracy on Test data: 0.658401370048523\n",
      "Step 4 | Training Loss: 0.715471 | Validation Accuracy: 0.670741\n",
      "Accuracy on Test data: 0.6934882998466492\n",
      "Step 5 | Training Loss: 0.705691 | Validation Accuracy: 0.677489\n",
      "Accuracy on Test data: 0.6971256136894226\n",
      "Step 6 | Training Loss: 0.705626 | Validation Accuracy: 0.692173\n",
      "Accuracy on Test data: 0.6898953318595886\n",
      "Step 7 | Training Loss: 0.688294 | Validation Accuracy: 0.706064\n",
      "Accuracy on Test data: 0.6894074082374573\n",
      "Step 8 | Training Loss: 0.685489 | Validation Accuracy: 0.702651\n",
      "Accuracy on Test data: 0.6902945637702942\n",
      "Step 9 | Training Loss: 0.674352 | Validation Accuracy: 0.727417\n",
      "Accuracy on Test data: 0.6988999247550964\n",
      "Step 10 | Training Loss: 0.662877 | Validation Accuracy: 0.799174\n",
      "Accuracy on Test data: 0.7251597046852112\n",
      "Step 11 | Training Loss: 0.676361 | Validation Accuracy: 0.871408\n",
      "Accuracy on Test data: 0.7467175126075745\n",
      "Step 12 | Training Loss: 0.663466 | Validation Accuracy: 0.897047\n",
      "Accuracy on Test data: 0.7547462582588196\n",
      "Step 13 | Training Loss: 0.651036 | Validation Accuracy: 0.906493\n",
      "Accuracy on Test data: 0.7595812678337097\n",
      "Step 14 | Training Loss: 0.676054 | Validation Accuracy: 0.910621\n",
      "Accuracy on Test data: 0.7623314261436462\n",
      "Step 15 | Training Loss: 0.656890 | Validation Accuracy: 0.927052\n",
      "Accuracy on Test data: 0.7678318023681641\n",
      "Step 16 | Training Loss: 0.642477 | Validation Accuracy: 0.938006\n",
      "Accuracy on Test data: 0.7728441953659058\n",
      "Step 17 | Training Loss: 0.630828 | Validation Accuracy: 0.943483\n",
      "Accuracy on Test data: 0.7774574160575867\n",
      "Step 18 | Training Loss: 0.623269 | Validation Accuracy: 0.948087\n",
      "Accuracy on Test data: 0.7814052700996399\n",
      "Step 19 | Training Loss: 0.628951 | Validation Accuracy: 0.950468\n",
      "Accuracy on Test data: 0.7849094867706299\n",
      "Step 20 | Training Loss: 0.627642 | Validation Accuracy: 0.953485\n",
      "Accuracy on Test data: 0.7886355519294739\n",
      "Step 21 | Training Loss: 0.629749 | Validation Accuracy: 0.956819\n",
      "Accuracy on Test data: 0.7924946546554565\n",
      "Step 22 | Training Loss: 0.601553 | Validation Accuracy: 0.957771\n",
      "Accuracy on Test data: 0.7943577170372009\n",
      "Step 23 | Training Loss: 0.610012 | Validation Accuracy: 0.960549\n",
      "Accuracy on Test data: 0.795821487903595\n",
      "Step 24 | Training Loss: 0.624748 | Validation Accuracy: 0.962137\n",
      "Accuracy on Test data: 0.7969304323196411\n",
      "Step 25 | Training Loss: 0.606946 | Validation Accuracy: 0.965471\n",
      "Accuracy on Test data: 0.7960432767868042\n",
      "Step 26 | Training Loss: 0.603380 | Validation Accuracy: 0.964439\n",
      "Accuracy on Test data: 0.796353816986084\n",
      "Step 27 | Training Loss: 0.622655 | Validation Accuracy: 0.966503\n",
      "Accuracy on Test data: 0.7968860864639282\n",
      "Step 28 | Training Loss: 0.584093 | Validation Accuracy: 0.968566\n",
      "Accuracy on Test data: 0.7967529892921448\n",
      "Step 29 | Training Loss: 0.579312 | Validation Accuracy: 0.964359\n",
      "Accuracy on Test data: 0.7971078753471375\n",
      "Step 30 | Training Loss: 0.578577 | Validation Accuracy: 0.965629\n",
      "Accuracy on Test data: 0.7974183559417725\n",
      "Step 31 | Training Loss: 0.570548 | Validation Accuracy: 0.968249\n",
      "Accuracy on Test data: 0.7974183559417725\n",
      "Step 32 | Training Loss: 0.583214 | Validation Accuracy: 0.968963\n",
      "Accuracy on Test data: 0.797507107257843\n",
      "Step 33 | Training Loss: 0.586239 | Validation Accuracy: 0.967376\n",
      "Accuracy on Test data: 0.7975514531135559\n",
      "Step 34 | Training Loss: 0.568952 | Validation Accuracy: 0.968566\n",
      "Accuracy on Test data: 0.7974627614021301\n",
      "Step 35 | Training Loss: 0.556844 | Validation Accuracy: 0.968805\n",
      "Accuracy on Test data: 0.7977288961410522\n",
      "Step 36 | Training Loss: 0.564922 | Validation Accuracy: 0.968408\n",
      "Accuracy on Test data: 0.7980393767356873\n",
      "Step 37 | Training Loss: 0.575185 | Validation Accuracy: 0.966106\n",
      "Accuracy on Test data: 0.7957771420478821\n",
      "Step 38 | Training Loss: 0.539488 | Validation Accuracy: 0.969122\n",
      "Accuracy on Test data: 0.7924059629440308\n",
      "Step 39 | Training Loss: 0.578509 | Validation Accuracy: 0.970313\n",
      "Accuracy on Test data: 0.791474461555481\n",
      "Step 40 | Training Loss: 0.564578 | Validation Accuracy: 0.965868\n",
      "Accuracy on Test data: 0.7904542088508606\n",
      "Step 41 | Training Loss: 0.549054 | Validation Accuracy: 0.969122\n",
      "Accuracy on Test data: 0.7895227074623108\n",
      "Step 42 | Training Loss: 0.545226 | Validation Accuracy: 0.968646\n",
      "Accuracy on Test data: 0.7880589365959167\n",
      "Step 43 | Training Loss: 0.552045 | Validation Accuracy: 0.967614\n",
      "Accuracy on Test data: 0.7869943380355835\n",
      "Step 44 | Training Loss: 0.550956 | Validation Accuracy: 0.968725\n",
      "Accuracy on Test data: 0.7861515283584595\n",
      "Step 45 | Training Loss: 0.560782 | Validation Accuracy: 0.968725\n",
      "Accuracy on Test data: 0.7849538922309875\n",
      "Step 46 | Training Loss: 0.531325 | Validation Accuracy: 0.970630\n",
      "Accuracy on Test data: 0.7842441201210022\n",
      "Step 47 | Training Loss: 0.537728 | Validation Accuracy: 0.968328\n",
      "Accuracy on Test data: 0.7826915979385376\n",
      "Step 48 | Training Loss: 0.524238 | Validation Accuracy: 0.968646\n",
      "Accuracy on Test data: 0.7813165187835693\n",
      "Step 49 | Training Loss: 0.529626 | Validation Accuracy: 0.968725\n",
      "Accuracy on Test data: 0.780518114566803\n",
      "Step 50 | Training Loss: 0.530676 | Validation Accuracy: 0.967931\n",
      "Accuracy on Test data: 0.7783445715904236\n",
      "Step 51 | Training Loss: 0.542780 | Validation Accuracy: 0.970392\n",
      "Accuracy on Test data: 0.777102530002594\n",
      "Step 52 | Training Loss: 0.529514 | Validation Accuracy: 0.969201\n",
      "Accuracy on Test data: 0.7755056619644165\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 53 | Training Loss: 0.522926 | Validation Accuracy: 0.969836\n",
      "Accuracy on Test data: 0.7740418910980225\n",
      "Step 54 | Training Loss: 0.517373 | Validation Accuracy: 0.968090\n",
      "Accuracy on Test data: 0.7730216383934021\n",
      "Step 55 | Training Loss: 0.511441 | Validation Accuracy: 0.969043\n",
      "Accuracy on Test data: 0.7721344828605652\n",
      "Step 56 | Training Loss: 0.522776 | Validation Accuracy: 0.968566\n",
      "Accuracy on Test data: 0.7718240022659302\n",
      "Step 57 | Training Loss: 0.515366 | Validation Accuracy: 0.968328\n",
      "Accuracy on Test data: 0.771025538444519\n",
      "Step 58 | Training Loss: 0.507282 | Validation Accuracy: 0.969836\n",
      "Accuracy on Test data: 0.7696948051452637\n",
      "Step 59 | Training Loss: 0.527852 | Validation Accuracy: 0.967217\n",
      "Accuracy on Test data: 0.7688964009284973\n",
      "Step 60 | Training Loss: 0.515176 | Validation Accuracy: 0.969916\n",
      "Accuracy on Test data: 0.7676100134849548\n",
      "Step 61 | Training Loss: 0.515883 | Validation Accuracy: 0.969043\n",
      "Accuracy on Test data: 0.7670333385467529\n",
      "Step 62 | Training Loss: 0.517009 | Validation Accuracy: 0.971265\n",
      "Accuracy on Test data: 0.7664567232131958\n",
      "Step 63 | Training Loss: 0.498645 | Validation Accuracy: 0.969281\n",
      "Accuracy on Test data: 0.7653477787971497\n",
      "Step 64 | Training Loss: 0.491100 | Validation Accuracy: 0.968328\n",
      "Accuracy on Test data: 0.7652146816253662\n",
      "Step 65 | Training Loss: 0.490899 | Validation Accuracy: 0.968170\n",
      "Accuracy on Test data: 0.7645936608314514\n",
      "Step 66 | Training Loss: 0.493324 | Validation Accuracy: 0.971662\n",
      "Accuracy on Test data: 0.7637952566146851\n",
      "Step 67 | Training Loss: 0.492365 | Validation Accuracy: 0.969836\n",
      "Accuracy on Test data: 0.7627306580543518\n",
      "Step 68 | Training Loss: 0.503218 | Validation Accuracy: 0.971742\n",
      "Accuracy on Test data: 0.7622870802879333\n",
      "Step 69 | Training Loss: 0.493867 | Validation Accuracy: 0.971821\n",
      "Accuracy on Test data: 0.7618435025215149\n",
      "Step 70 | Training Loss: 0.497380 | Validation Accuracy: 0.973091\n",
      "Accuracy on Test data: 0.7606902122497559\n",
      "Step 71 | Training Loss: 0.496250 | Validation Accuracy: 0.971662\n",
      "Accuracy on Test data: 0.759803056716919\n",
      "Step 72 | Training Loss: 0.485414 | Validation Accuracy: 0.968487\n",
      "Accuracy on Test data: 0.7581618428230286\n",
      "Step 73 | Training Loss: 0.484324 | Validation Accuracy: 0.970948\n",
      "Accuracy on Test data: 0.7576738595962524\n",
      "Step 74 | Training Loss: 0.503277 | Validation Accuracy: 0.970630\n",
      "Accuracy on Test data: 0.7572746872901917\n",
      "Step 75 | Training Loss: 0.483654 | Validation Accuracy: 0.970868\n",
      "Accuracy on Test data: 0.7570084929466248\n",
      "Step 76 | Training Loss: 0.479371 | Validation Accuracy: 0.973329\n",
      "Accuracy on Test data: 0.7565205693244934\n",
      "Step 77 | Training Loss: 0.472901 | Validation Accuracy: 0.973329\n",
      "Accuracy on Test data: 0.7562544345855713\n",
      "Step 78 | Training Loss: 0.474833 | Validation Accuracy: 0.971503\n",
      "Accuracy on Test data: 0.7562100887298584\n",
      "Step 79 | Training Loss: 0.498968 | Validation Accuracy: 0.972535\n",
      "Accuracy on Test data: 0.7555890679359436\n",
      "Step 80 | Training Loss: 0.477987 | Validation Accuracy: 0.971821\n",
      "Accuracy on Test data: 0.7550123929977417\n",
      "Step 81 | Training Loss: 0.471415 | Validation Accuracy: 0.969043\n",
      "Accuracy on Test data: 0.7547906041145325\n",
      "Step 82 | Training Loss: 0.480628 | Validation Accuracy: 0.973250\n",
      "Accuracy on Test data: 0.754879355430603\n",
      "Step 83 | Training Loss: 0.476421 | Validation Accuracy: 0.972694\n",
      "Accuracy on Test data: 0.7547019124031067\n",
      "Step 84 | Training Loss: 0.492474 | Validation Accuracy: 0.972932\n",
      "Accuracy on Test data: 0.7541252374649048\n",
      "Step 85 | Training Loss: 0.465509 | Validation Accuracy: 0.972218\n",
      "Accuracy on Test data: 0.7540808916091919\n",
      "Step 86 | Training Loss: 0.483737 | Validation Accuracy: 0.970710\n",
      "Accuracy on Test data: 0.7536816596984863\n",
      "Step 87 | Training Loss: 0.463129 | Validation Accuracy: 0.970154\n",
      "Accuracy on Test data: 0.7536816596984863\n",
      "Step 88 | Training Loss: 0.470967 | Validation Accuracy: 0.972773\n",
      "Accuracy on Test data: 0.7534599304199219\n",
      "Step 89 | Training Loss: 0.475545 | Validation Accuracy: 0.971424\n",
      "Accuracy on Test data: 0.7535486221313477\n",
      "Step 90 | Training Loss: 0.465772 | Validation Accuracy: 0.973012\n",
      "Accuracy on Test data: 0.7535486221313477\n",
      "Step 91 | Training Loss: 0.467942 | Validation Accuracy: 0.968725\n",
      "Accuracy on Test data: 0.7535929679870605\n",
      "Step 92 | Training Loss: 0.481461 | Validation Accuracy: 0.972138\n",
      "Accuracy on Test data: 0.7536816596984863\n",
      "Step 93 | Training Loss: 0.467915 | Validation Accuracy: 0.968170\n",
      "Accuracy on Test data: 0.7536373138427734\n",
      "Step 94 | Training Loss: 0.468385 | Validation Accuracy: 0.972932\n",
      "Accuracy on Test data: 0.7532381415367126\n",
      "Step 95 | Training Loss: 0.475454 | Validation Accuracy: 0.972535\n",
      "Accuracy on Test data: 0.7530163526535034\n",
      "Step 96 | Training Loss: 0.463264 | Validation Accuracy: 0.971345\n",
      "Accuracy on Test data: 0.7530606985092163\n",
      "Step 97 | Training Loss: 0.467394 | Validation Accuracy: 0.972932\n",
      "Accuracy on Test data: 0.7529276013374329\n",
      "Step 98 | Training Loss: 0.472297 | Validation Accuracy: 0.971345\n",
      "Accuracy on Test data: 0.7524396777153015\n",
      "Step 99 | Training Loss: 0.484212 | Validation Accuracy: 0.972456\n",
      "Accuracy on Test data: 0.7523509860038757\n",
      "Step 100 | Training Loss: 0.464892 | Validation Accuracy: 0.973250\n",
      "Accuracy on Test data: 0.7522622346878052\n",
      "Current Layer Attributes - epochs:100 hidden layers:4 features count:32\n",
      "Step 1 | Training Loss: 0.741496 | Validation Accuracy: 0.533974\n",
      "Accuracy on Test data: 0.4309350550174713\n",
      "Step 2 | Training Loss: 0.722608 | Validation Accuracy: 0.535799\n",
      "Accuracy on Test data: 0.43115684390068054\n",
      "Step 3 | Training Loss: 0.718635 | Validation Accuracy: 0.543340\n",
      "Accuracy on Test data: 0.43390703201293945\n",
      "Step 4 | Training Loss: 0.691443 | Validation Accuracy: 0.555167\n",
      "Accuracy on Test data: 0.4384315013885498\n",
      "Step 5 | Training Loss: 0.684687 | Validation Accuracy: 0.600889\n",
      "Accuracy on Test data: 0.4710344076156616\n",
      "Step 6 | Training Loss: 0.677580 | Validation Accuracy: 0.745277\n",
      "Accuracy on Test data: 0.5283002257347107\n",
      "Step 7 | Training Loss: 0.640509 | Validation Accuracy: 0.804731\n",
      "Accuracy on Test data: 0.5942600965499878\n",
      "Step 8 | Training Loss: 0.632202 | Validation Accuracy: 0.864661\n",
      "Accuracy on Test data: 0.6759669780731201\n",
      "Step 9 | Training Loss: 0.638384 | Validation Accuracy: 0.898317\n",
      "Accuracy on Test data: 0.722897469997406\n",
      "Step 10 | Training Loss: 0.627762 | Validation Accuracy: 0.925703\n",
      "Accuracy on Test data: 0.7460521459579468\n",
      "Step 11 | Training Loss: 0.586137 | Validation Accuracy: 0.933958\n",
      "Accuracy on Test data: 0.742237389087677\n",
      "Step 12 | Training Loss: 0.584336 | Validation Accuracy: 0.941181\n",
      "Accuracy on Test data: 0.751153290271759\n",
      "Step 13 | Training Loss: 0.569089 | Validation Accuracy: 0.940943\n",
      "Accuracy on Test data: 0.7585166692733765\n",
      "Step 14 | Training Loss: 0.562644 | Validation Accuracy: 0.941340\n",
      "Accuracy on Test data: 0.7643718719482422\n",
      "Step 15 | Training Loss: 0.516230 | Validation Accuracy: 0.944039\n",
      "Accuracy on Test data: 0.7759935855865479\n",
      "Step 16 | Training Loss: 0.517293 | Validation Accuracy: 0.941816\n",
      "Accuracy on Test data: 0.7792317271232605\n",
      "Step 17 | Training Loss: 0.490359 | Validation Accuracy: 0.941102\n",
      "Accuracy on Test data: 0.7838449478149414\n",
      "Step 18 | Training Loss: 0.500291 | Validation Accuracy: 0.939594\n",
      "Accuracy on Test data: 0.7860628366470337\n",
      "Step 19 | Training Loss: 0.514006 | Validation Accuracy: 0.944436\n",
      "Accuracy on Test data: 0.7880145311355591\n",
      "Step 20 | Training Loss: 0.472469 | Validation Accuracy: 0.948881\n",
      "Accuracy on Test data: 0.7897001504898071\n",
      "Step 21 | Training Loss: 0.466768 | Validation Accuracy: 0.947373\n",
      "Accuracy on Test data: 0.7908090949058533\n",
      "Step 22 | Training Loss: 0.463304 | Validation Accuracy: 0.949357\n",
      "Accuracy on Test data: 0.7911639213562012\n",
      "Step 23 | Training Loss: 0.479175 | Validation Accuracy: 0.952612\n",
      "Accuracy on Test data: 0.7870386838912964\n",
      "Step 24 | Training Loss: 0.444678 | Validation Accuracy: 0.953167\n",
      "Accuracy on Test data: 0.7855748534202576\n",
      "Step 25 | Training Loss: 0.438917 | Validation Accuracy: 0.955469\n",
      "Accuracy on Test data: 0.7835344076156616\n",
      "Step 26 | Training Loss: 0.434433 | Validation Accuracy: 0.953564\n",
      "Accuracy on Test data: 0.7829133868217468\n",
      "Step 27 | Training Loss: 0.435935 | Validation Accuracy: 0.960708\n",
      "Accuracy on Test data: 0.7827803492546082\n",
      "Step 28 | Training Loss: 0.417519 | Validation Accuracy: 0.960232\n",
      "Accuracy on Test data: 0.7817600965499878\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 29 | Training Loss: 0.424114 | Validation Accuracy: 0.958724\n",
      "Accuracy on Test data: 0.7806511521339417\n",
      "Step 30 | Training Loss: 0.404148 | Validation Accuracy: 0.956739\n",
      "Accuracy on Test data: 0.779985785484314\n",
      "Step 31 | Training Loss: 0.424002 | Validation Accuracy: 0.958168\n",
      "Accuracy on Test data: 0.7787438035011292\n",
      "Step 32 | Training Loss: 0.411622 | Validation Accuracy: 0.956342\n",
      "Accuracy on Test data: 0.7767033576965332\n",
      "Step 33 | Training Loss: 0.395796 | Validation Accuracy: 0.961105\n",
      "Accuracy on Test data: 0.7754169702529907\n",
      "Step 34 | Training Loss: 0.403996 | Validation Accuracy: 0.957850\n",
      "Accuracy on Test data: 0.7751508355140686\n",
      "Step 35 | Training Loss: 0.389845 | Validation Accuracy: 0.961105\n",
      "Accuracy on Test data: 0.7746185064315796\n",
      "Step 36 | Training Loss: 0.398625 | Validation Accuracy: 0.961026\n",
      "Accuracy on Test data: 0.7736870050430298\n",
      "Step 37 | Training Loss: 0.385626 | Validation Accuracy: 0.962613\n",
      "Accuracy on Test data: 0.7726668119430542\n",
      "Step 38 | Training Loss: 0.379066 | Validation Accuracy: 0.964201\n",
      "Accuracy on Test data: 0.7716465592384338\n",
      "Step 39 | Training Loss: 0.377737 | Validation Accuracy: 0.962375\n",
      "Accuracy on Test data: 0.7703158259391785\n",
      "Step 40 | Training Loss: 0.386975 | Validation Accuracy: 0.964042\n",
      "Accuracy on Test data: 0.7697391510009766\n",
      "Step 41 | Training Loss: 0.373326 | Validation Accuracy: 0.962057\n",
      "Accuracy on Test data: 0.768718957901001\n",
      "Step 42 | Training Loss: 0.371487 | Validation Accuracy: 0.964280\n",
      "Accuracy on Test data: 0.7685858607292175\n",
      "Step 43 | Training Loss: 0.369973 | Validation Accuracy: 0.964915\n",
      "Accuracy on Test data: 0.7669446468353271\n",
      "Step 44 | Training Loss: 0.371603 | Validation Accuracy: 0.964994\n",
      "Accuracy on Test data: 0.7660574913024902\n",
      "Step 45 | Training Loss: 0.386183 | Validation Accuracy: 0.964915\n",
      "Accuracy on Test data: 0.7624201774597168\n",
      "Step 46 | Training Loss: 0.367484 | Validation Accuracy: 0.965629\n",
      "Accuracy on Test data: 0.7616660594940186\n",
      "Step 47 | Training Loss: 0.374711 | Validation Accuracy: 0.963248\n",
      "Accuracy on Test data: 0.760645866394043\n",
      "Step 48 | Training Loss: 0.372640 | Validation Accuracy: 0.966979\n",
      "Accuracy on Test data: 0.7590489983558655\n",
      "Step 49 | Training Loss: 0.365543 | Validation Accuracy: 0.966820\n",
      "Accuracy on Test data: 0.7584279775619507\n",
      "Step 50 | Training Loss: 0.372546 | Validation Accuracy: 0.967535\n",
      "Accuracy on Test data: 0.7581618428230286\n",
      "Step 51 | Training Loss: 0.371681 | Validation Accuracy: 0.966741\n",
      "Accuracy on Test data: 0.7578069567680359\n",
      "Step 52 | Training Loss: 0.368094 | Validation Accuracy: 0.965233\n",
      "Accuracy on Test data: 0.757230281829834\n",
      "Step 53 | Training Loss: 0.381731 | Validation Accuracy: 0.964359\n",
      "Accuracy on Test data: 0.7568754553794861\n",
      "Step 54 | Training Loss: 0.368851 | Validation Accuracy: 0.968249\n",
      "Accuracy on Test data: 0.7565205693244934\n",
      "Step 55 | Training Loss: 0.354166 | Validation Accuracy: 0.968090\n",
      "Accuracy on Test data: 0.7567867040634155\n",
      "Step 56 | Training Loss: 0.351407 | Validation Accuracy: 0.966900\n",
      "Accuracy on Test data: 0.7567867040634155\n",
      "Step 57 | Training Loss: 0.360172 | Validation Accuracy: 0.966264\n",
      "Accuracy on Test data: 0.755722165107727\n",
      "Step 58 | Training Loss: 0.351268 | Validation Accuracy: 0.966185\n",
      "Accuracy on Test data: 0.7544357776641846\n",
      "Step 59 | Training Loss: 0.361857 | Validation Accuracy: 0.967455\n",
      "Accuracy on Test data: 0.7539478540420532\n",
      "Step 60 | Training Loss: 0.358887 | Validation Accuracy: 0.968805\n",
      "Accuracy on Test data: 0.7523509860038757\n",
      "Step 61 | Training Loss: 0.355484 | Validation Accuracy: 0.970551\n",
      "Accuracy on Test data: 0.7500443458557129\n",
      "Step 62 | Training Loss: 0.353384 | Validation Accuracy: 0.969360\n",
      "Accuracy on Test data: 0.748846709728241\n",
      "Step 63 | Training Loss: 0.360718 | Validation Accuracy: 0.971742\n",
      "Accuracy on Test data: 0.7472054362297058\n",
      "Step 64 | Training Loss: 0.356620 | Validation Accuracy: 0.971980\n",
      "Accuracy on Test data: 0.7460521459579468\n",
      "Step 65 | Training Loss: 0.355590 | Validation Accuracy: 0.974599\n",
      "Accuracy on Test data: 0.7455642223358154\n",
      "Step 66 | Training Loss: 0.352880 | Validation Accuracy: 0.972059\n",
      "Accuracy on Test data: 0.7453867793083191\n",
      "Step 67 | Training Loss: 0.348478 | Validation Accuracy: 0.971186\n",
      "Accuracy on Test data: 0.744810163974762\n",
      "Step 68 | Training Loss: 0.349454 | Validation Accuracy: 0.973012\n",
      "Accuracy on Test data: 0.7444109320640564\n",
      "Step 69 | Training Loss: 0.349874 | Validation Accuracy: 0.972297\n",
      "Accuracy on Test data: 0.7436568737030029\n",
      "Step 70 | Training Loss: 0.351592 | Validation Accuracy: 0.971107\n",
      "Accuracy on Test data: 0.7433019876480103\n",
      "Step 71 | Training Loss: 0.361369 | Validation Accuracy: 0.974758\n",
      "Accuracy on Test data: 0.7432576417922974\n",
      "Step 72 | Training Loss: 0.353656 | Validation Accuracy: 0.971345\n",
      "Accuracy on Test data: 0.7431245446205139\n",
      "Step 73 | Training Loss: 0.357152 | Validation Accuracy: 0.974520\n",
      "Accuracy on Test data: 0.742769718170166\n",
      "Step 74 | Training Loss: 0.333602 | Validation Accuracy: 0.973012\n",
      "Accuracy on Test data: 0.741926908493042\n",
      "Step 75 | Training Loss: 0.359454 | Validation Accuracy: 0.976663\n",
      "Accuracy on Test data: 0.7417051196098328\n",
      "Step 76 | Training Loss: 0.352208 | Validation Accuracy: 0.971345\n",
      "Accuracy on Test data: 0.7415720224380493\n",
      "Step 77 | Training Loss: 0.343051 | Validation Accuracy: 0.973091\n",
      "Accuracy on Test data: 0.7414389848709106\n",
      "Step 78 | Training Loss: 0.347835 | Validation Accuracy: 0.971742\n",
      "Accuracy on Test data: 0.7405961751937866\n",
      "Step 79 | Training Loss: 0.339155 | Validation Accuracy: 0.972773\n",
      "Accuracy on Test data: 0.7399751543998718\n",
      "Step 80 | Training Loss: 0.345661 | Validation Accuracy: 0.970710\n",
      "Accuracy on Test data: 0.7396202683448792\n",
      "Step 81 | Training Loss: 0.340414 | Validation Accuracy: 0.971900\n",
      "Accuracy on Test data: 0.7386887669563293\n",
      "Step 82 | Training Loss: 0.347126 | Validation Accuracy: 0.971583\n",
      "Accuracy on Test data: 0.7376685738563538\n",
      "Step 83 | Training Loss: 0.349489 | Validation Accuracy: 0.972535\n",
      "Accuracy on Test data: 0.7355393767356873\n",
      "Step 84 | Training Loss: 0.354722 | Validation Accuracy: 0.973726\n",
      "Accuracy on Test data: 0.7349183559417725\n",
      "Step 85 | Training Loss: 0.354983 | Validation Accuracy: 0.974282\n",
      "Accuracy on Test data: 0.7347409725189209\n",
      "Step 86 | Training Loss: 0.355725 | Validation Accuracy: 0.972694\n",
      "Accuracy on Test data: 0.7346078753471375\n",
      "Step 87 | Training Loss: 0.335908 | Validation Accuracy: 0.971265\n",
      "Accuracy on Test data: 0.7345191836357117\n",
      "Step 88 | Training Loss: 0.348120 | Validation Accuracy: 0.972932\n",
      "Accuracy on Test data: 0.7343417406082153\n",
      "Step 89 | Training Loss: 0.338037 | Validation Accuracy: 0.970948\n",
      "Accuracy on Test data: 0.7342529892921448\n",
      "Step 90 | Training Loss: 0.351764 | Validation Accuracy: 0.971821\n",
      "Accuracy on Test data: 0.7341199517250061\n",
      "Step 91 | Training Loss: 0.336355 | Validation Accuracy: 0.973567\n",
      "Accuracy on Test data: 0.7343860864639282\n",
      "Step 92 | Training Loss: 0.345548 | Validation Accuracy: 0.974917\n",
      "Accuracy on Test data: 0.7346965670585632\n",
      "Step 93 | Training Loss: 0.334610 | Validation Accuracy: 0.974599\n",
      "Accuracy on Test data: 0.7343860864639282\n",
      "Step 94 | Training Loss: 0.349962 | Validation Accuracy: 0.972297\n",
      "Accuracy on Test data: 0.7345191836357117\n",
      "Step 95 | Training Loss: 0.343013 | Validation Accuracy: 0.973408\n",
      "Accuracy on Test data: 0.7343860864639282\n",
      "Step 96 | Training Loss: 0.331700 | Validation Accuracy: 0.972059\n",
      "Accuracy on Test data: 0.7342529892921448\n",
      "Step 97 | Training Loss: 0.333867 | Validation Accuracy: 0.972615\n",
      "Accuracy on Test data: 0.7342973947525024\n",
      "Step 98 | Training Loss: 0.342089 | Validation Accuracy: 0.973885\n",
      "Accuracy on Test data: 0.7343860864639282\n",
      "Step 99 | Training Loss: 0.358166 | Validation Accuracy: 0.972218\n",
      "Accuracy on Test data: 0.7343417406082153\n",
      "Step 100 | Training Loss: 0.338649 | Validation Accuracy: 0.974043\n",
      "Accuracy on Test data: 0.7339425086975098\n",
      "Current Layer Attributes - epochs:100 hidden layers:4 features count:64\n",
      "Step 1 | Training Loss: 0.719585 | Validation Accuracy: 0.565645\n",
      "Accuracy on Test data: 0.6141323447227478\n",
      "Step 2 | Training Loss: 0.667789 | Validation Accuracy: 0.833386\n",
      "Accuracy on Test data: 0.8844925761222839\n",
      "Step 3 | Training Loss: 0.672807 | Validation Accuracy: 0.899349\n",
      "Accuracy on Test data: 0.8763750791549683\n",
      "Step 4 | Training Loss: 0.655954 | Validation Accuracy: 0.923321\n",
      "Accuracy on Test data: 0.8266944885253906\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 5 | Training Loss: 0.632847 | Validation Accuracy: 0.930148\n",
      "Accuracy on Test data: 0.813342809677124\n",
      "Step 6 | Training Loss: 0.605739 | Validation Accuracy: 0.938085\n",
      "Accuracy on Test data: 0.8152945637702942\n",
      "Step 7 | Training Loss: 0.589402 | Validation Accuracy: 0.942292\n",
      "Accuracy on Test data: 0.8154276013374329\n",
      "Step 8 | Training Loss: 0.546290 | Validation Accuracy: 0.947769\n",
      "Accuracy on Test data: 0.8147178888320923\n",
      "Step 9 | Training Loss: 0.553200 | Validation Accuracy: 0.952532\n",
      "Accuracy on Test data: 0.8147622346878052\n",
      "Step 10 | Training Loss: 0.513729 | Validation Accuracy: 0.954834\n",
      "Accuracy on Test data: 0.8134315013885498\n",
      "Step 11 | Training Loss: 0.509545 | Validation Accuracy: 0.950786\n",
      "Accuracy on Test data: 0.8113910555839539\n",
      "Step 12 | Training Loss: 0.480176 | Validation Accuracy: 0.953247\n",
      "Accuracy on Test data: 0.8094393014907837\n",
      "Step 13 | Training Loss: 0.473095 | Validation Accuracy: 0.956183\n",
      "Accuracy on Test data: 0.8066004514694214\n",
      "Step 14 | Training Loss: 0.458193 | Validation Accuracy: 0.955549\n",
      "Accuracy on Test data: 0.8023420572280884\n",
      "Step 15 | Training Loss: 0.424972 | Validation Accuracy: 0.959756\n",
      "Accuracy on Test data: 0.8008782863616943\n",
      "Step 16 | Training Loss: 0.429525 | Validation Accuracy: 0.957692\n",
      "Accuracy on Test data: 0.7985717058181763\n",
      "Step 17 | Training Loss: 0.418086 | Validation Accuracy: 0.960946\n",
      "Accuracy on Test data: 0.7967529892921448\n",
      "Step 18 | Training Loss: 0.406313 | Validation Accuracy: 0.962851\n",
      "Accuracy on Test data: 0.7950674295425415\n",
      "Step 19 | Training Loss: 0.396389 | Validation Accuracy: 0.965312\n",
      "Accuracy on Test data: 0.794313371181488\n",
      "Step 20 | Training Loss: 0.389641 | Validation Accuracy: 0.962851\n",
      "Accuracy on Test data: 0.7931156754493713\n",
      "Step 21 | Training Loss: 0.381679 | Validation Accuracy: 0.966979\n",
      "Accuracy on Test data: 0.7912083268165588\n",
      "Step 22 | Training Loss: 0.379175 | Validation Accuracy: 0.965709\n",
      "Accuracy on Test data: 0.7892565727233887\n",
      "Step 23 | Training Loss: 0.392587 | Validation Accuracy: 0.964201\n",
      "Accuracy on Test data: 0.7884137630462646\n",
      "Step 24 | Training Loss: 0.391053 | Validation Accuracy: 0.964598\n",
      "Accuracy on Test data: 0.7875709533691406\n",
      "Step 25 | Training Loss: 0.385422 | Validation Accuracy: 0.964836\n",
      "Accuracy on Test data: 0.7865064144134521\n",
      "Step 26 | Training Loss: 0.360954 | Validation Accuracy: 0.967376\n",
      "Accuracy on Test data: 0.7850869297981262\n",
      "Step 27 | Training Loss: 0.356895 | Validation Accuracy: 0.964915\n",
      "Accuracy on Test data: 0.7840667366981506\n",
      "Step 28 | Training Loss: 0.357814 | Validation Accuracy: 0.966661\n",
      "Accuracy on Test data: 0.7829577922821045\n",
      "Step 29 | Training Loss: 0.363620 | Validation Accuracy: 0.969519\n",
      "Accuracy on Test data: 0.7820262312889099\n",
      "Step 30 | Training Loss: 0.367746 | Validation Accuracy: 0.968328\n",
      "Accuracy on Test data: 0.7809616923332214\n",
      "Step 31 | Training Loss: 0.357439 | Validation Accuracy: 0.965471\n",
      "Accuracy on Test data: 0.7798527479171753\n",
      "Step 32 | Training Loss: 0.359762 | Validation Accuracy: 0.968725\n",
      "Accuracy on Test data: 0.7785663604736328\n",
      "Step 33 | Training Loss: 0.363881 | Validation Accuracy: 0.969281\n",
      "Accuracy on Test data: 0.777945339679718\n",
      "Step 34 | Training Loss: 0.363148 | Validation Accuracy: 0.967773\n",
      "Accuracy on Test data: 0.7768363952636719\n",
      "Step 35 | Training Loss: 0.359030 | Validation Accuracy: 0.969122\n",
      "Accuracy on Test data: 0.7752395272254944\n",
      "Step 36 | Training Loss: 0.363811 | Validation Accuracy: 0.970948\n",
      "Accuracy on Test data: 0.7745298147201538\n",
      "Step 37 | Training Loss: 0.353908 | Validation Accuracy: 0.968090\n",
      "Accuracy on Test data: 0.7735095620155334\n",
      "Step 38 | Training Loss: 0.351234 | Validation Accuracy: 0.969440\n",
      "Accuracy on Test data: 0.7735095620155334\n",
      "Step 39 | Training Loss: 0.362296 | Validation Accuracy: 0.970789\n",
      "Accuracy on Test data: 0.7729329466819763\n",
      "Step 40 | Training Loss: 0.361609 | Validation Accuracy: 0.968249\n",
      "Accuracy on Test data: 0.7716465592384338\n",
      "Step 41 | Training Loss: 0.356571 | Validation Accuracy: 0.970392\n",
      "Accuracy on Test data: 0.7696948051452637\n",
      "Step 42 | Training Loss: 0.355622 | Validation Accuracy: 0.969043\n",
      "Accuracy on Test data: 0.7682310342788696\n",
      "Step 43 | Training Loss: 0.360059 | Validation Accuracy: 0.970313\n",
      "Accuracy on Test data: 0.7656139135360718\n",
      "Step 44 | Training Loss: 0.351402 | Validation Accuracy: 0.971265\n",
      "Accuracy on Test data: 0.7652590274810791\n",
      "Step 45 | Training Loss: 0.361998 | Validation Accuracy: 0.973091\n",
      "Accuracy on Test data: 0.7652590274810791\n",
      "Step 46 | Training Loss: 0.353429 | Validation Accuracy: 0.970472\n",
      "Accuracy on Test data: 0.7649042010307312\n",
      "Step 47 | Training Loss: 0.370545 | Validation Accuracy: 0.970154\n",
      "Accuracy on Test data: 0.7645936608314514\n",
      "Step 48 | Training Loss: 0.337478 | Validation Accuracy: 0.972853\n",
      "Accuracy on Test data: 0.7644606232643127\n",
      "Step 49 | Training Loss: 0.361580 | Validation Accuracy: 0.970630\n",
      "Accuracy on Test data: 0.7641944885253906\n",
      "Step 50 | Training Loss: 0.347491 | Validation Accuracy: 0.971742\n",
      "Accuracy on Test data: 0.7639282941818237\n",
      "Step 51 | Training Loss: 0.340061 | Validation Accuracy: 0.972297\n",
      "Accuracy on Test data: 0.7625088691711426\n",
      "Step 52 | Training Loss: 0.344915 | Validation Accuracy: 0.970233\n",
      "Accuracy on Test data: 0.7610006928443909\n",
      "Step 53 | Training Loss: 0.351792 | Validation Accuracy: 0.971742\n",
      "Accuracy on Test data: 0.7607345581054688\n",
      "Step 54 | Training Loss: 0.339887 | Validation Accuracy: 0.971265\n",
      "Accuracy on Test data: 0.7593151330947876\n",
      "Step 55 | Training Loss: 0.341715 | Validation Accuracy: 0.971345\n",
      "Accuracy on Test data: 0.7575851678848267\n",
      "Step 56 | Training Loss: 0.353298 | Validation Accuracy: 0.972377\n",
      "Accuracy on Test data: 0.7573190331459045\n",
      "Step 57 | Training Loss: 0.340456 | Validation Accuracy: 0.969360\n",
      "Accuracy on Test data: 0.7568754553794861\n",
      "Step 58 | Training Loss: 0.353823 | Validation Accuracy: 0.972773\n",
      "Accuracy on Test data: 0.756609320640564\n",
      "Step 59 | Training Loss: 0.342737 | Validation Accuracy: 0.969360\n",
      "Accuracy on Test data: 0.7561657428741455\n",
      "Step 60 | Training Loss: 0.342281 | Validation Accuracy: 0.969678\n",
      "Accuracy on Test data: 0.7560326457023621\n",
      "Step 61 | Training Loss: 0.341166 | Validation Accuracy: 0.972535\n",
      "Accuracy on Test data: 0.7555003762245178\n",
      "Step 62 | Training Loss: 0.341210 | Validation Accuracy: 0.974361\n",
      "Accuracy on Test data: 0.7550567984580994\n",
      "Step 63 | Training Loss: 0.346403 | Validation Accuracy: 0.971027\n",
      "Accuracy on Test data: 0.7550567984580994\n",
      "Step 64 | Training Loss: 0.353493 | Validation Accuracy: 0.971107\n",
      "Accuracy on Test data: 0.7549680471420288\n",
      "Step 65 | Training Loss: 0.346124 | Validation Accuracy: 0.973805\n",
      "Accuracy on Test data: 0.754879355430603\n",
      "Step 66 | Training Loss: 0.348407 | Validation Accuracy: 0.970551\n",
      "Accuracy on Test data: 0.7547462582588196\n",
      "Step 67 | Training Loss: 0.334915 | Validation Accuracy: 0.971900\n",
      "Accuracy on Test data: 0.7547462582588196\n",
      "Step 68 | Training Loss: 0.333216 | Validation Accuracy: 0.969916\n",
      "Accuracy on Test data: 0.7546575665473938\n",
      "Step 69 | Training Loss: 0.340878 | Validation Accuracy: 0.972138\n",
      "Accuracy on Test data: 0.754347026348114\n",
      "Step 70 | Training Loss: 0.342617 | Validation Accuracy: 0.971424\n",
      "Accuracy on Test data: 0.7542583346366882\n",
      "Step 71 | Training Loss: 0.340858 | Validation Accuracy: 0.972218\n",
      "Accuracy on Test data: 0.7541696429252625\n",
      "Step 72 | Training Loss: 0.334759 | Validation Accuracy: 0.972456\n",
      "Accuracy on Test data: 0.7539478540420532\n",
      "Step 73 | Training Loss: 0.337344 | Validation Accuracy: 0.973012\n",
      "Accuracy on Test data: 0.7536373138427734\n",
      "Step 74 | Training Loss: 0.344092 | Validation Accuracy: 0.973012\n",
      "Accuracy on Test data: 0.7535042762756348\n",
      "Step 75 | Training Loss: 0.333927 | Validation Accuracy: 0.972377\n",
      "Accuracy on Test data: 0.7533268332481384\n",
      "Step 76 | Training Loss: 0.341114 | Validation Accuracy: 0.973250\n",
      "Accuracy on Test data: 0.753193736076355\n",
      "Step 77 | Training Loss: 0.351653 | Validation Accuracy: 0.973012\n",
      "Accuracy on Test data: 0.75288325548172\n",
      "Step 78 | Training Loss: 0.339672 | Validation Accuracy: 0.975393\n",
      "Accuracy on Test data: 0.7532381415367126\n",
      "Step 79 | Training Loss: 0.344631 | Validation Accuracy: 0.974679\n",
      "Accuracy on Test data: 0.7533268332481384\n",
      "Step 80 | Training Loss: 0.342972 | Validation Accuracy: 0.975552\n",
      "Accuracy on Test data: 0.7529276013374329\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 81 | Training Loss: 0.336424 | Validation Accuracy: 0.976663\n",
      "Accuracy on Test data: 0.7527945637702942\n",
      "Step 82 | Training Loss: 0.339816 | Validation Accuracy: 0.975790\n",
      "Accuracy on Test data: 0.75288325548172\n",
      "Step 83 | Training Loss: 0.350864 | Validation Accuracy: 0.975552\n",
      "Accuracy on Test data: 0.75288325548172\n",
      "Step 84 | Training Loss: 0.342899 | Validation Accuracy: 0.974599\n",
      "Accuracy on Test data: 0.7528389096260071\n",
      "Step 85 | Training Loss: 0.344312 | Validation Accuracy: 0.974520\n",
      "Accuracy on Test data: 0.7528389096260071\n",
      "Step 86 | Training Loss: 0.335077 | Validation Accuracy: 0.973091\n",
      "Accuracy on Test data: 0.7527501583099365\n",
      "Step 87 | Training Loss: 0.338147 | Validation Accuracy: 0.976028\n",
      "Accuracy on Test data: 0.7526614665985107\n",
      "Step 88 | Training Loss: 0.331838 | Validation Accuracy: 0.975710\n",
      "Accuracy on Test data: 0.7523509860038757\n",
      "Step 89 | Training Loss: 0.335126 | Validation Accuracy: 0.975472\n",
      "Accuracy on Test data: 0.7524396777153015\n",
      "Step 90 | Training Loss: 0.348008 | Validation Accuracy: 0.975234\n",
      "Accuracy on Test data: 0.7522622346878052\n",
      "Step 91 | Training Loss: 0.340160 | Validation Accuracy: 0.974599\n",
      "Accuracy on Test data: 0.7524396777153015\n",
      "Step 92 | Training Loss: 0.348015 | Validation Accuracy: 0.975552\n",
      "Accuracy on Test data: 0.7523509860038757\n",
      "Step 93 | Training Loss: 0.344494 | Validation Accuracy: 0.976107\n",
      "Accuracy on Test data: 0.7518630027770996\n",
      "Step 94 | Training Loss: 0.338863 | Validation Accuracy: 0.975472\n",
      "Accuracy on Test data: 0.752040445804596\n",
      "Step 95 | Training Loss: 0.349024 | Validation Accuracy: 0.977536\n",
      "Accuracy on Test data: 0.7519074082374573\n",
      "Step 96 | Training Loss: 0.335033 | Validation Accuracy: 0.977854\n",
      "Accuracy on Test data: 0.7518186569213867\n",
      "Step 97 | Training Loss: 0.346551 | Validation Accuracy: 0.975155\n",
      "Accuracy on Test data: 0.7519960999488831\n",
      "Step 98 | Training Loss: 0.334737 | Validation Accuracy: 0.976822\n",
      "Accuracy on Test data: 0.7519517540931702\n",
      "Step 99 | Training Loss: 0.338133 | Validation Accuracy: 0.976663\n",
      "Accuracy on Test data: 0.7519960999488831\n",
      "Step 100 | Training Loss: 0.330891 | Validation Accuracy: 0.977695\n",
      "Accuracy on Test data: 0.7518186569213867\n",
      "Current Layer Attributes - epochs:100 hidden layers:6 features count:4\n",
      "Step 1 | Training Loss: 0.697056 | Validation Accuracy: 0.300365\n",
      "Accuracy on Test data: 0.2881919741630554\n",
      "Step 2 | Training Loss: 0.690051 | Validation Accuracy: 0.286077\n",
      "Accuracy on Test data: 0.2686302363872528\n",
      "Step 3 | Training Loss: 0.696545 | Validation Accuracy: 0.297904\n",
      "Accuracy on Test data: 0.27319908142089844\n",
      "Step 4 | Training Loss: 0.692127 | Validation Accuracy: 0.366804\n",
      "Accuracy on Test data: 0.311479777097702\n",
      "Step 5 | Training Loss: 0.695793 | Validation Accuracy: 0.409430\n",
      "Accuracy on Test data: 0.37513306736946106\n",
      "Step 6 | Training Loss: 0.695933 | Validation Accuracy: 0.493967\n",
      "Accuracy on Test data: 0.4614531695842743\n",
      "Step 7 | Training Loss: 0.694045 | Validation Accuracy: 0.512542\n",
      "Accuracy on Test data: 0.4729418158531189\n",
      "Step 8 | Training Loss: 0.690068 | Validation Accuracy: 0.530322\n",
      "Accuracy on Test data: 0.476091206073761\n",
      "Step 9 | Training Loss: 0.694366 | Validation Accuracy: 0.541991\n",
      "Accuracy on Test data: 0.471344918012619\n",
      "Step 10 | Training Loss: 0.698058 | Validation Accuracy: 0.529449\n",
      "Accuracy on Test data: 0.4667760729789734\n",
      "Step 11 | Training Loss: 0.689222 | Validation Accuracy: 0.544134\n",
      "Accuracy on Test data: 0.46664300560951233\n",
      "Step 12 | Training Loss: 0.690719 | Validation Accuracy: 0.530084\n",
      "Accuracy on Test data: 0.46659865975379944\n",
      "Step 13 | Training Loss: 0.692511 | Validation Accuracy: 0.533577\n",
      "Accuracy on Test data: 0.4652235507965088\n",
      "Step 14 | Training Loss: 0.693126 | Validation Accuracy: 0.536514\n",
      "Accuracy on Test data: 0.4487668573856354\n",
      "Step 15 | Training Loss: 0.691643 | Validation Accuracy: 0.531037\n",
      "Accuracy on Test data: 0.44229063391685486\n",
      "Step 16 | Training Loss: 0.696677 | Validation Accuracy: 0.535085\n",
      "Accuracy on Test data: 0.4422019124031067\n",
      "Step 17 | Training Loss: 0.692835 | Validation Accuracy: 0.536355\n",
      "Accuracy on Test data: 0.44202449917793274\n",
      "Step 18 | Training Loss: 0.692770 | Validation Accuracy: 0.532148\n",
      "Accuracy on Test data: 0.44202449917793274\n",
      "Step 19 | Training Loss: 0.690211 | Validation Accuracy: 0.530084\n",
      "Accuracy on Test data: 0.4413147568702698\n",
      "Step 20 | Training Loss: 0.689576 | Validation Accuracy: 0.530402\n",
      "Accuracy on Test data: 0.4413147568702698\n",
      "Step 21 | Training Loss: 0.695634 | Validation Accuracy: 0.540244\n",
      "Accuracy on Test data: 0.4412260353565216\n",
      "Step 22 | Training Loss: 0.692511 | Validation Accuracy: 0.536117\n",
      "Accuracy on Test data: 0.4362579882144928\n",
      "Step 23 | Training Loss: 0.693279 | Validation Accuracy: 0.537149\n",
      "Accuracy on Test data: 0.43333038687705994\n",
      "Step 24 | Training Loss: 0.686715 | Validation Accuracy: 0.536990\n",
      "Accuracy on Test data: 0.4309350550174713\n",
      "Step 25 | Training Loss: 0.686471 | Validation Accuracy: 0.533180\n",
      "Accuracy on Test data: 0.43075764179229736\n",
      "Step 26 | Training Loss: 0.691605 | Validation Accuracy: 0.533100\n",
      "Accuracy on Test data: 0.43075764179229736\n",
      "Step 27 | Training Loss: 0.691567 | Validation Accuracy: 0.536831\n",
      "Accuracy on Test data: 0.43075764179229736\n",
      "Step 28 | Training Loss: 0.689313 | Validation Accuracy: 0.535799\n",
      "Accuracy on Test data: 0.43075764179229736\n",
      "Step 29 | Training Loss: 0.682890 | Validation Accuracy: 0.531513\n",
      "Accuracy on Test data: 0.43075764179229736\n",
      "Step 30 | Training Loss: 0.689966 | Validation Accuracy: 0.529687\n",
      "Accuracy on Test data: 0.43075764179229736\n",
      "Step 31 | Training Loss: 0.691962 | Validation Accuracy: 0.531672\n",
      "Accuracy on Test data: 0.43075764179229736\n",
      "Step 32 | Training Loss: 0.684524 | Validation Accuracy: 0.533259\n",
      "Accuracy on Test data: 0.43075764179229736\n",
      "Step 33 | Training Loss: 0.693088 | Validation Accuracy: 0.538657\n",
      "Accuracy on Test data: 0.43075764179229736\n",
      "Step 34 | Training Loss: 0.691250 | Validation Accuracy: 0.533259\n",
      "Accuracy on Test data: 0.43075764179229736\n",
      "Step 35 | Training Loss: 0.689921 | Validation Accuracy: 0.536276\n",
      "Accuracy on Test data: 0.43075764179229736\n",
      "Step 36 | Training Loss: 0.692647 | Validation Accuracy: 0.539768\n",
      "Accuracy on Test data: 0.43075764179229736\n",
      "Step 37 | Training Loss: 0.686173 | Validation Accuracy: 0.527227\n",
      "Accuracy on Test data: 0.43075764179229736\n",
      "Step 38 | Training Loss: 0.685461 | Validation Accuracy: 0.530560\n",
      "Accuracy on Test data: 0.43075764179229736\n",
      "Step 39 | Training Loss: 0.691624 | Validation Accuracy: 0.540244\n",
      "Accuracy on Test data: 0.43075764179229736\n",
      "Step 40 | Training Loss: 0.683236 | Validation Accuracy: 0.529608\n",
      "Accuracy on Test data: 0.43075764179229736\n",
      "Step 41 | Training Loss: 0.685313 | Validation Accuracy: 0.532942\n",
      "Accuracy on Test data: 0.43075764179229736\n",
      "Step 42 | Training Loss: 0.685099 | Validation Accuracy: 0.525321\n",
      "Accuracy on Test data: 0.43075764179229736\n",
      "Step 43 | Training Loss: 0.682986 | Validation Accuracy: 0.536434\n",
      "Accuracy on Test data: 0.43075764179229736\n",
      "Step 44 | Training Loss: 0.682399 | Validation Accuracy: 0.535085\n",
      "Accuracy on Test data: 0.43075764179229736\n",
      "Step 45 | Training Loss: 0.684772 | Validation Accuracy: 0.532942\n",
      "Accuracy on Test data: 0.43075764179229736\n",
      "Step 46 | Training Loss: 0.689878 | Validation Accuracy: 0.528576\n",
      "Accuracy on Test data: 0.43075764179229736\n",
      "Step 47 | Training Loss: 0.685351 | Validation Accuracy: 0.534132\n",
      "Accuracy on Test data: 0.43075764179229736\n",
      "Step 48 | Training Loss: 0.682557 | Validation Accuracy: 0.530640\n",
      "Accuracy on Test data: 0.43075764179229736\n",
      "Step 49 | Training Loss: 0.685564 | Validation Accuracy: 0.528179\n",
      "Accuracy on Test data: 0.43075764179229736\n",
      "Step 50 | Training Loss: 0.683201 | Validation Accuracy: 0.536752\n",
      "Accuracy on Test data: 0.43075764179229736\n",
      "Step 51 | Training Loss: 0.683523 | Validation Accuracy: 0.533180\n",
      "Accuracy on Test data: 0.43075764179229736\n",
      "Step 52 | Training Loss: 0.681062 | Validation Accuracy: 0.537863\n",
      "Accuracy on Test data: 0.43075764179229736\n",
      "Step 53 | Training Loss: 0.689397 | Validation Accuracy: 0.533815\n",
      "Accuracy on Test data: 0.43075764179229736\n",
      "Step 54 | Training Loss: 0.681765 | Validation Accuracy: 0.531592\n",
      "Accuracy on Test data: 0.43075764179229736\n",
      "Step 55 | Training Loss: 0.679556 | Validation Accuracy: 0.537784\n",
      "Accuracy on Test data: 0.43075764179229736\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 56 | Training Loss: 0.680730 | Validation Accuracy: 0.528020\n",
      "Accuracy on Test data: 0.43075764179229736\n",
      "Step 57 | Training Loss: 0.687763 | Validation Accuracy: 0.537149\n",
      "Accuracy on Test data: 0.43075764179229736\n",
      "Step 58 | Training Loss: 0.684347 | Validation Accuracy: 0.546357\n",
      "Accuracy on Test data: 0.43075764179229736\n",
      "Step 59 | Training Loss: 0.677017 | Validation Accuracy: 0.534609\n",
      "Accuracy on Test data: 0.43075764179229736\n",
      "Step 60 | Training Loss: 0.679873 | Validation Accuracy: 0.532704\n",
      "Accuracy on Test data: 0.43075764179229736\n",
      "Step 61 | Training Loss: 0.678963 | Validation Accuracy: 0.533656\n",
      "Accuracy on Test data: 0.43075764179229736\n",
      "Step 62 | Training Loss: 0.680195 | Validation Accuracy: 0.528179\n",
      "Accuracy on Test data: 0.43075764179229736\n",
      "Step 63 | Training Loss: 0.685780 | Validation Accuracy: 0.532465\n",
      "Accuracy on Test data: 0.43075764179229736\n",
      "Step 64 | Training Loss: 0.684111 | Validation Accuracy: 0.538022\n",
      "Accuracy on Test data: 0.43075764179229736\n",
      "Step 65 | Training Loss: 0.681600 | Validation Accuracy: 0.536752\n",
      "Accuracy on Test data: 0.43075764179229736\n",
      "Step 66 | Training Loss: 0.679358 | Validation Accuracy: 0.541197\n",
      "Accuracy on Test data: 0.43075764179229736\n",
      "Step 67 | Training Loss: 0.681530 | Validation Accuracy: 0.537387\n",
      "Accuracy on Test data: 0.43075764179229736\n",
      "Step 68 | Training Loss: 0.674323 | Validation Accuracy: 0.539451\n",
      "Accuracy on Test data: 0.43075764179229736\n",
      "Step 69 | Training Loss: 0.685030 | Validation Accuracy: 0.537704\n",
      "Accuracy on Test data: 0.43075764179229736\n",
      "Step 70 | Training Loss: 0.689806 | Validation Accuracy: 0.538895\n",
      "Accuracy on Test data: 0.43075764179229736\n",
      "Step 71 | Training Loss: 0.680743 | Validation Accuracy: 0.539133\n",
      "Accuracy on Test data: 0.43075764179229736\n",
      "Step 72 | Training Loss: 0.683514 | Validation Accuracy: 0.532307\n",
      "Accuracy on Test data: 0.43075764179229736\n",
      "Step 73 | Training Loss: 0.674021 | Validation Accuracy: 0.533259\n",
      "Accuracy on Test data: 0.43075764179229736\n",
      "Step 74 | Training Loss: 0.677326 | Validation Accuracy: 0.530084\n",
      "Accuracy on Test data: 0.43075764179229736\n",
      "Step 75 | Training Loss: 0.671995 | Validation Accuracy: 0.538260\n",
      "Accuracy on Test data: 0.43075764179229736\n",
      "Step 76 | Training Loss: 0.675859 | Validation Accuracy: 0.531672\n",
      "Accuracy on Test data: 0.43075764179229736\n",
      "Step 77 | Training Loss: 0.673832 | Validation Accuracy: 0.538181\n",
      "Accuracy on Test data: 0.43075764179229736\n",
      "Step 78 | Training Loss: 0.672681 | Validation Accuracy: 0.538181\n",
      "Accuracy on Test data: 0.43075764179229736\n",
      "Step 79 | Training Loss: 0.677877 | Validation Accuracy: 0.535482\n",
      "Accuracy on Test data: 0.43075764179229736\n",
      "Step 80 | Training Loss: 0.683495 | Validation Accuracy: 0.528020\n",
      "Accuracy on Test data: 0.43075764179229736\n",
      "Step 81 | Training Loss: 0.672247 | Validation Accuracy: 0.539451\n",
      "Accuracy on Test data: 0.43075764179229736\n",
      "Step 82 | Training Loss: 0.673782 | Validation Accuracy: 0.540324\n",
      "Accuracy on Test data: 0.43075764179229736\n",
      "Step 83 | Training Loss: 0.671004 | Validation Accuracy: 0.534847\n",
      "Accuracy on Test data: 0.43075764179229736\n",
      "Step 84 | Training Loss: 0.671180 | Validation Accuracy: 0.538022\n",
      "Accuracy on Test data: 0.43075764179229736\n",
      "Step 85 | Training Loss: 0.681201 | Validation Accuracy: 0.535244\n",
      "Accuracy on Test data: 0.43075764179229736\n",
      "Step 86 | Training Loss: 0.676517 | Validation Accuracy: 0.535164\n",
      "Accuracy on Test data: 0.43075764179229736\n",
      "Step 87 | Training Loss: 0.683898 | Validation Accuracy: 0.535720\n",
      "Accuracy on Test data: 0.43075764179229736\n",
      "Step 88 | Training Loss: 0.685128 | Validation Accuracy: 0.531275\n",
      "Accuracy on Test data: 0.43075764179229736\n",
      "Step 89 | Training Loss: 0.676066 | Validation Accuracy: 0.529449\n",
      "Accuracy on Test data: 0.43075764179229736\n",
      "Step 90 | Training Loss: 0.685249 | Validation Accuracy: 0.538101\n",
      "Accuracy on Test data: 0.43075764179229736\n",
      "Step 91 | Training Loss: 0.680663 | Validation Accuracy: 0.538895\n",
      "Accuracy on Test data: 0.43075764179229736\n",
      "Step 92 | Training Loss: 0.679674 | Validation Accuracy: 0.531830\n",
      "Accuracy on Test data: 0.43075764179229736\n",
      "Step 93 | Training Loss: 0.672490 | Validation Accuracy: 0.532704\n",
      "Accuracy on Test data: 0.43075764179229736\n",
      "Step 94 | Training Loss: 0.674137 | Validation Accuracy: 0.536514\n",
      "Accuracy on Test data: 0.43075764179229736\n",
      "Step 95 | Training Loss: 0.664774 | Validation Accuracy: 0.538022\n",
      "Accuracy on Test data: 0.43075764179229736\n",
      "Step 96 | Training Loss: 0.671817 | Validation Accuracy: 0.536990\n",
      "Accuracy on Test data: 0.43075764179229736\n",
      "Step 97 | Training Loss: 0.668829 | Validation Accuracy: 0.543261\n",
      "Accuracy on Test data: 0.43075764179229736\n",
      "Step 98 | Training Loss: 0.674975 | Validation Accuracy: 0.536434\n",
      "Accuracy on Test data: 0.43075764179229736\n",
      "Step 99 | Training Loss: 0.679842 | Validation Accuracy: 0.531354\n",
      "Accuracy on Test data: 0.43075764179229736\n",
      "Step 100 | Training Loss: 0.669675 | Validation Accuracy: 0.534926\n",
      "Accuracy on Test data: 0.43075764179229736\n",
      "Current Layer Attributes - epochs:100 hidden layers:6 features count:8\n",
      "Step 1 | Training Loss: 0.702007 | Validation Accuracy: 0.558025\n",
      "Accuracy on Test data: 0.47342973947525024\n",
      "Step 2 | Training Loss: 0.693720 | Validation Accuracy: 0.564137\n",
      "Accuracy on Test data: 0.47715577483177185\n",
      "Step 3 | Training Loss: 0.703064 | Validation Accuracy: 0.563343\n",
      "Accuracy on Test data: 0.47405073046684265\n",
      "Step 4 | Training Loss: 0.705316 | Validation Accuracy: 0.575885\n",
      "Accuracy on Test data: 0.4741838276386261\n",
      "Step 5 | Training Loss: 0.691677 | Validation Accuracy: 0.559454\n",
      "Accuracy on Test data: 0.4708126187324524\n",
      "Step 6 | Training Loss: 0.698034 | Validation Accuracy: 0.556120\n",
      "Accuracy on Test data: 0.46908268332481384\n",
      "Step 7 | Training Loss: 0.693482 | Validation Accuracy: 0.555326\n",
      "Accuracy on Test data: 0.46730837225914\n",
      "Step 8 | Training Loss: 0.702206 | Validation Accuracy: 0.551119\n",
      "Accuracy on Test data: 0.46841731667518616\n",
      "Step 9 | Training Loss: 0.698548 | Validation Accuracy: 0.560803\n",
      "Accuracy on Test data: 0.4701472818851471\n",
      "Step 10 | Training Loss: 0.685536 | Validation Accuracy: 0.565169\n",
      "Accuracy on Test data: 0.46846166253089905\n",
      "Step 11 | Training Loss: 0.695589 | Validation Accuracy: 0.559613\n",
      "Accuracy on Test data: 0.4685060381889343\n",
      "Step 12 | Training Loss: 0.697731 | Validation Accuracy: 0.566122\n",
      "Accuracy on Test data: 0.46784067153930664\n",
      "Step 13 | Training Loss: 0.687823 | Validation Accuracy: 0.561676\n",
      "Accuracy on Test data: 0.4682398736476898\n",
      "Step 14 | Training Loss: 0.687773 | Validation Accuracy: 0.557946\n",
      "Accuracy on Test data: 0.46872782707214355\n",
      "Step 15 | Training Loss: 0.694194 | Validation Accuracy: 0.563343\n",
      "Accuracy on Test data: 0.4692157506942749\n",
      "Step 16 | Training Loss: 0.691572 | Validation Accuracy: 0.573980\n",
      "Accuracy on Test data: 0.4707239270210266\n",
      "Step 17 | Training Loss: 0.690351 | Validation Accuracy: 0.571281\n",
      "Accuracy on Test data: 0.4728530943393707\n",
      "Step 18 | Training Loss: 0.689187 | Validation Accuracy: 0.597317\n",
      "Accuracy on Test data: 0.47688964009284973\n",
      "Step 19 | Training Loss: 0.690961 | Validation Accuracy: 0.601842\n",
      "Accuracy on Test data: 0.48061567544937134\n",
      "Step 20 | Training Loss: 0.691411 | Validation Accuracy: 0.603985\n",
      "Accuracy on Test data: 0.48207947611808777\n",
      "Step 21 | Training Loss: 0.678118 | Validation Accuracy: 0.609938\n",
      "Accuracy on Test data: 0.4848296642303467\n",
      "Step 22 | Training Loss: 0.681852 | Validation Accuracy: 0.614860\n",
      "Accuracy on Test data: 0.4885556995868683\n",
      "Step 23 | Training Loss: 0.689642 | Validation Accuracy: 0.626449\n",
      "Accuracy on Test data: 0.49205997586250305\n",
      "Step 24 | Training Loss: 0.691964 | Validation Accuracy: 0.640022\n",
      "Accuracy on Test data: 0.4966288208961487\n",
      "Step 25 | Training Loss: 0.687447 | Validation Accuracy: 0.649944\n",
      "Accuracy on Test data: 0.49955642223358154\n",
      "Step 26 | Training Loss: 0.689382 | Validation Accuracy: 0.662486\n",
      "Accuracy on Test data: 0.5095812678337097\n",
      "Step 27 | Training Loss: 0.686235 | Validation Accuracy: 0.697015\n",
      "Accuracy on Test data: 0.5294091701507568\n",
      "Step 28 | Training Loss: 0.682144 | Validation Accuracy: 0.731386\n",
      "Accuracy on Test data: 0.5449787378311157\n",
      "Step 29 | Training Loss: 0.683272 | Validation Accuracy: 0.778378\n",
      "Accuracy on Test data: 0.570573091506958\n",
      "Step 30 | Training Loss: 0.680101 | Validation Accuracy: 0.802032\n",
      "Accuracy on Test data: 0.5790897607803345\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 31 | Training Loss: 0.682495 | Validation Accuracy: 0.813621\n",
      "Accuracy on Test data: 0.5906671285629272\n",
      "Step 32 | Training Loss: 0.674351 | Validation Accuracy: 0.821400\n",
      "Accuracy on Test data: 0.6153743863105774\n",
      "Step 33 | Training Loss: 0.681253 | Validation Accuracy: 0.833942\n",
      "Accuracy on Test data: 0.6855925917625427\n",
      "Step 34 | Training Loss: 0.667842 | Validation Accuracy: 0.857200\n",
      "Accuracy on Test data: 0.7356724739074707\n",
      "Step 35 | Training Loss: 0.669939 | Validation Accuracy: 0.870853\n",
      "Accuracy on Test data: 0.7463183403015137\n",
      "Step 36 | Training Loss: 0.676611 | Validation Accuracy: 0.879584\n",
      "Accuracy on Test data: 0.7519074082374573\n",
      "Step 37 | Training Loss: 0.677946 | Validation Accuracy: 0.888077\n",
      "Accuracy on Test data: 0.7575851678848267\n",
      "Step 38 | Training Loss: 0.665614 | Validation Accuracy: 0.886252\n",
      "Accuracy on Test data: 0.7623757719993591\n",
      "Step 39 | Training Loss: 0.673300 | Validation Accuracy: 0.897603\n",
      "Accuracy on Test data: 0.76698899269104\n",
      "Step 40 | Training Loss: 0.665449 | Validation Accuracy: 0.898476\n",
      "Accuracy on Test data: 0.7713360786437988\n",
      "Step 41 | Training Loss: 0.663301 | Validation Accuracy: 0.899905\n",
      "Accuracy on Test data: 0.7732434272766113\n",
      "Step 42 | Training Loss: 0.662890 | Validation Accuracy: 0.903953\n",
      "Accuracy on Test data: 0.7749290466308594\n",
      "Step 43 | Training Loss: 0.665598 | Validation Accuracy: 0.909668\n",
      "Accuracy on Test data: 0.7817600965499878\n",
      "Step 44 | Training Loss: 0.676283 | Validation Accuracy: 0.917923\n",
      "Accuracy on Test data: 0.7860628366470337\n",
      "Step 45 | Training Loss: 0.650573 | Validation Accuracy: 0.918479\n",
      "Accuracy on Test data: 0.79262775182724\n",
      "Step 46 | Training Loss: 0.663892 | Validation Accuracy: 0.925464\n",
      "Accuracy on Test data: 0.7997693419456482\n",
      "Step 47 | Training Loss: 0.646765 | Validation Accuracy: 0.932767\n",
      "Accuracy on Test data: 0.8061124682426453\n",
      "Step 48 | Training Loss: 0.659580 | Validation Accuracy: 0.941737\n",
      "Accuracy on Test data: 0.8157824873924255\n",
      "Step 49 | Training Loss: 0.649161 | Validation Accuracy: 0.944436\n",
      "Accuracy on Test data: 0.819419801235199\n",
      "Step 50 | Training Loss: 0.653585 | Validation Accuracy: 0.949992\n",
      "Accuracy on Test data: 0.8176011443138123\n",
      "Step 51 | Training Loss: 0.648404 | Validation Accuracy: 0.949913\n",
      "Accuracy on Test data: 0.8097941875457764\n",
      "Step 52 | Training Loss: 0.641626 | Validation Accuracy: 0.950468\n",
      "Accuracy on Test data: 0.8097498416900635\n",
      "Step 53 | Training Loss: 0.636697 | Validation Accuracy: 0.954675\n",
      "Accuracy on Test data: 0.8112136125564575\n",
      "Step 54 | Training Loss: 0.665290 | Validation Accuracy: 0.953167\n",
      "Accuracy on Test data: 0.8132984638214111\n",
      "Step 55 | Training Loss: 0.639745 | Validation Accuracy: 0.954278\n",
      "Accuracy on Test data: 0.8142743110656738\n",
      "Step 56 | Training Loss: 0.657710 | Validation Accuracy: 0.954278\n",
      "Accuracy on Test data: 0.8146735429763794\n",
      "Step 57 | Training Loss: 0.648189 | Validation Accuracy: 0.954358\n",
      "Accuracy on Test data: 0.8150283694267273\n",
      "Step 58 | Training Loss: 0.643077 | Validation Accuracy: 0.957136\n",
      "Accuracy on Test data: 0.8152945637702942\n",
      "Step 59 | Training Loss: 0.639461 | Validation Accuracy: 0.959994\n",
      "Accuracy on Test data: 0.815072774887085\n",
      "Step 60 | Training Loss: 0.628086 | Validation Accuracy: 0.958962\n",
      "Accuracy on Test data: 0.8090400695800781\n",
      "Step 61 | Training Loss: 0.616700 | Validation Accuracy: 0.957771\n",
      "Accuracy on Test data: 0.8050922751426697\n",
      "Step 62 | Training Loss: 0.636669 | Validation Accuracy: 0.954596\n",
      "Accuracy on Test data: 0.8022533655166626\n",
      "Step 63 | Training Loss: 0.637123 | Validation Accuracy: 0.956422\n",
      "Accuracy on Test data: 0.7968860864639282\n",
      "Step 64 | Training Loss: 0.639779 | Validation Accuracy: 0.958485\n",
      "Accuracy on Test data: 0.7944464087486267\n",
      "Step 65 | Training Loss: 0.628216 | Validation Accuracy: 0.957136\n",
      "Accuracy on Test data: 0.7940471768379211\n",
      "Step 66 | Training Loss: 0.630212 | Validation Accuracy: 0.962057\n",
      "Accuracy on Test data: 0.792317271232605\n",
      "Step 67 | Training Loss: 0.625062 | Validation Accuracy: 0.959517\n",
      "Accuracy on Test data: 0.7918736934661865\n",
      "Step 68 | Training Loss: 0.610916 | Validation Accuracy: 0.961661\n",
      "Accuracy on Test data: 0.7891234755516052\n",
      "Step 69 | Training Loss: 0.623391 | Validation Accuracy: 0.960311\n",
      "Accuracy on Test data: 0.7865951061248779\n",
      "Step 70 | Training Loss: 0.616392 | Validation Accuracy: 0.961740\n",
      "Accuracy on Test data: 0.7864620089530945\n",
      "Step 71 | Training Loss: 0.622850 | Validation Accuracy: 0.960470\n",
      "Accuracy on Test data: 0.7870830297470093\n",
      "Step 72 | Training Loss: 0.623185 | Validation Accuracy: 0.961819\n",
      "Accuracy on Test data: 0.7869499921798706\n",
      "Step 73 | Training Loss: 0.607335 | Validation Accuracy: 0.963963\n",
      "Accuracy on Test data: 0.7858410477638245\n",
      "Step 74 | Training Loss: 0.615871 | Validation Accuracy: 0.965788\n",
      "Accuracy on Test data: 0.7842441201210022\n",
      "Step 75 | Training Loss: 0.618687 | Validation Accuracy: 0.961343\n",
      "Accuracy on Test data: 0.7847764492034912\n",
      "Step 76 | Training Loss: 0.630636 | Validation Accuracy: 0.963724\n",
      "Accuracy on Test data: 0.7860628366470337\n",
      "Step 77 | Training Loss: 0.604365 | Validation Accuracy: 0.965074\n",
      "Accuracy on Test data: 0.7863733172416687\n",
      "Step 78 | Training Loss: 0.609459 | Validation Accuracy: 0.963963\n",
      "Accuracy on Test data: 0.7870830297470093\n",
      "Step 79 | Training Loss: 0.597448 | Validation Accuracy: 0.963724\n",
      "Accuracy on Test data: 0.7881476283073425\n",
      "Step 80 | Training Loss: 0.605765 | Validation Accuracy: 0.963407\n",
      "Accuracy on Test data: 0.7890791296958923\n",
      "Step 81 | Training Loss: 0.612734 | Validation Accuracy: 0.964836\n",
      "Accuracy on Test data: 0.7901880741119385\n",
      "Step 82 | Training Loss: 0.609916 | Validation Accuracy: 0.965391\n",
      "Accuracy on Test data: 0.7898331880569458\n",
      "Step 83 | Training Loss: 0.591130 | Validation Accuracy: 0.964518\n",
      "Accuracy on Test data: 0.7893009185791016\n",
      "Step 84 | Training Loss: 0.605486 | Validation Accuracy: 0.965947\n",
      "Accuracy on Test data: 0.78974449634552\n",
      "Step 85 | Training Loss: 0.609755 | Validation Accuracy: 0.964677\n",
      "Accuracy on Test data: 0.7901880741119385\n",
      "Step 86 | Training Loss: 0.609717 | Validation Accuracy: 0.968011\n",
      "Accuracy on Test data: 0.7906316518783569\n",
      "Step 87 | Training Loss: 0.596538 | Validation Accuracy: 0.968328\n",
      "Accuracy on Test data: 0.7912526726722717\n",
      "Step 88 | Training Loss: 0.599175 | Validation Accuracy: 0.968408\n",
      "Accuracy on Test data: 0.7913413643836975\n",
      "Step 89 | Training Loss: 0.600437 | Validation Accuracy: 0.964994\n",
      "Accuracy on Test data: 0.7920954823493958\n",
      "Step 90 | Training Loss: 0.592540 | Validation Accuracy: 0.967535\n",
      "Accuracy on Test data: 0.792317271232605\n",
      "Step 91 | Training Loss: 0.617586 | Validation Accuracy: 0.967376\n",
      "Accuracy on Test data: 0.7925390601158142\n",
      "Step 92 | Training Loss: 0.599354 | Validation Accuracy: 0.966820\n",
      "Accuracy on Test data: 0.7926720976829529\n",
      "Step 93 | Training Loss: 0.585363 | Validation Accuracy: 0.964359\n",
      "Accuracy on Test data: 0.7927164435386658\n",
      "Step 94 | Training Loss: 0.584062 | Validation Accuracy: 0.965868\n",
      "Accuracy on Test data: 0.7932931184768677\n",
      "Step 95 | Training Loss: 0.598526 | Validation Accuracy: 0.968646\n",
      "Accuracy on Test data: 0.793470561504364\n",
      "Step 96 | Training Loss: 0.583577 | Validation Accuracy: 0.970392\n",
      "Accuracy on Test data: 0.7933374643325806\n",
      "Step 97 | Training Loss: 0.587034 | Validation Accuracy: 0.966423\n",
      "Accuracy on Test data: 0.7936480045318604\n",
      "Step 98 | Training Loss: 0.571509 | Validation Accuracy: 0.966979\n",
      "Accuracy on Test data: 0.7933818101882935\n",
      "Step 99 | Training Loss: 0.576020 | Validation Accuracy: 0.967773\n",
      "Accuracy on Test data: 0.7935592532157898\n",
      "Step 100 | Training Loss: 0.570205 | Validation Accuracy: 0.967296\n",
      "Accuracy on Test data: 0.7922285199165344\n",
      "Current Layer Attributes - epochs:100 hidden layers:6 features count:32\n",
      "Step 1 | Training Loss: 0.734030 | Validation Accuracy: 0.737022\n",
      "Accuracy on Test data: 0.8331263065338135\n",
      "Step 2 | Training Loss: 0.723874 | Validation Accuracy: 0.736387\n",
      "Accuracy on Test data: 0.8375177383422852\n",
      "Step 3 | Training Loss: 0.714735 | Validation Accuracy: 0.733450\n",
      "Accuracy on Test data: 0.8347675800323486\n",
      "Step 4 | Training Loss: 0.702992 | Validation Accuracy: 0.735196\n",
      "Accuracy on Test data: 0.8364531397819519\n",
      "Step 5 | Training Loss: 0.744405 | Validation Accuracy: 0.744404\n",
      "Accuracy on Test data: 0.8420422077178955\n",
      "Step 6 | Training Loss: 0.722111 | Validation Accuracy: 0.796555\n",
      "Accuracy on Test data: 0.8552164435386658\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 7 | Training Loss: 0.698972 | Validation Accuracy: 0.807350\n",
      "Accuracy on Test data: 0.8469659090042114\n",
      "Step 8 | Training Loss: 0.698362 | Validation Accuracy: 0.819813\n",
      "Accuracy on Test data: 0.8481636047363281\n",
      "Step 9 | Training Loss: 0.692390 | Validation Accuracy: 0.826163\n",
      "Accuracy on Test data: 0.8480305075645447\n",
      "Step 10 | Training Loss: 0.690116 | Validation Accuracy: 0.840610\n",
      "Accuracy on Test data: 0.8489620089530945\n",
      "Step 11 | Training Loss: 0.669885 | Validation Accuracy: 0.849262\n",
      "Accuracy on Test data: 0.8522001504898071\n",
      "Step 12 | Training Loss: 0.663251 | Validation Accuracy: 0.850135\n",
      "Accuracy on Test data: 0.8535308837890625\n",
      "Step 13 | Training Loss: 0.646792 | Validation Accuracy: 0.867916\n",
      "Accuracy on Test data: 0.8578779101371765\n",
      "Step 14 | Training Loss: 0.663005 | Validation Accuracy: 0.867836\n",
      "Accuracy on Test data: 0.8592086434364319\n",
      "Step 15 | Training Loss: 0.656947 | Validation Accuracy: 0.872281\n",
      "Accuracy on Test data: 0.8607611656188965\n",
      "Step 16 | Training Loss: 0.650879 | Validation Accuracy: 0.876726\n",
      "Accuracy on Test data: 0.8647090196609497\n",
      "Step 17 | Training Loss: 0.634635 | Validation Accuracy: 0.873789\n",
      "Accuracy on Test data: 0.8679471015930176\n",
      "Step 18 | Training Loss: 0.623606 | Validation Accuracy: 0.883950\n",
      "Accuracy on Test data: 0.8701649904251099\n",
      "Step 19 | Training Loss: 0.604298 | Validation Accuracy: 0.885537\n",
      "Accuracy on Test data: 0.874157190322876\n",
      "Step 20 | Training Loss: 0.617032 | Validation Accuracy: 0.907446\n",
      "Accuracy on Test data: 0.8804559707641602\n",
      "Step 21 | Training Loss: 0.589911 | Validation Accuracy: 0.915066\n",
      "Accuracy on Test data: 0.8816980123519897\n",
      "Step 22 | Training Loss: 0.595001 | Validation Accuracy: 0.912764\n",
      "Accuracy on Test data: 0.8841820359230042\n",
      "Step 23 | Training Loss: 0.563971 | Validation Accuracy: 0.921416\n",
      "Accuracy on Test data: 0.8907470107078552\n",
      "Step 24 | Training Loss: 0.582877 | Validation Accuracy: 0.925703\n",
      "Accuracy on Test data: 0.8970901370048523\n",
      "Step 25 | Training Loss: 0.566676 | Validation Accuracy: 0.930148\n",
      "Accuracy on Test data: 0.9031671285629272\n",
      "Step 26 | Training Loss: 0.559765 | Validation Accuracy: 0.936180\n",
      "Accuracy on Test data: 0.9037438035011292\n",
      "Step 27 | Training Loss: 0.541747 | Validation Accuracy: 0.934672\n",
      "Accuracy on Test data: 0.9040099382400513\n",
      "Step 28 | Training Loss: 0.544379 | Validation Accuracy: 0.941102\n",
      "Accuracy on Test data: 0.9039212465286255\n",
      "Step 29 | Training Loss: 0.551239 | Validation Accuracy: 0.941737\n",
      "Accuracy on Test data: 0.8938519954681396\n",
      "Step 30 | Training Loss: 0.530771 | Validation Accuracy: 0.941340\n",
      "Accuracy on Test data: 0.8871539831161499\n",
      "Step 31 | Training Loss: 0.540138 | Validation Accuracy: 0.947611\n",
      "Accuracy on Test data: 0.8854684233665466\n",
      "Step 32 | Training Loss: 0.510235 | Validation Accuracy: 0.945388\n",
      "Accuracy on Test data: 0.8837828040122986\n",
      "Step 33 | Training Loss: 0.501047 | Validation Accuracy: 0.944833\n",
      "Accuracy on Test data: 0.8824077248573303\n",
      "Step 34 | Training Loss: 0.501084 | Validation Accuracy: 0.945626\n",
      "Accuracy on Test data: 0.8803229331970215\n",
      "Step 35 | Training Loss: 0.486033 | Validation Accuracy: 0.944356\n",
      "Accuracy on Test data: 0.8767743110656738\n",
      "Step 36 | Training Loss: 0.498020 | Validation Accuracy: 0.947531\n",
      "Accuracy on Test data: 0.8734918236732483\n",
      "Step 37 | Training Loss: 0.485529 | Validation Accuracy: 0.947452\n",
      "Accuracy on Test data: 0.8708747625350952\n",
      "Step 38 | Training Loss: 0.492786 | Validation Accuracy: 0.949516\n",
      "Accuracy on Test data: 0.8691891431808472\n",
      "Step 39 | Training Loss: 0.489974 | Validation Accuracy: 0.948563\n",
      "Accuracy on Test data: 0.8679471015930176\n",
      "Step 40 | Training Loss: 0.479643 | Validation Accuracy: 0.948246\n",
      "Accuracy on Test data: 0.8666607737541199\n",
      "Step 41 | Training Loss: 0.479230 | Validation Accuracy: 0.948643\n",
      "Accuracy on Test data: 0.8650195002555847\n",
      "Step 42 | Training Loss: 0.480310 | Validation Accuracy: 0.945785\n",
      "Accuracy on Test data: 0.8626685738563538\n",
      "Step 43 | Training Loss: 0.464317 | Validation Accuracy: 0.948087\n",
      "Accuracy on Test data: 0.861160397529602\n",
      "Step 44 | Training Loss: 0.465121 | Validation Accuracy: 0.951580\n",
      "Accuracy on Test data: 0.8602288961410522\n",
      "Step 45 | Training Loss: 0.463013 | Validation Accuracy: 0.947690\n",
      "Accuracy on Test data: 0.8595635294914246\n",
      "Step 46 | Training Loss: 0.458040 | Validation Accuracy: 0.952770\n",
      "Accuracy on Test data: 0.8589425086975098\n",
      "Step 47 | Training Loss: 0.456083 | Validation Accuracy: 0.954040\n",
      "Accuracy on Test data: 0.8579222559928894\n",
      "Step 48 | Training Loss: 0.452429 | Validation Accuracy: 0.957057\n",
      "Accuracy on Test data: 0.8504258394241333\n",
      "Step 49 | Training Loss: 0.433676 | Validation Accuracy: 0.955310\n",
      "Accuracy on Test data: 0.8462561964988708\n",
      "Step 50 | Training Loss: 0.460293 | Validation Accuracy: 0.956819\n",
      "Accuracy on Test data: 0.845014214515686\n",
      "Step 51 | Training Loss: 0.430244 | Validation Accuracy: 0.956977\n",
      "Accuracy on Test data: 0.8423970937728882\n",
      "Step 52 | Training Loss: 0.430028 | Validation Accuracy: 0.959279\n",
      "Accuracy on Test data: 0.841288149356842\n",
      "Step 53 | Training Loss: 0.441078 | Validation Accuracy: 0.960391\n",
      "Accuracy on Test data: 0.8400017619132996\n",
      "Step 54 | Training Loss: 0.425398 | Validation Accuracy: 0.958406\n",
      "Accuracy on Test data: 0.8391146063804626\n",
      "Step 55 | Training Loss: 0.422331 | Validation Accuracy: 0.959517\n",
      "Accuracy on Test data: 0.8379169702529907\n",
      "Step 56 | Training Loss: 0.419628 | Validation Accuracy: 0.957612\n",
      "Accuracy on Test data: 0.8376951813697815\n",
      "Step 57 | Training Loss: 0.427333 | Validation Accuracy: 0.959756\n",
      "Accuracy on Test data: 0.8370298147201538\n",
      "Step 58 | Training Loss: 0.425453 | Validation Accuracy: 0.956501\n",
      "Accuracy on Test data: 0.8360095620155334\n",
      "Step 59 | Training Loss: 0.424242 | Validation Accuracy: 0.960311\n",
      "Accuracy on Test data: 0.834945023059845\n",
      "Step 60 | Training Loss: 0.408673 | Validation Accuracy: 0.961184\n",
      "Accuracy on Test data: 0.8340134620666504\n",
      "Step 61 | Training Loss: 0.411333 | Validation Accuracy: 0.960946\n",
      "Accuracy on Test data: 0.8333480954170227\n",
      "Step 62 | Training Loss: 0.405447 | Validation Accuracy: 0.961899\n",
      "Accuracy on Test data: 0.8326383829116821\n",
      "Step 63 | Training Loss: 0.396653 | Validation Accuracy: 0.962613\n",
      "Accuracy on Test data: 0.8316181898117065\n",
      "Step 64 | Training Loss: 0.392520 | Validation Accuracy: 0.964677\n",
      "Accuracy on Test data: 0.8313076496124268\n",
      "Step 65 | Training Loss: 0.397534 | Validation Accuracy: 0.963566\n",
      "Accuracy on Test data: 0.8310858607292175\n",
      "Step 66 | Training Loss: 0.385481 | Validation Accuracy: 0.960311\n",
      "Accuracy on Test data: 0.8306422829627991\n",
      "Step 67 | Training Loss: 0.386301 | Validation Accuracy: 0.963169\n",
      "Accuracy on Test data: 0.8297551274299622\n",
      "Step 68 | Training Loss: 0.372650 | Validation Accuracy: 0.963407\n",
      "Accuracy on Test data: 0.8274485468864441\n",
      "Step 69 | Training Loss: 0.386515 | Validation Accuracy: 0.964994\n",
      "Accuracy on Test data: 0.8262065052986145\n",
      "Step 70 | Training Loss: 0.405968 | Validation Accuracy: 0.964994\n",
      "Accuracy on Test data: 0.823766827583313\n",
      "Step 71 | Training Loss: 0.375802 | Validation Accuracy: 0.963089\n",
      "Accuracy on Test data: 0.8125\n",
      "Step 72 | Training Loss: 0.383577 | Validation Accuracy: 0.962137\n",
      "Accuracy on Test data: 0.8069552779197693\n",
      "Step 73 | Training Loss: 0.392306 | Validation Accuracy: 0.964439\n",
      "Accuracy on Test data: 0.8018985390663147\n",
      "Step 74 | Training Loss: 0.373571 | Validation Accuracy: 0.965153\n",
      "Accuracy on Test data: 0.8005678057670593\n",
      "Step 75 | Training Loss: 0.392430 | Validation Accuracy: 0.966423\n",
      "Accuracy on Test data: 0.7993701100349426\n",
      "Step 76 | Training Loss: 0.384955 | Validation Accuracy: 0.962613\n",
      "Accuracy on Test data: 0.7980837225914001\n",
      "Step 77 | Training Loss: 0.379461 | Validation Accuracy: 0.965550\n",
      "Accuracy on Test data: 0.7964425086975098\n",
      "Step 78 | Training Loss: 0.374599 | Validation Accuracy: 0.963645\n",
      "Accuracy on Test data: 0.7962650656700134\n",
      "Step 79 | Training Loss: 0.375328 | Validation Accuracy: 0.965074\n",
      "Accuracy on Test data: 0.7960432767868042\n",
      "Step 80 | Training Loss: 0.362328 | Validation Accuracy: 0.965788\n",
      "Accuracy on Test data: 0.7957327961921692\n",
      "Step 81 | Training Loss: 0.374464 | Validation Accuracy: 0.966026\n",
      "Accuracy on Test data: 0.7947569489479065\n",
      "Step 82 | Training Loss: 0.369445 | Validation Accuracy: 0.967138\n",
      "Accuracy on Test data: 0.794313371181488\n",
      "Step 83 | Training Loss: 0.371513 | Validation Accuracy: 0.965233\n",
      "Accuracy on Test data: 0.7941802740097046\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 84 | Training Loss: 0.357013 | Validation Accuracy: 0.963010\n",
      "Accuracy on Test data: 0.7939141392707825\n",
      "Step 85 | Training Loss: 0.357771 | Validation Accuracy: 0.968249\n",
      "Accuracy on Test data: 0.7939141392707825\n",
      "Step 86 | Training Loss: 0.366857 | Validation Accuracy: 0.964836\n",
      "Accuracy on Test data: 0.7937366962432861\n",
      "Step 87 | Training Loss: 0.381985 | Validation Accuracy: 0.964994\n",
      "Accuracy on Test data: 0.793470561504364\n",
      "Step 88 | Training Loss: 0.361715 | Validation Accuracy: 0.964518\n",
      "Accuracy on Test data: 0.7936035990715027\n",
      "Step 89 | Training Loss: 0.366785 | Validation Accuracy: 0.965868\n",
      "Accuracy on Test data: 0.7933818101882935\n",
      "Step 90 | Training Loss: 0.376252 | Validation Accuracy: 0.965074\n",
      "Accuracy on Test data: 0.7934262156486511\n",
      "Step 91 | Training Loss: 0.347939 | Validation Accuracy: 0.966900\n",
      "Accuracy on Test data: 0.7932931184768677\n",
      "Step 92 | Training Loss: 0.365896 | Validation Accuracy: 0.969281\n",
      "Accuracy on Test data: 0.792317271232605\n",
      "Step 93 | Training Loss: 0.362093 | Validation Accuracy: 0.966026\n",
      "Accuracy on Test data: 0.7917405962944031\n",
      "Step 94 | Training Loss: 0.368404 | Validation Accuracy: 0.964439\n",
      "Accuracy on Test data: 0.7915188074111938\n",
      "Step 95 | Training Loss: 0.355162 | Validation Accuracy: 0.969440\n",
      "Accuracy on Test data: 0.7901437282562256\n",
      "Step 96 | Training Loss: 0.360004 | Validation Accuracy: 0.965788\n",
      "Accuracy on Test data: 0.7879258394241333\n",
      "Step 97 | Training Loss: 0.379537 | Validation Accuracy: 0.967138\n",
      "Accuracy on Test data: 0.7846876978874207\n",
      "Step 98 | Training Loss: 0.354644 | Validation Accuracy: 0.970075\n",
      "Accuracy on Test data: 0.7849094867706299\n",
      "Step 99 | Training Loss: 0.369418 | Validation Accuracy: 0.972853\n",
      "Accuracy on Test data: 0.7837561964988708\n",
      "Step 100 | Training Loss: 0.361004 | Validation Accuracy: 0.971107\n",
      "Accuracy on Test data: 0.7835787534713745\n",
      "Current Layer Attributes - epochs:100 hidden layers:6 features count:64\n",
      "Step 1 | Training Loss: 0.695284 | Validation Accuracy: 0.531116\n",
      "Accuracy on Test data: 0.6344925761222839\n",
      "Step 2 | Training Loss: 0.710406 | Validation Accuracy: 0.726941\n",
      "Accuracy on Test data: 0.8193311095237732\n",
      "Step 3 | Training Loss: 0.677886 | Validation Accuracy: 0.755914\n",
      "Accuracy on Test data: 0.8090400695800781\n",
      "Step 4 | Training Loss: 0.664675 | Validation Accuracy: 0.770916\n",
      "Accuracy on Test data: 0.816847026348114\n",
      "Step 5 | Training Loss: 0.665637 | Validation Accuracy: 0.794332\n",
      "Accuracy on Test data: 0.8138307332992554\n",
      "Step 6 | Training Loss: 0.648906 | Validation Accuracy: 0.848389\n",
      "Accuracy on Test data: 0.8271380662918091\n",
      "Step 7 | Training Loss: 0.643762 | Validation Accuracy: 0.865296\n",
      "Accuracy on Test data: 0.8326383829116821\n",
      "Step 8 | Training Loss: 0.628192 | Validation Accuracy: 0.881489\n",
      "Accuracy on Test data: 0.8167583346366882\n",
      "Step 9 | Training Loss: 0.625468 | Validation Accuracy: 0.887046\n",
      "Accuracy on Test data: 0.8159155249595642\n",
      "Step 10 | Training Loss: 0.629450 | Validation Accuracy: 0.895221\n",
      "Accuracy on Test data: 0.8139194250106812\n",
      "Step 11 | Training Loss: 0.613127 | Validation Accuracy: 0.899746\n",
      "Accuracy on Test data: 0.8097054362297058\n",
      "Step 12 | Training Loss: 0.595871 | Validation Accuracy: 0.908239\n",
      "Accuracy on Test data: 0.8056245446205139\n",
      "Step 13 | Training Loss: 0.580073 | Validation Accuracy: 0.908874\n",
      "Accuracy on Test data: 0.8037615418434143\n",
      "Step 14 | Training Loss: 0.579819 | Validation Accuracy: 0.912843\n",
      "Accuracy on Test data: 0.8017654418945312\n",
      "Step 15 | Training Loss: 0.571592 | Validation Accuracy: 0.916971\n",
      "Accuracy on Test data: 0.7991926670074463\n",
      "Step 16 | Training Loss: 0.565264 | Validation Accuracy: 0.917844\n",
      "Accuracy on Test data: 0.7976401448249817\n",
      "Step 17 | Training Loss: 0.575301 | Validation Accuracy: 0.917209\n",
      "Accuracy on Test data: 0.7948899865150452\n",
      "Step 18 | Training Loss: 0.547633 | Validation Accuracy: 0.922527\n",
      "Accuracy on Test data: 0.7949343323707581\n",
      "Step 19 | Training Loss: 0.536830 | Validation Accuracy: 0.922369\n",
      "Accuracy on Test data: 0.7949787378311157\n",
      "Step 20 | Training Loss: 0.561841 | Validation Accuracy: 0.931338\n",
      "Accuracy on Test data: 0.7956440448760986\n",
      "Step 21 | Training Loss: 0.543250 | Validation Accuracy: 0.933085\n",
      "Accuracy on Test data: 0.7963094115257263\n",
      "Step 22 | Training Loss: 0.524597 | Validation Accuracy: 0.936260\n",
      "Accuracy on Test data: 0.7983055114746094\n",
      "Step 23 | Training Loss: 0.514614 | Validation Accuracy: 0.939911\n",
      "Accuracy on Test data: 0.8011444211006165\n",
      "Step 24 | Training Loss: 0.511459 | Validation Accuracy: 0.940943\n",
      "Accuracy on Test data: 0.8019428849220276\n",
      "Step 25 | Training Loss: 0.504120 | Validation Accuracy: 0.940864\n",
      "Accuracy on Test data: 0.802696943283081\n",
      "Step 26 | Training Loss: 0.501594 | Validation Accuracy: 0.944753\n",
      "Accuracy on Test data: 0.8034510016441345\n",
      "Step 27 | Training Loss: 0.495479 | Validation Accuracy: 0.949040\n",
      "Accuracy on Test data: 0.8041607737541199\n",
      "Step 28 | Training Loss: 0.472863 | Validation Accuracy: 0.946023\n",
      "Accuracy on Test data: 0.8041163682937622\n",
      "Step 29 | Training Loss: 0.489649 | Validation Accuracy: 0.944594\n",
      "Accuracy on Test data: 0.8036727905273438\n",
      "Step 30 | Training Loss: 0.460076 | Validation Accuracy: 0.949516\n",
      "Accuracy on Test data: 0.8026082515716553\n",
      "Step 31 | Training Loss: 0.460892 | Validation Accuracy: 0.953961\n",
      "Accuracy on Test data: 0.7934262156486511\n",
      "Step 32 | Training Loss: 0.464361 | Validation Accuracy: 0.952929\n",
      "Accuracy on Test data: 0.7802519798278809\n",
      "Step 33 | Training Loss: 0.443381 | Validation Accuracy: 0.954358\n",
      "Accuracy on Test data: 0.7796309590339661\n",
      "Step 34 | Training Loss: 0.454708 | Validation Accuracy: 0.958168\n",
      "Accuracy on Test data: 0.7798527479171753\n",
      "Step 35 | Training Loss: 0.449296 | Validation Accuracy: 0.956739\n",
      "Accuracy on Test data: 0.7788324952125549\n",
      "Step 36 | Training Loss: 0.437054 | Validation Accuracy: 0.956263\n",
      "Accuracy on Test data: 0.7739975452423096\n",
      "Step 37 | Training Loss: 0.434301 | Validation Accuracy: 0.961184\n",
      "Accuracy on Test data: 0.7727998495101929\n",
      "Step 38 | Training Loss: 0.435475 | Validation Accuracy: 0.960470\n",
      "Accuracy on Test data: 0.7719570398330688\n",
      "Step 39 | Training Loss: 0.425700 | Validation Accuracy: 0.960549\n",
      "Accuracy on Test data: 0.7720457911491394\n",
      "Step 40 | Training Loss: 0.412667 | Validation Accuracy: 0.960470\n",
      "Accuracy on Test data: 0.7723119258880615\n",
      "Step 41 | Training Loss: 0.414297 | Validation Accuracy: 0.963089\n",
      "Accuracy on Test data: 0.7706263065338135\n",
      "Step 42 | Training Loss: 0.405865 | Validation Accuracy: 0.964359\n",
      "Accuracy on Test data: 0.7701383829116821\n",
      "Step 43 | Training Loss: 0.392790 | Validation Accuracy: 0.965391\n",
      "Accuracy on Test data: 0.7712916731834412\n",
      "Step 44 | Training Loss: 0.406344 | Validation Accuracy: 0.970075\n",
      "Accuracy on Test data: 0.7734652161598206\n",
      "Step 45 | Training Loss: 0.387933 | Validation Accuracy: 0.961026\n",
      "Accuracy on Test data: 0.7734652161598206\n",
      "Step 46 | Training Loss: 0.399786 | Validation Accuracy: 0.965947\n",
      "Accuracy on Test data: 0.7737757563591003\n",
      "Step 47 | Training Loss: 0.380946 | Validation Accuracy: 0.966582\n",
      "Accuracy on Test data: 0.7740418910980225\n",
      "Step 48 | Training Loss: 0.382560 | Validation Accuracy: 0.966741\n",
      "Accuracy on Test data: 0.7745298147201538\n",
      "Step 49 | Training Loss: 0.379345 | Validation Accuracy: 0.967058\n",
      "Accuracy on Test data: 0.7756387591362\n",
      "Step 50 | Training Loss: 0.380542 | Validation Accuracy: 0.965788\n",
      "Accuracy on Test data: 0.7751064300537109\n",
      "Step 51 | Training Loss: 0.386160 | Validation Accuracy: 0.967217\n",
      "Accuracy on Test data: 0.7757274508476257\n",
      "Step 52 | Training Loss: 0.365326 | Validation Accuracy: 0.969836\n",
      "Accuracy on Test data: 0.7760379910469055\n",
      "Step 53 | Training Loss: 0.363103 | Validation Accuracy: 0.967217\n",
      "Accuracy on Test data: 0.7763928174972534\n",
      "Step 54 | Training Loss: 0.377558 | Validation Accuracy: 0.966423\n",
      "Accuracy on Test data: 0.776481568813324\n",
      "Step 55 | Training Loss: 0.363627 | Validation Accuracy: 0.966503\n",
      "Accuracy on Test data: 0.7761710286140442\n",
      "Step 56 | Training Loss: 0.376252 | Validation Accuracy: 0.965312\n",
      "Accuracy on Test data: 0.7757274508476257\n",
      "Step 57 | Training Loss: 0.379496 | Validation Accuracy: 0.968646\n",
      "Accuracy on Test data: 0.7753282189369202\n",
      "Step 58 | Training Loss: 0.360784 | Validation Accuracy: 0.969201\n",
      "Accuracy on Test data: 0.773598313331604\n",
      "Step 59 | Training Loss: 0.364589 | Validation Accuracy: 0.964439\n",
      "Accuracy on Test data: 0.77275550365448\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 60 | Training Loss: 0.367254 | Validation Accuracy: 0.968884\n",
      "Accuracy on Test data: 0.7731547355651855\n",
      "Step 61 | Training Loss: 0.380112 | Validation Accuracy: 0.967455\n",
      "Accuracy on Test data: 0.7731990814208984\n",
      "Step 62 | Training Loss: 0.347035 | Validation Accuracy: 0.967455\n",
      "Accuracy on Test data: 0.77275550365448\n",
      "Step 63 | Training Loss: 0.362435 | Validation Accuracy: 0.967852\n",
      "Accuracy on Test data: 0.771025538444519\n",
      "Step 64 | Training Loss: 0.357439 | Validation Accuracy: 0.968170\n",
      "Accuracy on Test data: 0.7708925008773804\n",
      "Step 65 | Training Loss: 0.349743 | Validation Accuracy: 0.965947\n",
      "Accuracy on Test data: 0.7709811925888062\n",
      "Step 66 | Training Loss: 0.362328 | Validation Accuracy: 0.969360\n",
      "Accuracy on Test data: 0.7706707119941711\n",
      "Step 67 | Training Loss: 0.362992 | Validation Accuracy: 0.969440\n",
      "Accuracy on Test data: 0.7704045176506042\n",
      "Step 68 | Training Loss: 0.351573 | Validation Accuracy: 0.969836\n",
      "Accuracy on Test data: 0.7699165940284729\n",
      "Step 69 | Training Loss: 0.351873 | Validation Accuracy: 0.970075\n",
      "Accuracy on Test data: 0.7697391510009766\n",
      "Step 70 | Training Loss: 0.354096 | Validation Accuracy: 0.970075\n",
      "Accuracy on Test data: 0.7696504592895508\n",
      "Step 71 | Training Loss: 0.348964 | Validation Accuracy: 0.969916\n",
      "Accuracy on Test data: 0.7693399786949158\n",
      "Step 72 | Training Loss: 0.350143 | Validation Accuracy: 0.970313\n",
      "Accuracy on Test data: 0.7692955732345581\n",
      "Step 73 | Training Loss: 0.353965 | Validation Accuracy: 0.971821\n",
      "Accuracy on Test data: 0.7691181898117065\n",
      "Step 74 | Training Loss: 0.348178 | Validation Accuracy: 0.971821\n",
      "Accuracy on Test data: 0.7689850926399231\n",
      "Step 75 | Training Loss: 0.355892 | Validation Accuracy: 0.969519\n",
      "Accuracy on Test data: 0.7688964009284973\n",
      "Step 76 | Training Loss: 0.353418 | Validation Accuracy: 0.971027\n",
      "Accuracy on Test data: 0.7685858607292175\n",
      "Step 77 | Training Loss: 0.370719 | Validation Accuracy: 0.969678\n",
      "Accuracy on Test data: 0.7684084177017212\n",
      "Step 78 | Training Loss: 0.349560 | Validation Accuracy: 0.969598\n",
      "Accuracy on Test data: 0.7683197259902954\n",
      "Step 79 | Training Loss: 0.350059 | Validation Accuracy: 0.974282\n",
      "Accuracy on Test data: 0.7680535912513733\n",
      "Step 80 | Training Loss: 0.357084 | Validation Accuracy: 0.971265\n",
      "Accuracy on Test data: 0.7679648399353027\n",
      "Step 81 | Training Loss: 0.354870 | Validation Accuracy: 0.968963\n",
      "Accuracy on Test data: 0.7676987051963806\n",
      "Step 82 | Training Loss: 0.358895 | Validation Accuracy: 0.971265\n",
      "Accuracy on Test data: 0.7676543593406677\n",
      "Step 83 | Training Loss: 0.350093 | Validation Accuracy: 0.970154\n",
      "Accuracy on Test data: 0.7673438787460327\n",
      "Step 84 | Training Loss: 0.351953 | Validation Accuracy: 0.972853\n",
      "Accuracy on Test data: 0.7673882246017456\n",
      "Step 85 | Training Loss: 0.348605 | Validation Accuracy: 0.972218\n",
      "Accuracy on Test data: 0.7669446468353271\n",
      "Step 86 | Training Loss: 0.351258 | Validation Accuracy: 0.971742\n",
      "Accuracy on Test data: 0.76698899269104\n",
      "Step 87 | Training Loss: 0.355068 | Validation Accuracy: 0.972694\n",
      "Accuracy on Test data: 0.7671664357185364\n",
      "Step 88 | Training Loss: 0.359580 | Validation Accuracy: 0.972059\n",
      "Accuracy on Test data: 0.7672107815742493\n",
      "Step 89 | Training Loss: 0.353890 | Validation Accuracy: 0.974599\n",
      "Accuracy on Test data: 0.7671220898628235\n",
      "Step 90 | Training Loss: 0.360091 | Validation Accuracy: 0.971027\n",
      "Accuracy on Test data: 0.7669446468353271\n",
      "Step 91 | Training Loss: 0.354612 | Validation Accuracy: 0.972773\n",
      "Accuracy on Test data: 0.7665010690689087\n",
      "Step 92 | Training Loss: 0.352446 | Validation Accuracy: 0.971821\n",
      "Accuracy on Test data: 0.7665897607803345\n",
      "Step 93 | Training Loss: 0.357072 | Validation Accuracy: 0.972853\n",
      "Accuracy on Test data: 0.7665010690689087\n",
      "Step 94 | Training Loss: 0.335462 | Validation Accuracy: 0.971107\n",
      "Accuracy on Test data: 0.7662792801856995\n",
      "Step 95 | Training Loss: 0.351086 | Validation Accuracy: 0.971662\n",
      "Accuracy on Test data: 0.7660574913024902\n",
      "Step 96 | Training Loss: 0.346793 | Validation Accuracy: 0.971583\n",
      "Accuracy on Test data: 0.7658800482749939\n",
      "Step 97 | Training Loss: 0.353612 | Validation Accuracy: 0.975075\n",
      "Accuracy on Test data: 0.7653477787971497\n",
      "Step 98 | Training Loss: 0.346684 | Validation Accuracy: 0.971503\n",
      "Accuracy on Test data: 0.7650816440582275\n",
      "Step 99 | Training Loss: 0.336292 | Validation Accuracy: 0.973964\n",
      "Accuracy on Test data: 0.7650372385978699\n",
      "Step 100 | Training Loss: 0.347039 | Validation Accuracy: 0.973726\n",
      "Accuracy on Test data: 0.7643718719482422\n"
     ]
    }
   ],
   "source": [
    "import itertools\n",
    "class Hyperparameters:\n",
    "#    features_arr = [2, 4, 8, 16, 32, 64, 128, 256]\n",
    "#    hidden_layers_arr = [2, 4, 6, 10]\n",
    "    features_arr = [4, 8, 32, 64]\n",
    "    hidden_layers_arr = [4, 6]\n",
    "\n",
    "    epochs = [100]\n",
    "    \n",
    "    for e, h, f in itertools.product(epochs, hidden_layers_arr, features_arr):\n",
    "        print(\"Current Layer Attributes - epochs:{} hidden layers:{} features count:{}\".format(e,h,f))\n",
    "        n = network(2,h,f)\n",
    "        n.build_layers()\n",
    "        Train.train(e, n, h,f)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-05-15T12:09:44.257615Z",
     "start_time": "2017-05-15T12:09:44.231705Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_results = pd.DataFrame(Train.results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-05-15T12:09:44.291676Z",
     "start_time": "2017-05-15T12:09:44.259568Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>epoch</th>\n",
       "      <th>no_of_features</th>\n",
       "      <th>hidden_layers</th>\n",
       "      <th>train_score</th>\n",
       "      <th>test_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>100</td>\n",
       "      <td>32</td>\n",
       "      <td>6</td>\n",
       "      <td>0.934672</td>\n",
       "      <td>0.904010</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>100</td>\n",
       "      <td>32</td>\n",
       "      <td>6</td>\n",
       "      <td>0.936180</td>\n",
       "      <td>0.903744</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>100</td>\n",
       "      <td>32</td>\n",
       "      <td>6</td>\n",
       "      <td>0.930148</td>\n",
       "      <td>0.903167</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>100</td>\n",
       "      <td>32</td>\n",
       "      <td>6</td>\n",
       "      <td>0.925703</td>\n",
       "      <td>0.897090</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>100</td>\n",
       "      <td>32</td>\n",
       "      <td>6</td>\n",
       "      <td>0.921416</td>\n",
       "      <td>0.890747</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>100</td>\n",
       "      <td>64</td>\n",
       "      <td>4</td>\n",
       "      <td>0.833386</td>\n",
       "      <td>0.884493</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>100</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>0.956660</td>\n",
       "      <td>0.835832</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>100</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>0.954517</td>\n",
       "      <td>0.835566</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>100</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>0.954437</td>\n",
       "      <td>0.834989</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>100</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>0.948484</td>\n",
       "      <td>0.834457</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>100</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>0.949119</td>\n",
       "      <td>0.833171</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>100</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>0.948087</td>\n",
       "      <td>0.832505</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>100</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>0.947928</td>\n",
       "      <td>0.831707</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>100</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>0.944515</td>\n",
       "      <td>0.830066</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>100</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>0.943880</td>\n",
       "      <td>0.828691</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>100</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>0.942927</td>\n",
       "      <td>0.824920</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>100</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>0.946341</td>\n",
       "      <td>0.821283</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>100</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>0.947769</td>\n",
       "      <td>0.818400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>100</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>0.945706</td>\n",
       "      <td>0.814807</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>100</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>0.941022</td>\n",
       "      <td>0.811524</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>100</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>0.936657</td>\n",
       "      <td>0.804072</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>100</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>0.929989</td>\n",
       "      <td>0.798660</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>100</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>0.924988</td>\n",
       "      <td>0.789212</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>100</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>0.913558</td>\n",
       "      <td>0.760557</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>100</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>0.896015</td>\n",
       "      <td>0.750621</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>100</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>0.872916</td>\n",
       "      <td>0.731725</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>100</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>0.801080</td>\n",
       "      <td>0.660575</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>100</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>0.718844</td>\n",
       "      <td>0.599627</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    epoch  no_of_features  hidden_layers  train_score  test_score\n",
       "27    100              32              6     0.934672    0.904010\n",
       "26    100              32              6     0.936180    0.903744\n",
       "25    100              32              6     0.930148    0.903167\n",
       "24    100              32              6     0.925703    0.897090\n",
       "23    100              32              6     0.921416    0.890747\n",
       "22    100              64              4     0.833386    0.884493\n",
       "21    100               4              4     0.956660    0.835832\n",
       "20    100               4              4     0.954517    0.835566\n",
       "19    100               4              4     0.954437    0.834989\n",
       "18    100               4              4     0.948484    0.834457\n",
       "17    100               4              4     0.949119    0.833171\n",
       "16    100               4              4     0.948087    0.832505\n",
       "15    100               4              4     0.947928    0.831707\n",
       "14    100               4              4     0.944515    0.830066\n",
       "13    100               4              4     0.943880    0.828691\n",
       "12    100               4              4     0.942927    0.824920\n",
       "11    100               4              4     0.946341    0.821283\n",
       "10    100               4              4     0.947769    0.818400\n",
       "9     100               4              4     0.945706    0.814807\n",
       "8     100               4              4     0.941022    0.811524\n",
       "7     100               4              4     0.936657    0.804072\n",
       "6     100               4              4     0.929989    0.798660\n",
       "5     100               4              4     0.924988    0.789212\n",
       "4     100               4              4     0.913558    0.760557\n",
       "3     100               4              4     0.896015    0.750621\n",
       "2     100               4              4     0.872916    0.731725\n",
       "1     100               4              4     0.801080    0.660575\n",
       "0     100               4              4     0.718844    0.599627"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_results.sort_values(by = 'test_score', ascending = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-05-15T12:09:44.336513Z",
     "start_time": "2017-05-15T12:09:44.293906Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pd.Panel(Train.predictions).to_pickle(\"dataset/tf_dense_only_nsl_kdd_predictions.pkl\")\n",
    "df_results.to_pickle(\"dataset/tf_dense_only_nsl_kdd_scores.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-05-15T12:09:44.439640Z",
     "start_time": "2017-05-15T12:09:44.338968Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import itertools\n",
    "\n",
    "def plot_confusion_matrix(cm, classes,\n",
    "                          normalize=False,\n",
    "                          title='Confusion matrix',\n",
    "                          cmap=plt.cm.Blues):\n",
    "    \"\"\"\n",
    "    This function prints and plots the confusion matrix.\n",
    "    Normalization can be applied by setting `normalize=True`.\n",
    "    \"\"\"\n",
    "    np.set_printoptions(precision=4)\n",
    "\n",
    "    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n",
    "    plt.title(title)\n",
    "    plt.colorbar()\n",
    "    tick_marks = np.arange(len(classes))\n",
    "    plt.xticks(tick_marks, classes, rotation=45)\n",
    "    plt.yticks(tick_marks, classes)\n",
    "\n",
    "    if normalize:\n",
    "        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "        print(\"Normalized confusion matrix\")\n",
    "    else:\n",
    "        print('Confusion matrix, without normalization')\n",
    "\n",
    "    print(cm)\n",
    "\n",
    "    thresh = cm.max() / 2.\n",
    "    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
    "        plt.text(j, i, cm[i, j].round(4),\n",
    "                 horizontalalignment=\"center\",\n",
    "                 color=\"white\" if cm[i, j] > thresh else \"black\")\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.ylabel('True label')\n",
    "    plt.xlabel('Predicted label')\n",
    "\n",
    "def plot(actual_value, pred_value):\n",
    "    from sklearn.metrics import confusion_matrix\n",
    "    cm_2labels = confusion_matrix(y_pred = pred_value, y_true = actual_value)\n",
    "    plt.figure(figsize=[6,6])\n",
    "    plot_confusion_matrix(cm_2labels, preprocess.output_columns_2labels, normalize = True,\n",
    "                         title = Train.best_parameters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-05-15T12:09:45.863039Z",
     "start_time": "2017-05-15T12:09:44.441873Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Normalized confusion matrix\n",
      "[[ 0.8675  0.1325]\n",
      " [ 0.0478  0.9522]]\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAbcAAAGeCAYAAAAXNE8VAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nSUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7fbbdfc68e10>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot(actual_value = Train.actual_value, pred_value = Train.pred_value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "_draft": {
   "nbviewer_url": "https://gist.github.com/7d1ace18a82178e15ece8fc5252fce88"
  },
  "anaconda-cloud": {},
  "gist": {
   "data": {
    "description": "Hyper parameter tuning",
    "public": false
   },
   "id": "7d1ace18a82178e15ece8fc5252fce88"
  },
  "kernelspec": {
   "display_name": "Python [conda env:p3]",
   "language": "python",
   "name": "conda-env-p3-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
