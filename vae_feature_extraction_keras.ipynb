{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Deep Learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.layers import Input, Dense, Lambda, Layer\n",
    "from keras.models import Model\n",
    "from keras import regularizers\n",
    "import keras\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from keras import backend as K\n",
    "from keras import metrics\n",
    "from collections import namedtuple\n",
    "pd.set_option(\"display.max_rows\",35)\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "kdd_train_2labels = pd.read_pickle(\"dataset/kdd_train_2labels.pkl\")\n",
    "kdd_test_2labels = pd.read_pickle(\"dataset/kdd_test_2labels.pkl\")\n",
    "\n",
    "#y_train_labels = pd.read_pickle(\"dataset/kdd_train_2labels_y.pkl\")\n",
    "#y_train_labels = pd.read_pickle(\"dataset/kdd_train_2labels.pkl\")\n",
    "#y_test_labels = pd.read_pickle(\"dataset/kdd_test_2labels_y.pkl\")\n",
    "\n",
    "output_columns_2labels = ['is_Attack','is_Normal']\n",
    "\n",
    "from sklearn import model_selection as ms\n",
    "from sklearn import preprocessing as pp\n",
    "\n",
    "x_input = kdd_train_2labels.drop(output_columns_2labels, axis = 1)\n",
    "y_output = kdd_train_2labels.loc[:,output_columns_2labels]\n",
    "\n",
    "ss = pp.StandardScaler()\n",
    "x_input = ss.fit_transform(x_input)\n",
    "\n",
    "#le = pp.LabelEncoder()\n",
    "#y_train = le.fit_transform(y_train_labels).reshape(-1, 1)\n",
    "#y_test = le.transform(y_test_labels).reshape(-1, 1)\n",
    "\n",
    "y_train = kdd_train_2labels.loc[:,output_columns_2labels]\n",
    "\n",
    "x_train, x_valid, y_train, y_valid = ms.train_test_split(x_input, \n",
    "                              y_train, \n",
    "                              test_size=0.1)\n",
    "#x_valid, x_test, y_valid, y_test = ms.train_test_split(x_valid, y_valid, test_size = 0.4)\n",
    "\n",
    "x_test = kdd_test_2labels.drop(output_columns_2labels, axis = 1)\n",
    "y_test = kdd_test_2labels.loc[:,output_columns_2labels]\n",
    "\n",
    "x_test = ss.transform(x_test)\n",
    "\n",
    "#x_train = np.hstack((x_train, y_train))\n",
    "#x_valid = np.hstack((x_valid, y_valid))\n",
    "\n",
    "#x_test = np.hstack((x_test, np.random.normal(loc = 0, scale = 0.01, size = y_test.shape)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "input_dim = 122\n",
    "intermediate_dim = 122\n",
    "latent_dim = 32\n",
    "batch_size = 1409\n",
    "epochs = 5\n",
    "hidden_layers = 8\n",
    "\n",
    "class Train:\n",
    "    def train():\n",
    "        Train.x = Input(shape=(input_dim,))\n",
    "        \n",
    "        hidden_encoder = Train.x\n",
    "        for i in range(hidden_layers):\n",
    "            hidden_encoder = Dense(intermediate_dim, activation='relu')(hidden_encoder)\n",
    "\n",
    "        mean_encoder = Dense(latent_dim, activation=None)(hidden_encoder)\n",
    "\n",
    "        logvar_encoder = Dense(latent_dim, activation=None)(hidden_encoder)\n",
    "\n",
    "        def get_distrib(args):\n",
    "\n",
    "            mean_encoder, logvar_encoder = args\n",
    "\n",
    "            # Sample epsilon\n",
    "            epsilon = np.random.normal(loc=0.0, scale=0.05, size = (batch_size, latent_dim))\n",
    "\n",
    "            # Sample latent variable\n",
    "            z = mean_encoder + K.exp(logvar_encoder / 2) * epsilon\n",
    "            return z\n",
    "\n",
    "        z = Lambda(get_distrib)([mean_encoder, logvar_encoder])\n",
    "\n",
    "        hidden_decoder = z\n",
    "        for i in range(hidden_layers):\n",
    "            hidden_decoder = Dense(intermediate_dim, activation=\"relu\")(hidden_decoder)\n",
    "\n",
    "        Train.x_ = Dense(input_dim, activation=None)(hidden_decoder)\n",
    "\n",
    "def get_loss(x, x_):\n",
    "    xent_loss = input_dim * metrics.binary_crossentropy(x, x_) \n",
    "    kl_loss = - 0.5 * K.sum(1 + logvar_encoder - K.square(mean_encoder) - K.exp(logvar_encoder), axis=-1)\n",
    "    \n",
    "    return K.abs(K.mean(xent_loss + kl_loss + label_loss))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " \n",
      " Current Layer Attributes - epochs:10 hidden layers:2 features count:4\n",
      "Train on 112720 samples, validate on 22544 samples\n",
      "Epoch 1/10\n",
      "112720/112720 [==============================] - 2s - loss: 1.0253 - acc: 0.0545 - val_loss: 1.8146 - val_acc: 0.0362\n",
      "Epoch 2/10\n",
      "112720/112720 [==============================] - 1s - loss: 0.7613 - acc: 0.1098 - val_loss: 1.7234 - val_acc: 0.2256\n",
      "Epoch 3/10\n",
      "112720/112720 [==============================] - 1s - loss: 0.6864 - acc: 0.2856 - val_loss: 1.6391 - val_acc: 0.4060\n",
      "Epoch 4/10\n",
      "112720/112720 [==============================] - 1s - loss: 0.6178 - acc: 0.5789 - val_loss: 1.5410 - val_acc: 0.7103\n",
      "Epoch 5/10\n",
      "112720/112720 [==============================] - 1s - loss: 0.5609 - acc: 0.7341 - val_loss: 1.4288 - val_acc: 0.7595\n",
      "Epoch 6/10\n",
      "112720/112720 [==============================] - 1s - loss: 0.5136 - acc: 0.7974 - val_loss: 1.3410 - val_acc: 0.7744\n",
      "Epoch 7/10\n",
      "112720/112720 [==============================] - 1s - loss: 0.4722 - acc: 0.8237 - val_loss: 1.2514 - val_acc: 0.8019\n",
      "Epoch 8/10\n",
      "112720/112720 [==============================] - 2s - loss: 0.4400 - acc: 0.8293 - val_loss: 1.1869 - val_acc: 0.8105\n",
      "Epoch 9/10\n",
      "112720/112720 [==============================] - 2s - loss: 0.4108 - acc: 0.8360 - val_loss: 1.1538 - val_acc: 0.8145\n",
      "Epoch 10/10\n",
      "112720/112720 [==============================] - 2s - loss: 0.3844 - acc: 0.8417 - val_loss: 1.1199 - val_acc: 0.8154\n",
      "22544/22544 [==============================] - 0s     \n",
      "\n",
      " Train Acc: 0.8411107137799263, Test Acc: 0.8154276013374329\n",
      " \n",
      " Current Layer Attributes - epochs:10 hidden layers:2 features count:16\n",
      "Train on 112720 samples, validate on 22544 samples\n",
      "Epoch 1/10\n",
      "112720/112720 [==============================] - 2s - loss: 2110040627340.7759 - acc: 0.0190 - val_loss: 79735337.6699 - val_acc: 0.0168\n",
      "Epoch 2/10\n",
      "112720/112720 [==============================] - 3s - loss: 718093644.0417 - acc: 0.0178 - val_loss: 29.6445 - val_acc: 0.0351\n",
      "Epoch 3/10\n",
      "112720/112720 [==============================] - 3s - loss: 106.0687 - acc: 0.0536 - val_loss: 8.5408 - val_acc: 0.0894\n",
      "Epoch 4/10\n",
      "112720/112720 [==============================] - 3s - loss: 18.6675 - acc: 0.0936 - val_loss: 3.2809 - val_acc: 0.1066\n",
      "Epoch 5/10\n",
      "112720/112720 [==============================] - 3s - loss: 1.8069 - acc: 0.1241 - val_loss: 2.4229 - val_acc: 0.1271\n",
      "Epoch 6/10\n",
      "112720/112720 [==============================] - 3s - loss: 0.8808 - acc: 0.1404 - val_loss: 2.9847 - val_acc: 0.1297\n",
      "Epoch 7/10\n",
      "112720/112720 [==============================] - 3s - loss: 1.5293 - acc: 0.1446 - val_loss: 1.8911 - val_acc: 0.1359\n",
      "Epoch 8/10\n",
      "112720/112720 [==============================] - 3s - loss: 0.8326 - acc: 0.1493 - val_loss: 1.8636 - val_acc: 0.1621\n",
      "Epoch 9/10\n",
      "112720/112720 [==============================] - 3s - loss: 0.8239 - acc: 0.1485 - val_loss: 1.8841 - val_acc: 0.1295\n",
      "Epoch 10/10\n",
      "112720/112720 [==============================] - 3s - loss: 0.8099 - acc: 0.1441 - val_loss: 2.1325 - val_acc: 0.1291\n",
      "11272/11272 [==============================] - 0s     \n",
      "18317/22544 [=======================>......] - ETA: 0s\n",
      " Train Acc: 0.14948545210063457, Test Acc: 0.1290809093043208\n",
      " \n",
      " Current Layer Attributes - epochs:10 hidden layers:2 features count:32\n",
      "Train on 112720 samples, validate on 22544 samples\n",
      "Epoch 1/10\n",
      "112720/112720 [==============================] - 3s - loss: nan - acc: 0.0351 - val_loss: nan - val_acc: 1.7743e-04\n",
      "Epoch 2/10\n",
      "112720/112720 [==============================] - 3s - loss: nan - acc: 0.0050 - val_loss: nan - val_acc: 1.7743e-04\n",
      "Epoch 3/10\n",
      "112720/112720 [==============================] - 3s - loss: nan - acc: 0.0050 - val_loss: nan - val_acc: 1.7743e-04\n",
      "Epoch 4/10\n",
      "112720/112720 [==============================] - 3s - loss: nan - acc: 0.0050 - val_loss: nan - val_acc: 1.7743e-04\n",
      "Epoch 5/10\n",
      "112720/112720 [==============================] - 3s - loss: nan - acc: 0.0050 - val_loss: nan - val_acc: 1.7743e-04\n",
      "Epoch 6/10\n",
      "112720/112720 [==============================] - 3s - loss: nan - acc: 0.0050 - val_loss: nan - val_acc: 1.7743e-04\n",
      "Epoch 7/10\n",
      "112720/112720 [==============================] - 3s - loss: nan - acc: 0.0050 - val_loss: nan - val_acc: 1.7743e-04\n",
      "Epoch 8/10\n",
      "112720/112720 [==============================] - 3s - loss: nan - acc: 0.0050 - val_loss: nan - val_acc: 1.7743e-04\n",
      "Epoch 9/10\n",
      "112720/112720 [==============================] - 3s - loss: nan - acc: 0.0050 - val_loss: nan - val_acc: 1.7743e-04\n",
      "Epoch 10/10\n",
      "112720/112720 [==============================] - 3s - loss: nan - acc: 0.0050 - val_loss: nan - val_acc: 1.7743e-04\n",
      "22544/22544 [==============================] - 0s     \n",
      "\n",
      " Train Acc: 0.005234208714682609, Test Acc: 0.00017743080388754606\n",
      " \n",
      " Current Layer Attributes - epochs:10 hidden layers:6 features count:4\n",
      "Train on 112720 samples, validate on 22544 samples\n",
      "Epoch 1/10\n",
      "112720/112720 [==============================] - 9s - loss: 0.8604 - acc: 0.0590 - val_loss: 1.7666 - val_acc: 0.1142\n",
      "Epoch 2/10\n",
      "112720/112720 [==============================] - 8s - loss: 0.6926 - acc: 0.3011 - val_loss: 1.6543 - val_acc: 0.5052\n",
      "Epoch 3/10\n",
      "112720/112720 [==============================] - 8s - loss: 0.5965 - acc: 0.6022 - val_loss: 1.5366 - val_acc: 0.6642\n",
      "Epoch 4/10\n",
      "112720/112720 [==============================] - 8s - loss: 0.5093 - acc: 0.7445 - val_loss: 1.4105 - val_acc: 0.7704\n",
      "Epoch 5/10\n",
      "112720/112720 [==============================] - 7s - loss: 0.4204 - acc: 0.8151 - val_loss: 1.2261 - val_acc: 0.7952\n",
      "Epoch 6/10\n",
      "112720/112720 [==============================] - 8s - loss: 0.3559 - acc: 0.8544 - val_loss: 1.1118 - val_acc: 0.8121\n",
      "Epoch 7/10\n",
      "112720/112720 [==============================] - 8s - loss: 0.3111 - acc: 0.8598 - val_loss: 1.0424 - val_acc: 0.8206\n",
      "Epoch 8/10\n",
      "112720/112720 [==============================] - 8s - loss: 0.2806 - acc: 0.8658 - val_loss: 0.9319 - val_acc: 0.8144\n",
      "Epoch 9/10\n",
      "112720/112720 [==============================] - 8s - loss: 0.2622 - acc: 0.8723 - val_loss: 0.9160 - val_acc: 0.8286\n",
      "Epoch 10/10\n",
      "112720/112720 [==============================] - 8s - loss: 0.2373 - acc: 0.8773 - val_loss: 0.9735 - val_acc: 0.8232\n",
      "21135/22544 [===========================>..] - ETA: 0s\n",
      " Train Acc: 0.872515968978405, Test Acc: 0.8231902047991753\n",
      " \n",
      " Current Layer Attributes - epochs:10 hidden layers:6 features count:16\n",
      "Train on 112720 samples, validate on 22544 samples\n",
      "Epoch 1/10\n",
      "112720/112720 [==============================] - 8s - loss: 24.6822 - acc: 0.0097 - val_loss: 1.8261 - val_acc: 0.0664\n",
      "Epoch 2/10\n",
      "112720/112720 [==============================] - 8s - loss: 0.8079 - acc: 0.2261 - val_loss: 1.7137 - val_acc: 0.4496\n",
      "Epoch 3/10\n",
      "112720/112720 [==============================] - 8s - loss: 0.7030 - acc: 0.5099 - val_loss: 1.5634 - val_acc: 0.6874\n",
      "Epoch 4/10\n",
      "112720/112720 [==============================] - 9s - loss: 0.6377 - acc: 0.5976 - val_loss: 1.3999 - val_acc: 0.7005\n",
      "Epoch 5/10\n",
      "112720/112720 [==============================] - 8s - loss: 0.5940 - acc: 0.6422 - val_loss: 1.3489 - val_acc: 0.7356\n",
      "Epoch 6/10\n",
      "112720/112720 [==============================] - 8s - loss: 0.5548 - acc: 0.6902 - val_loss: 1.2730 - val_acc: 0.7524\n",
      "Epoch 7/10\n",
      "112720/112720 [==============================] - 8s - loss: 0.5130 - acc: 0.7164 - val_loss: 1.1863 - val_acc: 0.7690\n",
      "Epoch 8/10\n",
      "112720/112720 [==============================] - 8s - loss: 0.4801 - acc: 0.7469 - val_loss: 1.0997 - val_acc: 0.7846\n",
      "Epoch 9/10\n",
      "112720/112720 [==============================] - 8s - loss: 0.4482 - acc: 0.7658 - val_loss: 1.1010 - val_acc: 0.7666\n",
      "Epoch 10/10\n",
      "112720/112720 [==============================] - 8s - loss: 0.4439 - acc: 0.7773 - val_loss: 1.0139 - val_acc: 0.8213\n",
      "21135/22544 [===========================>..] - ETA: 0s\n",
      " Train Acc: 0.8516678437590599, Test Acc: 0.8213271833956242\n",
      " \n",
      " Current Layer Attributes - epochs:10 hidden layers:6 features count:32\n",
      "Train on 112720 samples, validate on 22544 samples\n",
      "Epoch 1/10\n",
      "112720/112720 [==============================] - 8s - loss: 1.3063 - acc: 0.0427 - val_loss: 1.8004 - val_acc: 0.0732\n",
      "Epoch 2/10\n",
      "112720/112720 [==============================] - 8s - loss: 0.7365 - acc: 0.2927 - val_loss: 1.6783 - val_acc: 0.6080\n",
      "Epoch 3/10\n",
      "112720/112720 [==============================] - 8s - loss: 0.6341 - acc: 0.6315 - val_loss: 1.5290 - val_acc: 0.7631\n",
      "Epoch 4/10\n",
      "112720/112720 [==============================] - 9s - loss: 0.5470 - acc: 0.7228 - val_loss: 1.4118 - val_acc: 0.7362\n",
      "Epoch 5/10\n",
      "112720/112720 [==============================] - 9s - loss: 0.4787 - acc: 0.7857 - val_loss: 1.3040 - val_acc: 0.7506\n",
      "Epoch 6/10\n",
      "112720/112720 [==============================] - 8s - loss: 0.4230 - acc: 0.8292 - val_loss: 1.1638 - val_acc: 0.7394\n",
      "Epoch 7/10\n",
      "112720/112720 [==============================] - 8s - loss: 0.3832 - acc: 0.8283 - val_loss: 1.0606 - val_acc: 0.8600\n",
      "Epoch 8/10\n",
      "112720/112720 [==============================] - 8s - loss: 0.3451 - acc: 0.8543 - val_loss: 0.9519 - val_acc: 0.8603\n",
      "Epoch 9/10\n",
      "112720/112720 [==============================] - 8s - loss: 0.3126 - acc: 0.8518 - val_loss: 0.9121 - val_acc: 0.8634\n",
      "Epoch 10/10\n",
      "112720/112720 [==============================] - 8s - loss: 0.2782 - acc: 0.8546 - val_loss: 0.8074 - val_acc: 0.8709\n",
      "21135/22544 [===========================>..] - ETA: 0s\n",
      " Train Acc: 0.8954045474529266, Test Acc: 0.870919082313776\n",
      " \n",
      " Current Layer Attributes - epochs:10 hidden layers:10 features count:4\n",
      "Train on 112720 samples, validate on 22544 samples\n",
      "Epoch 1/10\n",
      "112720/112720 [==============================] - 14s - loss: 0.9280 - acc: 0.0594 - val_loss: 1.8611 - val_acc: 9.7587e-04\n",
      "Epoch 2/10\n",
      "112720/112720 [==============================] - 13s - loss: 0.8167 - acc: 0.1639 - val_loss: 1.7958 - val_acc: 0.2121\n",
      "Epoch 3/10\n",
      "112720/112720 [==============================] - 13s - loss: 0.7530 - acc: 0.3893 - val_loss: 1.7572 - val_acc: 0.5817\n",
      "Epoch 4/10\n",
      "112720/112720 [==============================] - 13s - loss: 0.7201 - acc: 0.4876 - val_loss: 1.7374 - val_acc: 0.5853\n",
      "Epoch 5/10\n",
      "112720/112720 [==============================] - 13s - loss: 0.7054 - acc: 0.5311 - val_loss: 1.7250 - val_acc: 0.5644\n",
      "Epoch 6/10\n",
      "112720/112720 [==============================] - 13s - loss: 0.6788 - acc: 0.5645 - val_loss: 1.6960 - val_acc: 0.6329\n",
      "Epoch 7/10\n",
      "112720/112720 [==============================] - 13s - loss: 0.6590 - acc: 0.5901 - val_loss: 1.6581 - val_acc: 0.6760\n",
      "Epoch 8/10\n",
      "112720/112720 [==============================] - 11s - loss: 0.6508 - acc: 0.6010 - val_loss: 1.6266 - val_acc: 0.6900\n",
      "Epoch 9/10\n",
      "112720/112720 [==============================] - 13s - loss: 0.6117 - acc: 0.6371 - val_loss: 1.6064 - val_acc: 0.7169\n",
      "Epoch 10/10\n",
      "112720/112720 [==============================] - 13s - loss: 0.6191 - acc: 0.6211 - val_loss: 1.5593 - val_acc: 0.6878\n",
      "11272/11272 [==============================] - 0s     \n",
      "22544/22544 [==============================] - 0s     \n",
      "\n",
      " Train Acc: 0.617459200322628, Test Acc: 0.687766145914793\n",
      " \n",
      " Current Layer Attributes - epochs:10 hidden layers:10 features count:16\n",
      "Train on 112720 samples, validate on 22544 samples\n",
      "Epoch 1/10\n",
      "112720/112720 [==============================] - 16s - loss: 0.9222 - acc: 0.0024 - val_loss: 1.8666 - val_acc: 0.0033\n",
      "Epoch 2/10\n",
      "112720/112720 [==============================] - 13s - loss: 0.8126 - acc: 0.1466 - val_loss: 1.7889 - val_acc: 0.4668\n",
      "Epoch 3/10\n",
      "112720/112720 [==============================] - 13s - loss: 0.7456 - acc: 0.4611 - val_loss: 1.7615 - val_acc: 0.5692\n",
      "Epoch 4/10\n",
      "112720/112720 [==============================] - 14s - loss: 0.7229 - acc: 0.4975 - val_loss: 1.7554 - val_acc: 0.5403\n",
      "Epoch 5/10\n",
      "112720/112720 [==============================] - 13s - loss: 0.6907 - acc: 0.5705 - val_loss: 1.7772 - val_acc: 0.4890\n",
      "Epoch 6/10\n",
      "112720/112720 [==============================] - 11s - loss: 0.6765 - acc: 0.6095 - val_loss: 1.6832 - val_acc: 0.6468\n",
      "Epoch 7/10\n",
      "112720/112720 [==============================] - 13s - loss: 0.6398 - acc: 0.6756 - val_loss: 1.6360 - val_acc: 0.7305\n",
      "Epoch 8/10\n",
      "112720/112720 [==============================] - 13s - loss: 0.6273 - acc: 0.6893 - val_loss: 1.6306 - val_acc: 0.7024\n",
      "Epoch 9/10\n",
      "112720/112720 [==============================] - 13s - loss: 0.6013 - acc: 0.7222 - val_loss: 1.5608 - val_acc: 0.6842\n",
      "Epoch 10/10\n",
      "112720/112720 [==============================] - 15s - loss: 0.5887 - acc: 0.7121 - val_loss: 1.5508 - val_acc: 0.7355\n",
      "11272/11272 [==============================] - 0s     \n",
      "22544/22544 [==============================] - 0s     \n",
      "\n",
      " Train Acc: 0.7491128444671631, Test Acc: 0.7355393879115582\n",
      " \n",
      " Current Layer Attributes - epochs:10 hidden layers:10 features count:32\n",
      "Train on 112720 samples, validate on 22544 samples\n",
      "Epoch 1/10\n",
      "112720/112720 [==============================] - 16s - loss: 0.9312 - acc: 0.0618 - val_loss: 1.8757 - val_acc: 0.2826\n",
      "Epoch 2/10\n",
      "112720/112720 [==============================] - 14s - loss: 0.8053 - acc: 0.2476 - val_loss: 1.7866 - val_acc: 0.4278\n",
      "Epoch 3/10\n",
      "112720/112720 [==============================] - 14s - loss: 0.7417 - acc: 0.4739 - val_loss: 1.7342 - val_acc: 0.6192\n",
      "Epoch 4/10\n",
      "112720/112720 [==============================] - 14s - loss: 0.6945 - acc: 0.5400 - val_loss: 1.7132 - val_acc: 0.6340\n",
      "Epoch 5/10\n",
      "112720/112720 [==============================] - 13s - loss: 0.6431 - acc: 0.5973 - val_loss: 1.6110 - val_acc: 0.7115\n",
      "Epoch 6/10\n",
      "112720/112720 [==============================] - 11s - loss: 0.6318 - acc: 0.6177 - val_loss: 1.4674 - val_acc: 0.7272\n",
      "Epoch 7/10\n",
      "112720/112720 [==============================] - 14s - loss: 0.5666 - acc: 0.6548 - val_loss: 1.5907 - val_acc: 0.6967\n",
      "Epoch 8/10\n",
      "112720/112720 [==============================] - 14s - loss: 0.5475 - acc: 0.6780 - val_loss: 1.3612 - val_acc: 0.7870\n",
      "Epoch 9/10\n",
      "112720/112720 [==============================] - 14s - loss: 0.5032 - acc: 0.7202 - val_loss: 1.4393 - val_acc: 0.7682\n",
      "Epoch 10/10\n",
      "112720/112720 [==============================] - 14s - loss: 0.4763 - acc: 0.7829 - val_loss: 1.3120 - val_acc: 0.8053\n",
      "11272/11272 [==============================] - 0s     \n",
      "22544/22544 [==============================] - 0s     \n",
      "\n",
      " Train Acc: 0.8126330673694611, Test Acc: 0.8053140491247177\n"
     ]
    }
   ],
   "source": [
    "import itertools\n",
    "#features_arr = [4, 16, 32, 256, 1024]\n",
    "#hidden_layers_arr = [2, 6, 10, 100]\n",
    "\n",
    "features_arr = [4, 16, 32]\n",
    "hidden_layers_arr = [2, 6, 10]\n",
    "\n",
    "epoch_arr = [10]\n",
    "\n",
    "score = namedtuple(\"score\", ['epoch', 'no_of_features','hidden_layers','train_score', 'test_score'])\n",
    "scores = []\n",
    "predictions = pd.DataFrame()\n",
    "\n",
    "for e, h, f in itertools.product(epoch_arr, hidden_layers_arr, features_arr):\n",
    "    \n",
    "    print(\" \\n Current Layer Attributes - epochs:{} hidden layers:{} features count:{}\".format(e,h,f))\n",
    "    latent_dim = f\n",
    "    epochs = e\n",
    "    hidden_layers = h\n",
    "\n",
    "    Train.train()\n",
    "\n",
    "    vae_model = Model(inputs = Train.x, outputs = Train.x_ )\n",
    "    vae_model.compile(optimizer = \"adam\", loss = \"mean_squared_error\", metrics = ['accuracy'] )\n",
    "\n",
    "    train_size = x_train.shape[0] - x_train.shape[0]%batch_size\n",
    "    valid_size = x_valid.shape[0] - x_valid.shape[0]%batch_size\n",
    "\n",
    "    vae_model.fit(x = x_train[:train_size,:], y = x_train[:train_size,:], \n",
    "                  shuffle=True, epochs=epochs, \n",
    "                  batch_size = batch_size, \n",
    "                  #validation_data = (x_valid[:valid_size,:], x_valid[:valid_size,:]),\n",
    "                  validation_data = (x_test, x_test),\n",
    "                  verbose = 1)\n",
    "    \n",
    "    score_train = vae_model.evaluate(x_valid[:valid_size,:], y = x_valid[:valid_size,:],\n",
    "                               batch_size = batch_size,\n",
    "                               verbose = 1)\n",
    "    \n",
    "    score_test = vae_model.evaluate(x_test, y = x_test,\n",
    "                           batch_size = batch_size,\n",
    "                           verbose = 1)\n",
    "    \n",
    "    scores.append(score(e,f,h,score_train[-1], score_test[-1])) #score_test[-1]))\n",
    "    \n",
    "    print(\"\\n Train Acc: {}, Test Acc: {}\".format(score_train[-1], \n",
    "                                                  score_test[-1])  )\n",
    "    \n",
    "scores = pd.DataFrame(scores)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>epoch</th>\n",
       "      <th>no_of_features</th>\n",
       "      <th>hidden_layers</th>\n",
       "      <th>train_score</th>\n",
       "      <th>test_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>10</td>\n",
       "      <td>32</td>\n",
       "      <td>6</td>\n",
       "      <td>0.895405</td>\n",
       "      <td>0.870919</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>10</td>\n",
       "      <td>4</td>\n",
       "      <td>6</td>\n",
       "      <td>0.872516</td>\n",
       "      <td>0.823190</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>10</td>\n",
       "      <td>16</td>\n",
       "      <td>6</td>\n",
       "      <td>0.851668</td>\n",
       "      <td>0.821327</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>0.841111</td>\n",
       "      <td>0.815428</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>10</td>\n",
       "      <td>32</td>\n",
       "      <td>10</td>\n",
       "      <td>0.812633</td>\n",
       "      <td>0.805314</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>10</td>\n",
       "      <td>16</td>\n",
       "      <td>10</td>\n",
       "      <td>0.749113</td>\n",
       "      <td>0.735539</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>10</td>\n",
       "      <td>4</td>\n",
       "      <td>10</td>\n",
       "      <td>0.617459</td>\n",
       "      <td>0.687766</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10</td>\n",
       "      <td>16</td>\n",
       "      <td>2</td>\n",
       "      <td>0.149485</td>\n",
       "      <td>0.129081</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>10</td>\n",
       "      <td>32</td>\n",
       "      <td>2</td>\n",
       "      <td>0.005234</td>\n",
       "      <td>0.000177</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   epoch  no_of_features  hidden_layers  train_score  test_score\n",
       "5     10              32              6     0.895405    0.870919\n",
       "3     10               4              6     0.872516    0.823190\n",
       "4     10              16              6     0.851668    0.821327\n",
       "0     10               4              2     0.841111    0.815428\n",
       "8     10              32             10     0.812633    0.805314\n",
       "7     10              16             10     0.749113    0.735539\n",
       "6     10               4             10     0.617459    0.687766\n",
       "1     10              16              2     0.149485    0.129081\n",
       "2     10              32              2     0.005234    0.000177"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scores.sort_values(\"test_score\", ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "scores.to_pickle(\"dataset/vae_only_feature_extraction_scores.pkl\")"
   ]
  }
 ],
 "metadata": {
  "_draft": {
   "nbviewer_url": "https://gist.github.com/33dcb1bcf3ca4a3461c4405a003a7591"
  },
  "anaconda-cloud": {},
  "gist": {
   "data": {
    "description": "Final Hyper parameter tuning",
    "public": false
   },
   "id": "33dcb1bcf3ca4a3461c4405a003a7591"
  },
  "kernelspec": {
   "display_name": "Python [conda env:p3]",
   "language": "python",
   "name": "conda-env-p3-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
