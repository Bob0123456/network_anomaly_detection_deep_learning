{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Deep Learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.layers import Input, Dense, Lambda, Layer\n",
    "from keras.models import Model\n",
    "from keras import regularizers\n",
    "import keras\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from keras import backend as K\n",
    "from keras import metrics\n",
    "from collections import namedtuple\n",
    "pd.set_option(\"display.max_rows\",35)\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "kdd_train_2labels = pd.read_pickle(\"dataset/kdd_train_2labels.pkl\")\n",
    "kdd_test_2labels = pd.read_pickle(\"dataset/kdd_test_2labels.pkl\")\n",
    "\n",
    "#y_train_labels = pd.read_pickle(\"dataset/kdd_train_2labels_y.pkl\")\n",
    "#y_train_labels = pd.read_pickle(\"dataset/kdd_train_2labels.pkl\")\n",
    "#y_test_labels = pd.read_pickle(\"dataset/kdd_test_2labels_y.pkl\")\n",
    "\n",
    "output_columns_2labels = ['is_Attack','is_Normal']\n",
    "\n",
    "from sklearn import model_selection as ms\n",
    "from sklearn import preprocessing as pp\n",
    "\n",
    "x_input = kdd_train_2labels.drop(output_columns_2labels, axis = 1)\n",
    "y_output = kdd_train_2labels.loc[:,output_columns_2labels]\n",
    "\n",
    "ss = pp.StandardScaler()\n",
    "x_input = ss.fit_transform(x_input)\n",
    "\n",
    "#le = pp.LabelEncoder()\n",
    "#y_train = le.fit_transform(y_train_labels).reshape(-1, 1)\n",
    "#y_test = le.transform(y_test_labels).reshape(-1, 1)\n",
    "\n",
    "y_train = kdd_train_2labels.loc[:,output_columns_2labels]\n",
    "\n",
    "x_train, x_valid, y_train, y_valid = ms.train_test_split(x_input, \n",
    "                              y_train, \n",
    "                              test_size=0.1)\n",
    "#x_valid, x_test, y_valid, y_test = ms.train_test_split(x_valid, y_valid, test_size = 0.4)\n",
    "\n",
    "x_test = kdd_test_2labels.drop(output_columns_2labels, axis = 1)\n",
    "y_test = kdd_test_2labels.loc[:,output_columns_2labels]\n",
    "\n",
    "x_test = ss.transform(x_test)\n",
    "\n",
    "#x_train = np.hstack((x_train, y_train))\n",
    "#x_valid = np.hstack((x_valid, y_valid))\n",
    "\n",
    "#x_test = np.hstack((x_test, np.random.normal(loc = 0, scale = 0.01, size = y_test.shape)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "input_dim = 122\n",
    "intermediate_dim = 122\n",
    "latent_dim = 32\n",
    "batch_size = 1409\n",
    "epochs = 5\n",
    "hidden_layers = 8\n",
    "\n",
    "class Train:\n",
    "    def train():\n",
    "        Train.x = Input(shape=(input_dim,))\n",
    "        \n",
    "        hidden_encoder = Train.x\n",
    "        for i in range(hidden_layers):\n",
    "            hidden_encoder = Dense(intermediate_dim, activation='relu')(hidden_encoder)\n",
    "\n",
    "        mean_encoder = Dense(latent_dim, activation=None)(hidden_encoder)\n",
    "\n",
    "        logvar_encoder = Dense(latent_dim, activation=None)(hidden_encoder)\n",
    "\n",
    "        def get_distrib(args):\n",
    "\n",
    "            mean_encoder, logvar_encoder = args\n",
    "\n",
    "            # Sample epsilon\n",
    "            epsilon = np.random.normal(loc=0.0, scale=0.05, size = (batch_size, latent_dim))\n",
    "\n",
    "            # Sample latent variable\n",
    "            z = mean_encoder + K.exp(logvar_encoder / 2) * epsilon\n",
    "            return z\n",
    "\n",
    "        z = Lambda(get_distrib)([mean_encoder, logvar_encoder])\n",
    "\n",
    "        hidden_decoder = z\n",
    "        for i in range(hidden_layers):\n",
    "            hidden_decoder = Dense(intermediate_dim, activation=\"relu\")(hidden_decoder)\n",
    "\n",
    "        Train.x_ = Dense(input_dim, activation=None)(hidden_decoder)\n",
    "\n",
    "def get_loss(x, x_):\n",
    "    xent_loss = input_dim * metrics.binary_crossentropy(x, x_) \n",
    "    kl_loss = - 0.5 * K.sum(1 + logvar_encoder - K.square(mean_encoder) - K.exp(logvar_encoder), axis=-1)\n",
    "    \n",
    "    return K.abs(K.mean(xent_loss + kl_loss + label_loss))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " \n",
      " Current Layer Attributes - epochs:50 hidden layers:2 features count:4\n",
      "Train on 112720 samples, validate on 22544 samples\n",
      "Epoch 1/50\n",
      "112720/112720 [==============================] - 1s - loss: 0.8667 - acc: 0.0529 - val_loss: 1.7562 - val_acc: 0.1637\n",
      "Epoch 2/50\n",
      "112720/112720 [==============================] - 0s - loss: 0.6748 - acc: 0.4359 - val_loss: 1.5903 - val_acc: 0.6757\n",
      "Epoch 3/50\n",
      "112720/112720 [==============================] - 0s - loss: 0.5707 - acc: 0.6723 - val_loss: 1.4343 - val_acc: 0.7369\n",
      "Epoch 4/50\n",
      "112720/112720 [==============================] - 0s - loss: 0.4954 - acc: 0.7938 - val_loss: 1.3161 - val_acc: 0.7855\n",
      "Epoch 5/50\n",
      "112720/112720 [==============================] - 0s - loss: 0.4391 - acc: 0.8329 - val_loss: 1.2154 - val_acc: 0.7904\n",
      "Epoch 6/50\n",
      "112720/112720 [==============================] - 0s - loss: 0.3891 - acc: 0.8462 - val_loss: 1.1568 - val_acc: 0.7949\n",
      "Epoch 7/50\n",
      "112720/112720 [==============================] - 0s - loss: 0.3568 - acc: 0.8542 - val_loss: 1.1100 - val_acc: 0.7988\n",
      "Epoch 8/50\n",
      "112720/112720 [==============================] - 0s - loss: 0.3278 - acc: 0.8598 - val_loss: 1.1044 - val_acc: 0.7999\n",
      "Epoch 9/50\n",
      "112720/112720 [==============================] - 0s - loss: 0.3132 - acc: 0.8625 - val_loss: 1.0762 - val_acc: 0.8036\n",
      "Epoch 10/50\n",
      "112720/112720 [==============================] - 0s - loss: 0.2948 - acc: 0.8671 - val_loss: 1.0661 - val_acc: 0.8047\n",
      "Epoch 11/50\n",
      "112720/112720 [==============================] - 0s - loss: 0.2806 - acc: 0.8690 - val_loss: 1.0569 - val_acc: 0.8196\n",
      "Epoch 12/50\n",
      "112720/112720 [==============================] - 0s - loss: 0.2670 - acc: 0.8715 - val_loss: 1.0434 - val_acc: 0.8227\n",
      "Epoch 13/50\n",
      "112720/112720 [==============================] - 0s - loss: 0.2530 - acc: 0.8733 - val_loss: 1.0243 - val_acc: 0.8302\n",
      "Epoch 14/50\n",
      "112720/112720 [==============================] - 0s - loss: 0.2440 - acc: 0.8746 - val_loss: 1.0186 - val_acc: 0.8472\n",
      "Epoch 15/50\n",
      "112720/112720 [==============================] - 0s - loss: 0.2356 - acc: 0.8748 - val_loss: 1.0076 - val_acc: 0.8531\n",
      "Epoch 16/50\n",
      "112720/112720 [==============================] - 0s - loss: 0.2279 - acc: 0.8758 - val_loss: 0.9873 - val_acc: 0.8531\n",
      "Epoch 17/50\n",
      "112720/112720 [==============================] - 0s - loss: 0.2233 - acc: 0.8776 - val_loss: 0.9726 - val_acc: 0.8555\n",
      "Epoch 18/50\n",
      "112720/112720 [==============================] - 0s - loss: 0.2146 - acc: 0.8788 - val_loss: 0.9840 - val_acc: 0.8550\n",
      "Epoch 19/50\n",
      "112720/112720 [==============================] - 0s - loss: 0.2108 - acc: 0.8799 - val_loss: 0.9688 - val_acc: 0.8565\n",
      "Epoch 20/50\n",
      "112720/112720 [==============================] - 0s - loss: 0.2050 - acc: 0.8807 - val_loss: 0.9412 - val_acc: 0.8572\n",
      "Epoch 21/50\n",
      "112720/112720 [==============================] - 0s - loss: 0.1997 - acc: 0.8829 - val_loss: 0.9305 - val_acc: 0.8604\n",
      "Epoch 22/50\n",
      "112720/112720 [==============================] - 0s - loss: 0.1929 - acc: 0.8849 - val_loss: 0.9391 - val_acc: 0.8621\n",
      "Epoch 23/50\n",
      "112720/112720 [==============================] - 0s - loss: 0.1894 - acc: 0.8855 - val_loss: 0.9184 - val_acc: 0.8625\n",
      "Epoch 24/50\n",
      "112720/112720 [==============================] - 0s - loss: 0.1875 - acc: 0.8870 - val_loss: 0.8904 - val_acc: 0.8633\n",
      "Epoch 25/50\n",
      "112720/112720 [==============================] - 0s - loss: 0.1804 - acc: 0.8871 - val_loss: 0.8864 - val_acc: 0.8620\n",
      "Epoch 26/50\n",
      "112720/112720 [==============================] - 0s - loss: 0.1829 - acc: 0.8876 - val_loss: 0.8761 - val_acc: 0.8628\n",
      "Epoch 27/50\n",
      "112720/112720 [==============================] - 0s - loss: 0.1801 - acc: 0.8876 - val_loss: 0.8588 - val_acc: 0.8628\n",
      "Epoch 28/50\n",
      "112720/112720 [==============================] - 0s - loss: 0.1743 - acc: 0.8884 - val_loss: 0.8638 - val_acc: 0.8632\n",
      "Epoch 29/50\n",
      "112720/112720 [==============================] - 0s - loss: 0.1673 - acc: 0.8890 - val_loss: 0.8436 - val_acc: 0.8640\n",
      "Epoch 30/50\n",
      "112720/112720 [==============================] - 0s - loss: 0.1657 - acc: 0.8896 - val_loss: 0.8189 - val_acc: 0.8644\n",
      "Epoch 31/50\n",
      "112720/112720 [==============================] - 0s - loss: 0.1621 - acc: 0.8900 - val_loss: 0.8227 - val_acc: 0.8644\n",
      "Epoch 32/50\n",
      "112720/112720 [==============================] - 0s - loss: 0.1583 - acc: 0.8905 - val_loss: 0.8220 - val_acc: 0.8647\n",
      "Epoch 33/50\n",
      "112720/112720 [==============================] - 0s - loss: 0.1556 - acc: 0.8911 - val_loss: 0.8225 - val_acc: 0.8671\n",
      "Epoch 34/50\n",
      "112720/112720 [==============================] - 0s - loss: 0.1547 - acc: 0.8919 - val_loss: 0.8257 - val_acc: 0.8657\n",
      "Epoch 35/50\n",
      "112720/112720 [==============================] - 0s - loss: 0.1585 - acc: 0.8929 - val_loss: 0.8250 - val_acc: 0.8644\n",
      "Epoch 36/50\n",
      "112720/112720 [==============================] - 0s - loss: 0.1526 - acc: 0.8931 - val_loss: 0.8181 - val_acc: 0.8649\n",
      "Epoch 37/50\n",
      "112720/112720 [==============================] - 0s - loss: 0.1469 - acc: 0.8936 - val_loss: 0.7938 - val_acc: 0.8676\n",
      "Epoch 38/50\n",
      "112720/112720 [==============================] - 0s - loss: 0.1483 - acc: 0.8948 - val_loss: 0.8074 - val_acc: 0.8681\n",
      "Epoch 39/50\n",
      "112720/112720 [==============================] - 0s - loss: 0.1448 - acc: 0.8951 - val_loss: 0.8137 - val_acc: 0.8684\n",
      "Epoch 40/50\n",
      "112720/112720 [==============================] - 0s - loss: 0.1500 - acc: 0.8955 - val_loss: 0.7969 - val_acc: 0.8679\n",
      "Epoch 41/50\n",
      "112720/112720 [==============================] - 0s - loss: 0.1421 - acc: 0.8958 - val_loss: 0.7790 - val_acc: 0.8681\n",
      "Epoch 42/50\n",
      "112720/112720 [==============================] - 0s - loss: 0.1375 - acc: 0.8957 - val_loss: 0.7992 - val_acc: 0.8695\n",
      "Epoch 43/50\n",
      "112720/112720 [==============================] - 0s - loss: 0.1391 - acc: 0.8971 - val_loss: 0.7816 - val_acc: 0.8685\n",
      "Epoch 44/50\n",
      "112720/112720 [==============================] - 0s - loss: 0.1360 - acc: 0.8975 - val_loss: 0.7799 - val_acc: 0.8697\n",
      "Epoch 45/50\n",
      "112720/112720 [==============================] - 0s - loss: 0.1368 - acc: 0.8986 - val_loss: 0.7693 - val_acc: 0.8718\n",
      "Epoch 46/50\n",
      "112720/112720 [==============================] - 0s - loss: 0.1360 - acc: 0.8995 - val_loss: 0.7736 - val_acc: 0.8711\n",
      "Epoch 47/50\n",
      "112720/112720 [==============================] - 0s - loss: 0.1324 - acc: 0.8997 - val_loss: 0.7779 - val_acc: 0.8714\n",
      "Epoch 48/50\n",
      "112720/112720 [==============================] - 0s - loss: 0.1315 - acc: 0.9011 - val_loss: 0.8131 - val_acc: 0.8724\n",
      "Epoch 49/50\n",
      "112720/112720 [==============================] - 0s - loss: 0.1315 - acc: 0.9019 - val_loss: 0.7779 - val_acc: 0.8717\n",
      "Epoch 50/50\n",
      "112720/112720 [==============================] - 1s - loss: 0.1313 - acc: 0.9025 - val_loss: 0.7775 - val_acc: 0.8731\n",
      "14090/22544 [=================>............] - ETA: 0s\n",
      " Train Acc: 0.8995741531252861, Test Acc: 0.8730926103889942\n",
      " \n",
      " Current Layer Attributes - epochs:50 hidden layers:2 features count:16\n",
      "Train on 112720 samples, validate on 22544 samples\n",
      "Epoch 1/50\n",
      "112720/112720 [==============================] - 1s - loss: 835675235888561.2500 - acc: 0.2210 - val_loss: 8178307.8748 - val_acc: 0.3229\n",
      "Epoch 2/50\n",
      "112720/112720 [==============================] - 1s - loss: 12390798.4645 - acc: 0.3008 - val_loss: 44383736.4447 - val_acc: 0.3133\n",
      "Epoch 3/50\n",
      "112720/112720 [==============================] - 1s - loss: 5546723.3069 - acc: 0.2903 - val_loss: 1.9125 - val_acc: 0.3283\n",
      "Epoch 4/50\n",
      "112720/112720 [==============================] - 1s - loss: 0.8773 - acc: 0.3086 - val_loss: 1.9011 - val_acc: 0.3366\n",
      "Epoch 5/50\n",
      "112720/112720 [==============================] - 1s - loss: 0.8651 - acc: 0.3250 - val_loss: 1.8835 - val_acc: 0.3322\n",
      "Epoch 6/50\n",
      "112720/112720 [==============================] - 1s - loss: 0.8468 - acc: 0.2614 - val_loss: 1.8610 - val_acc: 0.0819\n",
      "Epoch 7/50\n",
      "112720/112720 [==============================] - 1s - loss: 0.8311 - acc: 0.0729 - val_loss: 1.8442 - val_acc: 0.0459\n",
      "Epoch 8/50\n",
      "112720/112720 [==============================] - 1s - loss: 0.8191 - acc: 0.0749 - val_loss: 1.8257 - val_acc: 0.0485\n",
      "Epoch 9/50\n",
      "112720/112720 [==============================] - 1s - loss: 0.8078 - acc: 0.0906 - val_loss: 1.8085 - val_acc: 0.0564\n",
      "Epoch 10/50\n",
      "112720/112720 [==============================] - 1s - loss: 0.7970 - acc: 0.0986 - val_loss: 1.7929 - val_acc: 0.0927\n",
      "Epoch 11/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "112720/112720 [==============================] - 1s - loss: 0.7869 - acc: 0.1091 - val_loss: 1.7773 - val_acc: 0.2033\n",
      "Epoch 12/50\n",
      "112720/112720 [==============================] - 1s - loss: 0.7780 - acc: 0.1367 - val_loss: 1.7657 - val_acc: 0.2098\n",
      "Epoch 13/50\n",
      "112720/112720 [==============================] - 1s - loss: 0.7697 - acc: 0.1437 - val_loss: 1.7567 - val_acc: 0.2302\n",
      "Epoch 14/50\n",
      "112720/112720 [==============================] - 1s - loss: 0.7620 - acc: 0.1497 - val_loss: 1.7490 - val_acc: 0.1834\n",
      "Epoch 15/50\n",
      "112720/112720 [==============================] - 1s - loss: 0.7551 - acc: 0.1604 - val_loss: 1.7439 - val_acc: 0.1898\n",
      "Epoch 16/50\n",
      "112720/112720 [==============================] - 1s - loss: 0.7486 - acc: 0.1827 - val_loss: 1.7381 - val_acc: 0.2015\n",
      "Epoch 17/50\n",
      "112720/112720 [==============================] - 1s - loss: 0.7425 - acc: 0.2018 - val_loss: 1.7352 - val_acc: 0.2075\n",
      "Epoch 18/50\n",
      "112720/112720 [==============================] - 1s - loss: 0.7367 - acc: 0.2129 - val_loss: 1.7261 - val_acc: 0.2069\n",
      "Epoch 19/50\n",
      "112720/112720 [==============================] - 1s - loss: 0.7314 - acc: 0.2139 - val_loss: 1.7190 - val_acc: 0.2035\n",
      "Epoch 20/50\n",
      "112720/112720 [==============================] - 1s - loss: 0.7264 - acc: 0.2102 - val_loss: 1.7129 - val_acc: 0.1761\n",
      "Epoch 21/50\n",
      "112720/112720 [==============================] - 1s - loss: 0.7215 - acc: 0.2155 - val_loss: 1.7050 - val_acc: 0.1756\n",
      "Epoch 22/50\n",
      "112720/112720 [==============================] - 1s - loss: 0.7170 - acc: 0.2194 - val_loss: 1.6980 - val_acc: 0.1830\n",
      "Epoch 23/50\n",
      "112720/112720 [==============================] - 1s - loss: 0.7129 - acc: 0.2286 - val_loss: 1.6909 - val_acc: 0.1821\n",
      "Epoch 24/50\n",
      "112720/112720 [==============================] - 1s - loss: 0.7091 - acc: 0.2349 - val_loss: 1.6845 - val_acc: 0.1821\n",
      "Epoch 25/50\n",
      "112720/112720 [==============================] - 1s - loss: 0.7052 - acc: 0.2372 - val_loss: 1.6761 - val_acc: 0.1861\n",
      "Epoch 26/50\n",
      "112720/112720 [==============================] - 1s - loss: 0.7016 - acc: 0.2412 - val_loss: 1.6695 - val_acc: 0.1914\n",
      "Epoch 27/50\n",
      "112720/112720 [==============================] - 1s - loss: 0.6983 - acc: 0.2501 - val_loss: 1.6637 - val_acc: 0.1957\n",
      "Epoch 28/50\n",
      "112720/112720 [==============================] - 1s - loss: 0.6950 - acc: 0.2527 - val_loss: 1.6574 - val_acc: 0.1993\n",
      "Epoch 29/50\n",
      "112720/112720 [==============================] - 1s - loss: 0.6921 - acc: 0.2611 - val_loss: 1.6520 - val_acc: 0.2129\n",
      "Epoch 30/50\n",
      "112720/112720 [==============================] - 1s - loss: 0.6892 - acc: 0.2664 - val_loss: 1.6471 - val_acc: 0.2195\n",
      "Epoch 31/50\n",
      "112720/112720 [==============================] - 1s - loss: 0.6863 - acc: 0.2755 - val_loss: 1.6409 - val_acc: 0.2381\n",
      "Epoch 32/50\n",
      "112720/112720 [==============================] - 1s - loss: 0.6836 - acc: 0.2865 - val_loss: 1.6344 - val_acc: 0.2582\n",
      "Epoch 33/50\n",
      "112720/112720 [==============================] - 1s - loss: 0.6806 - acc: 0.2941 - val_loss: 1.6311 - val_acc: 0.3123\n",
      "Epoch 34/50\n",
      "112720/112720 [==============================] - 1s - loss: 0.6778 - acc: 0.3140 - val_loss: 1.6258 - val_acc: 0.2678\n",
      "Epoch 35/50\n",
      "112720/112720 [==============================] - 1s - loss: 0.6748 - acc: 0.3107 - val_loss: 1.6210 - val_acc: 0.2812\n",
      "Epoch 36/50\n",
      "112720/112720 [==============================] - 1s - loss: 0.6719 - acc: 0.3154 - val_loss: 1.6152 - val_acc: 0.2717\n",
      "Epoch 37/50\n",
      "112720/112720 [==============================] - 1s - loss: 0.6688 - acc: 0.3314 - val_loss: 1.6099 - val_acc: 0.2776\n",
      "Epoch 38/50\n",
      "112720/112720 [==============================] - 1s - loss: 0.6658 - acc: 0.3181 - val_loss: 1.6039 - val_acc: 0.2841\n",
      "Epoch 39/50\n",
      "112720/112720 [==============================] - 1s - loss: 0.6630 - acc: 0.3364 - val_loss: 1.6000 - val_acc: 0.2842\n",
      "Epoch 40/50\n",
      "112720/112720 [==============================] - 1s - loss: 0.6603 - acc: 0.3370 - val_loss: 1.5961 - val_acc: 0.2994\n",
      "Epoch 41/50\n",
      "112720/112720 [==============================] - 1s - loss: 0.6575 - acc: 0.3325 - val_loss: 1.5907 - val_acc: 0.3050\n",
      "Epoch 42/50\n",
      "112720/112720 [==============================] - 1s - loss: 0.6549 - acc: 0.3326 - val_loss: 1.5873 - val_acc: 0.2993\n",
      "Epoch 43/50\n",
      "112720/112720 [==============================] - 1s - loss: 0.6524 - acc: 0.3492 - val_loss: 1.5809 - val_acc: 0.2930\n",
      "Epoch 44/50\n",
      "112720/112720 [==============================] - 1s - loss: 0.6497 - acc: 0.3356 - val_loss: 1.5773 - val_acc: 0.3070\n",
      "Epoch 45/50\n",
      "112720/112720 [==============================] - 1s - loss: 0.6472 - acc: 0.3460 - val_loss: 1.5734 - val_acc: 0.3008\n",
      "Epoch 46/50\n",
      "112720/112720 [==============================] - 1s - loss: 0.6446 - acc: 0.3413 - val_loss: 1.5724 - val_acc: 0.3135\n",
      "Epoch 47/50\n",
      "112720/112720 [==============================] - 1s - loss: 0.6419 - acc: 0.3419 - val_loss: 1.5641 - val_acc: 0.3086\n",
      "Epoch 48/50\n",
      "112720/112720 [==============================] - 1s - loss: 0.6395 - acc: 0.3597 - val_loss: 1.5598 - val_acc: 0.3151\n",
      "Epoch 49/50\n",
      "112720/112720 [==============================] - 1s - loss: 0.6370 - acc: 0.3650 - val_loss: 1.5576 - val_acc: 0.3220\n",
      "Epoch 50/50\n",
      "112720/112720 [==============================] - 1s - loss: 0.6345 - acc: 0.3605 - val_loss: 1.5518 - val_acc: 0.3350\n",
      "11272/11272 [==============================] - 0s     \n",
      "21135/22544 [===========================>..] - ETA: 0s\n",
      " Train Acc: 0.36328956484794617, Test Acc: 0.33503371477127075\n",
      " \n",
      " Current Layer Attributes - epochs:50 hidden layers:2 features count:32\n",
      "Train on 112720 samples, validate on 22544 samples\n",
      "Epoch 1/50\n",
      "112720/112720 [==============================] - 2s - loss: 753.7413 - acc: 0.1162 - val_loss: 2.0436 - val_acc: 0.1325\n",
      "Epoch 2/50\n",
      "112720/112720 [==============================] - 1s - loss: 0.7265 - acc: 0.1854 - val_loss: 2.0131 - val_acc: 0.2353\n",
      "Epoch 3/50\n",
      "112720/112720 [==============================] - 1s - loss: 0.6424 - acc: 0.5308 - val_loss: 1.6074 - val_acc: 0.6187\n",
      "Epoch 4/50\n",
      "112720/112720 [==============================] - 1s - loss: 0.5806 - acc: 0.6966 - val_loss: 1.5299 - val_acc: 0.6936\n",
      "Epoch 5/50\n",
      "112720/112720 [==============================] - 1s - loss: 0.5319 - acc: 0.7433 - val_loss: 1.4615 - val_acc: 0.8153\n",
      "Epoch 6/50\n",
      "112720/112720 [==============================] - 1s - loss: 0.4928 - acc: 0.7632 - val_loss: 1.4027 - val_acc: 0.8298\n",
      "Epoch 7/50\n",
      "112720/112720 [==============================] - 1s - loss: 0.4591 - acc: 0.7761 - val_loss: 1.3383 - val_acc: 0.8343\n",
      "Epoch 8/50\n",
      "112720/112720 [==============================] - 1s - loss: 0.4305 - acc: 0.7820 - val_loss: 1.2819 - val_acc: 0.8358\n",
      "Epoch 9/50\n",
      "112720/112720 [==============================] - 1s - loss: 0.4057 - acc: 0.7855 - val_loss: 1.2323 - val_acc: 0.8429\n",
      "Epoch 10/50\n",
      "112720/112720 [==============================] - 1s - loss: 0.3836 - acc: 0.7924 - val_loss: 1.1883 - val_acc: 0.8449\n",
      "Epoch 11/50\n",
      "112720/112720 [==============================] - 1s - loss: 0.3645 - acc: 0.7965 - val_loss: 1.1515 - val_acc: 0.8500\n",
      "Epoch 12/50\n",
      "112720/112720 [==============================] - 1s - loss: 0.3474 - acc: 0.7987 - val_loss: 1.1243 - val_acc: 0.8546\n",
      "Epoch 13/50\n",
      "112720/112720 [==============================] - 1s - loss: 0.3331 - acc: 0.7963 - val_loss: 1.0857 - val_acc: 0.8579\n",
      "Epoch 14/50\n",
      "112720/112720 [==============================] - 1s - loss: 0.3183 - acc: 0.7985 - val_loss: 1.0590 - val_acc: 0.8580\n",
      "Epoch 15/50\n",
      "112720/112720 [==============================] - 1s - loss: 0.3058 - acc: 0.7973 - val_loss: 1.0305 - val_acc: 0.8579\n",
      "Epoch 16/50\n",
      "112720/112720 [==============================] - 1s - loss: 0.2940 - acc: 0.8020 - val_loss: 1.0045 - val_acc: 0.8602\n",
      "Epoch 17/50\n",
      "112720/112720 [==============================] - 1s - loss: 0.2844 - acc: 0.8218 - val_loss: 0.9733 - val_acc: 0.8782\n",
      "Epoch 18/50\n",
      "112720/112720 [==============================] - 1s - loss: 0.2743 - acc: 0.8259 - val_loss: 0.9517 - val_acc: 0.8612\n",
      "Epoch 19/50\n",
      "112720/112720 [==============================] - 1s - loss: 0.2651 - acc: 0.8322 - val_loss: 0.9211 - val_acc: 0.8717\n",
      "Epoch 20/50\n",
      "112720/112720 [==============================] - 1s - loss: 0.2565 - acc: 0.8555 - val_loss: 0.8905 - val_acc: 0.8704\n",
      "Epoch 21/50\n",
      "112720/112720 [==============================] - 1s - loss: 0.2479 - acc: 0.8644 - val_loss: 0.8652 - val_acc: 0.8926\n",
      "Epoch 22/50\n",
      "112720/112720 [==============================] - 1s - loss: 0.2404 - acc: 0.8738 - val_loss: 0.8496 - val_acc: 0.8649\n",
      "Epoch 23/50\n",
      "112720/112720 [==============================] - 1s - loss: 0.2354 - acc: 0.8847 - val_loss: 0.8291 - val_acc: 0.8894\n",
      "Epoch 24/50\n",
      "112720/112720 [==============================] - 1s - loss: 0.2285 - acc: 0.8920 - val_loss: 0.8175 - val_acc: 0.8960\n",
      "Epoch 25/50\n",
      "112720/112720 [==============================] - 1s - loss: 0.2224 - acc: 0.8984 - val_loss: 0.7921 - val_acc: 0.8888\n",
      "Epoch 26/50\n",
      "112720/112720 [==============================] - 1s - loss: 0.2167 - acc: 0.9042 - val_loss: 0.7805 - val_acc: 0.8974\n",
      "Epoch 27/50\n",
      "112720/112720 [==============================] - 1s - loss: 0.2104 - acc: 0.9083 - val_loss: 0.7537 - val_acc: 0.9018\n",
      "Epoch 28/50\n",
      "112720/112720 [==============================] - 1s - loss: 0.2059 - acc: 0.9104 - val_loss: 0.7412 - val_acc: 0.9017\n",
      "Epoch 29/50\n",
      "112720/112720 [==============================] - 1s - loss: 0.2015 - acc: 0.9105 - val_loss: 0.7278 - val_acc: 0.9030\n",
      "Epoch 30/50\n",
      "112720/112720 [==============================] - 1s - loss: 0.1976 - acc: 0.9121 - val_loss: 0.7050 - val_acc: 0.9020\n",
      "Epoch 31/50\n",
      "112720/112720 [==============================] - 1s - loss: 0.1945 - acc: 0.9131 - val_loss: 0.6934 - val_acc: 0.9038\n",
      "Epoch 32/50\n",
      "112720/112720 [==============================] - 1s - loss: 0.1865 - acc: 0.9128 - val_loss: 0.6787 - val_acc: 0.9026\n",
      "Epoch 33/50\n",
      "112720/112720 [==============================] - 1s - loss: 0.1821 - acc: 0.9138 - val_loss: 0.6610 - val_acc: 0.9054\n",
      "Epoch 34/50\n",
      "112720/112720 [==============================] - 1s - loss: 0.1786 - acc: 0.9138 - val_loss: 0.6470 - val_acc: 0.9009\n",
      "Epoch 35/50\n",
      "112720/112720 [==============================] - 1s - loss: 0.1755 - acc: 0.9142 - val_loss: 0.6351 - val_acc: 0.9027\n",
      "Epoch 36/50\n",
      "112720/112720 [==============================] - 1s - loss: 0.1756 - acc: 0.9147 - val_loss: 0.6207 - val_acc: 0.9063\n",
      "Epoch 37/50\n",
      "112720/112720 [==============================] - 1s - loss: 0.1684 - acc: 0.9152 - val_loss: 0.5946 - val_acc: 0.9053\n",
      "Epoch 38/50\n",
      "112720/112720 [==============================] - 1s - loss: 0.1626 - acc: 0.9157 - val_loss: 0.5919 - val_acc: 0.9053\n",
      "Epoch 39/50\n",
      "112720/112720 [==============================] - 1s - loss: 0.1602 - acc: 0.9162 - val_loss: 0.5766 - val_acc: 0.9078\n",
      "Epoch 40/50\n",
      "112720/112720 [==============================] - 1s - loss: 0.1560 - acc: 0.9168 - val_loss: 0.5722 - val_acc: 0.9078\n",
      "Epoch 41/50\n",
      "112720/112720 [==============================] - 1s - loss: 0.1522 - acc: 0.9176 - val_loss: 0.5816 - val_acc: 0.9063\n",
      "Epoch 42/50\n",
      "112720/112720 [==============================] - 1s - loss: 0.1515 - acc: 0.9176 - val_loss: 0.5499 - val_acc: 0.9084\n",
      "Epoch 43/50\n",
      "112720/112720 [==============================] - 1s - loss: 0.1500 - acc: 0.9188 - val_loss: 0.5554 - val_acc: 0.9061\n",
      "Epoch 44/50\n",
      "112720/112720 [==============================] - 1s - loss: 0.1457 - acc: 0.9187 - val_loss: 0.5966 - val_acc: 0.9081\n",
      "Epoch 45/50\n",
      "112720/112720 [==============================] - 1s - loss: 0.1474 - acc: 0.9197 - val_loss: 0.5637 - val_acc: 0.9051\n",
      "Epoch 46/50\n",
      "112720/112720 [==============================] - 1s - loss: 0.1435 - acc: 0.9211 - val_loss: 0.5185 - val_acc: 0.9267\n",
      "Epoch 47/50\n",
      "112720/112720 [==============================] - 1s - loss: 0.1384 - acc: 0.9196 - val_loss: 0.4967 - val_acc: 0.9246\n",
      "Epoch 48/50\n",
      "112720/112720 [==============================] - 1s - loss: 0.1347 - acc: 0.9207 - val_loss: 0.4662 - val_acc: 0.9088\n",
      "Epoch 49/50\n",
      "112720/112720 [==============================] - 1s - loss: 0.1300 - acc: 0.9219 - val_loss: 0.4711 - val_acc: 0.9072\n",
      "Epoch 50/50\n",
      "112720/112720 [==============================] - 1s - loss: 0.1285 - acc: 0.9233 - val_loss: 0.4675 - val_acc: 0.9267\n",
      "12681/22544 [===============>..............] - ETA: 0s\n",
      " Train Acc: 0.926543653011322, Test Acc: 0.9267210736870766\n",
      " \n",
      " Current Layer Attributes - epochs:50 hidden layers:6 features count:4\n",
      "Train on 112720 samples, validate on 22544 samples\n",
      "Epoch 1/50\n",
      "112720/112720 [==============================] - 4s - loss: 0.8703 - acc: 0.0218 - val_loss: 1.7845 - val_acc: 0.1002\n",
      "Epoch 2/50\n",
      "112720/112720 [==============================] - 2s - loss: 0.6591 - acc: 0.4958 - val_loss: 1.6360 - val_acc: 0.6869\n",
      "Epoch 3/50\n",
      "112720/112720 [==============================] - 2s - loss: 0.5382 - acc: 0.7433 - val_loss: 1.4757 - val_acc: 0.7755\n",
      "Epoch 4/50\n",
      "112720/112720 [==============================] - 2s - loss: 0.4604 - acc: 0.8104 - val_loss: 1.3108 - val_acc: 0.7891\n",
      "Epoch 5/50\n",
      "112720/112720 [==============================] - 2s - loss: 0.4073 - acc: 0.8281 - val_loss: 1.2230 - val_acc: 0.7892\n",
      "Epoch 6/50\n",
      "112720/112720 [==============================] - 2s - loss: 0.3394 - acc: 0.8606 - val_loss: 1.2023 - val_acc: 0.8241\n",
      "Epoch 7/50\n",
      "112720/112720 [==============================] - 2s - loss: 0.2927 - acc: 0.8727 - val_loss: 1.1543 - val_acc: 0.8334\n",
      "Epoch 8/50\n",
      "112720/112720 [==============================] - 2s - loss: 0.2717 - acc: 0.8766 - val_loss: 1.0821 - val_acc: 0.8414\n",
      "Epoch 9/50\n",
      "112720/112720 [==============================] - 2s - loss: 0.2425 - acc: 0.8907 - val_loss: 1.0253 - val_acc: 0.8452\n",
      "Epoch 10/50\n",
      "112720/112720 [==============================] - 2s - loss: 0.2204 - acc: 0.8948 - val_loss: 0.9775 - val_acc: 0.8490\n",
      "Epoch 11/50\n",
      "112720/112720 [==============================] - 2s - loss: 0.1997 - acc: 0.9015 - val_loss: 0.9601 - val_acc: 0.8571\n",
      "Epoch 12/50\n",
      "112720/112720 [==============================] - 2s - loss: 0.2062 - acc: 0.8952 - val_loss: 1.0074 - val_acc: 0.8635\n",
      "Epoch 13/50\n",
      "112720/112720 [==============================] - 2s - loss: 0.1955 - acc: 0.9061 - val_loss: 0.9607 - val_acc: 0.8575\n",
      "Epoch 14/50\n",
      "112720/112720 [==============================] - 2s - loss: 0.1741 - acc: 0.9097 - val_loss: 0.8725 - val_acc: 0.8656\n",
      "Epoch 15/50\n",
      "112720/112720 [==============================] - 2s - loss: 0.1581 - acc: 0.9122 - val_loss: 0.8554 - val_acc: 0.8685\n",
      "Epoch 16/50\n",
      "112720/112720 [==============================] - 2s - loss: 0.1471 - acc: 0.9138 - val_loss: 0.8281 - val_acc: 0.8628\n",
      "Epoch 17/50\n",
      "112720/112720 [==============================] - 2s - loss: 0.1461 - acc: 0.9167 - val_loss: 0.8407 - val_acc: 0.8692\n",
      "Epoch 18/50\n",
      "112720/112720 [==============================] - 2s - loss: 0.1470 - acc: 0.9172 - val_loss: 0.8967 - val_acc: 0.8649\n",
      "Epoch 19/50\n",
      "112720/112720 [==============================] - 2s - loss: 0.1503 - acc: 0.9143 - val_loss: 0.7546 - val_acc: 0.8747\n",
      "Epoch 20/50\n",
      "112720/112720 [==============================] - 2s - loss: 0.1387 - acc: 0.9175 - val_loss: 0.7752 - val_acc: 0.8760\n",
      "Epoch 21/50\n",
      "112720/112720 [==============================] - 2s - loss: 0.1392 - acc: 0.9174 - val_loss: 0.8192 - val_acc: 0.8668\n",
      "Epoch 22/50\n",
      "112720/112720 [==============================] - 2s - loss: 0.1402 - acc: 0.9183 - val_loss: 0.8081 - val_acc: 0.87150.91\n",
      "Epoch 23/50\n",
      "112720/112720 [==============================] - 2s - loss: 0.1285 - acc: 0.9198 - val_loss: 0.7530 - val_acc: 0.8675\n",
      "Epoch 24/50\n",
      "112720/112720 [==============================] - 2s - loss: 0.1236 - acc: 0.9213 - val_loss: 0.7096 - val_acc: 0.8739\n",
      "Epoch 25/50\n",
      "112720/112720 [==============================] - 3s - loss: 0.1254 - acc: 0.9224 - val_loss: 0.6617 - val_acc: 0.8700\n",
      "Epoch 26/50\n",
      "112720/112720 [==============================] - 2s - loss: 0.1339 - acc: 0.9106 - val_loss: 0.6652 - val_acc: 0.8742\n",
      "Epoch 27/50\n",
      "112720/112720 [==============================] - 2s - loss: 0.1490 - acc: 0.9216 - val_loss: 0.5898 - val_acc: 0.8733\n",
      "Epoch 28/50\n",
      "112720/112720 [==============================] - 2s - loss: 0.1254 - acc: 0.9273 - val_loss: 0.5800 - val_acc: 0.8490\n",
      "Epoch 29/50\n",
      "112720/112720 [==============================] - 3s - loss: 0.1270 - acc: 0.9246 - val_loss: 0.5142 - val_acc: 0.8813\n",
      "Epoch 30/50\n",
      "112720/112720 [==============================] - 2s - loss: 0.1190 - acc: 0.9290 - val_loss: 0.4517 - val_acc: 0.8801\n",
      "Epoch 31/50\n",
      "112720/112720 [==============================] - 2s - loss: 0.1052 - acc: 0.9344 - val_loss: 0.4916 - val_acc: 0.8734\n",
      "Epoch 32/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "112720/112720 [==============================] - 2s - loss: 0.1104 - acc: 0.9328 - val_loss: 0.7518 - val_acc: 0.8737\n",
      "Epoch 33/50\n",
      "112720/112720 [==============================] - 2s - loss: 0.1446 - acc: 0.9231 - val_loss: 0.7542 - val_acc: 0.8824\n",
      "Epoch 34/50\n",
      "112720/112720 [==============================] - 2s - loss: 0.1176 - acc: 0.9304 - val_loss: 0.7851 - val_acc: 0.8796\n",
      "Epoch 35/50\n",
      "112720/112720 [==============================] - 2s - loss: 0.1536 - acc: 0.9235 - val_loss: 0.7604 - val_acc: 0.8456\n",
      "Epoch 36/50\n",
      "112720/112720 [==============================] - 2s - loss: 0.1556 - acc: 0.9245 - val_loss: 0.5751 - val_acc: 0.8612\n",
      "Epoch 37/50\n",
      "112720/112720 [==============================] - 3s - loss: 0.1726 - acc: 0.9097 - val_loss: 0.7656 - val_acc: 0.8690\n",
      "Epoch 38/50\n",
      "112720/112720 [==============================] - 3s - loss: 0.1656 - acc: 0.9212 - val_loss: 0.8156 - val_acc: 0.8864\n",
      "Epoch 39/50\n",
      "112720/112720 [==============================] - 2s - loss: 0.1353 - acc: 0.9244 - val_loss: 0.7527 - val_acc: 0.8989\n",
      "Epoch 40/50\n",
      "112720/112720 [==============================] - 3s - loss: 0.1087 - acc: 0.9328 - val_loss: 0.6982 - val_acc: 0.8784\n",
      "Epoch 41/50\n",
      "112720/112720 [==============================] - 3s - loss: 0.1140 - acc: 0.9311 - val_loss: 0.7663 - val_acc: 0.8754\n",
      "Epoch 42/50\n",
      "112720/112720 [==============================] - 3s - loss: 0.0949 - acc: 0.9342 - val_loss: 0.6820 - val_acc: 0.8868\n",
      "Epoch 43/50\n",
      "112720/112720 [==============================] - 3s - loss: 0.0838 - acc: 0.9369 - val_loss: 0.6832 - val_acc: 0.8878\n",
      "Epoch 44/50\n",
      "112720/112720 [==============================] - 2s - loss: 0.0933 - acc: 0.9339 - val_loss: 0.6753 - val_acc: 0.8865\n",
      "Epoch 45/50\n",
      "112720/112720 [==============================] - 2s - loss: 0.1014 - acc: 0.9332 - val_loss: 0.6546 - val_acc: 0.8939\n",
      "Epoch 46/50\n",
      "112720/112720 [==============================] - 2s - loss: 0.1200 - acc: 0.9327 - val_loss: 0.7077 - val_acc: 0.8898\n",
      "Epoch 47/50\n",
      "112720/112720 [==============================] - 2s - loss: 0.1079 - acc: 0.9321 - val_loss: 0.6855 - val_acc: 0.8834\n",
      "Epoch 48/50\n",
      "112720/112720 [==============================] - 2s - loss: 0.0915 - acc: 0.9370 - val_loss: 0.6680 - val_acc: 0.9025\n",
      "Epoch 49/50\n",
      "112720/112720 [==============================] - 2s - loss: 0.0990 - acc: 0.9367 - val_loss: 0.6623 - val_acc: 0.8905\n",
      "Epoch 50/50\n",
      "112720/112720 [==============================] - 2s - loss: 0.0952 - acc: 0.9399 - val_loss: 0.6175 - val_acc: 0.8942\n",
      "18317/22544 [=======================>......] - ETA: 0s\n",
      " Train Acc: 0.9406493976712227, Test Acc: 0.8941625319421291\n",
      " \n",
      " Current Layer Attributes - epochs:50 hidden layers:6 features count:16\n",
      "Train on 112720 samples, validate on 22544 samples\n",
      "Epoch 1/50\n",
      "112720/112720 [==============================] - 4s - loss: 6.7809 - acc: 0.2476 - val_loss: 1.8655 - val_acc: 0.3498\n",
      "Epoch 2/50\n",
      "112720/112720 [==============================] - 2s - loss: 0.7882 - acc: 0.3610 - val_loss: 1.7696 - val_acc: 0.4147\n",
      "Epoch 3/50\n",
      "112720/112720 [==============================] - 2s - loss: 0.7145 - acc: 0.5171 - val_loss: 1.6922 - val_acc: 0.5233\n",
      "Epoch 4/50\n",
      "112720/112720 [==============================] - 2s - loss: 0.6627 - acc: 0.4347 - val_loss: 1.6271 - val_acc: 0.4639\n",
      "Epoch 5/50\n",
      "112720/112720 [==============================] - 3s - loss: 0.6190 - acc: 0.5697 - val_loss: 1.5812 - val_acc: 0.6885\n",
      "Epoch 6/50\n",
      "112720/112720 [==============================] - 3s - loss: 0.5840 - acc: 0.7105 - val_loss: 1.5114 - val_acc: 0.7171\n",
      "Epoch 7/50\n",
      "112720/112720 [==============================] - 3s - loss: 0.5472 - acc: 0.7582 - val_loss: 1.4253 - val_acc: 0.7764\n",
      "Epoch 8/50\n",
      "112720/112720 [==============================] - 3s - loss: 0.5131 - acc: 0.7667 - val_loss: 1.3882 - val_acc: 0.7778\n",
      "Epoch 9/50\n",
      "112720/112720 [==============================] - 2s - loss: 0.4895 - acc: 0.7655 - val_loss: 1.3334 - val_acc: 0.7937\n",
      "Epoch 10/50\n",
      "112720/112720 [==============================] - 2s - loss: 0.4594 - acc: 0.7935 - val_loss: 1.2774 - val_acc: 0.7841\n",
      "Epoch 11/50\n",
      "112720/112720 [==============================] - 2s - loss: 0.4471 - acc: 0.7934 - val_loss: 1.1992 - val_acc: 0.7826\n",
      "Epoch 12/50\n",
      "112720/112720 [==============================] - 2s - loss: 0.4171 - acc: 0.8115 - val_loss: 1.1639 - val_acc: 0.8072\n",
      "Epoch 13/50\n",
      "112720/112720 [==============================] - 2s - loss: 0.4049 - acc: 0.8269 - val_loss: 1.1052 - val_acc: 0.8211\n",
      "Epoch 14/50\n",
      "112720/112720 [==============================] - 3s - loss: 0.3821 - acc: 0.8423 - val_loss: 1.0599 - val_acc: 0.7859\n",
      "Epoch 15/50\n",
      "112720/112720 [==============================] - 3s - loss: 0.3611 - acc: 0.8617 - val_loss: 1.0680 - val_acc: 0.7644\n",
      "Epoch 16/50\n",
      "112720/112720 [==============================] - 3s - loss: 0.3706 - acc: 0.8280 - val_loss: 0.9624 - val_acc: 0.8320\n",
      "Epoch 17/50\n",
      "112720/112720 [==============================] - 3s - loss: 0.3348 - acc: 0.8669 - val_loss: 0.9133 - val_acc: 0.8380\n",
      "Epoch 18/50\n",
      "112720/112720 [==============================] - 3s - loss: 0.3202 - acc: 0.8697 - val_loss: 0.9093 - val_acc: 0.7958\n",
      "Epoch 19/50\n",
      "112720/112720 [==============================] - 3s - loss: 0.3084 - acc: 0.8722 - val_loss: 0.8670 - val_acc: 0.8289\n",
      "Epoch 20/50\n",
      "112720/112720 [==============================] - 2s - loss: 0.2926 - acc: 0.8849 - val_loss: 0.9004 - val_acc: 0.8488\n",
      "Epoch 21/50\n",
      "112720/112720 [==============================] - 3s - loss: 0.3013 - acc: 0.8741 - val_loss: 0.8383 - val_acc: 0.8555\n",
      "Epoch 22/50\n",
      "112720/112720 [==============================] - 3s - loss: 0.2767 - acc: 0.8791 - val_loss: 0.7564 - val_acc: 0.8492\n",
      "Epoch 23/50\n",
      "112720/112720 [==============================] - 3s - loss: 0.2584 - acc: 0.8914 - val_loss: 0.7252 - val_acc: 0.8502\n",
      "Epoch 24/50\n",
      "112720/112720 [==============================] - 3s - loss: 0.2478 - acc: 0.8924 - val_loss: 0.6930 - val_acc: 0.8492\n",
      "Epoch 25/50\n",
      "112720/112720 [==============================] - 3s - loss: 0.2483 - acc: 0.8890 - val_loss: 0.6780 - val_acc: 0.8206\n",
      "Epoch 26/50\n",
      "112720/112720 [==============================] - 3s - loss: 0.2376 - acc: 0.8915 - val_loss: 0.6209 - val_acc: 0.8593\n",
      "Epoch 27/50\n",
      "112720/112720 [==============================] - 3s - loss: 0.2291 - acc: 0.8920 - val_loss: 0.6213 - val_acc: 0.8634\n",
      "Epoch 28/50\n",
      "112720/112720 [==============================] - 2s - loss: 0.2216 - acc: 0.8965 - val_loss: 0.5794 - val_acc: 0.8665\n",
      "Epoch 29/50\n",
      "112720/112720 [==============================] - 2s - loss: 0.2098 - acc: 0.8983 - val_loss: 0.5580 - val_acc: 0.8669\n",
      "Epoch 30/50\n",
      "112720/112720 [==============================] - 2s - loss: 0.2045 - acc: 0.8973 - val_loss: 0.6139 - val_acc: 0.8691\n",
      "Epoch 31/50\n",
      "112720/112720 [==============================] - 3s - loss: 0.2080 - acc: 0.8994 - val_loss: 0.6291 - val_acc: 0.8731\n",
      "Epoch 32/50\n",
      "112720/112720 [==============================] - 3s - loss: 0.1984 - acc: 0.8989 - val_loss: 0.5870 - val_acc: 0.8709\n",
      "Epoch 33/50\n",
      "112720/112720 [==============================] - 3s - loss: 0.1903 - acc: 0.9048 - val_loss: 0.4676 - val_acc: 0.8748\n",
      "Epoch 34/50\n",
      "112720/112720 [==============================] - 2s - loss: 0.1773 - acc: 0.9057 - val_loss: 0.4613 - val_acc: 0.8757\n",
      "Epoch 35/50\n",
      "112720/112720 [==============================] - 2s - loss: 0.1809 - acc: 0.9009 - val_loss: 0.4628 - val_acc: 0.8808\n",
      "Epoch 36/50\n",
      "112720/112720 [==============================] - 2s - loss: 0.1850 - acc: 0.9042 - val_loss: 0.4719 - val_acc: 0.8775\n",
      "Epoch 37/50\n",
      "112720/112720 [==============================] - 2s - loss: 0.1740 - acc: 0.9053 - val_loss: 0.4096 - val_acc: 0.8804\n",
      "Epoch 38/50\n",
      "112720/112720 [==============================] - 3s - loss: 0.1629 - acc: 0.9072 - val_loss: 0.3878 - val_acc: 0.8826\n",
      "Epoch 39/50\n",
      "112720/112720 [==============================] - 3s - loss: 0.1522 - acc: 0.9086 - val_loss: 0.3597 - val_acc: 0.8798\n",
      "Epoch 40/50\n",
      "112720/112720 [==============================] - 2s - loss: 0.1477 - acc: 0.9090 - val_loss: 0.3445 - val_acc: 0.8819\n",
      "Epoch 41/50\n",
      "112720/112720 [==============================] - 2s - loss: 0.1468 - acc: 0.9097 - val_loss: 0.3832 - val_acc: 0.8828\n",
      "Epoch 42/50\n",
      "112720/112720 [==============================] - 3s - loss: 0.1540 - acc: 0.9085 - val_loss: 0.3415 - val_acc: 0.8816\n",
      "Epoch 43/50\n",
      "112720/112720 [==============================] - 3s - loss: 0.1507 - acc: 0.9079 - val_loss: 0.3302 - val_acc: 0.8825\n",
      "Epoch 44/50\n",
      "112720/112720 [==============================] - 3s - loss: 0.1519 - acc: 0.9074 - val_loss: 0.4170 - val_acc: 0.8357\n",
      "Epoch 45/50\n",
      "112720/112720 [==============================] - 3s - loss: 0.1864 - acc: 0.8984 - val_loss: 0.4490 - val_acc: 0.8784\n",
      "Epoch 46/50\n",
      "112720/112720 [==============================] - 3s - loss: 0.1528 - acc: 0.9084 - val_loss: 0.4017 - val_acc: 0.8836\n",
      "Epoch 47/50\n",
      "112720/112720 [==============================] - 3s - loss: 0.1406 - acc: 0.9082 - val_loss: 0.3631 - val_acc: 0.8843\n",
      "Epoch 48/50\n",
      "112720/112720 [==============================] - 2s - loss: 0.1199 - acc: 0.9101 - val_loss: 0.3047 - val_acc: 0.8870\n",
      "Epoch 49/50\n",
      "112720/112720 [==============================] - 3s - loss: 0.1122 - acc: 0.9104 - val_loss: 0.3030 - val_acc: 0.8884\n",
      "Epoch 50/50\n",
      "112720/112720 [==============================] - 3s - loss: 0.1172 - acc: 0.9103 - val_loss: 0.2820 - val_acc: 0.8877\n",
      "22544/22544 [==============================] - 0s     \n",
      "\n",
      " Train Acc: 0.9071149677038193, Test Acc: 0.8877306692302227\n",
      " \n",
      " Current Layer Attributes - epochs:50 hidden layers:6 features count:32\n",
      "Train on 112720 samples, validate on 22544 samples\n",
      "Epoch 1/50\n",
      "112720/112720 [==============================] - 3s - loss: 5869.4504 - acc: 0.0332 - val_loss: 1.9947 - val_acc: 0.0287\n",
      "Epoch 2/50\n",
      "112720/112720 [==============================] - 2s - loss: 1.9287 - acc: 0.1815 - val_loss: 1.7758 - val_acc: 0.4736\n",
      "Epoch 3/50\n",
      "112720/112720 [==============================] - 3s - loss: 0.7202 - acc: 0.4998 - val_loss: 1.6883 - val_acc: 0.5926\n",
      "Epoch 4/50\n",
      "112720/112720 [==============================] - 3s - loss: 0.6595 - acc: 0.6380 - val_loss: 1.5974 - val_acc: 0.6760\n",
      "Epoch 5/50\n",
      "112720/112720 [==============================] - 3s - loss: 0.6011 - acc: 0.7020 - val_loss: 1.5056 - val_acc: 0.7075\n",
      "Epoch 6/50\n",
      "112720/112720 [==============================] - 3s - loss: 0.5519 - acc: 0.7326 - val_loss: 1.4040 - val_acc: 0.7341\n",
      "Epoch 7/50\n",
      "112720/112720 [==============================] - 3s - loss: 0.5099 - acc: 0.7512 - val_loss: 1.3382 - val_acc: 0.7679\n",
      "Epoch 8/50\n",
      "112720/112720 [==============================] - 3s - loss: 0.4821 - acc: 0.7571 - val_loss: 1.2639 - val_acc: 0.7763\n",
      "Epoch 9/50\n",
      "112720/112720 [==============================] - 3s - loss: 0.4575 - acc: 0.7576 - val_loss: 1.2311 - val_acc: 0.7860\n",
      "Epoch 10/50\n",
      "112720/112720 [==============================] - 3s - loss: 0.4418 - acc: 0.7614 - val_loss: 1.2099 - val_acc: 0.7932\n",
      "Epoch 11/50\n",
      "112720/112720 [==============================] - 3s - loss: 0.4282 - acc: 0.7635 - val_loss: 1.1734 - val_acc: 0.8040\n",
      "Epoch 12/50\n",
      "112720/112720 [==============================] - 3s - loss: 0.4123 - acc: 0.7670 - val_loss: 1.1375 - val_acc: 0.8011\n",
      "Epoch 13/50\n",
      "112720/112720 [==============================] - 3s - loss: 0.3980 - acc: 0.7683 - val_loss: 1.1185 - val_acc: 0.8061\n",
      "Epoch 14/50\n",
      "112720/112720 [==============================] - 3s - loss: 0.3874 - acc: 0.7698 - val_loss: 1.0945 - val_acc: 0.8368\n",
      "Epoch 15/50\n",
      "112720/112720 [==============================] - 3s - loss: 0.3768 - acc: 0.7726 - val_loss: 1.0736 - val_acc: 0.8106\n",
      "Epoch 16/50\n",
      "112720/112720 [==============================] - 3s - loss: 0.3695 - acc: 0.7719 - val_loss: 1.0411 - val_acc: 0.8125\n",
      "Epoch 17/50\n",
      "112720/112720 [==============================] - 3s - loss: 0.3576 - acc: 0.7721 - val_loss: 1.0245 - val_acc: 0.8003\n",
      "Epoch 18/50\n",
      "112720/112720 [==============================] - 3s - loss: 0.3517 - acc: 0.7724 - val_loss: 0.9901 - val_acc: 0.8216\n",
      "Epoch 19/50\n",
      "112720/112720 [==============================] - 3s - loss: 0.3406 - acc: 0.7721 - val_loss: 0.9709 - val_acc: 0.8094\n",
      "Epoch 20/50\n",
      "112720/112720 [==============================] - 3s - loss: 0.3347 - acc: 0.7798 - val_loss: 0.9432 - val_acc: 0.8220\n",
      "Epoch 21/50\n",
      "112720/112720 [==============================] - 3s - loss: 0.3285 - acc: 0.7786 - val_loss: 0.9372 - val_acc: 0.8268\n",
      "Epoch 22/50\n",
      "112720/112720 [==============================] - 3s - loss: 0.3242 - acc: 0.7835 - val_loss: 0.9202 - val_acc: 0.8335\n",
      "Epoch 23/50\n",
      "112720/112720 [==============================] - 3s - loss: 0.3207 - acc: 0.7807 - val_loss: 0.8784 - val_acc: 0.8230\n",
      "Epoch 24/50\n",
      "112720/112720 [==============================] - 3s - loss: 0.3178 - acc: 0.7868 - val_loss: 0.8885 - val_acc: 0.8298\n",
      "Epoch 25/50\n",
      "112720/112720 [==============================] - 3s - loss: 0.3120 - acc: 0.7984 - val_loss: 0.8572 - val_acc: 0.8300\n",
      "Epoch 26/50\n",
      "112720/112720 [==============================] - 3s - loss: 0.3038 - acc: 0.7912 - val_loss: 0.8051 - val_acc: 0.8324\n",
      "Epoch 27/50\n",
      "112720/112720 [==============================] - 3s - loss: 0.2966 - acc: 0.8047 - val_loss: 0.7921 - val_acc: 0.8278\n",
      "Epoch 28/50\n",
      "112720/112720 [==============================] - 3s - loss: 0.2893 - acc: 0.8039 - val_loss: 0.7622 - val_acc: 0.8413\n",
      "Epoch 29/50\n",
      "112720/112720 [==============================] - 2s - loss: 0.2815 - acc: 0.8096 - val_loss: 0.7571 - val_acc: 0.8424\n",
      "Epoch 30/50\n",
      "112720/112720 [==============================] - 2s - loss: 0.2778 - acc: 0.8231 - val_loss: 0.7616 - val_acc: 0.8442\n",
      "Epoch 31/50\n",
      "112720/112720 [==============================] - 2s - loss: 0.2822 - acc: 0.8216 - val_loss: 0.7687 - val_acc: 0.8601\n",
      "Epoch 32/50\n",
      "112720/112720 [==============================] - 3s - loss: 0.2765 - acc: 0.8280 - val_loss: 0.7546 - val_acc: 0.8238\n",
      "Epoch 33/50\n",
      "112720/112720 [==============================] - 3s - loss: 0.2725 - acc: 0.8275 - val_loss: 0.7112 - val_acc: 0.8754\n",
      "Epoch 34/50\n",
      "112720/112720 [==============================] - 3s - loss: 0.2641 - acc: 0.8432 - val_loss: 0.6778 - val_acc: 0.8424\n",
      "Epoch 35/50\n",
      "112720/112720 [==============================] - 3s - loss: 0.2577 - acc: 0.8483 - val_loss: 0.6959 - val_acc: 0.8511\n",
      "Epoch 36/50\n",
      "112720/112720 [==============================] - 3s - loss: 0.2596 - acc: 0.8331 - val_loss: 0.6581 - val_acc: 0.8740\n",
      "Epoch 37/50\n",
      "112720/112720 [==============================] - 3s - loss: 0.2521 - acc: 0.8600 - val_loss: 0.6503 - val_acc: 0.8591\n",
      "Epoch 38/50\n",
      "112720/112720 [==============================] - 3s - loss: 0.2513 - acc: 0.8414 - val_loss: 0.6250 - val_acc: 0.8481\n",
      "Epoch 39/50\n",
      "112720/112720 [==============================] - 3s - loss: 0.2464 - acc: 0.8549 - val_loss: 0.6164 - val_acc: 0.8698\n",
      "Epoch 40/50\n",
      "112720/112720 [==============================] - 3s - loss: 0.2404 - acc: 0.8695 - val_loss: 0.6353 - val_acc: 0.8068\n",
      "Epoch 41/50\n",
      "112720/112720 [==============================] - 3s - loss: 0.2406 - acc: 0.8599 - val_loss: 0.6210 - val_acc: 0.8523\n",
      "Epoch 42/50\n",
      "112720/112720 [==============================] - 3s - loss: 0.2471 - acc: 0.8566 - val_loss: 0.6351 - val_acc: 0.8693\n",
      "Epoch 43/50\n",
      "112720/112720 [==============================] - 3s - loss: 0.2405 - acc: 0.8695 - val_loss: 0.5955 - val_acc: 0.8577\n",
      "Epoch 44/50\n",
      "112720/112720 [==============================] - 3s - loss: 0.2347 - acc: 0.8704 - val_loss: 0.5961 - val_acc: 0.8817\n",
      "Epoch 45/50\n",
      "112720/112720 [==============================] - 3s - loss: 0.2353 - acc: 0.8619 - val_loss: 0.5705 - val_acc: 0.8894\n",
      "Epoch 46/50\n",
      "112720/112720 [==============================] - 3s - loss: 0.2329 - acc: 0.8761 - val_loss: 0.5885 - val_acc: 0.8531\n",
      "Epoch 47/50\n",
      "112720/112720 [==============================] - 3s - loss: 0.2340 - acc: 0.8683 - val_loss: 0.5551 - val_acc: 0.8709\n",
      "Epoch 48/50\n",
      "112720/112720 [==============================] - 3s - loss: 0.2228 - acc: 0.8839 - val_loss: 0.5810 - val_acc: 0.8864\n",
      "Epoch 49/50\n",
      "112720/112720 [==============================] - 3s - loss: 0.2249 - acc: 0.8711 - val_loss: 0.5539 - val_acc: 0.8967\n",
      "Epoch 50/50\n",
      "112720/112720 [==============================] - 3s - loss: 0.2268 - acc: 0.8827 - val_loss: 0.5466 - val_acc: 0.8936\n",
      "21135/22544 [===========================>..] - ETA: 0s\n",
      " Train Acc: 0.910308726131916, Test Acc: 0.8936302363872528\n",
      " \n",
      " Current Layer Attributes - epochs:50 hidden layers:10 features count:4\n",
      "Train on 112720 samples, validate on 22544 samples\n",
      "Epoch 1/50\n",
      "112720/112720 [==============================] - 6s - loss: 0.9244 - acc: 0.0663 - val_loss: 1.9106 - val_acc: 0.0078\n",
      "Epoch 2/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "112720/112720 [==============================] - 4s - loss: 0.8066 - acc: 0.1131 - val_loss: 1.8052 - val_acc: 0.2453\n",
      "Epoch 3/50\n",
      "112720/112720 [==============================] - 4s - loss: 0.7414 - acc: 0.4150 - val_loss: 1.7942 - val_acc: 0.3581\n",
      "Epoch 4/50\n",
      "112720/112720 [==============================] - 4s - loss: 0.7175 - acc: 0.4996 - val_loss: 1.7236 - val_acc: 0.6078\n",
      "Epoch 5/50\n",
      "112720/112720 [==============================] - 4s - loss: 0.6878 - acc: 0.5399 - val_loss: 1.7575 - val_acc: 0.5983\n",
      "Epoch 6/50\n",
      "112720/112720 [==============================] - 4s - loss: 0.6634 - acc: 0.6293 - val_loss: 1.6946 - val_acc: 0.6643\n",
      "Epoch 7/50\n",
      "112720/112720 [==============================] - 4s - loss: 0.6390 - acc: 0.6786 - val_loss: 1.8440 - val_acc: 0.3736\n",
      "Epoch 8/50\n",
      "112720/112720 [==============================] - 4s - loss: 0.6489 - acc: 0.6267 - val_loss: 1.6706 - val_acc: 0.6509\n",
      "Epoch 9/50\n",
      "112720/112720 [==============================] - 4s - loss: 0.5855 - acc: 0.7274 - val_loss: 1.6604 - val_acc: 0.6439\n",
      "Epoch 10/50\n",
      "112720/112720 [==============================] - 4s - loss: 0.5576 - acc: 0.7632 - val_loss: 1.6450 - val_acc: 0.6900\n",
      "Epoch 11/50\n",
      "112720/112720 [==============================] - 4s - loss: 0.5375 - acc: 0.7755 - val_loss: 1.6026 - val_acc: 0.7010\n",
      "Epoch 12/50\n",
      "112720/112720 [==============================] - 4s - loss: 0.5080 - acc: 0.8071 - val_loss: 1.5792 - val_acc: 0.7262\n",
      "Epoch 13/50\n",
      "112720/112720 [==============================] - 3s - loss: 0.4820 - acc: 0.8269 - val_loss: 1.5428 - val_acc: 0.7586\n",
      "Epoch 14/50\n",
      "112720/112720 [==============================] - 4s - loss: 0.4561 - acc: 0.8390 - val_loss: 1.5274 - val_acc: 0.7192\n",
      "Epoch 15/50\n",
      "112720/112720 [==============================] - 4s - loss: 0.4835 - acc: 0.7618 - val_loss: 1.4940 - val_acc: 0.7194\n",
      "Epoch 16/50\n",
      "112720/112720 [==============================] - 4s - loss: 0.4261 - acc: 0.8314 - val_loss: 1.4776 - val_acc: 0.7218\n",
      "Epoch 17/50\n",
      "112720/112720 [==============================] - 4s - loss: 0.4151 - acc: 0.8277 - val_loss: 1.4381 - val_acc: 0.7575\n",
      "Epoch 18/50\n",
      "112720/112720 [==============================] - 4s - loss: 0.3912 - acc: 0.8459 - val_loss: 1.3821 - val_acc: 0.7747\n",
      "Epoch 19/50\n",
      "112720/112720 [==============================] - 4s - loss: 0.3701 - acc: 0.8538 - val_loss: 1.3379 - val_acc: 0.7788\n",
      "Epoch 20/50\n",
      "112720/112720 [==============================] - 4s - loss: 0.3734 - acc: 0.8430 - val_loss: 1.3251 - val_acc: 0.7561\n",
      "Epoch 21/50\n",
      "112720/112720 [==============================] - 4s - loss: 0.3597 - acc: 0.8495 - val_loss: 1.2721 - val_acc: 0.7668\n",
      "Epoch 22/50\n",
      "112720/112720 [==============================] - 4s - loss: 0.3476 - acc: 0.8560 - val_loss: 1.2581 - val_acc: 0.7579\n",
      "Epoch 23/50\n",
      "112720/112720 [==============================] - 4s - loss: 0.3282 - acc: 0.8639 - val_loss: 1.3405 - val_acc: 0.7571\n",
      "Epoch 24/50\n",
      "112720/112720 [==============================] - 4s - loss: 0.3447 - acc: 0.8613 - val_loss: 1.2328 - val_acc: 0.7854\n",
      "Epoch 25/50\n",
      "112720/112720 [==============================] - 4s - loss: 0.3279 - acc: 0.8657 - val_loss: 1.2066 - val_acc: 0.7897\n",
      "Epoch 26/50\n",
      "112720/112720 [==============================] - 4s - loss: 0.3027 - acc: 0.8693 - val_loss: 1.1700 - val_acc: 0.7924\n",
      "Epoch 27/50\n",
      "112720/112720 [==============================] - 4s - loss: 0.2986 - acc: 0.8691 - val_loss: 1.2560 - val_acc: 0.7408\n",
      "Epoch 28/50\n",
      "112720/112720 [==============================] - 4s - loss: 0.3299 - acc: 0.8438 - val_loss: 1.1756 - val_acc: 0.7932\n",
      "Epoch 29/50\n",
      "112720/112720 [==============================] - 4s - loss: 0.2891 - acc: 0.8660 - val_loss: 1.2200 - val_acc: 0.7808\n",
      "Epoch 30/50\n",
      "112720/112720 [==============================] - 4s - loss: 0.3168 - acc: 0.8562 - val_loss: 1.2062 - val_acc: 0.7633\n",
      "Epoch 31/50\n",
      "112720/112720 [==============================] - 4s - loss: 0.3014 - acc: 0.8633 - val_loss: 1.1623 - val_acc: 0.7914\n",
      "Epoch 32/50\n",
      "112720/112720 [==============================] - 4s - loss: 0.2567 - acc: 0.8764 - val_loss: 1.1451 - val_acc: 0.7931\n",
      "Epoch 33/50\n",
      "112720/112720 [==============================] - 4s - loss: 0.2485 - acc: 0.8780 - val_loss: 1.1560 - val_acc: 0.7963\n",
      "Epoch 34/50\n",
      "112720/112720 [==============================] - 4s - loss: 0.2505 - acc: 0.8763 - val_loss: 1.1869 - val_acc: 0.7843\n",
      "Epoch 35/50\n",
      "112720/112720 [==============================] - 3s - loss: 0.2974 - acc: 0.8579 - val_loss: 1.1749 - val_acc: 0.7881\n",
      "Epoch 36/50\n",
      "112720/112720 [==============================] - 4s - loss: 0.3242 - acc: 0.8541 - val_loss: 1.2481 - val_acc: 0.7853\n",
      "Epoch 37/50\n",
      "112720/112720 [==============================] - 4s - loss: 0.2923 - acc: 0.8712 - val_loss: 1.3808 - val_acc: 0.7806\n",
      "Epoch 38/50\n",
      "112720/112720 [==============================] - 4s - loss: 0.3539 - acc: 0.7176 - val_loss: 1.3245 - val_acc: 0.6005\n",
      "Epoch 39/50\n",
      "112720/112720 [==============================] - 4s - loss: 0.3349 - acc: 0.7655 - val_loss: 1.2064 - val_acc: 0.7615\n",
      "Epoch 40/50\n",
      "112720/112720 [==============================] - 4s - loss: 0.3200 - acc: 0.8340 - val_loss: 1.2181 - val_acc: 0.7813\n",
      "Epoch 41/50\n",
      "112720/112720 [==============================] - 4s - loss: 0.2980 - acc: 0.8401 - val_loss: 1.1546 - val_acc: 0.7803\n",
      "Epoch 42/50\n",
      "112720/112720 [==============================] - 3s - loss: 0.2693 - acc: 0.8504 - val_loss: 1.1505 - val_acc: 0.7783\n",
      "Epoch 43/50\n",
      "112720/112720 [==============================] - 3s - loss: 0.2664 - acc: 0.8506 - val_loss: 1.1614 - val_acc: 0.7751\n",
      "Epoch 44/50\n",
      "112720/112720 [==============================] - 3s - loss: 0.3802 - acc: 0.7943 - val_loss: 1.2773 - val_acc: 0.7405\n",
      "Epoch 45/50\n",
      "112720/112720 [==============================] - 3s - loss: 0.3010 - acc: 0.8484 - val_loss: 1.2008 - val_acc: 0.7848\n",
      "Epoch 46/50\n",
      "112720/112720 [==============================] - 3s - loss: 0.2936 - acc: 0.8536 - val_loss: 1.1487 - val_acc: 0.7838\n",
      "Epoch 47/50\n",
      "112720/112720 [==============================] - 3s - loss: 0.2734 - acc: 0.8657 - val_loss: 1.1487 - val_acc: 0.7875\n",
      "Epoch 48/50\n",
      "112720/112720 [==============================] - 3s - loss: 0.2752 - acc: 0.8662 - val_loss: 1.1184 - val_acc: 0.7947\n",
      "Epoch 49/50\n",
      "112720/112720 [==============================] - 3s - loss: 0.2517 - acc: 0.8762 - val_loss: 1.1036 - val_acc: 0.7977\n",
      "Epoch 50/50\n",
      "112720/112720 [==============================] - 3s - loss: 0.2487 - acc: 0.8774 - val_loss: 1.1055 - val_acc: 0.7978\n",
      "22544/22544 [==============================] - 0s     \n",
      "\n",
      " Train Acc: 0.8771291747689247, Test Acc: 0.7977732382714748\n",
      " \n",
      " Current Layer Attributes - epochs:50 hidden layers:10 features count:16\n",
      "Train on 112720 samples, validate on 22544 samples\n",
      "Epoch 1/50\n",
      "112720/112720 [==============================] - 5s - loss: 0.9355 - acc: 0.0156 - val_loss: 1.9283 - val_acc: 0.0014\n",
      "Epoch 2/50\n",
      "112720/112720 [==============================] - 3s - loss: 0.8445 - acc: 0.1393 - val_loss: 1.8289 - val_acc: 0.3378\n",
      "Epoch 3/50\n",
      "112720/112720 [==============================] - 3s - loss: 0.7825 - acc: 0.3557 - val_loss: 6.2876 - val_acc: 0.4448\n",
      "Epoch 4/50\n",
      "112720/112720 [==============================] - 3s - loss: 0.7298 - acc: 0.4594 - val_loss: 89.9106 - val_acc: 0.5788\n",
      "Epoch 5/50\n",
      "112720/112720 [==============================] - 3s - loss: 0.6864 - acc: 0.5543 - val_loss: 1.7662 - val_acc: 0.6322\n",
      "Epoch 6/50\n",
      "112720/112720 [==============================] - 3s - loss: 0.6619 - acc: 0.5846 - val_loss: 1.6962 - val_acc: 0.6506\n",
      "Epoch 7/50\n",
      "112720/112720 [==============================] - 3s - loss: 0.6320 - acc: 0.6053 - val_loss: 1.6454 - val_acc: 0.6562\n",
      "Epoch 8/50\n",
      "112720/112720 [==============================] - 3s - loss: 0.6131 - acc: 0.6071 - val_loss: 1.6563 - val_acc: 0.6116\n",
      "Epoch 9/50\n",
      "112720/112720 [==============================] - 3s - loss: 0.5861 - acc: 0.6368 - val_loss: 1.6516 - val_acc: 0.5859\n",
      "Epoch 10/50\n",
      "112720/112720 [==============================] - 3s - loss: 0.5758 - acc: 0.6396 - val_loss: 1.5436 - val_acc: 0.6533\n",
      "Epoch 11/50\n",
      "112720/112720 [==============================] - 3s - loss: 0.5669 - acc: 0.6421 - val_loss: 1.5321 - val_acc: 0.6301\n",
      "Epoch 12/50\n",
      "112720/112720 [==============================] - 3s - loss: 0.5471 - acc: 0.6604 - val_loss: 1.4146 - val_acc: 0.7256\n",
      "Epoch 13/50\n",
      "112720/112720 [==============================] - 3s - loss: 0.5253 - acc: 0.6839 - val_loss: 1.3791 - val_acc: 0.7413\n",
      "Epoch 14/50\n",
      "112720/112720 [==============================] - 3s - loss: 0.4855 - acc: 0.7643 - val_loss: 1.3454 - val_acc: 0.7422\n",
      "Epoch 15/50\n",
      "112720/112720 [==============================] - 3s - loss: 0.4798 - acc: 0.7683 - val_loss: 1.3113 - val_acc: 0.7435\n",
      "Epoch 16/50\n",
      "112720/112720 [==============================] - 3s - loss: 0.4789 - acc: 0.7677 - val_loss: 1.3866 - val_acc: 0.7486\n",
      "Epoch 17/50\n",
      "112720/112720 [==============================] - 3s - loss: 0.4534 - acc: 0.7969 - val_loss: 1.2249 - val_acc: 0.7864\n",
      "Epoch 18/50\n",
      "112720/112720 [==============================] - 3s - loss: 0.4276 - acc: 0.8215 - val_loss: 1.2129 - val_acc: 0.7762\n",
      "Epoch 19/50\n",
      "112720/112720 [==============================] - 3s - loss: 0.4176 - acc: 0.8282 - val_loss: 1.2099 - val_acc: 0.8018\n",
      "Epoch 20/50\n",
      "112720/112720 [==============================] - 3s - loss: 0.4410 - acc: 0.7834 - val_loss: 1.1862 - val_acc: 0.7940\n",
      "Epoch 21/50\n",
      "112720/112720 [==============================] - 3s - loss: 0.4087 - acc: 0.8298 - val_loss: 1.1938 - val_acc: 0.7992\n",
      "Epoch 22/50\n",
      "112720/112720 [==============================] - 2s - loss: 0.4379 - acc: 0.7768 - val_loss: 1.3363 - val_acc: 0.6207\n",
      "Epoch 23/50\n",
      "112720/112720 [==============================] - 2s - loss: 0.4294 - acc: 0.8085 - val_loss: 1.1900 - val_acc: 0.7907\n",
      "Epoch 24/50\n",
      "112720/112720 [==============================] - 3s - loss: 0.3733 - acc: 0.8489 - val_loss: 1.1798 - val_acc: 0.7917\n",
      "Epoch 25/50\n",
      "112720/112720 [==============================] - 3s - loss: 0.3839 - acc: 0.8124 - val_loss: 1.1795 - val_acc: 0.7907\n",
      "Epoch 26/50\n",
      "112720/112720 [==============================] - 3s - loss: 0.3603 - acc: 0.8426 - val_loss: 1.1576 - val_acc: 0.7851\n",
      "Epoch 27/50\n",
      "112720/112720 [==============================] - 3s - loss: 0.3410 - acc: 0.8540 - val_loss: 1.1386 - val_acc: 0.8038\n",
      "Epoch 28/50\n",
      "112720/112720 [==============================] - 3s - loss: 0.3312 - acc: 0.8520 - val_loss: 1.1399 - val_acc: 0.8023\n",
      "Epoch 29/50\n",
      "112720/112720 [==============================] - 3s - loss: 0.3396 - acc: 0.8360 - val_loss: 1.1461 - val_acc: 0.8114\n",
      "Epoch 30/50\n",
      "112720/112720 [==============================] - 3s - loss: 0.3476 - acc: 0.8270 - val_loss: 1.2222 - val_acc: 0.7961\n",
      "Epoch 31/50\n",
      "112720/112720 [==============================] - 3s - loss: 0.3198 - acc: 0.8479 - val_loss: 1.1265 - val_acc: 0.8033\n",
      "Epoch 32/50\n",
      "112720/112720 [==============================] - 3s - loss: 0.3052 - acc: 0.8532 - val_loss: 1.1282 - val_acc: 0.7989\n",
      "Epoch 33/50\n",
      "112720/112720 [==============================] - 3s - loss: 0.3007 - acc: 0.8564 - val_loss: 1.1140 - val_acc: 0.8063\n",
      "Epoch 34/50\n",
      "112720/112720 [==============================] - 3s - loss: 0.3021 - acc: 0.8594 - val_loss: 1.1137 - val_acc: 0.8145\n",
      "Epoch 35/50\n",
      "112720/112720 [==============================] - 3s - loss: 0.2979 - acc: 0.8650 - val_loss: 1.1059 - val_acc: 0.8073\n",
      "Epoch 36/50\n",
      "112720/112720 [==============================] - 3s - loss: 0.2987 - acc: 0.8640 - val_loss: 1.1047 - val_acc: 0.8082\n",
      "Epoch 37/50\n",
      "112720/112720 [==============================] - 3s - loss: 0.2812 - acc: 0.8731 - val_loss: 1.0893 - val_acc: 0.8153\n",
      "Epoch 38/50\n",
      "112720/112720 [==============================] - 3s - loss: 0.2792 - acc: 0.8717 - val_loss: 1.0807 - val_acc: 0.8202\n",
      "Epoch 39/50\n",
      "112720/112720 [==============================] - 3s - loss: 0.2692 - acc: 0.8796 - val_loss: 1.0730 - val_acc: 0.8185\n",
      "Epoch 40/50\n",
      "112720/112720 [==============================] - 3s - loss: 0.2662 - acc: 0.8821 - val_loss: 1.0695 - val_acc: 0.8176\n",
      "Epoch 41/50\n",
      "112720/112720 [==============================] - 3s - loss: 0.2649 - acc: 0.8801 - val_loss: 1.0743 - val_acc: 0.8129\n",
      "Epoch 42/50\n",
      "112720/112720 [==============================] - 3s - loss: 0.3583 - acc: 0.8220 - val_loss: 1.3194 - val_acc: 0.7954\n",
      "Epoch 43/50\n",
      "112720/112720 [==============================] - 3s - loss: 0.3743 - acc: 0.8277 - val_loss: 1.1547 - val_acc: 0.8124\n",
      "Epoch 44/50\n",
      "112720/112720 [==============================] - 3s - loss: 0.3089 - acc: 0.8715 - val_loss: 1.0916 - val_acc: 0.8242\n",
      "Epoch 45/50\n",
      "112720/112720 [==============================] - 3s - loss: 0.2813 - acc: 0.8827 - val_loss: 1.0785 - val_acc: 0.8140\n",
      "Epoch 46/50\n",
      "112720/112720 [==============================] - 3s - loss: 0.2752 - acc: 0.8829 - val_loss: 1.0835 - val_acc: 0.8159\n",
      "Epoch 47/50\n",
      "112720/112720 [==============================] - 3s - loss: 0.2647 - acc: 0.8862 - val_loss: 1.0713 - val_acc: 0.8280\n",
      "Epoch 48/50\n",
      "112720/112720 [==============================] - 3s - loss: 0.2528 - acc: 0.8916 - val_loss: 1.0673 - val_acc: 0.8251\n",
      "Epoch 49/50\n",
      "112720/112720 [==============================] - 3s - loss: 0.2461 - acc: 0.8917 - val_loss: 1.0678 - val_acc: 0.8353\n",
      "Epoch 50/50\n",
      "112720/112720 [==============================] - 3s - loss: 0.2437 - acc: 0.8949 - val_loss: 1.0926 - val_acc: 0.8315\n",
      "21135/22544 [===========================>..] - ETA: 0s\n",
      " Train Acc: 0.8907026126980782, Test Acc: 0.8315294533967972\n",
      " \n",
      " Current Layer Attributes - epochs:50 hidden layers:10 features count:32\n",
      "Train on 112720 samples, validate on 22544 samples\n",
      "Epoch 1/50\n",
      "112720/112720 [==============================] - 5s - loss: 0.9191 - acc: 0.0090 - val_loss: 1.8766 - val_acc: 0.0341\n",
      "Epoch 2/50\n",
      "112720/112720 [==============================] - 3s - loss: 0.8025 - acc: 0.0670 - val_loss: 1.7721 - val_acc: 0.2264\n",
      "Epoch 3/50\n",
      "112720/112720 [==============================] - 3s - loss: 0.7482 - acc: 0.1783 - val_loss: 1.7380 - val_acc: 0.2767\n",
      "Epoch 4/50\n",
      "112720/112720 [==============================] - 3s - loss: 0.6687 - acc: 0.4527 - val_loss: 1.6910 - val_acc: 0.5779\n",
      "Epoch 5/50\n",
      "112720/112720 [==============================] - 3s - loss: 0.6276 - acc: 0.5925 - val_loss: 1.7344 - val_acc: 0.5185\n",
      "Epoch 6/50\n",
      "112720/112720 [==============================] - 3s - loss: 0.5858 - acc: 0.6447 - val_loss: 1.5123 - val_acc: 0.7423\n",
      "Epoch 7/50\n",
      "112720/112720 [==============================] - 3s - loss: 0.5222 - acc: 0.7402 - val_loss: 1.4352 - val_acc: 0.7703\n",
      "Epoch 8/50\n",
      "112720/112720 [==============================] - 3s - loss: 0.4813 - acc: 0.7945 - val_loss: 1.3557 - val_acc: 0.7833\n",
      "Epoch 9/50\n",
      "112720/112720 [==============================] - 3s - loss: 0.4322 - acc: 0.8254 - val_loss: 1.2827 - val_acc: 0.7960\n",
      "Epoch 10/50\n",
      "112720/112720 [==============================] - 3s - loss: 0.3879 - acc: 0.8431 - val_loss: 1.2126 - val_acc: 0.7955\n",
      "Epoch 11/50\n",
      "112720/112720 [==============================] - 3s - loss: 0.3892 - acc: 0.8275 - val_loss: 1.2439 - val_acc: 0.7986\n",
      "Epoch 12/50\n",
      "112720/112720 [==============================] - 3s - loss: 0.3588 - acc: 0.8468 - val_loss: 1.1621 - val_acc: 0.8080\n",
      "Epoch 13/50\n",
      "112720/112720 [==============================] - 3s - loss: 0.3173 - acc: 0.8642 - val_loss: 1.1298 - val_acc: 0.8265\n",
      "Epoch 14/50\n",
      "112720/112720 [==============================] - 3s - loss: 0.2875 - acc: 0.8738 - val_loss: 1.1045 - val_acc: 0.8272\n",
      "Epoch 15/50\n",
      "112720/112720 [==============================] - 3s - loss: 0.3427 - acc: 0.8185 - val_loss: 1.1047 - val_acc: 0.8240\n",
      "Epoch 16/50\n",
      "112720/112720 [==============================] - 3s - loss: 0.2783 - acc: 0.8762 - val_loss: 1.1278 - val_acc: 0.8349\n",
      "Epoch 17/50\n",
      "112720/112720 [==============================] - 3s - loss: 0.2630 - acc: 0.8817 - val_loss: 1.0731 - val_acc: 0.8260\n",
      "Epoch 18/50\n",
      "112720/112720 [==============================] - 3s - loss: 0.2992 - acc: 0.8517 - val_loss: 1.0847 - val_acc: 0.8338\n",
      "Epoch 19/50\n",
      "112720/112720 [==============================] - 3s - loss: 0.2596 - acc: 0.8720 - val_loss: 1.1054 - val_acc: 0.8149\n",
      "Epoch 20/50\n",
      "112720/112720 [==============================] - 3s - loss: 0.2492 - acc: 0.8810 - val_loss: 1.0819 - val_acc: 0.8347\n",
      "Epoch 21/50\n",
      "112720/112720 [==============================] - 3s - loss: 0.2650 - acc: 0.8713 - val_loss: 1.0754 - val_acc: 0.8199\n",
      "Epoch 22/50\n",
      "112720/112720 [==============================] - 2s - loss: 0.3122 - acc: 0.8456 - val_loss: 1.1121 - val_acc: 0.8306\n",
      "Epoch 23/50\n",
      "112720/112720 [==============================] - 2s - loss: 0.2372 - acc: 0.8850 - val_loss: 1.0440 - val_acc: 0.8289\n",
      "Epoch 24/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "112720/112720 [==============================] - 2s - loss: 0.2382 - acc: 0.8753 - val_loss: 1.0224 - val_acc: 0.8480\n",
      "Epoch 25/50\n",
      "112720/112720 [==============================] - 3s - loss: 0.2738 - acc: 0.8658 - val_loss: 1.1902 - val_acc: 0.8160\n",
      "Epoch 26/50\n",
      "112720/112720 [==============================] - 3s - loss: 0.3014 - acc: 0.8417 - val_loss: 1.1514 - val_acc: 0.7944\n",
      "Epoch 27/50\n",
      "112720/112720 [==============================] - 3s - loss: 0.2119 - acc: 0.8854 - val_loss: 1.1474 - val_acc: 0.7768\n",
      "Epoch 28/50\n",
      "112720/112720 [==============================] - 3s - loss: 0.2458 - acc: 0.8686 - val_loss: 1.1391 - val_acc: 0.7939\n",
      "Epoch 29/50\n",
      "112720/112720 [==============================] - 3s - loss: 0.2201 - acc: 0.8802 - val_loss: 1.0754 - val_acc: 0.8303\n",
      "Epoch 30/50\n",
      "112720/112720 [==============================] - 3s - loss: 0.1913 - acc: 0.8921 - val_loss: 1.0591 - val_acc: 0.8270\n",
      "Epoch 31/50\n",
      "112720/112720 [==============================] - 3s - loss: 0.1989 - acc: 0.8899 - val_loss: 1.1804 - val_acc: 0.8078\n",
      "Epoch 32/50\n",
      "112720/112720 [==============================] - 3s - loss: 0.2052 - acc: 0.8901 - val_loss: 1.0401 - val_acc: 0.8280\n",
      "Epoch 33/50\n",
      "112720/112720 [==============================] - 3s - loss: 0.1804 - acc: 0.8948 - val_loss: 1.0372 - val_acc: 0.8814\n",
      "Epoch 34/50\n",
      "112720/112720 [==============================] - 3s - loss: 0.2860 - acc: 0.8571 - val_loss: 1.3229 - val_acc: 0.8330\n",
      "Epoch 35/50\n",
      "112720/112720 [==============================] - 3s - loss: 0.2798 - acc: 0.8667 - val_loss: 1.1589 - val_acc: 0.8528\n",
      "Epoch 36/50\n",
      "112720/112720 [==============================] - 3s - loss: 0.2260 - acc: 0.8900 - val_loss: 1.0183 - val_acc: 0.8632\n",
      "Epoch 37/50\n",
      "112720/112720 [==============================] - 3s - loss: 0.2086 - acc: 0.8929 - val_loss: 0.9572 - val_acc: 0.8904\n",
      "Epoch 38/50\n",
      "112720/112720 [==============================] - 3s - loss: 0.2035 - acc: 0.8937 - val_loss: 1.0236 - val_acc: 0.8541\n",
      "Epoch 39/50\n",
      "112720/112720 [==============================] - 3s - loss: 0.1955 - acc: 0.8903 - val_loss: 0.9539 - val_acc: 0.8612\n",
      "Epoch 40/50\n",
      "112720/112720 [==============================] - 3s - loss: 0.1751 - acc: 0.9007 - val_loss: 0.9210 - val_acc: 0.8860\n",
      "Epoch 41/50\n",
      "112720/112720 [==============================] - 3s - loss: 0.1676 - acc: 0.9027 - val_loss: 0.9166 - val_acc: 0.8715\n",
      "Epoch 42/50\n",
      "112720/112720 [==============================] - 3s - loss: 0.1651 - acc: 0.9043 - val_loss: 0.8990 - val_acc: 0.8764\n",
      "Epoch 43/50\n",
      "112720/112720 [==============================] - 3s - loss: 0.1663 - acc: 0.9014 - val_loss: 0.8827 - val_acc: 0.8810\n",
      "Epoch 44/50\n",
      "112720/112720 [==============================] - 3s - loss: 0.2515 - acc: 0.8641 - val_loss: 1.0511 - val_acc: 0.8457\n",
      "Epoch 45/50\n",
      "112720/112720 [==============================] - 3s - loss: 0.1889 - acc: 0.8971 - val_loss: 0.9283 - val_acc: 0.8907\n",
      "Epoch 46/50\n",
      "112720/112720 [==============================] - 3s - loss: 0.1671 - acc: 0.9083 - val_loss: 0.9224 - val_acc: 0.8840\n",
      "Epoch 47/50\n",
      "112720/112720 [==============================] - 3s - loss: 0.1615 - acc: 0.9126 - val_loss: 0.9084 - val_acc: 0.8852\n",
      "Epoch 48/50\n",
      "112720/112720 [==============================] - 3s - loss: 0.1585 - acc: 0.9180 - val_loss: 0.9064 - val_acc: 0.8913\n",
      "Epoch 49/50\n",
      "112720/112720 [==============================] - 3s - loss: 0.1559 - acc: 0.9184 - val_loss: 0.9178 - val_acc: 0.8774\n",
      "Epoch 50/50\n",
      "112720/112720 [==============================] - 3s - loss: 0.1643 - acc: 0.9202 - val_loss: 0.9017 - val_acc: 0.8902\n",
      "22544/22544 [==============================] - 0s     \n",
      "\n",
      " Train Acc: 0.9216643050312996, Test Acc: 0.890170332044363\n"
     ]
    }
   ],
   "source": [
    "import itertools\n",
    "#features_arr = [4, 16, 32, 256, 1024]\n",
    "#hidden_layers_arr = [2, 6, 10, 100]\n",
    "\n",
    "features_arr = [4, 16, 32]\n",
    "hidden_layers_arr = [2, 6, 10]\n",
    "\n",
    "epoch_arr = [50]\n",
    "\n",
    "score = namedtuple(\"score\", ['epoch', 'no_of_features','hidden_layers','train_score', 'test_score'])\n",
    "scores = []\n",
    "predictions = pd.DataFrame()\n",
    "\n",
    "for e, h, f in itertools.product(epoch_arr, hidden_layers_arr, features_arr):\n",
    "    \n",
    "    print(\" \\n Current Layer Attributes - epochs:{} hidden layers:{} features count:{}\".format(e,h,f))\n",
    "    latent_dim = f\n",
    "    epochs = e\n",
    "    hidden_layers = h\n",
    "\n",
    "    Train.train()\n",
    "\n",
    "    vae_model = Model(inputs = Train.x, outputs = Train.x_ )\n",
    "    vae_model.compile(optimizer = \"adam\", loss = \"mean_squared_error\", metrics = ['accuracy'] )\n",
    "\n",
    "    train_size = x_train.shape[0] - x_train.shape[0]%batch_size\n",
    "    valid_size = x_valid.shape[0] - x_valid.shape[0]%batch_size\n",
    "\n",
    "    vae_model.fit(x = x_train[:train_size,:], y = x_train[:train_size,:], \n",
    "                  shuffle=True, epochs=epochs, \n",
    "                  batch_size = batch_size, \n",
    "                  #validation_data = (x_valid[:valid_size,:], x_valid[:valid_size,:]),\n",
    "                  validation_data = (x_test, x_test),\n",
    "                  verbose = 1)\n",
    "    \n",
    "    score_train = vae_model.evaluate(x_valid[:valid_size,:], y = x_valid[:valid_size,:],\n",
    "                               batch_size = batch_size,\n",
    "                               verbose = 1)\n",
    "    \n",
    "    score_test = vae_model.evaluate(x_test, y = x_test,\n",
    "                           batch_size = batch_size,\n",
    "                           verbose = 1)\n",
    "    \n",
    "    scores.append(score(e,f,h,score_train[-1], score_test[-1])) #score_test[-1]))\n",
    "    \n",
    "    print(\"\\n Train Acc: {}, Test Acc: {}\".format(score_train[-1], \n",
    "                                                  score_test[-1])  )\n",
    "    \n",
    "scores = pd.DataFrame(scores)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>epoch</th>\n",
       "      <th>no_of_features</th>\n",
       "      <th>hidden_layers</th>\n",
       "      <th>train_score</th>\n",
       "      <th>test_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>50</td>\n",
       "      <td>32</td>\n",
       "      <td>2</td>\n",
       "      <td>0.926544</td>\n",
       "      <td>0.926721</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>50</td>\n",
       "      <td>4</td>\n",
       "      <td>6</td>\n",
       "      <td>0.940649</td>\n",
       "      <td>0.894163</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>50</td>\n",
       "      <td>32</td>\n",
       "      <td>6</td>\n",
       "      <td>0.910309</td>\n",
       "      <td>0.893630</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>50</td>\n",
       "      <td>32</td>\n",
       "      <td>10</td>\n",
       "      <td>0.921664</td>\n",
       "      <td>0.890170</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>50</td>\n",
       "      <td>16</td>\n",
       "      <td>6</td>\n",
       "      <td>0.907115</td>\n",
       "      <td>0.887731</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>50</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>0.899574</td>\n",
       "      <td>0.873093</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>50</td>\n",
       "      <td>16</td>\n",
       "      <td>10</td>\n",
       "      <td>0.890703</td>\n",
       "      <td>0.831529</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>50</td>\n",
       "      <td>4</td>\n",
       "      <td>10</td>\n",
       "      <td>0.877129</td>\n",
       "      <td>0.797773</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>50</td>\n",
       "      <td>16</td>\n",
       "      <td>2</td>\n",
       "      <td>0.363290</td>\n",
       "      <td>0.335034</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   epoch  no_of_features  hidden_layers  train_score  test_score\n",
       "2     50              32              2     0.926544    0.926721\n",
       "3     50               4              6     0.940649    0.894163\n",
       "5     50              32              6     0.910309    0.893630\n",
       "8     50              32             10     0.921664    0.890170\n",
       "4     50              16              6     0.907115    0.887731\n",
       "0     50               4              2     0.899574    0.873093\n",
       "7     50              16             10     0.890703    0.831529\n",
       "6     50               4             10     0.877129    0.797773\n",
       "1     50              16              2     0.363290    0.335034"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scores.sort_values(\"test_score\", ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "scores.to_pickle(\"dataset/vae_only_feature_extraction_scores.pkl\")"
   ]
  }
 ],
 "metadata": {
  "_draft": {
   "nbviewer_url": "https://gist.github.com/33dcb1bcf3ca4a3461c4405a003a7591"
  },
  "anaconda-cloud": {},
  "gist": {
   "data": {
    "description": "Final Hyper parameter tuning",
    "public": false
   },
   "id": "33dcb1bcf3ca4a3461c4405a003a7591"
  },
  "kernelspec": {
   "display_name": "Python [conda env:p3]",
   "language": "python",
   "name": "conda-env-p3-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
