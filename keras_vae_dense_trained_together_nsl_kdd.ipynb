{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Deep Learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.layers import Input, Dense, Lambda, Layer\n",
    "from keras.models import Model\n",
    "from keras import regularizers\n",
    "import keras\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from keras import backend as K\n",
    "from keras import metrics\n",
    "from collections import namedtuple\n",
    "pd.set_option(\"display.max_rows\",35)\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "kdd_train_2labels = pd.read_pickle(\"dataset/kdd_train_2labels.pkl\")\n",
    "kdd_test_2labels = pd.read_pickle(\"dataset/kdd_test_2labels.pkl\")\n",
    "\n",
    "#y_train_labels = pd.read_pickle(\"dataset/kdd_train_2labels_y.pkl\")\n",
    "#y_train_labels = pd.read_pickle(\"dataset/kdd_train_2labels.pkl\")\n",
    "#y_test_labels = pd.read_pickle(\"dataset/kdd_test_2labels_y.pkl\")\n",
    "\n",
    "output_columns_2labels = ['is_Attack','is_Normal']\n",
    "\n",
    "from sklearn import model_selection as ms\n",
    "from sklearn import preprocessing as pp\n",
    "\n",
    "x_input = kdd_train_2labels.drop(output_columns_2labels, axis = 1)\n",
    "y_output = kdd_train_2labels.loc[:,output_columns_2labels]\n",
    "\n",
    "ss = pp.StandardScaler()\n",
    "x_input = ss.fit_transform(x_input)\n",
    "\n",
    "#le = pp.LabelEncoder()\n",
    "#y_train = le.fit_transform(y_train_labels).reshape(-1, 1)\n",
    "#y_test = le.transform(y_test_labels).reshape(-1, 1)\n",
    "\n",
    "y_train = kdd_train_2labels.loc[:,output_columns_2labels].values\n",
    "\n",
    "x_train, x_valid, y_train, y_valid = ms.train_test_split(x_input, \n",
    "                              y_train, \n",
    "                              test_size=0.1)\n",
    "#x_valid, x_test, y_valid, y_test = ms.train_test_split(x_valid, y_valid, test_size = 0.4)\n",
    "\n",
    "x_test = kdd_test_2labels.drop(output_columns_2labels, axis = 1)\n",
    "y_test = kdd_test_2labels.loc[:,output_columns_2labels].values\n",
    "\n",
    "x_test = ss.transform(x_test)\n",
    "\n",
    "#x_train = np.hstack((x_train, y_train))\n",
    "#x_valid = np.hstack((x_valid, y_valid))\n",
    "\n",
    "#x_test = np.hstack((x_test, np.random.normal(loc = 0, scale = 0.01, size = y_test.shape)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "input_dim = 122\n",
    "intermediate_dim = 10\n",
    "latent_dim = 32\n",
    "batch_size = 1409\n",
    "epochs = 5\n",
    "hidden_layers = 8\n",
    "classes = 2\n",
    "\n",
    "class Train:\n",
    "    def train():\n",
    "        Train.x = Input(shape=(input_dim,))\n",
    "        \n",
    "        hidden_encoder = Train.x\n",
    "        for i in range(hidden_layers):\n",
    "            hidden_encoder = Dense(intermediate_dim, activation='relu')(hidden_encoder)\n",
    "            \n",
    "\n",
    "        mean_encoder = Dense(latent_dim, activation=None)(hidden_encoder)\n",
    "\n",
    "        logvar_encoder = Dense(latent_dim, activation=None)(hidden_encoder)\n",
    "\n",
    "        def get_distrib(args):\n",
    "\n",
    "            mean_encoder, logvar_encoder = args\n",
    "\n",
    "            # Sample epsilon\n",
    "            epsilon = np.random.normal(loc=0.0, scale=0.05, size = (batch_size, latent_dim))\n",
    "\n",
    "            # Sample latent variable\n",
    "            z = mean_encoder + K.exp(logvar_encoder / 2) * epsilon\n",
    "            return z\n",
    "\n",
    "        z = Lambda(get_distrib)([mean_encoder, logvar_encoder])\n",
    "\n",
    "        hidden_decoder = z\n",
    "        for i in range(hidden_layers):\n",
    "            hidden_decoder = Dense(intermediate_dim, activation=\"relu\")(hidden_decoder)\n",
    "\n",
    "        Train.x_ = Dense(input_dim, activation=None, name='vae_output')(hidden_decoder)\n",
    "        \n",
    "        hidden_y = Dense(latent_dim, activation='softmax', name='softmax_hidden')(z)\n",
    "        \n",
    "        Train.y = Dense(classes, activation='softmax', name='softmax_output')(hidden_y)\n",
    "        \n",
    "\n",
    "def get_loss(x, x_):\n",
    "    xent_loss = input_dim * metrics.binary_crossentropy(x, x_) \n",
    "    kl_loss = - 0.5 * K.sum(1 + logvar_encoder - K.square(mean_encoder) - K.exp(logvar_encoder), axis=-1)\n",
    "    \n",
    "    return K.abs(K.mean(xent_loss + kl_loss + label_loss))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " \n",
      " Current Layer Attributes - epochs:5 hidden layers:2 features count:4\n",
      "Train on 112720 samples, validate on 22544 samples\n",
      "Epoch 1/5\n",
      "112720/112720 [==============================] - 0s - loss: 0.6352 - acc: 0.6652 - val_loss: 0.5404 - val_acc: 0.7817\n",
      "Epoch 2/5\n",
      "112720/112720 [==============================] - 0s - loss: 0.3817 - acc: 0.9609 - val_loss: 0.5292 - val_acc: 0.7374\n",
      "Epoch 3/5\n",
      "112720/112720 [==============================] - 0s - loss: 0.3015 - acc: 0.9723 - val_loss: 0.5260 - val_acc: 0.7605\n",
      "Epoch 4/5\n",
      "112720/112720 [==============================] - 0s - loss: 0.2627 - acc: 0.9746 - val_loss: 0.5353 - val_acc: 0.7547\n",
      "Epoch 5/5\n",
      "112720/112720 [==============================] - 0s - loss: 0.2338 - acc: 0.9756 - val_loss: 0.5362 - val_acc: 0.7650\n",
      " 1409/22544 [>.............................] - ETA: 0s\n",
      " Train Acc: 0.9779098629951477, Test Acc: 0.7650372534990311\n",
      " \n",
      " Current Layer Attributes - epochs:5 hidden layers:2 features count:16\n",
      "Train on 112720 samples, validate on 22544 samples\n",
      "Epoch 1/5\n",
      "112720/112720 [==============================] - 0s - loss: 0.5557 - acc: 0.8577 - val_loss: 0.5633 - val_acc: 0.7562\n",
      "Epoch 2/5\n",
      "112720/112720 [==============================] - 0s - loss: 0.3562 - acc: 0.9692 - val_loss: 0.5688 - val_acc: 0.7479\n",
      "Epoch 3/5\n",
      "112720/112720 [==============================] - 0s - loss: 0.2877 - acc: 0.9755 - val_loss: 0.5616 - val_acc: 0.7539\n",
      "Epoch 4/5\n",
      "112720/112720 [==============================] - 0s - loss: 0.2513 - acc: 0.9777 - val_loss: 0.5680 - val_acc: 0.7534\n",
      "Epoch 5/5\n",
      "112720/112720 [==============================] - 0s - loss: 0.2238 - acc: 0.9788 - val_loss: 0.5628 - val_acc: 0.7644\n",
      " 1409/22544 [>.............................] - ETA: 0s\n",
      " Train Acc: 0.978087306022644, Test Acc: 0.764371894299984\n",
      " \n",
      " Current Layer Attributes - epochs:5 hidden layers:2 features count:32\n",
      "Train on 112720 samples, validate on 22544 samples\n",
      "Epoch 1/5\n",
      "112720/112720 [==============================] - 0s - loss: 0.5713 - acc: 0.8913 - val_loss: 0.5258 - val_acc: 0.8413\n",
      "Epoch 2/5\n",
      "112720/112720 [==============================] - 0s - loss: 0.3829 - acc: 0.9665 - val_loss: 0.5584 - val_acc: 0.7577\n",
      "Epoch 3/5\n",
      "112720/112720 [==============================] - 0s - loss: 0.2886 - acc: 0.9770 - val_loss: 0.5741 - val_acc: 0.7525\n",
      "Epoch 4/5\n",
      "112720/112720 [==============================] - 0s - loss: 0.2490 - acc: 0.9796 - val_loss: 0.5799 - val_acc: 0.7516\n",
      "Epoch 5/5\n",
      "112720/112720 [==============================] - 0s - loss: 0.2214 - acc: 0.9803 - val_loss: 0.5713 - val_acc: 0.7625\n",
      " 1409/22544 [>.............................] - ETA: 0s\n",
      " Train Acc: 0.9789744466543198, Test Acc: 0.7625088766217232\n",
      " \n",
      " Current Layer Attributes - epochs:5 hidden layers:6 features count:4\n",
      "Train on 112720 samples, validate on 22544 samples\n",
      "Epoch 1/5\n",
      "112720/112720 [==============================] - 1s - loss: 0.6170 - acc: 0.6741 - val_loss: 0.5549 - val_acc: 0.8026\n",
      "Epoch 2/5\n",
      "112720/112720 [==============================] - 0s - loss: 0.3589 - acc: 0.9675 - val_loss: 0.5205 - val_acc: 0.7924\n",
      "Epoch 3/5\n",
      "112720/112720 [==============================] - 0s - loss: 0.2933 - acc: 0.9751 - val_loss: 0.5506 - val_acc: 0.7653\n",
      "Epoch 4/5\n",
      "112720/112720 [==============================] - 0s - loss: 0.2560 - acc: 0.9786 - val_loss: 0.5498 - val_acc: 0.7693\n",
      "Epoch 5/5\n",
      "112720/112720 [==============================] - 0s - loss: 0.2278 - acc: 0.9805 - val_loss: 0.5606 - val_acc: 0.7661\n",
      " 1409/22544 [>.............................] - ETA: 0s\n",
      " Train Acc: 0.9795954674482346, Test Acc: 0.7660574838519096\n",
      " \n",
      " Current Layer Attributes - epochs:5 hidden layers:6 features count:16\n",
      "Train on 112720 samples, validate on 22544 samples\n",
      "Epoch 1/5\n",
      "112720/112720 [==============================] - 1s - loss: 0.6446 - acc: 0.7126 - val_loss: 0.5609 - val_acc: 0.8475\n",
      "Epoch 2/5\n",
      "112720/112720 [==============================] - 0s - loss: 0.4331 - acc: 0.9634 - val_loss: 0.5825 - val_acc: 0.7514\n",
      "Epoch 3/5\n",
      "112720/112720 [==============================] - 0s - loss: 0.2687 - acc: 0.9744 - val_loss: 0.6216 - val_acc: 0.7392\n",
      "Epoch 4/5\n",
      "112720/112720 [==============================] - 0s - loss: 0.2205 - acc: 0.9766 - val_loss: 0.6014 - val_acc: 0.7525\n",
      "Epoch 5/5\n",
      "112720/112720 [==============================] - 0s - loss: 0.1933 - acc: 0.9782 - val_loss: 0.5978 - val_acc: 0.7618\n",
      "22544/22544 [==============================] - 0s     \n",
      "\n",
      " Train Acc: 0.9793293103575706, Test Acc: 0.7617991454899311\n",
      " \n",
      " Current Layer Attributes - epochs:5 hidden layers:6 features count:32\n",
      "Train on 112720 samples, validate on 22544 samples\n",
      "Epoch 1/5\n",
      "112720/112720 [==============================] - 1s - loss: 0.6202 - acc: 0.7335 - val_loss: 0.5523 - val_acc: 0.7602\n",
      "Epoch 2/5\n",
      "112720/112720 [==============================] - 0s - loss: 0.3404 - acc: 0.9669 - val_loss: 0.5945 - val_acc: 0.7370\n",
      "Epoch 3/5\n",
      "112720/112720 [==============================] - 0s - loss: 0.2673 - acc: 0.9774 - val_loss: 0.5616 - val_acc: 0.7639\n",
      "Epoch 4/5\n",
      "112720/112720 [==============================] - 0s - loss: 0.2338 - acc: 0.9791 - val_loss: 0.5788 - val_acc: 0.7559\n",
      "Epoch 5/5\n",
      "112720/112720 [==============================] - 0s - loss: 0.2093 - acc: 0.9803 - val_loss: 0.5839 - val_acc: 0.7584\n",
      "22544/22544 [==============================] - 0s     \n",
      "\n",
      " Train Acc: 0.9792405962944031, Test Acc: 0.7584279663860798\n"
     ]
    }
   ],
   "source": [
    "import itertools\n",
    "#features_arr = [4, 16, 32, 256, 1024]\n",
    "#hidden_layers_arr = [2, 6, 10, 100]\n",
    "\n",
    "#features_arr = [4, 16, 32]\n",
    "#hidden_layers_arr = [2, 6, 10]\n",
    "\n",
    "features_arr = [4, 16, 32]\n",
    "hidden_layers_arr = [2, 6]\n",
    "\n",
    "epoch_arr = [5]\n",
    "\n",
    "score = namedtuple(\"score\", ['epoch', 'no_of_features','hidden_layers','train_score', 'test_score'])\n",
    "scores = []\n",
    "predictions = pd.DataFrame()\n",
    "\n",
    "for e, h, f in itertools.product(epoch_arr, hidden_layers_arr, features_arr):\n",
    "    \n",
    "    print(\" \\n Current Layer Attributes - epochs:{} hidden layers:{} features count:{}\".format(e,h,f))\n",
    "    latent_dim = f\n",
    "    epochs = e\n",
    "    hidden_layers = h\n",
    "\n",
    "    Train.train()\n",
    "\n",
    "    vae_model = Model(inputs = Train.x, outputs = Train.y)\n",
    "    #vae_model.compile(optimizer = \"adam\", loss = \"mean_squared_error\", metrics = ['accuracy'] )\n",
    "    vae_model.compile(optimizer = \"adam\", loss = \"binary_crossentropy\", metrics = ['accuracy'] )\n",
    "    \n",
    "    train_size = x_train.shape[0] - x_train.shape[0]%batch_size\n",
    "    valid_size = x_valid.shape[0] - x_valid.shape[0]%batch_size\n",
    "\n",
    "    vae_model.fit(x = x_train[:train_size,:], y = y_train[:train_size,:], \n",
    "                  shuffle=True, epochs=epochs, \n",
    "                  batch_size = batch_size, \n",
    "                  #validation_data = (x_valid[:valid_size,:], y_valid[:valid_size,:]),\n",
    "                  validation_data = (x_test, y_test),\n",
    "                  verbose = 1)\n",
    "    \n",
    "    score_train = vae_model.evaluate(x_valid[:valid_size,:], y = y_valid[:valid_size,:],\n",
    "                               batch_size = batch_size,\n",
    "                               verbose = 1)\n",
    "    \n",
    "    score_test = vae_model.evaluate(x_test, y = y_test,\n",
    "                           batch_size = batch_size,\n",
    "                           verbose = 1)\n",
    "    \n",
    "    y_test_pred = vae_model.predict(x_test, batch_size=batch_size)\n",
    "    \n",
    "    y_pred = np.argmax(y_test_pred[:,-2:], axis = 1)\n",
    "    \n",
    "    curr_pred = pd.DataFrame({\"{}_{}_{}\".format(e,f,h):y_pred},)\n",
    "    predictions = pd.concat([predictions, curr_pred], axis = 1)\n",
    "    \n",
    "    scores.append(score(e,f,h,score_train[-1], score_test[-1])) #score_test[-1]))\n",
    "    \n",
    "    print(\"\\n Train Acc: {}, Test Acc: {}\".format(score_train[-1], \n",
    "                                                  score_test[-1])  )\n",
    "    \n",
    "scores = pd.DataFrame(scores)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>epoch</th>\n",
       "      <th>no_of_features</th>\n",
       "      <th>hidden_layers</th>\n",
       "      <th>train_score</th>\n",
       "      <th>test_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>6</td>\n",
       "      <td>0.979595</td>\n",
       "      <td>0.766057</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>0.977910</td>\n",
       "      <td>0.765037</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5</td>\n",
       "      <td>16</td>\n",
       "      <td>2</td>\n",
       "      <td>0.978087</td>\n",
       "      <td>0.764372</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5</td>\n",
       "      <td>32</td>\n",
       "      <td>2</td>\n",
       "      <td>0.978974</td>\n",
       "      <td>0.762509</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>16</td>\n",
       "      <td>6</td>\n",
       "      <td>0.979329</td>\n",
       "      <td>0.761799</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5</td>\n",
       "      <td>32</td>\n",
       "      <td>6</td>\n",
       "      <td>0.979241</td>\n",
       "      <td>0.758428</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   epoch  no_of_features  hidden_layers  train_score  test_score\n",
       "3      5               4              6     0.979595    0.766057\n",
       "0      5               4              2     0.977910    0.765037\n",
       "1      5              16              2     0.978087    0.764372\n",
       "2      5              32              2     0.978974    0.762509\n",
       "4      5              16              6     0.979329    0.761799\n",
       "5      5              32              6     0.979241    0.758428"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scores.sort_values(\"test_score\", ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.23562810503903478"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred = predictions.loc[:,'{}_16_2'.format(epochs)]\n",
    "y_actual = np.argmax(y_test, axis = 1)\n",
    "(y_test.shape[0] - np.sum(np.equal(y_pred, y_actual))) / y_test.shape[0] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import itertools\n",
    "\n",
    "def plot_confusion_matrix(cm, classes,\n",
    "                          normalize=False,\n",
    "                          title='Confusion matrix',\n",
    "                          cmap=plt.cm.Blues):\n",
    "    \"\"\"\n",
    "    This function prints and plots the confusion matrix.\n",
    "    Normalization can be applied by setting `normalize=True`.\n",
    "    \"\"\"\n",
    "    np.set_printoptions(precision=4)\n",
    "\n",
    "    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n",
    "    plt.title(title)\n",
    "    plt.colorbar()\n",
    "    tick_marks = np.arange(len(classes))\n",
    "    plt.xticks(tick_marks, classes, rotation=45)\n",
    "    plt.yticks(tick_marks, classes)\n",
    "\n",
    "    if normalize:\n",
    "        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "        print(\"Normalized confusion matrix\")\n",
    "    else:\n",
    "        print('Confusion matrix, without normalization')\n",
    "\n",
    "    print(cm)\n",
    "\n",
    "    thresh = cm.max() / 2.\n",
    "    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
    "        plt.text(j, i, cm[i, j].round(4),\n",
    "                 horizontalalignment=\"center\",\n",
    "                 color=\"white\" if cm[i, j] > thresh else \"black\")\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.ylabel('True label')\n",
    "    plt.xlabel('Predicted label')\n",
    "\n",
    "def plot(actual_value, pred_value):\n",
    "    from sklearn.metrics import confusion_matrix\n",
    "    cm_2labels = confusion_matrix(y_pred = pred_value, y_true = actual_value)\n",
    "    plt.figure(figsize=[6,6])\n",
    "    plot_confusion_matrix(cm_2labels, output_columns_2labels, normalize = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Normalized confusion matrix\n",
      "[[ 0.6418  0.3582]\n",
      " [ 0.0736  0.9264]]\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAbUAAAGgCAYAAAAtsfn1AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nhoOamZmVDAc1MzMrGQ5qZmZWMv4/wm5eZoWkhg0AAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f1c51bc3cc0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot(actual_value = y_actual, pred_value = y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "predictions.to_pickle(\"dataset/vae_dense_keras_predictions.pkl\")\n",
    "scores.to_pickle(\"dataset/vae_dense_keras_scores.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "_draft": {
   "nbviewer_url": "https://gist.github.com/33dcb1bcf3ca4a3461c4405a003a7591"
  },
  "anaconda-cloud": {},
  "gist": {
   "data": {
    "description": "Final Hyper parameter tuning",
    "public": false
   },
   "id": "33dcb1bcf3ca4a3461c4405a003a7591"
  },
  "kernelspec": {
   "display_name": "Python [conda env:p3]",
   "language": "python",
   "name": "conda-env-p3-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
