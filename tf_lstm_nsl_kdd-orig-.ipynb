{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Read Data Sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-07-17T21:10:37.252359Z",
     "start_time": "2017-07-17T21:10:36.753729Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import time\n",
    "from collections import namedtuple\n",
    "pd.set_option(\"display.max_rows\",35)\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-07-17T21:10:37.330793Z",
     "start_time": "2017-07-17T21:10:37.254226Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class dataset:\n",
    "    kdd_train_2labels = pd.read_pickle(\"dataset/kdd_train__2labels.pkl\")\n",
    "    kdd_test_2labels = pd.read_pickle(\"dataset/kdd_test_2labels.pkl\")\n",
    "    kdd_test__2labels = pd.read_pickle(\"dataset/kdd_test__2labels.pkl\")\n",
    "    \n",
    "    kdd_train_5labels = pd.read_pickle(\"dataset/kdd_train_5labels.pkl\")\n",
    "    kdd_test_5labels = pd.read_pickle(\"dataset/kdd_test_5labels.pkl\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-07-17T21:10:37.339742Z",
     "start_time": "2017-07-17T21:10:37.333242Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(25192, 124)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.kdd_train_2labels.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-07-17T21:10:37.346150Z",
     "start_time": "2017-07-17T21:10:37.341596Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(22544, 124)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.kdd_test_2labels.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-07-17T21:10:37.847962Z",
     "start_time": "2017-07-17T21:10:37.347996Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.97509982675167528"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn import model_selection as ms\n",
    "from sklearn import preprocessing as pp\n",
    "\n",
    "class preprocess:\n",
    "    \n",
    "    output_columns_2labels = ['is_Normal','is_Attack']\n",
    "    \n",
    "    x_input = dataset.kdd_train_2labels.drop(output_columns_2labels, axis = 1)\n",
    "    y_output = dataset.kdd_train_2labels.loc[:,output_columns_2labels]\n",
    "\n",
    "    x_test_input = dataset.kdd_test_2labels.drop(output_columns_2labels, axis = 1)\n",
    "    y_test = dataset.kdd_test_2labels.loc[:,output_columns_2labels]\n",
    "    \n",
    "    x_test__input = dataset.kdd_test__2labels.drop(output_columns_2labels, axis = 1)\n",
    "    y_test_ = dataset.kdd_test__2labels.loc[:,output_columns_2labels]\n",
    "\n",
    "    ss = pp.StandardScaler()\n",
    "\n",
    "    x_train = ss.fit_transform(x_input)\n",
    "    x_test = ss.transform(x_test_input)\n",
    "    x_test_ = ss.transform(x_test__input)\n",
    "\n",
    "    y_train = y_output.values\n",
    "    y_test = y_test.values\n",
    "    y_test_ = y_test_.values\n",
    "\n",
    "    \n",
    "preprocess.x_train.std()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-07-17T21:10:49.253755Z",
     "start_time": "2017-07-17T21:10:37.851041Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.contrib.legacy_seq2seq.python.ops.seq2seq import basic_rnn_seq2seq\n",
    "from tensorflow.contrib.rnn import RNNCell, LSTMCell, MultiRNNCell\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-07-17T21:10:49.569658Z",
     "start_time": "2017-07-17T21:10:49.255876Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class network(object):\n",
    "    \n",
    "    input_dim = 122\n",
    "    classes = 2\n",
    "    hidden_encoder_dim = 122\n",
    "    hidden_layers = 1\n",
    "    latent_dim = 10\n",
    "\n",
    "    hidden_decoder_dim = 122\n",
    "    lam = 0.01\n",
    "    \n",
    "    def __init__(self, classes, hidden_layers, num_of_features):\n",
    "        self.classes = classes\n",
    "        self.hidden_layers = hidden_layers\n",
    "        self.latent_dim = num_of_features\n",
    "            \n",
    "    def build_layers(self):\n",
    "        tf.reset_default_graph()\n",
    "        #learning_rate = tf.Variable(initial_value=0.001)\n",
    "\n",
    "        input_dim = self.input_dim\n",
    "        classes = self.classes\n",
    "        hidden_encoder_dim = self.hidden_encoder_dim\n",
    "        hidden_layers = self.hidden_layers\n",
    "        latent_dim = self.latent_dim\n",
    "        hidden_decoder_dim = self.hidden_decoder_dim\n",
    "        lam = self.lam\n",
    "        \n",
    "        with tf.variable_scope(\"Input\"):\n",
    "            self.x_input = tf.placeholder(\"float\", shape=[None, 1, input_dim])\n",
    "            self.y_input_ = tf.placeholder(\"float\", shape=[None, 1, classes])\n",
    "            self.keep_prob = tf.placeholder(\"float\")\n",
    "            self.lr = tf.placeholder(\"float\")\n",
    "            self.x_list = tf.unstack(self.x_input, axis= 1)\n",
    "            self.y_list_ = tf.unstack(self.y_input_, axis = 1)\n",
    "            self.y_ = self.y_list_[0]\n",
    "            \n",
    "            #GO = tf.fill((tf.shape(self.x)[0], 1), 0.5)\n",
    "            \n",
    "            #y_with_GO = tf.stack([self.y_, GO])\n",
    "            \n",
    "        with tf.variable_scope(\"lstm\"):\n",
    "            multi_cell = MultiRNNCell([LSTMCell(input_dim) for i in range(hidden_layers)] )\n",
    "            \n",
    "            self.y, states = basic_rnn_seq2seq(self.x_list, self.y_list_, multi_cell)\n",
    "            #self.y = tf.slice(self.y, [0, 0], [-1,2])\n",
    "            \n",
    "            #self.out = tf.squeeze(self.y)\n",
    "            \n",
    "            #self.y = tf.layers.dense(self.y[0], classes, activation = None)\n",
    "            \n",
    "            self.y = tf.slice(self.y[0], [0, 0], [-1,2])\n",
    "            \n",
    "        with tf.variable_scope(\"Loss\"):\n",
    "            \n",
    "            self.regularized_loss = tf.losses.mean_squared_error(self.y_, self.y)\n",
    "            correct_prediction = tf.equal(tf.argmax(self.y_, 1), tf.argmax(self.y, 1))\n",
    "            self.tf_accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32), name = \"Accuracy\")\n",
    "\n",
    "        with tf.variable_scope(\"Optimizer\"):\n",
    "            learning_rate=self.lr\n",
    "            optimizer = tf.train.AdamOptimizer(learning_rate)\n",
    "            gradients, variables = zip(*optimizer.compute_gradients(self.regularized_loss))\n",
    "            gradients = [\n",
    "                None if gradient is None else tf.clip_by_value(gradient, -1, 1)\n",
    "                for gradient in gradients]\n",
    "            self.train_op = optimizer.apply_gradients(zip(gradients, variables))\n",
    "            #self.train_op = optimizer.minimize(self.regularized_loss)\n",
    "            \n",
    "        # add op for merging summary\n",
    "        #self.summary_op = tf.summary.merge_all()\n",
    "        self.pred = tf.argmax(self.y, axis = 1)\n",
    "        self.actual = tf.argmax(self.y_, axis = 1)\n",
    "\n",
    "        # add Saver ops\n",
    "        self.saver = tf.train.Saver()\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-06-01T00:59:00.684124Z",
     "start_time": "2017-06-01T00:58:59.843181Z"
    }
   },
   "source": [
    "batch_iterations = 200\n",
    "\n",
    "x_train, x_valid, y_train, y_valid, = ms.train_test_split(preprocess.x_train, \n",
    "                                                                          preprocess.y_train, \n",
    "                                                                          test_size=0.1)\n",
    "batch_indices = np.array_split(np.arange(x_train.shape[0]), \n",
    "                                           batch_iterations)\n",
    "                                                                          \n",
    "for i in batch_indices:\n",
    "    print(x_train[i,np.newaxis,:])\n",
    "    print(y_train[i,np.newaxis,:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-07-17T21:10:49.962464Z",
     "start_time": "2017-07-17T21:10:49.571511Z"
    },
    "collapsed": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import collections\n",
    "import sklearn.metrics as me\n",
    "\n",
    "class Train:    \n",
    "    \n",
    "    result = namedtuple(\"score\", ['epoch', 'no_of_features','hidden_layers','train_score', 'test_score', 'f1_score', 'test_score_20', 'f1_score_20', 'time_taken'])\n",
    "\n",
    "    predictions = {}\n",
    "    predictions_ = {}\n",
    "\n",
    "    results = []\n",
    "    best_acc = 0\n",
    "    best_acc_global = 0\n",
    "\n",
    "    def train(epochs, net, h,f, lrs):\n",
    "        batch_iterations = 200\n",
    "        train_loss = None\n",
    "        Train.best_acc = 0\n",
    "        os.makedirs(\"dataset/tf_lstm_nsl_kdd-orig-/hidden layers_{}_features count_{}\".format(h,f),\n",
    "                    exist_ok = True)\n",
    "        with tf.Session() as sess:\n",
    "            #summary_writer_train = tf.summary.FileWriter('./logs/kdd/VAE/training', graph=sess.graph)\n",
    "            #summary_writer_valid = tf.summary.FileWriter('./logs/kdd/VAE/validation')\n",
    "\n",
    "            sess.run(tf.global_variables_initializer())\n",
    "            start_time = time.perf_counter()\n",
    "            \n",
    "            accuracy, pred_value, actual_value, y_pred = sess.run([net.tf_accuracy, \n",
    "                                                                   net.pred, \n",
    "                                                                   net.actual, net.y], \n",
    "                                                                  feed_dict={net.x_input: preprocess.x_test[:,np.newaxis,:], \n",
    "                                                                             net.y_input_: preprocess.y_test[:,np.newaxis,:], \n",
    "                                                                             net.keep_prob:1})\n",
    "            \n",
    "            print(\"Initial Accuracy, before training: {}\".format(accuracy))\n",
    "            \n",
    "            for c, lr in enumerate(lrs):\n",
    "                for epoch in range(1, (epochs+1)):\n",
    "                    x_train, x_valid, y_train, y_valid, = ms.train_test_split(preprocess.x_train, \n",
    "                                                                              preprocess.y_train, \n",
    "                                                                              test_size=0.1)\n",
    "                    batch_indices = np.array_split(np.arange(x_train.shape[0]), \n",
    "                                               batch_iterations)\n",
    "\n",
    "                    for i in batch_indices:\n",
    "\n",
    "                        _, train_loss = sess.run([net.train_op, net.regularized_loss], #net.summary_op\n",
    "                                                              feed_dict={net.x_input: x_train[i,np.newaxis,:], \n",
    "                                                                         net.y_input_: y_train[i,np.newaxis,:], \n",
    "                                                                         net.keep_prob:1, net.lr:lr})\n",
    "                        #summary_writer_train.add_summary(summary_str, epoch)\n",
    "                        if(train_loss > 1e9):\n",
    "                            print(\"Step {} | Training Loss: {:.6f}\".format(epoch, train_loss))\n",
    "\n",
    "\n",
    "                    valid_accuracy,valid_loss = sess.run([net.tf_accuracy, net.regularized_loss], #net.summary_op \n",
    "                                                          feed_dict={net.x_input: x_valid[:,np.newaxis,:], \n",
    "                                                                     net.y_input_: y_valid[:,np.newaxis,:], \n",
    "                                                                     net.keep_prob:1, net.lr:lr})\n",
    "                    #summary_writer_valid.add_summary(summary_str, epoch)\n",
    "\n",
    "\n",
    "\n",
    "                    accuracy, pred_value, actual_value, y_pred = sess.run([net.tf_accuracy, \n",
    "                                                                   net.pred, \n",
    "                                                                   net.actual, net.y], \n",
    "                                                                  feed_dict={net.x_input: preprocess.x_test[:,np.newaxis,:], \n",
    "                                                                             net.y_input_: preprocess.y_test[:,np.newaxis,:], \n",
    "                                                                             net.keep_prob:1, net.lr:lr})\n",
    "                    f1_score = me.f1_score(actual_value, pred_value)\n",
    "                    accuracy_, pred_value_, actual_value_, y_pred_ = sess.run([net.tf_accuracy, \n",
    "                                                                   net.pred, \n",
    "                                                                   net.actual, net.y], \n",
    "                                                                  feed_dict={net.x_input: preprocess.x_test_[:,np.newaxis,:], \n",
    "                                                                             net.y_input_: preprocess.y_test_[:,np.newaxis,:], \n",
    "                                                                             net.keep_prob:1, net.lr:lr})\n",
    "                    f1_score_ = me.f1_score(actual_value_, pred_value_)\n",
    "                    print(\"Step {} | Training Loss: {:.6f} | Train Accuracy: {:.6f} | Test Accuracy: {:.6f}, {:.6f}\".format(epoch, train_loss, valid_accuracy, accuracy, accuracy_))\n",
    "\n",
    "                    if accuracy > Train.best_acc_global:\n",
    "                                Train.best_acc_global = accuracy\n",
    "                                Train.pred_value = pred_value\n",
    "                                Train.actual_value = actual_value\n",
    "                                Train.pred_value_ = pred_value_\n",
    "                                Train.actual_value_ = actual_value_\n",
    "                                Train.best_parameters = \"Hidden Layers:{}, Features Count:{}\".format(h, f)\n",
    "\n",
    "                    if accuracy > Train.best_acc:\n",
    "\n",
    "                        #net.saver.save(sess, \"dataset/tf_vae_only_nsl_kdd_hidden layers_{}_features count_{}\".format(epochs,h,f))\n",
    "                        #Train.results.append(Train.result(epochs, f, h,valid_accuracy, accuracy))\n",
    "                        #curr_pred = pd.DataFrame({\"Attack_prob\":y_pred[:,-2], \"Normal_prob\":y_pred[:, -1]})\n",
    "                        #Train.predictions.update({\"{}_{}_{}\".format(epochs,f,h):curr_pred})\n",
    "\n",
    "                        Train.best_acc = accuracy\n",
    "                        if not (np.isnan(train_loss)):\n",
    "                            net.saver.save(sess, \n",
    "                                       \"dataset/tf_lstm_nsl_kdd-orig-/hidden layers_{}_features count_{}/model\"\n",
    "                                       .format(h,f), \n",
    "                                       global_step = epoch, \n",
    "                                       write_meta_graph=False)\n",
    "\n",
    "                        curr_pred = pd.DataFrame({\"Attack_prob\":y_pred[:,-2], \"Normal_prob\":y_pred[:, -1], \"Prediction\":pred_value})\n",
    "                        curr_pred_ = pd.DataFrame({\"Attack_prob\":y_pred_[:,-2], \"Normal_prob\":y_pred_[:, -1], \"Prediction\":pred_value_})\n",
    "                        Train.predictions.update({\"{}_{}_{}\".format((epochs+1)* (c+1),f,h):\n",
    "                                                  (curr_pred,\n",
    "                                                   Train.result((epochs+1)*(c+1), f, h,valid_accuracy, accuracy, f1_score, accuracy_, f1_score_, time.perf_counter() - start_time))})\n",
    "                        Train.predictions_.update({\"{}_{}_{}\".format((epochs+1)* (c+1),f,h):\n",
    "                                                  (curr_pred_,\n",
    "                                                   Train.result((epochs+1)*(c+1), f, h,valid_accuracy, accuracy, f1_score, accuracy_, f1_score_, time.perf_counter() - start_time))})\n",
    "\n",
    "\n",
    "\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-07-17T21:10:50.055953Z",
     "start_time": "2017-07-17T21:10:49.964242Z"
    },
    "collapsed": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import itertools\n",
    "\n",
    "df_results = []\n",
    "past_scores = []\n",
    "\n",
    "class Hyperparameters:\n",
    "#    features_arr = [2, 4, 8, 16, 32, 64, 128, 256]\n",
    "#    hidden_layers_arr = [2, 4, 6, 10]\n",
    "\n",
    "    def start_training():\n",
    "\n",
    "        global df_results\n",
    "        global past_scores\n",
    "        \n",
    "        Train.predictions = {}\n",
    "        Train.results = []\n",
    "        \n",
    "        features_arr = [1] #[4, 8, 16, 32]\n",
    "        hidden_layers_arr = [1, 3]\n",
    "\n",
    "        epochs = [10]\n",
    "        lrs = [1e-2, 1e-3]\n",
    "\n",
    "        for e, h, f in itertools.product(epochs, hidden_layers_arr, features_arr):\n",
    "            print(\"Current Layer Attributes - epochs:{} hidden layers:{} features count:{}\".format(e,h,f))\n",
    "            n = network(2,h,f)\n",
    "            n.build_layers()\n",
    "            Train.train(e, n, h,f, lrs)\n",
    "            \n",
    "        dict1 = {}\n",
    "        dict1_ = {}\n",
    "        dict2 = []\n",
    "        for k, (v1, v2) in Train.predictions.items():\n",
    "            dict1.update({k: v1})\n",
    "            dict2.append(v2)\n",
    "\n",
    "        for k, (v1_, v2) in Train.predictions.items():\n",
    "            dict1_.update({k: v1_})\n",
    "\n",
    "            \n",
    "        Train.predictions = dict1\n",
    "        Train.predictions_ = dict1_\n",
    "\n",
    "        Train.results = dict2\n",
    "        df_results = pd.DataFrame(Train.results)\n",
    "        temp = df_results.set_index(['no_of_features', 'hidden_layers'])\n",
    "\n",
    "        if not os.path.isfile('dataset/scores/tf_lstm_nsl_kdd-orig_all-.pkl'):\n",
    "            past_scores = temp\n",
    "        else:\n",
    "            past_scores = pd.read_pickle(\"dataset/scores/tf_lstm_nsl_kdd-orig_all-.pkl\")\n",
    "\n",
    "        past_scores.append(temp).to_pickle(\"dataset/scores/tf_lstm_nsl_kdd-orig_all-.pkl\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-07-17T21:26:37.222020Z",
     "start_time": "2017-07-17T21:10:50.058060Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current Layer Attributes - epochs:10 hidden layers:1 features count:1\n",
      "Initial Accuracy, before training: 0.6701561212539673\n",
      "Step 1 | Training Loss: 0.003627 | Train Accuracy: 0.989683 | Test Accuracy: 0.798882, 0.617384\n",
      "Step 2 | Training Loss: 0.002081 | Train Accuracy: 0.998810 | Test Accuracy: 0.827670, 0.672152\n",
      "Step 3 | Training Loss: 0.002216 | Train Accuracy: 1.000000 | Test Accuracy: 0.848164, 0.711139\n",
      "Step 4 | Training Loss: 0.001697 | Train Accuracy: 1.000000 | Test Accuracy: 0.878815, 0.769451\n",
      "Step 5 | Training Loss: 0.002121 | Train Accuracy: 1.000000 | Test Accuracy: 0.888041, 0.787004\n",
      "Step 6 | Training Loss: 0.000990 | Train Accuracy: 1.000000 | Test Accuracy: 0.899175, 0.808186\n",
      "Step 7 | Training Loss: 0.001240 | Train Accuracy: 1.000000 | Test Accuracy: 0.882275, 0.776034\n",
      "Step 8 | Training Loss: 0.001218 | Train Accuracy: 1.000000 | Test Accuracy: 0.878194, 0.768270\n",
      "Step 9 | Training Loss: 0.001478 | Train Accuracy: 1.000000 | Test Accuracy: 0.896026, 0.802194\n",
      "Step 10 | Training Loss: 0.000993 | Train Accuracy: 1.000000 | Test Accuracy: 0.885291, 0.781772\n",
      "Step 1 | Training Loss: 0.001444 | Train Accuracy: 1.000000 | Test Accuracy: 0.881831, 0.775190\n",
      "Step 2 | Training Loss: 0.001178 | Train Accuracy: 1.000000 | Test Accuracy: 0.880855, 0.773333\n",
      "Step 3 | Training Loss: 0.000931 | Train Accuracy: 1.000000 | Test Accuracy: 0.880767, 0.773165\n",
      "Step 4 | Training Loss: 0.000941 | Train Accuracy: 1.000000 | Test Accuracy: 0.880545, 0.772743\n",
      "Step 5 | Training Loss: 0.000933 | Train Accuracy: 1.000000 | Test Accuracy: 0.881875, 0.775274\n",
      "Step 6 | Training Loss: 0.000681 | Train Accuracy: 1.000000 | Test Accuracy: 0.882275, 0.776034\n",
      "Step 7 | Training Loss: 0.001448 | Train Accuracy: 1.000000 | Test Accuracy: 0.883295, 0.777975\n",
      "Step 8 | Training Loss: 0.001443 | Train Accuracy: 1.000000 | Test Accuracy: 0.882319, 0.776118\n",
      "Step 9 | Training Loss: 0.001438 | Train Accuracy: 1.000000 | Test Accuracy: 0.881654, 0.774852\n",
      "Step 10 | Training Loss: 0.001439 | Train Accuracy: 1.000000 | Test Accuracy: 0.880589, 0.772827\n",
      "Current Layer Attributes - epochs:10 hidden layers:3 features count:1\n",
      "Initial Accuracy, before training: 0.25665366649627686\n",
      "Step 1 | Training Loss: 0.017658 | Train Accuracy: 0.972222 | Test Accuracy: 0.753504, 0.532236\n",
      "Step 2 | Training Loss: 0.001147 | Train Accuracy: 0.994444 | Test Accuracy: 0.944109, 0.894937\n",
      "Step 3 | Training Loss: 0.000658 | Train Accuracy: 0.999206 | Test Accuracy: 0.980704, 0.963291\n",
      "Step 4 | Training Loss: 0.000655 | Train Accuracy: 0.998810 | Test Accuracy: 0.977732, 0.957637\n",
      "Step 5 | Training Loss: 0.000651 | Train Accuracy: 0.999603 | Test Accuracy: 0.972321, 0.947342\n",
      "Step 6 | Training Loss: 0.000649 | Train Accuracy: 0.999603 | Test Accuracy: 0.972321, 0.947342\n",
      "Step 7 | Training Loss: 0.000648 | Train Accuracy: 1.000000 | Test Accuracy: 0.972232, 0.947173\n",
      "Step 8 | Training Loss: 0.000648 | Train Accuracy: 0.999603 | Test Accuracy: 0.972232, 0.947173\n",
      "Step 9 | Training Loss: 0.000649 | Train Accuracy: 0.999603 | Test Accuracy: 0.972232, 0.947173\n",
      "Step 10 | Training Loss: 0.000741 | Train Accuracy: 0.999603 | Test Accuracy: 0.972232, 0.947173\n",
      "Step 1 | Training Loss: 0.000649 | Train Accuracy: 0.999603 | Test Accuracy: 0.972232, 0.947173\n",
      "Step 2 | Training Loss: 0.000648 | Train Accuracy: 0.999206 | Test Accuracy: 0.972232, 0.947173\n",
      "Step 3 | Training Loss: 0.000648 | Train Accuracy: 1.000000 | Test Accuracy: 0.972232, 0.947173\n",
      "Step 4 | Training Loss: 0.000648 | Train Accuracy: 0.999603 | Test Accuracy: 0.972232, 0.947173\n",
      "Step 5 | Training Loss: 0.000648 | Train Accuracy: 0.999603 | Test Accuracy: 0.972232, 0.947173\n",
      "Step 6 | Training Loss: 0.000648 | Train Accuracy: 1.000000 | Test Accuracy: 0.972232, 0.947173\n",
      "Step 7 | Training Loss: 0.000647 | Train Accuracy: 1.000000 | Test Accuracy: 0.972232, 0.947173\n",
      "Step 8 | Training Loss: 0.000648 | Train Accuracy: 0.999206 | Test Accuracy: 0.972232, 0.947173\n",
      "Step 9 | Training Loss: 0.000648 | Train Accuracy: 1.000000 | Test Accuracy: 0.972188, 0.947089\n",
      "Step 10 | Training Loss: 0.000647 | Train Accuracy: 0.999206 | Test Accuracy: 0.972188, 0.947089\n",
      "Current Layer Attributes - epochs:10 hidden layers:1 features count:1\n",
      "Initial Accuracy, before training: 0.4508516788482666\n",
      "Step 1 | Training Loss: 0.015704 | Train Accuracy: 0.994048 | Test Accuracy: 0.790853, 0.602110\n",
      "Step 2 | Training Loss: 0.002314 | Train Accuracy: 0.998810 | Test Accuracy: 0.858854, 0.731477\n",
      "Step 3 | Training Loss: 0.002806 | Train Accuracy: 0.999603 | Test Accuracy: 0.894340, 0.798987\n",
      "Step 4 | Training Loss: 0.002027 | Train Accuracy: 1.000000 | Test Accuracy: 0.877395, 0.766751\n",
      "Step 5 | Training Loss: 0.001735 | Train Accuracy: 1.000000 | Test Accuracy: 0.897933, 0.805823\n",
      "Step 6 | Training Loss: 0.000957 | Train Accuracy: 1.000000 | Test Accuracy: 0.890747, 0.792152\n",
      "Step 7 | Training Loss: 0.000970 | Train Accuracy: 1.000000 | Test Accuracy: 0.882630, 0.776709\n",
      "Step 8 | Training Loss: 0.002257 | Train Accuracy: 1.000000 | Test Accuracy: 0.897001, 0.804051\n",
      "Step 9 | Training Loss: 0.000958 | Train Accuracy: 1.000000 | Test Accuracy: 0.903167, 0.815781\n",
      "Step 10 | Training Loss: 0.001461 | Train Accuracy: 1.000000 | Test Accuracy: 0.903699, 0.816793\n",
      "Step 1 | Training Loss: 0.001454 | Train Accuracy: 1.000000 | Test Accuracy: 0.901082, 0.811814\n",
      "Step 2 | Training Loss: 0.000933 | Train Accuracy: 1.000000 | Test Accuracy: 0.899219, 0.808270\n",
      "Step 3 | Training Loss: 0.001517 | Train Accuracy: 1.000000 | Test Accuracy: 0.899131, 0.808101\n",
      "Step 4 | Training Loss: 0.000967 | Train Accuracy: 1.000000 | Test Accuracy: 0.899219, 0.808270\n",
      "Step 5 | Training Loss: 0.001197 | Train Accuracy: 1.000000 | Test Accuracy: 0.899264, 0.808354\n",
      "Step 6 | Training Loss: 0.001701 | Train Accuracy: 1.000000 | Test Accuracy: 0.899086, 0.808017\n",
      "Step 7 | Training Loss: 0.001170 | Train Accuracy: 1.000000 | Test Accuracy: 0.898909, 0.807679\n",
      "Step 8 | Training Loss: 0.000947 | Train Accuracy: 1.000000 | Test Accuracy: 0.899131, 0.808101\n",
      "Step 9 | Training Loss: 0.002089 | Train Accuracy: 1.000000 | Test Accuracy: 0.898953, 0.807764\n",
      "Step 10 | Training Loss: 0.001680 | Train Accuracy: 1.000000 | Test Accuracy: 0.898687, 0.807257\n",
      "Current Layer Attributes - epochs:10 hidden layers:3 features count:1\n",
      "Initial Accuracy, before training: 0.49024131894111633\n",
      "Step 1 | Training Loss: 0.017884 | Train Accuracy: 0.969444 | Test Accuracy: 0.733055, 0.494684\n",
      "Step 2 | Training Loss: 0.000669 | Train Accuracy: 0.999206 | Test Accuracy: 0.965312, 0.935274\n",
      "Step 3 | Training Loss: 0.000657 | Train Accuracy: 0.998413 | Test Accuracy: 0.996363, 0.994177\n",
      "Step 4 | Training Loss: 0.000673 | Train Accuracy: 1.000000 | Test Accuracy: 0.999734, 0.999494\n",
      "Step 5 | Training Loss: 0.000654 | Train Accuracy: 1.000000 | Test Accuracy: 0.999734, 0.999494\n",
      "Step 6 | Training Loss: 0.000651 | Train Accuracy: 1.000000 | Test Accuracy: 0.999734, 0.999494\n",
      "Step 7 | Training Loss: 0.000648 | Train Accuracy: 1.000000 | Test Accuracy: 0.999734, 0.999494\n",
      "Step 8 | Training Loss: 0.000648 | Train Accuracy: 1.000000 | Test Accuracy: 0.999734, 0.999494\n",
      "Step 9 | Training Loss: 0.000649 | Train Accuracy: 1.000000 | Test Accuracy: 0.999734, 0.999494\n",
      "Step 10 | Training Loss: 0.000648 | Train Accuracy: 1.000000 | Test Accuracy: 0.999734, 0.999494\n",
      "Step 1 | Training Loss: 0.000648 | Train Accuracy: 1.000000 | Test Accuracy: 0.999734, 0.999494\n",
      "Step 2 | Training Loss: 0.000648 | Train Accuracy: 1.000000 | Test Accuracy: 0.999734, 0.999494\n",
      "Step 3 | Training Loss: 0.000648 | Train Accuracy: 1.000000 | Test Accuracy: 0.999734, 0.999494\n",
      "Step 4 | Training Loss: 0.000648 | Train Accuracy: 1.000000 | Test Accuracy: 0.999734, 0.999494\n",
      "Step 5 | Training Loss: 0.000648 | Train Accuracy: 1.000000 | Test Accuracy: 0.999734, 0.999494\n",
      "Step 6 | Training Loss: 0.000648 | Train Accuracy: 1.000000 | Test Accuracy: 0.999734, 0.999494\n",
      "Step 7 | Training Loss: 0.000647 | Train Accuracy: 1.000000 | Test Accuracy: 0.999734, 0.999494\n",
      "Step 8 | Training Loss: 0.000648 | Train Accuracy: 1.000000 | Test Accuracy: 0.999734, 0.999494\n",
      "Step 9 | Training Loss: 0.000647 | Train Accuracy: 0.999603 | Test Accuracy: 0.999734, 0.999494\n",
      "Step 10 | Training Loss: 0.000648 | Train Accuracy: 1.000000 | Test Accuracy: 0.999734, 0.999494\n",
      "Current Layer Attributes - epochs:10 hidden layers:1 features count:1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initial Accuracy, before training: 0.3531759977340698\n",
      "Step 1 | Training Loss: 0.013891 | Train Accuracy: 0.988095 | Test Accuracy: 0.781583, 0.584473\n",
      "Step 2 | Training Loss: 0.002480 | Train Accuracy: 0.998413 | Test Accuracy: 0.837917, 0.691646\n",
      "Step 3 | Training Loss: 0.003878 | Train Accuracy: 0.999603 | Test Accuracy: 0.873181, 0.758734\n",
      "Step 4 | Training Loss: 0.001976 | Train Accuracy: 0.999603 | Test Accuracy: 0.881742, 0.775021\n",
      "Step 5 | Training Loss: 0.001798 | Train Accuracy: 1.000000 | Test Accuracy: 0.902014, 0.813586\n",
      "Step 6 | Training Loss: 0.001708 | Train Accuracy: 1.000000 | Test Accuracy: 0.916962, 0.842025\n",
      "Step 7 | Training Loss: 0.001443 | Train Accuracy: 1.000000 | Test Accuracy: 0.914434, 0.837215\n",
      "Step 8 | Training Loss: 0.002534 | Train Accuracy: 1.000000 | Test Accuracy: 0.913369, 0.835190\n",
      "Step 9 | Training Loss: 0.000698 | Train Accuracy: 1.000000 | Test Accuracy: 0.918559, 0.845063\n",
      "Step 10 | Training Loss: 0.001226 | Train Accuracy: 1.000000 | Test Accuracy: 0.915632, 0.839494\n",
      "Step 1 | Training Loss: 0.001444 | Train Accuracy: 1.000000 | Test Accuracy: 0.916563, 0.841266\n",
      "Step 2 | Training Loss: 0.001271 | Train Accuracy: 1.000000 | Test Accuracy: 0.917229, 0.842532\n",
      "Step 3 | Training Loss: 0.001231 | Train Accuracy: 1.000000 | Test Accuracy: 0.917273, 0.842616\n",
      "Step 4 | Training Loss: 0.000934 | Train Accuracy: 1.000000 | Test Accuracy: 0.916785, 0.841688\n",
      "Step 5 | Training Loss: 0.000682 | Train Accuracy: 1.000000 | Test Accuracy: 0.917095, 0.842278\n",
      "Step 6 | Training Loss: 0.001467 | Train Accuracy: 1.000000 | Test Accuracy: 0.917450, 0.842954\n",
      "Step 7 | Training Loss: 0.001932 | Train Accuracy: 1.000000 | Test Accuracy: 0.917450, 0.842954\n",
      "Step 8 | Training Loss: 0.001436 | Train Accuracy: 1.000000 | Test Accuracy: 0.916652, 0.841435\n",
      "Step 9 | Training Loss: 0.000921 | Train Accuracy: 1.000000 | Test Accuracy: 0.916962, 0.842025\n",
      "Step 10 | Training Loss: 0.001422 | Train Accuracy: 1.000000 | Test Accuracy: 0.917317, 0.842700\n",
      "Current Layer Attributes - epochs:10 hidden layers:3 features count:1\n",
      "Initial Accuracy, before training: 0.6807132959365845\n",
      "Step 1 | Training Loss: 0.009261 | Train Accuracy: 1.000000 | Test Accuracy: 0.980882, 0.963629\n",
      "Step 2 | Training Loss: 0.000662 | Train Accuracy: 1.000000 | Test Accuracy: 0.999734, 0.999494\n",
      "Step 3 | Training Loss: 0.000650 | Train Accuracy: 1.000000 | Test Accuracy: 0.999690, 0.999409\n",
      "Step 4 | Training Loss: 0.000649 | Train Accuracy: 1.000000 | Test Accuracy: 0.999690, 0.999409\n",
      "Step 5 | Training Loss: 0.000649 | Train Accuracy: 1.000000 | Test Accuracy: 0.999645, 0.999325\n",
      "Step 6 | Training Loss: 0.000648 | Train Accuracy: 1.000000 | Test Accuracy: 0.999734, 0.999494\n",
      "Step 7 | Training Loss: 0.000648 | Train Accuracy: 1.000000 | Test Accuracy: 0.999734, 0.999494\n",
      "Step 8 | Training Loss: 0.000649 | Train Accuracy: 1.000000 | Test Accuracy: 0.999690, 0.999409\n",
      "Step 9 | Training Loss: 0.000648 | Train Accuracy: 1.000000 | Test Accuracy: 0.999690, 0.999409\n",
      "Step 10 | Training Loss: 0.000647 | Train Accuracy: 1.000000 | Test Accuracy: 0.999645, 0.999325\n",
      "Step 1 | Training Loss: 0.000648 | Train Accuracy: 1.000000 | Test Accuracy: 0.999645, 0.999325\n",
      "Step 2 | Training Loss: 0.000648 | Train Accuracy: 1.000000 | Test Accuracy: 0.999645, 0.999325\n",
      "Step 3 | Training Loss: 0.000647 | Train Accuracy: 1.000000 | Test Accuracy: 0.999645, 0.999325\n",
      "Step 4 | Training Loss: 0.000647 | Train Accuracy: 1.000000 | Test Accuracy: 0.999645, 0.999325\n",
      "Step 5 | Training Loss: 0.000647 | Train Accuracy: 1.000000 | Test Accuracy: 0.999645, 0.999325\n",
      "Step 6 | Training Loss: 0.000647 | Train Accuracy: 1.000000 | Test Accuracy: 0.999645, 0.999325\n",
      "Step 7 | Training Loss: 0.000647 | Train Accuracy: 1.000000 | Test Accuracy: 0.999645, 0.999325\n",
      "Step 8 | Training Loss: 0.000647 | Train Accuracy: 1.000000 | Test Accuracy: 0.999645, 0.999325\n",
      "Step 9 | Training Loss: 0.000647 | Train Accuracy: 1.000000 | Test Accuracy: 0.999601, 0.999241\n",
      "Step 10 | Training Loss: 0.000647 | Train Accuracy: 1.000000 | Test Accuracy: 0.999601, 0.999241\n",
      "Current Layer Attributes - epochs:10 hidden layers:1 features count:1\n",
      "Initial Accuracy, before training: 0.7830908298492432\n",
      "Step 1 | Training Loss: 0.006651 | Train Accuracy: 0.994841 | Test Accuracy: 0.786373, 0.593587\n",
      "Step 2 | Training Loss: 0.002085 | Train Accuracy: 0.998810 | Test Accuracy: 0.845059, 0.705232\n",
      "Step 3 | Training Loss: 0.001966 | Train Accuracy: 0.999206 | Test Accuracy: 0.847809, 0.710464\n",
      "Step 4 | Training Loss: 0.001298 | Train Accuracy: 0.999603 | Test Accuracy: 0.848873, 0.712489\n",
      "Step 5 | Training Loss: 0.000762 | Train Accuracy: 1.000000 | Test Accuracy: 0.892787, 0.796034\n",
      "Step 6 | Training Loss: 0.000973 | Train Accuracy: 1.000000 | Test Accuracy: 0.895360, 0.800928\n",
      "Step 7 | Training Loss: 0.001050 | Train Accuracy: 1.000000 | Test Accuracy: 0.885025, 0.781266\n",
      "Step 8 | Training Loss: 0.002224 | Train Accuracy: 1.000000 | Test Accuracy: 0.897667, 0.805316\n",
      "Step 9 | Training Loss: 0.001649 | Train Accuracy: 1.000000 | Test Accuracy: 0.896159, 0.802447\n",
      "Step 10 | Training Loss: 0.002247 | Train Accuracy: 1.000000 | Test Accuracy: 0.895804, 0.801772\n",
      "Step 1 | Training Loss: 0.001003 | Train Accuracy: 1.000000 | Test Accuracy: 0.895937, 0.802025\n",
      "Step 2 | Training Loss: 0.001737 | Train Accuracy: 1.000000 | Test Accuracy: 0.896114, 0.802363\n",
      "Step 3 | Training Loss: 0.001464 | Train Accuracy: 1.000000 | Test Accuracy: 0.896203, 0.802532\n",
      "Step 4 | Training Loss: 0.000709 | Train Accuracy: 0.999603 | Test Accuracy: 0.896380, 0.802869\n",
      "Step 5 | Training Loss: 0.001735 | Train Accuracy: 0.999603 | Test Accuracy: 0.895626, 0.801435\n",
      "Step 6 | Training Loss: 0.001953 | Train Accuracy: 0.999603 | Test Accuracy: 0.895493, 0.801181\n",
      "Step 7 | Training Loss: 0.001194 | Train Accuracy: 1.000000 | Test Accuracy: 0.895671, 0.801519\n",
      "Step 8 | Training Loss: 0.001679 | Train Accuracy: 1.000000 | Test Accuracy: 0.895626, 0.801435\n",
      "Step 9 | Training Loss: 0.000932 | Train Accuracy: 1.000000 | Test Accuracy: 0.895937, 0.802025\n",
      "Step 10 | Training Loss: 0.001234 | Train Accuracy: 1.000000 | Test Accuracy: 0.895582, 0.801350\n",
      "Current Layer Attributes - epochs:10 hidden layers:3 features count:1\n",
      "Initial Accuracy, before training: 0.5727022886276245\n",
      "Step 1 | Training Loss: 0.015209 | Train Accuracy: 0.975397 | Test Accuracy: 0.738378, 0.502616\n",
      "Step 2 | Training Loss: 0.009214 | Train Accuracy: 0.999206 | Test Accuracy: 0.972055, 0.947173\n",
      "Step 3 | Training Loss: 0.009185 | Train Accuracy: 1.000000 | Test Accuracy: 0.973785, 0.950127\n",
      "Step 4 | Training Loss: 0.000650 | Train Accuracy: 1.000000 | Test Accuracy: 0.973829, 0.950211\n",
      "Step 5 | Training Loss: 0.000649 | Train Accuracy: 1.000000 | Test Accuracy: 0.973873, 0.950295\n",
      "Step 6 | Training Loss: 0.000653 | Train Accuracy: 1.000000 | Test Accuracy: 0.973873, 0.950295\n",
      "Step 7 | Training Loss: 0.000648 | Train Accuracy: 0.999603 | Test Accuracy: 0.974006, 0.950549\n",
      "Step 8 | Training Loss: 0.000648 | Train Accuracy: 1.000000 | Test Accuracy: 0.974627, 0.951730\n",
      "Step 9 | Training Loss: 0.000648 | Train Accuracy: 1.000000 | Test Accuracy: 0.993701, 0.988017\n",
      "Step 10 | Training Loss: 0.000649 | Train Accuracy: 1.000000 | Test Accuracy: 0.993701, 0.988017\n",
      "Step 1 | Training Loss: 0.000648 | Train Accuracy: 0.999206 | Test Accuracy: 0.993701, 0.988017\n",
      "Step 2 | Training Loss: 0.000893 | Train Accuracy: 1.000000 | Test Accuracy: 0.994588, 0.989705\n",
      "Step 3 | Training Loss: 0.000648 | Train Accuracy: 1.000000 | Test Accuracy: 0.994633, 0.989789\n",
      "Step 4 | Training Loss: 0.000648 | Train Accuracy: 0.999603 | Test Accuracy: 0.994633, 0.989789\n",
      "Step 5 | Training Loss: 0.000648 | Train Accuracy: 1.000000 | Test Accuracy: 0.994633, 0.989789\n",
      "Step 6 | Training Loss: 0.000648 | Train Accuracy: 1.000000 | Test Accuracy: 0.994633, 0.989789\n",
      "Step 7 | Training Loss: 0.000647 | Train Accuracy: 1.000000 | Test Accuracy: 0.994633, 0.989789\n",
      "Step 8 | Training Loss: 0.000647 | Train Accuracy: 0.999603 | Test Accuracy: 0.994633, 0.989789\n",
      "Step 9 | Training Loss: 0.000648 | Train Accuracy: 1.000000 | Test Accuracy: 0.994633, 0.989789\n",
      "Step 10 | Training Loss: 0.000648 | Train Accuracy: 1.000000 | Test Accuracy: 0.994633, 0.989789\n",
      "Current Layer Attributes - epochs:10 hidden layers:1 features count:1\n",
      "Initial Accuracy, before training: 0.6369765996932983\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 1 | Training Loss: 0.014180 | Train Accuracy: 0.992063 | Test Accuracy: 0.781849, 0.584979\n",
      "Step 2 | Training Loss: 0.003658 | Train Accuracy: 1.000000 | Test Accuracy: 0.860406, 0.734430\n",
      "Step 3 | Training Loss: 0.001256 | Train Accuracy: 0.999206 | Test Accuracy: 0.893009, 0.796456\n",
      "Step 4 | Training Loss: 0.001298 | Train Accuracy: 1.000000 | Test Accuracy: 0.896780, 0.803629\n",
      "Step 5 | Training Loss: 0.001283 | Train Accuracy: 1.000000 | Test Accuracy: 0.892965, 0.796371\n",
      "Step 6 | Training Loss: 0.002811 | Train Accuracy: 1.000000 | Test Accuracy: 0.906450, 0.822025\n",
      "Step 7 | Training Loss: 0.001033 | Train Accuracy: 1.000000 | Test Accuracy: 0.899441, 0.808692\n",
      "Step 8 | Training Loss: 0.000738 | Train Accuracy: 1.000000 | Test Accuracy: 0.897534, 0.805063\n",
      "Step 9 | Training Loss: 0.000968 | Train Accuracy: 1.000000 | Test Accuracy: 0.898421, 0.806751\n",
      "Step 10 | Training Loss: 0.001177 | Train Accuracy: 1.000000 | Test Accuracy: 0.898953, 0.807764\n",
      "Step 1 | Training Loss: 0.000692 | Train Accuracy: 1.000000 | Test Accuracy: 0.900772, 0.811224\n",
      "Step 2 | Training Loss: 0.001188 | Train Accuracy: 1.000000 | Test Accuracy: 0.900106, 0.809958\n",
      "Step 3 | Training Loss: 0.000931 | Train Accuracy: 1.000000 | Test Accuracy: 0.900062, 0.809873\n",
      "Step 4 | Training Loss: 0.001428 | Train Accuracy: 1.000000 | Test Accuracy: 0.900328, 0.810380\n",
      "Step 5 | Training Loss: 0.000930 | Train Accuracy: 1.000000 | Test Accuracy: 0.899574, 0.808945\n",
      "Step 6 | Training Loss: 0.001666 | Train Accuracy: 1.000000 | Test Accuracy: 0.899397, 0.808608\n",
      "Step 7 | Training Loss: 0.000931 | Train Accuracy: 1.000000 | Test Accuracy: 0.898998, 0.807848\n",
      "Step 8 | Training Loss: 0.001689 | Train Accuracy: 1.000000 | Test Accuracy: 0.899175, 0.808186\n",
      "Step 9 | Training Loss: 0.000920 | Train Accuracy: 1.000000 | Test Accuracy: 0.899042, 0.807932\n",
      "Step 10 | Training Loss: 0.000682 | Train Accuracy: 1.000000 | Test Accuracy: 0.898199, 0.806329\n",
      "Current Layer Attributes - epochs:10 hidden layers:3 features count:1\n",
      "Initial Accuracy, before training: 0.2316802740097046\n",
      "Step 1 | Training Loss: 0.009085 | Train Accuracy: 0.994841 | Test Accuracy: 0.911018, 0.831899\n",
      "Step 2 | Training Loss: 0.000663 | Train Accuracy: 1.000000 | Test Accuracy: 0.998270, 0.996709\n",
      "Step 3 | Training Loss: 0.000650 | Train Accuracy: 1.000000 | Test Accuracy: 0.998891, 0.997890\n",
      "Step 4 | Training Loss: 0.000649 | Train Accuracy: 1.000000 | Test Accuracy: 0.999290, 0.998650\n",
      "Step 5 | Training Loss: 0.000649 | Train Accuracy: 1.000000 | Test Accuracy: 0.998980, 0.998059\n",
      "Step 6 | Training Loss: 0.000649 | Train Accuracy: 0.999603 | Test Accuracy: 0.998891, 0.997890\n",
      "Step 7 | Training Loss: 0.000648 | Train Accuracy: 0.999603 | Test Accuracy: 0.998891, 0.997890\n",
      "Step 8 | Training Loss: 0.000648 | Train Accuracy: 1.000000 | Test Accuracy: 0.998891, 0.997890\n",
      "Step 9 | Training Loss: 0.000648 | Train Accuracy: 1.000000 | Test Accuracy: 0.998891, 0.997890\n",
      "Step 10 | Training Loss: 0.000648 | Train Accuracy: 1.000000 | Test Accuracy: 0.998891, 0.997890\n",
      "Step 1 | Training Loss: 0.000648 | Train Accuracy: 1.000000 | Test Accuracy: 0.998891, 0.997890\n",
      "Step 2 | Training Loss: 0.000647 | Train Accuracy: 1.000000 | Test Accuracy: 0.998891, 0.997890\n",
      "Step 3 | Training Loss: 0.000647 | Train Accuracy: 1.000000 | Test Accuracy: 0.998891, 0.997890\n",
      "Step 4 | Training Loss: 0.000648 | Train Accuracy: 1.000000 | Test Accuracy: 0.998891, 0.997890\n",
      "Step 5 | Training Loss: 0.000647 | Train Accuracy: 1.000000 | Test Accuracy: 0.999202, 0.998481\n",
      "Step 6 | Training Loss: 0.000647 | Train Accuracy: 1.000000 | Test Accuracy: 0.999202, 0.998481\n",
      "Step 7 | Training Loss: 0.000647 | Train Accuracy: 1.000000 | Test Accuracy: 0.999202, 0.998481\n",
      "Step 8 | Training Loss: 0.000647 | Train Accuracy: 1.000000 | Test Accuracy: 0.999202, 0.998481\n",
      "Step 9 | Training Loss: 0.000647 | Train Accuracy: 1.000000 | Test Accuracy: 0.999202, 0.998481\n",
      "Step 10 | Training Loss: 0.000647 | Train Accuracy: 1.000000 | Test Accuracy: 0.999202, 0.998481\n",
      "Current Layer Attributes - epochs:10 hidden layers:1 features count:1\n",
      "Initial Accuracy, before training: 0.38103264570236206\n",
      "Step 1 | Training Loss: 0.020186 | Train Accuracy: 0.990476 | Test Accuracy: 0.788502, 0.597637\n",
      "Step 2 | Training Loss: 0.002459 | Train Accuracy: 0.998016 | Test Accuracy: 0.832683, 0.681688\n",
      "Step 3 | Training Loss: 0.002184 | Train Accuracy: 0.999603 | Test Accuracy: 0.844482, 0.704135\n",
      "Step 4 | Training Loss: 0.001779 | Train Accuracy: 0.999603 | Test Accuracy: 0.858455, 0.730717\n",
      "Step 5 | Training Loss: 0.002022 | Train Accuracy: 1.000000 | Test Accuracy: 0.876242, 0.764557\n",
      "Step 6 | Training Loss: 0.001571 | Train Accuracy: 1.000000 | Test Accuracy: 0.898421, 0.806751\n",
      "Step 7 | Training Loss: 0.000740 | Train Accuracy: 1.000000 | Test Accuracy: 0.899574, 0.808945\n",
      "Step 8 | Training Loss: 0.001994 | Train Accuracy: 1.000000 | Test Accuracy: 0.888174, 0.787257\n",
      "Step 9 | Training Loss: 0.001224 | Train Accuracy: 1.000000 | Test Accuracy: 0.895138, 0.800506\n",
      "Step 10 | Training Loss: 0.000931 | Train Accuracy: 0.999603 | Test Accuracy: 0.897090, 0.804219\n",
      "Step 1 | Training Loss: 0.001501 | Train Accuracy: 1.000000 | Test Accuracy: 0.895360, 0.800928\n",
      "Step 2 | Training Loss: 0.000960 | Train Accuracy: 1.000000 | Test Accuracy: 0.895005, 0.800253\n",
      "Step 3 | Training Loss: 0.000675 | Train Accuracy: 1.000000 | Test Accuracy: 0.895538, 0.801266\n",
      "Step 4 | Training Loss: 0.001167 | Train Accuracy: 1.000000 | Test Accuracy: 0.894784, 0.799831\n",
      "Step 5 | Training Loss: 0.001953 | Train Accuracy: 1.000000 | Test Accuracy: 0.894739, 0.799747\n",
      "Step 6 | Training Loss: 0.000690 | Train Accuracy: 1.000000 | Test Accuracy: 0.894872, 0.800000\n",
      "Step 7 | Training Loss: 0.001277 | Train Accuracy: 0.999603 | Test Accuracy: 0.894473, 0.799241\n",
      "Step 8 | Training Loss: 0.001815 | Train Accuracy: 1.000000 | Test Accuracy: 0.894606, 0.799494\n",
      "Step 9 | Training Loss: 0.000668 | Train Accuracy: 1.000000 | Test Accuracy: 0.894784, 0.799831\n",
      "Step 10 | Training Loss: 0.001214 | Train Accuracy: 1.000000 | Test Accuracy: 0.894029, 0.798397\n",
      "Current Layer Attributes - epochs:10 hidden layers:3 features count:1\n",
      "Initial Accuracy, before training: 0.7723562717437744\n",
      "Step 1 | Training Loss: 0.009570 | Train Accuracy: 0.963095 | Test Accuracy: 0.788236, 0.598903\n",
      "Step 2 | Training Loss: 0.000685 | Train Accuracy: 1.000000 | Test Accuracy: 0.986870, 0.975021\n",
      "Step 3 | Training Loss: 0.000653 | Train Accuracy: 1.000000 | Test Accuracy: 0.986914, 0.975105\n",
      "Step 4 | Training Loss: 0.000650 | Train Accuracy: 1.000000 | Test Accuracy: 0.986826, 0.974937\n",
      "Step 5 | Training Loss: 0.000649 | Train Accuracy: 1.000000 | Test Accuracy: 0.986826, 0.974937\n",
      "Step 6 | Training Loss: 0.000648 | Train Accuracy: 1.000000 | Test Accuracy: 0.986826, 0.974937\n",
      "Step 7 | Training Loss: 0.000648 | Train Accuracy: 1.000000 | Test Accuracy: 0.986826, 0.974937\n",
      "Step 8 | Training Loss: 0.000648 | Train Accuracy: 1.000000 | Test Accuracy: 0.986781, 0.974852\n",
      "Step 9 | Training Loss: 0.000647 | Train Accuracy: 1.000000 | Test Accuracy: 0.986781, 0.974852\n",
      "Step 10 | Training Loss: 0.000648 | Train Accuracy: 1.000000 | Test Accuracy: 0.986781, 0.974852\n",
      "Step 1 | Training Loss: 0.000648 | Train Accuracy: 1.000000 | Test Accuracy: 0.986781, 0.974852\n",
      "Step 2 | Training Loss: 0.000647 | Train Accuracy: 1.000000 | Test Accuracy: 0.986781, 0.974852\n",
      "Step 3 | Training Loss: 0.000649 | Train Accuracy: 1.000000 | Test Accuracy: 0.986781, 0.974852\n",
      "Step 4 | Training Loss: 0.000648 | Train Accuracy: 1.000000 | Test Accuracy: 0.986781, 0.974852\n",
      "Step 5 | Training Loss: 0.000648 | Train Accuracy: 1.000000 | Test Accuracy: 0.986781, 0.974852\n",
      "Step 6 | Training Loss: 0.000647 | Train Accuracy: 1.000000 | Test Accuracy: 0.986781, 0.974852\n",
      "Step 7 | Training Loss: 0.000647 | Train Accuracy: 1.000000 | Test Accuracy: 0.986737, 0.974768\n",
      "Step 8 | Training Loss: 0.000648 | Train Accuracy: 1.000000 | Test Accuracy: 0.986737, 0.974768\n",
      "Step 9 | Training Loss: 0.000647 | Train Accuracy: 1.000000 | Test Accuracy: 0.986737, 0.974768\n",
      "Step 10 | Training Loss: 0.000647 | Train Accuracy: 1.000000 | Test Accuracy: 0.986737, 0.974768\n",
      "Current Layer Attributes - epochs:10 hidden layers:1 features count:1\n",
      "Initial Accuracy, before training: 0.5839247703552246\n",
      "Step 1 | Training Loss: 0.006637 | Train Accuracy: 0.989286 | Test Accuracy: 0.774574, 0.571139\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 2 | Training Loss: 0.002226 | Train Accuracy: 0.997222 | Test Accuracy: 0.829090, 0.674852\n",
      "Step 3 | Training Loss: 0.001995 | Train Accuracy: 0.997619 | Test Accuracy: 0.838760, 0.693249\n",
      "Step 4 | Training Loss: 0.004410 | Train Accuracy: 0.998413 | Test Accuracy: 0.845813, 0.706667\n",
      "Step 5 | Training Loss: 0.002442 | Train Accuracy: 0.999206 | Test Accuracy: 0.860140, 0.733924\n",
      "Step 6 | Training Loss: 0.002720 | Train Accuracy: 0.999603 | Test Accuracy: 0.862092, 0.737637\n",
      "Step 7 | Training Loss: 0.001091 | Train Accuracy: 1.000000 | Test Accuracy: 0.866661, 0.746329\n",
      "Step 8 | Training Loss: 0.001547 | Train Accuracy: 1.000000 | Test Accuracy: 0.891501, 0.793586\n",
      "Step 9 | Training Loss: 0.001018 | Train Accuracy: 1.000000 | Test Accuracy: 0.886844, 0.784726\n",
      "Step 10 | Training Loss: 0.001457 | Train Accuracy: 1.000000 | Test Accuracy: 0.890836, 0.792321\n",
      "Step 1 | Training Loss: 0.001209 | Train Accuracy: 1.000000 | Test Accuracy: 0.882984, 0.777384\n",
      "Step 2 | Training Loss: 0.000964 | Train Accuracy: 1.000000 | Test Accuracy: 0.882585, 0.776625\n",
      "Step 3 | Training Loss: 0.002017 | Train Accuracy: 1.000000 | Test Accuracy: 0.882319, 0.776118\n",
      "Step 4 | Training Loss: 0.001581 | Train Accuracy: 1.000000 | Test Accuracy: 0.882230, 0.775949\n",
      "Step 5 | Training Loss: 0.002238 | Train Accuracy: 1.000000 | Test Accuracy: 0.882142, 0.775781\n",
      "Step 6 | Training Loss: 0.001441 | Train Accuracy: 1.000000 | Test Accuracy: 0.881476, 0.774515\n",
      "Step 7 | Training Loss: 0.001157 | Train Accuracy: 1.000000 | Test Accuracy: 0.881299, 0.774177\n",
      "Step 8 | Training Loss: 0.001207 | Train Accuracy: 1.000000 | Test Accuracy: 0.880767, 0.773165\n",
      "Step 9 | Training Loss: 0.000672 | Train Accuracy: 1.000000 | Test Accuracy: 0.880545, 0.772743\n",
      "Step 10 | Training Loss: 0.001992 | Train Accuracy: 1.000000 | Test Accuracy: 0.879391, 0.770549\n",
      "Current Layer Attributes - epochs:10 hidden layers:3 features count:1\n",
      "Initial Accuracy, before training: 0.3321504592895508\n",
      "Step 1 | Training Loss: 0.009805 | Train Accuracy: 0.982937 | Test Accuracy: 0.759404, 0.542447\n",
      "Step 2 | Training Loss: 0.000684 | Train Accuracy: 1.000000 | Test Accuracy: 0.976579, 0.955443\n",
      "Step 3 | Training Loss: 0.000651 | Train Accuracy: 1.000000 | Test Accuracy: 0.968861, 0.940759\n",
      "Step 4 | Training Loss: 0.000650 | Train Accuracy: 1.000000 | Test Accuracy: 0.967486, 0.938143\n",
      "Step 5 | Training Loss: 0.000649 | Train Accuracy: 1.000000 | Test Accuracy: 0.966909, 0.937046\n",
      "Step 6 | Training Loss: 0.000649 | Train Accuracy: 0.999603 | Test Accuracy: 0.966820, 0.936878\n",
      "Step 7 | Training Loss: 0.000649 | Train Accuracy: 0.999603 | Test Accuracy: 0.966554, 0.936371\n",
      "Step 8 | Training Loss: 0.000648 | Train Accuracy: 1.000000 | Test Accuracy: 0.966111, 0.935527\n",
      "Step 9 | Training Loss: 0.000651 | Train Accuracy: 1.000000 | Test Accuracy: 0.966111, 0.935527\n",
      "Step 10 | Training Loss: 0.000648 | Train Accuracy: 1.000000 | Test Accuracy: 0.966066, 0.935443\n",
      "Step 1 | Training Loss: 0.000648 | Train Accuracy: 1.000000 | Test Accuracy: 0.965978, 0.935274\n",
      "Step 2 | Training Loss: 0.000647 | Train Accuracy: 1.000000 | Test Accuracy: 0.965978, 0.935274\n",
      "Step 3 | Training Loss: 0.000648 | Train Accuracy: 1.000000 | Test Accuracy: 0.966022, 0.935359\n",
      "Step 4 | Training Loss: 0.000648 | Train Accuracy: 1.000000 | Test Accuracy: 0.966022, 0.935359\n",
      "Step 5 | Training Loss: 0.000648 | Train Accuracy: 1.000000 | Test Accuracy: 0.966022, 0.935359\n",
      "Step 6 | Training Loss: 0.000648 | Train Accuracy: 1.000000 | Test Accuracy: 0.966022, 0.935359\n",
      "Step 7 | Training Loss: 0.000647 | Train Accuracy: 1.000000 | Test Accuracy: 0.966022, 0.935359\n",
      "Step 8 | Training Loss: 0.000647 | Train Accuracy: 1.000000 | Test Accuracy: 0.966022, 0.935359\n",
      "Step 9 | Training Loss: 0.000648 | Train Accuracy: 1.000000 | Test Accuracy: 0.966022, 0.935359\n",
      "Step 10 | Training Loss: 0.000647 | Train Accuracy: 1.000000 | Test Accuracy: 0.966022, 0.935359\n",
      "Current Layer Attributes - epochs:10 hidden layers:1 features count:1\n",
      "Initial Accuracy, before training: 0.5213360786437988\n",
      "Step 1 | Training Loss: 0.008397 | Train Accuracy: 0.988492 | Test Accuracy: 0.775151, 0.572236\n",
      "Step 2 | Training Loss: 0.002729 | Train Accuracy: 0.996825 | Test Accuracy: 0.840623, 0.696793\n",
      "Step 3 | Training Loss: 0.001459 | Train Accuracy: 0.999206 | Test Accuracy: 0.861737, 0.736962\n",
      "Step 4 | Training Loss: 0.000863 | Train Accuracy: 1.000000 | Test Accuracy: 0.886755, 0.784557\n",
      "Step 5 | Training Loss: 0.000848 | Train Accuracy: 1.000000 | Test Accuracy: 0.899707, 0.809198\n",
      "Step 6 | Training Loss: 0.002607 | Train Accuracy: 1.000000 | Test Accuracy: 0.891679, 0.793924\n",
      "Step 7 | Training Loss: 0.001719 | Train Accuracy: 1.000000 | Test Accuracy: 0.891945, 0.794430\n",
      "Step 8 | Training Loss: 0.001571 | Train Accuracy: 1.000000 | Test Accuracy: 0.891989, 0.794515\n",
      "Step 9 | Training Loss: 0.000962 | Train Accuracy: 1.000000 | Test Accuracy: 0.895848, 0.801857\n",
      "Step 10 | Training Loss: 0.000671 | Train Accuracy: 0.999603 | Test Accuracy: 0.890969, 0.792574\n",
      "Step 1 | Training Loss: 0.001175 | Train Accuracy: 0.999603 | Test Accuracy: 0.893009, 0.796456\n",
      "Step 2 | Training Loss: 0.001191 | Train Accuracy: 1.000000 | Test Accuracy: 0.893231, 0.796878\n",
      "Step 3 | Training Loss: 0.001670 | Train Accuracy: 1.000000 | Test Accuracy: 0.893719, 0.797806\n",
      "Step 4 | Training Loss: 0.001176 | Train Accuracy: 1.000000 | Test Accuracy: 0.893719, 0.797806\n",
      "Step 5 | Training Loss: 0.001485 | Train Accuracy: 1.000000 | Test Accuracy: 0.893231, 0.796878\n",
      "Step 6 | Training Loss: 0.000986 | Train Accuracy: 1.000000 | Test Accuracy: 0.893675, 0.797722\n",
      "Step 7 | Training Loss: 0.001177 | Train Accuracy: 1.000000 | Test Accuracy: 0.893408, 0.797215\n",
      "Step 8 | Training Loss: 0.001700 | Train Accuracy: 1.000000 | Test Accuracy: 0.893453, 0.797300\n",
      "Step 9 | Training Loss: 0.000941 | Train Accuracy: 1.000000 | Test Accuracy: 0.893408, 0.797215\n",
      "Step 10 | Training Loss: 0.000927 | Train Accuracy: 1.000000 | Test Accuracy: 0.892477, 0.795443\n",
      "Current Layer Attributes - epochs:10 hidden layers:3 features count:1\n",
      "Initial Accuracy, before training: 0.400771826505661\n",
      "Step 1 | Training Loss: 0.015662 | Train Accuracy: 0.967063 | Test Accuracy: 0.756654, 0.538228\n",
      "Step 2 | Training Loss: 0.029210 | Train Accuracy: 0.980556 | Test Accuracy: 0.735584, 0.497890\n",
      "Step 3 | Training Loss: 0.000701 | Train Accuracy: 0.998810 | Test Accuracy: 0.991084, 0.983122\n",
      "Step 4 | Training Loss: 0.000650 | Train Accuracy: 1.000000 | Test Accuracy: 0.960167, 0.924219\n",
      "Step 5 | Training Loss: 0.000650 | Train Accuracy: 1.000000 | Test Accuracy: 0.961320, 0.926413\n",
      "Step 6 | Training Loss: 0.000648 | Train Accuracy: 1.000000 | Test Accuracy: 0.961276, 0.926329\n",
      "Step 7 | Training Loss: 0.000648 | Train Accuracy: 1.000000 | Test Accuracy: 0.961187, 0.926160\n",
      "Step 8 | Training Loss: 0.000648 | Train Accuracy: 0.999603 | Test Accuracy: 0.961098, 0.925992\n",
      "Step 9 | Training Loss: 0.000648 | Train Accuracy: 0.999206 | Test Accuracy: 0.961098, 0.925992\n",
      "Step 10 | Training Loss: 0.000648 | Train Accuracy: 1.000000 | Test Accuracy: 0.954800, 0.914008\n",
      "Step 1 | Training Loss: 0.000647 | Train Accuracy: 1.000000 | Test Accuracy: 0.955021, 0.914430\n",
      "Step 2 | Training Loss: 0.000647 | Train Accuracy: 0.999603 | Test Accuracy: 0.955066, 0.914515\n",
      "Step 3 | Training Loss: 0.000649 | Train Accuracy: 0.999603 | Test Accuracy: 0.955110, 0.914599\n",
      "Step 4 | Training Loss: 0.000648 | Train Accuracy: 1.000000 | Test Accuracy: 0.955110, 0.914599\n",
      "Step 5 | Training Loss: 0.000647 | Train Accuracy: 0.999603 | Test Accuracy: 0.955110, 0.914599\n",
      "Step 6 | Training Loss: 0.000650 | Train Accuracy: 0.999603 | Test Accuracy: 0.955199, 0.914768\n",
      "Step 7 | Training Loss: 0.000647 | Train Accuracy: 1.000000 | Test Accuracy: 0.955199, 0.914768\n",
      "Step 8 | Training Loss: 0.000650 | Train Accuracy: 1.000000 | Test Accuracy: 0.955243, 0.914852\n",
      "Step 9 | Training Loss: 0.000647 | Train Accuracy: 1.000000 | Test Accuracy: 0.955509, 0.915359\n",
      "Step 10 | Training Loss: 0.000648 | Train Accuracy: 0.999603 | Test Accuracy: 0.959280, 0.922532\n",
      "Current Layer Attributes - epochs:10 hidden layers:1 features count:1\n",
      "Initial Accuracy, before training: 0.45879170298576355\n",
      "Step 1 | Training Loss: 0.013123 | Train Accuracy: 0.987698 | Test Accuracy: 0.774619, 0.571224\n",
      "Step 2 | Training Loss: 0.006511 | Train Accuracy: 0.997222 | Test Accuracy: 0.820174, 0.657890\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 3 | Training Loss: 0.001206 | Train Accuracy: 0.998810 | Test Accuracy: 0.871141, 0.754852\n",
      "Step 4 | Training Loss: 0.001779 | Train Accuracy: 1.000000 | Test Accuracy: 0.877484, 0.766920\n",
      "Step 5 | Training Loss: 0.000848 | Train Accuracy: 1.000000 | Test Accuracy: 0.895094, 0.800422\n",
      "Step 6 | Training Loss: 0.003481 | Train Accuracy: 1.000000 | Test Accuracy: 0.893941, 0.798228\n",
      "Step 7 | Training Loss: 0.001490 | Train Accuracy: 1.000000 | Test Accuracy: 0.895626, 0.801435\n",
      "Step 8 | Training Loss: 0.000955 | Train Accuracy: 1.000000 | Test Accuracy: 0.896602, 0.803291\n",
      "Step 9 | Training Loss: 0.001212 | Train Accuracy: 1.000000 | Test Accuracy: 0.898776, 0.807426\n",
      "Step 10 | Training Loss: 0.000701 | Train Accuracy: 1.000000 | Test Accuracy: 0.894296, 0.798903\n",
      "Step 1 | Training Loss: 0.001183 | Train Accuracy: 1.000000 | Test Accuracy: 0.893453, 0.797300\n",
      "Step 2 | Training Loss: 0.000926 | Train Accuracy: 1.000000 | Test Accuracy: 0.893142, 0.796709\n",
      "Step 3 | Training Loss: 0.001251 | Train Accuracy: 1.000000 | Test Accuracy: 0.892388, 0.795274\n",
      "Step 4 | Training Loss: 0.001215 | Train Accuracy: 1.000000 | Test Accuracy: 0.892654, 0.795781\n",
      "Step 5 | Training Loss: 0.001201 | Train Accuracy: 1.000000 | Test Accuracy: 0.892610, 0.795696\n",
      "Step 6 | Training Loss: 0.001685 | Train Accuracy: 1.000000 | Test Accuracy: 0.892122, 0.794768\n",
      "Step 7 | Training Loss: 0.002039 | Train Accuracy: 1.000000 | Test Accuracy: 0.892388, 0.795274\n",
      "Step 8 | Training Loss: 0.001700 | Train Accuracy: 1.000000 | Test Accuracy: 0.892876, 0.796203\n",
      "Step 9 | Training Loss: 0.001416 | Train Accuracy: 1.000000 | Test Accuracy: 0.891723, 0.794008\n",
      "Step 10 | Training Loss: 0.000931 | Train Accuracy: 1.000000 | Test Accuracy: 0.892433, 0.795359\n",
      "Current Layer Attributes - epochs:10 hidden layers:3 features count:1\n",
      "Initial Accuracy, before training: 0.1710432916879654\n",
      "Step 1 | Training Loss: 0.000863 | Train Accuracy: 0.998016 | Test Accuracy: 0.995121, 0.990717\n",
      "Step 2 | Training Loss: 0.000655 | Train Accuracy: 0.998413 | Test Accuracy: 0.999335, 0.998734\n",
      "Step 3 | Training Loss: 0.005003 | Train Accuracy: 0.997619 | Test Accuracy: 0.996141, 0.992827\n",
      "Step 4 | Training Loss: 0.005091 | Train Accuracy: 0.998016 | Test Accuracy: 0.999379, 0.999156\n",
      "Step 5 | Training Loss: 0.000650 | Train Accuracy: 1.000000 | Test Accuracy: 0.999379, 0.998819\n",
      "Step 6 | Training Loss: 0.000649 | Train Accuracy: 1.000000 | Test Accuracy: 0.987802, 0.976793\n",
      "Step 7 | Training Loss: 0.000649 | Train Accuracy: 0.999603 | Test Accuracy: 0.998270, 0.996709\n",
      "Step 8 | Training Loss: 0.000648 | Train Accuracy: 1.000000 | Test Accuracy: 0.995254, 0.990970\n",
      "Step 9 | Training Loss: 0.000648 | Train Accuracy: 1.000000 | Test Accuracy: 0.987402, 0.976034\n",
      "Step 10 | Training Loss: 0.000648 | Train Accuracy: 1.000000 | Test Accuracy: 0.987402, 0.976034\n",
      "Step 1 | Training Loss: 0.000648 | Train Accuracy: 1.000000 | Test Accuracy: 0.987402, 0.976034\n",
      "Step 2 | Training Loss: 0.000650 | Train Accuracy: 0.999603 | Test Accuracy: 0.987402, 0.976034\n",
      "Step 3 | Training Loss: 0.000648 | Train Accuracy: 1.000000 | Test Accuracy: 0.987402, 0.976034\n",
      "Step 4 | Training Loss: 0.000648 | Train Accuracy: 1.000000 | Test Accuracy: 0.987402, 0.976034\n",
      "Step 5 | Training Loss: 0.000650 | Train Accuracy: 1.000000 | Test Accuracy: 0.987402, 0.976034\n",
      "Step 6 | Training Loss: 0.000648 | Train Accuracy: 1.000000 | Test Accuracy: 0.987402, 0.976034\n",
      "Step 7 | Training Loss: 0.000648 | Train Accuracy: 1.000000 | Test Accuracy: 0.987402, 0.976034\n",
      "Step 8 | Training Loss: 0.000648 | Train Accuracy: 0.999603 | Test Accuracy: 0.987402, 0.976034\n",
      "Step 9 | Training Loss: 0.000648 | Train Accuracy: 1.000000 | Test Accuracy: 0.987402, 0.976034\n",
      "Step 10 | Training Loss: 0.000647 | Train Accuracy: 1.000000 | Test Accuracy: 0.987402, 0.976034\n",
      "Current Layer Attributes - epochs:10 hidden layers:1 features count:1\n",
      "Initial Accuracy, before training: 0.5808640718460083\n",
      "Step 1 | Training Loss: 0.011447 | Train Accuracy: 0.996032 | Test Accuracy: 0.810238, 0.638987\n",
      "Step 2 | Training Loss: 0.004250 | Train Accuracy: 0.998016 | Test Accuracy: 0.851801, 0.718059\n",
      "Step 3 | Training Loss: 0.002046 | Train Accuracy: 0.999206 | Test Accuracy: 0.845059, 0.705232\n",
      "Step 4 | Training Loss: 0.001804 | Train Accuracy: 1.000000 | Test Accuracy: 0.863689, 0.740675\n",
      "Step 5 | Training Loss: 0.001055 | Train Accuracy: 1.000000 | Test Accuracy: 0.883827, 0.778987\n",
      "Step 6 | Training Loss: 0.001342 | Train Accuracy: 1.000000 | Test Accuracy: 0.877484, 0.766920\n",
      "Step 7 | Training Loss: 0.001311 | Train Accuracy: 1.000000 | Test Accuracy: 0.893586, 0.797553\n",
      "Step 8 | Training Loss: 0.001254 | Train Accuracy: 1.000000 | Test Accuracy: 0.885424, 0.782025\n",
      "Step 9 | Training Loss: 0.001777 | Train Accuracy: 1.000000 | Test Accuracy: 0.884714, 0.780675\n",
      "Step 10 | Training Loss: 0.001336 | Train Accuracy: 1.000000 | Test Accuracy: 0.888973, 0.788776\n",
      "Step 1 | Training Loss: 0.000928 | Train Accuracy: 1.000000 | Test Accuracy: 0.887376, 0.785738\n",
      "Step 2 | Training Loss: 0.001185 | Train Accuracy: 1.000000 | Test Accuracy: 0.886045, 0.783207\n",
      "Step 3 | Training Loss: 0.000926 | Train Accuracy: 1.000000 | Test Accuracy: 0.886400, 0.783882\n",
      "Step 4 | Training Loss: 0.000888 | Train Accuracy: 1.000000 | Test Accuracy: 0.886533, 0.784135\n",
      "Step 5 | Training Loss: 0.001199 | Train Accuracy: 1.000000 | Test Accuracy: 0.886400, 0.783882\n",
      "Step 6 | Training Loss: 0.000936 | Train Accuracy: 1.000000 | Test Accuracy: 0.887110, 0.785232\n",
      "Step 7 | Training Loss: 0.000943 | Train Accuracy: 1.000000 | Test Accuracy: 0.886666, 0.784388\n",
      "Step 8 | Training Loss: 0.001179 | Train Accuracy: 1.000000 | Test Accuracy: 0.886932, 0.784895\n",
      "Step 9 | Training Loss: 0.001680 | Train Accuracy: 1.000000 | Test Accuracy: 0.887598, 0.786160\n",
      "Step 10 | Training Loss: 0.000925 | Train Accuracy: 1.000000 | Test Accuracy: 0.886444, 0.783966\n",
      "Current Layer Attributes - epochs:10 hidden layers:3 features count:1\n",
      "Initial Accuracy, before training: 0.36173704266548157\n",
      "Step 1 | Training Loss: 0.016110 | Train Accuracy: 0.982143 | Test Accuracy: 0.759936, 0.544810\n",
      "Step 2 | Training Loss: 0.000675 | Train Accuracy: 1.000000 | Test Accuracy: 0.892300, 0.795105\n",
      "Step 3 | Training Loss: 0.000652 | Train Accuracy: 1.000000 | Test Accuracy: 0.977466, 0.957131\n",
      "Step 4 | Training Loss: 0.000651 | Train Accuracy: 1.000000 | Test Accuracy: 0.997072, 0.994430\n",
      "Step 5 | Training Loss: 0.000650 | Train Accuracy: 1.000000 | Test Accuracy: 0.996673, 0.993671\n",
      "Step 6 | Training Loss: 0.000652 | Train Accuracy: 1.000000 | Test Accuracy: 0.996451, 0.993249\n",
      "Step 7 | Training Loss: 0.000648 | Train Accuracy: 1.000000 | Test Accuracy: 0.996274, 0.992911\n",
      "Step 8 | Training Loss: 0.000648 | Train Accuracy: 1.000000 | Test Accuracy: 0.996097, 0.992574\n",
      "Step 9 | Training Loss: 0.000648 | Train Accuracy: 1.000000 | Test Accuracy: 0.996097, 0.992574\n",
      "Step 10 | Training Loss: 0.000648 | Train Accuracy: 1.000000 | Test Accuracy: 0.996097, 0.992574\n",
      "Step 1 | Training Loss: 0.000648 | Train Accuracy: 1.000000 | Test Accuracy: 0.996097, 0.992574\n",
      "Step 2 | Training Loss: 0.000648 | Train Accuracy: 1.000000 | Test Accuracy: 0.996097, 0.992574\n",
      "Step 3 | Training Loss: 0.000647 | Train Accuracy: 1.000000 | Test Accuracy: 0.996097, 0.992574\n",
      "Step 4 | Training Loss: 0.000647 | Train Accuracy: 1.000000 | Test Accuracy: 0.996097, 0.992574\n",
      "Step 5 | Training Loss: 0.000647 | Train Accuracy: 1.000000 | Test Accuracy: 0.996141, 0.992658\n",
      "Step 6 | Training Loss: 0.000647 | Train Accuracy: 1.000000 | Test Accuracy: 0.996141, 0.992658\n",
      "Step 7 | Training Loss: 0.000648 | Train Accuracy: 1.000000 | Test Accuracy: 0.996185, 0.992743\n",
      "Step 8 | Training Loss: 0.000647 | Train Accuracy: 1.000000 | Test Accuracy: 0.996230, 0.992827\n",
      "Step 9 | Training Loss: 0.000648 | Train Accuracy: 1.000000 | Test Accuracy: 0.996274, 0.992911\n",
      "Step 10 | Training Loss: 0.000647 | Train Accuracy: 1.000000 | Test Accuracy: 0.996274, 0.992911\n",
      "Current Layer Attributes - epochs:10 hidden layers:1 features count:1\n",
      "Initial Accuracy, before training: 0.6264194250106812\n",
      "Step 1 | Training Loss: 0.007100 | Train Accuracy: 0.992063 | Test Accuracy: 0.776082, 0.574008\n",
      "Step 2 | Training Loss: 0.002457 | Train Accuracy: 0.999603 | Test Accuracy: 0.837207, 0.690295\n",
      "Step 3 | Training Loss: 0.002816 | Train Accuracy: 0.998810 | Test Accuracy: 0.854196, 0.722616\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 4 | Training Loss: 0.001456 | Train Accuracy: 0.999603 | Test Accuracy: 0.895360, 0.800928\n",
      "Step 5 | Training Loss: 0.000962 | Train Accuracy: 0.999603 | Test Accuracy: 0.883162, 0.777722\n",
      "Step 6 | Training Loss: 0.001419 | Train Accuracy: 0.999603 | Test Accuracy: 0.890658, 0.791983\n",
      "Step 7 | Training Loss: 0.001322 | Train Accuracy: 1.000000 | Test Accuracy: 0.892078, 0.794684\n",
      "Step 8 | Training Loss: 0.000702 | Train Accuracy: 1.000000 | Test Accuracy: 0.897844, 0.805654\n",
      "Step 9 | Training Loss: 0.001515 | Train Accuracy: 1.000000 | Test Accuracy: 0.894517, 0.799325\n",
      "Step 10 | Training Loss: 0.001324 | Train Accuracy: 1.000000 | Test Accuracy: 0.892300, 0.795105\n",
      "Step 1 | Training Loss: 0.001038 | Train Accuracy: 1.000000 | Test Accuracy: 0.891102, 0.792827\n",
      "Step 2 | Training Loss: 0.000704 | Train Accuracy: 1.000000 | Test Accuracy: 0.890924, 0.792489\n",
      "Step 3 | Training Loss: 0.000687 | Train Accuracy: 1.000000 | Test Accuracy: 0.891191, 0.792996\n",
      "Step 4 | Training Loss: 0.001183 | Train Accuracy: 1.000000 | Test Accuracy: 0.889949, 0.790633\n",
      "Step 5 | Training Loss: 0.001198 | Train Accuracy: 1.000000 | Test Accuracy: 0.890836, 0.792321\n",
      "Step 6 | Training Loss: 0.000831 | Train Accuracy: 1.000000 | Test Accuracy: 0.889328, 0.789451\n",
      "Step 7 | Training Loss: 0.000687 | Train Accuracy: 1.000000 | Test Accuracy: 0.890259, 0.791224\n",
      "Step 8 | Training Loss: 0.000690 | Train Accuracy: 1.000000 | Test Accuracy: 0.889505, 0.789789\n",
      "Step 9 | Training Loss: 0.000687 | Train Accuracy: 1.000000 | Test Accuracy: 0.889638, 0.790042\n",
      "Step 10 | Training Loss: 0.001514 | Train Accuracy: 1.000000 | Test Accuracy: 0.891634, 0.793840\n",
      "Current Layer Attributes - epochs:10 hidden layers:3 features count:1\n",
      "Initial Accuracy, before training: 0.5506564974784851\n",
      "Step 1 | Training Loss: 0.001526 | Train Accuracy: 0.996032 | Test Accuracy: 0.992548, 0.986160\n",
      "Step 2 | Training Loss: 0.000680 | Train Accuracy: 1.000000 | Test Accuracy: 0.999512, 0.999072\n",
      "Step 3 | Training Loss: 0.000651 | Train Accuracy: 1.000000 | Test Accuracy: 0.999911, 0.999831\n",
      "Step 4 | Training Loss: 0.000650 | Train Accuracy: 1.000000 | Test Accuracy: 0.999867, 0.999747\n",
      "Step 5 | Training Loss: 0.000649 | Train Accuracy: 1.000000 | Test Accuracy: 1.000000, 1.000000\n",
      "Step 6 | Training Loss: 0.000649 | Train Accuracy: 1.000000 | Test Accuracy: 1.000000, 1.000000\n",
      "Step 7 | Training Loss: 0.000648 | Train Accuracy: 1.000000 | Test Accuracy: 1.000000, 1.000000\n",
      "Step 8 | Training Loss: 0.000648 | Train Accuracy: 1.000000 | Test Accuracy: 1.000000, 1.000000\n",
      "Step 9 | Training Loss: 0.000648 | Train Accuracy: 1.000000 | Test Accuracy: 1.000000, 1.000000\n",
      "Step 10 | Training Loss: 0.000647 | Train Accuracy: 1.000000 | Test Accuracy: 1.000000, 1.000000\n",
      "Step 1 | Training Loss: 0.000647 | Train Accuracy: 1.000000 | Test Accuracy: 1.000000, 1.000000\n",
      "Step 2 | Training Loss: 0.000647 | Train Accuracy: 1.000000 | Test Accuracy: 1.000000, 1.000000\n",
      "Step 3 | Training Loss: 0.000647 | Train Accuracy: 1.000000 | Test Accuracy: 1.000000, 1.000000\n",
      "Step 4 | Training Loss: 0.000647 | Train Accuracy: 1.000000 | Test Accuracy: 1.000000, 1.000000\n",
      "Step 5 | Training Loss: 0.000648 | Train Accuracy: 1.000000 | Test Accuracy: 1.000000, 1.000000\n",
      "Step 6 | Training Loss: 0.000647 | Train Accuracy: 1.000000 | Test Accuracy: 1.000000, 1.000000\n",
      "Step 7 | Training Loss: 0.000647 | Train Accuracy: 1.000000 | Test Accuracy: 1.000000, 1.000000\n",
      "Step 8 | Training Loss: 0.000647 | Train Accuracy: 1.000000 | Test Accuracy: 1.000000, 1.000000\n",
      "Step 9 | Training Loss: 0.000648 | Train Accuracy: 1.000000 | Test Accuracy: 1.000000, 1.000000\n",
      "Step 10 | Training Loss: 0.000647 | Train Accuracy: 1.000000 | Test Accuracy: 1.000000, 1.000000\n",
      "1min 26s ± 2.28 s per loop (mean ± std. dev. of 10 runs, 1 loop each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit -r 10\n",
    "\n",
    "Hyperparameters.start_training()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-06-16T20:12:38.742950Z",
     "start_time": "2017-06-16T20:12:38.705898Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-06-16T20:12:38.748800Z",
     "start_time": "2017-06-16T20:12:38.744607Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-07-17T21:26:37.254856Z",
     "start_time": "2017-07-17T21:26:37.223976Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>epoch</th>\n",
       "      <th>no_of_features</th>\n",
       "      <th>hidden_layers</th>\n",
       "      <th>train_score</th>\n",
       "      <th>test_score</th>\n",
       "      <th>f1_score</th>\n",
       "      <th>test_score_20</th>\n",
       "      <th>f1_score_20</th>\n",
       "      <th>time_taken</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>11</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>15.237297</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   epoch  no_of_features  hidden_layers  train_score  test_score  f1_score  \\\n",
       "1     11               1              3          1.0         1.0       1.0   \n",
       "\n",
       "   test_score_20  f1_score_20  time_taken  \n",
       "1            1.0          1.0   15.237297  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "g = df_results.groupby(by=['no_of_features'])\n",
    "idx = g['test_score'].transform(max) == df_results['test_score']\n",
    "df_results[idx].sort_values(by = 'test_score', ascending = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-07-17T21:26:37.349779Z",
     "start_time": "2017-07-17T21:26:37.257289Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>epoch</th>\n",
       "      <th>no_of_features</th>\n",
       "      <th>hidden_layers</th>\n",
       "      <th>train_score</th>\n",
       "      <th>test_score</th>\n",
       "      <th>f1_score</th>\n",
       "      <th>test_score_20</th>\n",
       "      <th>f1_score_20</th>\n",
       "      <th>time_taken</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>11</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>15.237297</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>11</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.897844</td>\n",
       "      <td>0.906195</td>\n",
       "      <td>0.805654</td>\n",
       "      <td>0.874022</td>\n",
       "      <td>9.943235</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   epoch  no_of_features  hidden_layers  train_score  test_score  f1_score  \\\n",
       "1     11               1              3          1.0    1.000000  1.000000   \n",
       "0     11               1              1          1.0    0.897844  0.906195   \n",
       "\n",
       "   test_score_20  f1_score_20  time_taken  \n",
       "1       1.000000     1.000000   15.237297  \n",
       "0       0.805654     0.874022    9.943235  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_results.sort_values(by = 'test_score', ascending = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-07-17T21:26:37.470713Z",
     "start_time": "2017-07-17T21:26:37.351776Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pd.Panel(Train.predictions).to_pickle(\"dataset/tf_lstm_nsl_kdd_predictions-.pkl\")\n",
    "pd.Panel(Train.predictions_).to_pickle(\"dataset/tf_lstm_nsl_kdd_predictions-__.pkl\")\n",
    "\n",
    "df_results.to_pickle(\"dataset/tf_lstm_nsl_kdd_scores-.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-07-17T21:26:37.543605Z",
     "start_time": "2017-07-17T21:26:37.472511Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import itertools\n",
    "\n",
    "def plot_confusion_matrix(cm, classes,\n",
    "                          normalize=False,\n",
    "                          title='Confusion matrix',\n",
    "                          cmap=plt.cm.Blues):\n",
    "    \"\"\"\n",
    "    This function prints and plots the confusion matrix.\n",
    "    Normalization can be applied by setting `normalize=True`.\n",
    "    \"\"\"\n",
    "    np.set_printoptions(precision=4)\n",
    "\n",
    "    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n",
    "    plt.title(title)\n",
    "    plt.colorbar()\n",
    "    tick_marks = np.arange(len(classes))\n",
    "    plt.xticks(tick_marks, classes, rotation=45)\n",
    "    plt.yticks(tick_marks, classes)\n",
    "\n",
    "    if normalize:\n",
    "        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "        print(\"Normalized confusion matrix\")\n",
    "    else:\n",
    "        print('Confusion matrix, without normalization')\n",
    "\n",
    "    print(cm)\n",
    "\n",
    "    thresh = cm.max() / 2.\n",
    "    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
    "        plt.text(j, i, cm[i, j].round(4),\n",
    "                 horizontalalignment=\"center\",\n",
    "                 color=\"white\" if cm[i, j] > thresh else \"black\")\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.ylabel('True label')\n",
    "    plt.xlabel('Predicted label')\n",
    "\n",
    "def plot(actual_value, pred_value):\n",
    "    from sklearn.metrics import confusion_matrix\n",
    "    cm_2labels = confusion_matrix(y_pred = pred_value, y_true = actual_value)\n",
    "    plt.figure(figsize=[6,6])\n",
    "    plot_confusion_matrix(cm_2labels, preprocess.output_columns_2labels, normalize = False,\n",
    "                         title = Train.best_parameters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-07-17T21:26:38.487765Z",
     "start_time": "2017-07-17T21:26:37.545490Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion matrix, without normalization\n",
      "[[ 9711     0]\n",
      " [    0 12833]]\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAbcAAAGeCAYAAAAXNE8VAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAAIABJREFUeJzt3XmclWX9//HXG4ZVBMSFEFBcSyA3RM3KH6UpKootKuWu\nqal91cxcstL6RllZppWapoFWAmol5oJKX3MFRFxxRVEBEUEUF5Rl+Pz+uK/BwzT7nJkzc5/308d5\nzDnXvV3nMM7nfD73dd+XIgIzM7M86VDqDpiZmRWbg5uZmeWOg5uZmeWOg5uZmeWOg5uZmeWOg5uZ\nmeWOg5uZmeWOg5uZmeWOg5uZmeVORak7YGZmxdWx5+YRqz8s2v7iw8VTImJk0XbYChzczMxyJlZ/\nSJdPHlq0/X30+B82KtrOWomDm5lZ7ghU3medyvvdm5lZLjlzMzPLGwFSqXtRUg5uZmZ55LKkmZlZ\nvjhzMzPLI5clzcwsXzxasrzfvZmZ5ZIzNzOzPHJZ0szMckW4LFnqDpiZmRWbMzczs9yRy5Kl7oCZ\nmbUAlyXNzMzyxZmbmVkeuSxpZmb54ou4y/vdm5lZLjlzMzPLG0954+BmZpZLLkuamZnli4ObmVnu\npAElxXrUdzTpWklvSnq6oO1Xkp6T9KSkf0jqXbDsPElzJD0vad+C9mGSnkrLLpOy2qqkLpImpvbp\nkgbV1ycHNzOzPOqg4j3qNw4YWa3tbmBoRGwPvACcByBpMDAGGJK2uVxSx7TNFcAJwDbpUbXP44G3\nI2Jr4BLgF/W+/Yb02szMrDYRcR+wtFrbXRGxOr2cBgxIz0cDEyJiRUTMBeYAu0rqB/SMiGkREcB1\nwMEF24xPz28C9qrK6mrjASVmZnlT/FkBNpI0s+D1VRFxVSO2Pw6YmJ73Jwt2VeantlXpefX2qm3m\nAUTEaknLgA2BJbUd0MHNzCyPinspwJKI2KVp3dD5wGrgr8XsUH1cljQzsxYh6RhgFHB4KjUCLAAG\nFqw2ILUt4OPSZWH7OttIqgB6AW/VdWwHNzOz3Gnd0ZI19kAaCZwNHBQRywsWTQbGpBGQW5ANHJkR\nEQuBdyXtns6nHQXcUrDN0en514B/FwTLGrksaWZmzSLpBmAE2bm5+cAFZKMjuwB3p7Ef0yLiWxEx\nW9Ik4BmycuWpEVGZdnUK2cjLbsAd6QFwDXC9pDlkA1fG1NuneoKfmZm1Mx16Doguu/1P0fb30T3n\nPtrUc26l4szNzCyPfPstMzOzfHHmZmaWN5JnBSh1B8zMrAW4LGlmZpYvztzMzPLIZUkzM8sXuSxZ\n6g5Y65A0W9KIWpaNSBde1rbtOEk/bbHOmZkVmYNbDkh6RdLe1dqOkfRA1euIGBIR97Z65+pQvY9t\nnaQvpIkU35H0VpqAsX/9W4KkQZJC0vsFjyeK0KcLJf2lufspFknbSrpR0hJJy9JElWcWzNfVUset\n9wuYpG9LmilphaRxLdmfNqFqxGQxHu2Qg5uVLWUa8//AM8D+wAbApsCLZJMrNkbviOiRHjs0ctui\nSzehLda+tgKmk01N8umI6AUcAgwD1i/WcZrhdeCnwLWl7kiLq5rypoT3liy19tlra7TC7E5St/RN\n921JzwDDq627k6RZkt6TNBHoWm35KEmPpwzmIUnbVzvOWekb+7I0Nfw62zewv8dKejb14WVJJxUs\ne1rSgQWvO6VMYaf0evfUr3ckPVFYjpV0r6Sxkh4ElgNbpgzy5XSsuZIOr6lPEbEoIuYV3LC1Eti6\nse+tlvd7XHq/b0uaImnzgmWXSpon6V1Jj0r6fGofCXwfOKwwE6yeyRdmdwUZ5PGSXgP+3YDPrEGf\nD/Bj4KGIODPdBJeIeD4iDo+Id9K+Dkol8nfSv8V2BccJSVsXvF6bjSmVziV9V9KbkhZKOjYtOxE4\nHDg7fQ631tS5iPh7RPyTeu4mb/ng4FaeLgC2So99+fhu20jqDPwTuB7oA9wIfLVg+U5k33xPIpss\n8I/AZEldCvZ/KNn08FsA2wPHNKGPb5JNldETOBa4RNLOadl1wBEF6+4PLIyIx1KZ8Dayb+h9gLOA\nmyVtXLD+kcCJZNnEYuAyYL+IWB/YA3g8vdfN0h/hzQre/2aS3gE+TPv+ZRPe2zokjSYLUl8BNgbu\nB24oWOURYMf0fv4G3Cipa0TcCfwMmNiETPD/AdsB+9b1mUlaj1o+nxrsTTZLcm3vc9v0vs5I7/N2\n4Nb0O9cQnyCb6qQ/cDzwB0kbpEkz/wr8Mn0OB6bjXS7p8gbuO2dKPytAqbXPXltN/pn+EL+T/vjW\n9T/1ocDYiFgaEfPI/nhV2R3oBPw2IlZFxE1kf1yrnAj8MSKmR0RlRIwHVqTtqlwWEa9HxFLgVrI/\nzI0SEbdFxEuR+Q9wF/D5tPgvwP6SeqbXR5IFY8iC3u0RcXtErImIu4GZZAGwyriImB0Rq8nuSr4G\nGCqpW0QsjIjZqQ+vRUTviHitoF+vRURvYCPgB8BzjXxrSwr+nc5Kbd8Cfh4Rz6Y+/QzYsSp7i4i/\nRMRbEbE6In5Ndqf1TzbyuNVdGBEfRMSH1P+Z1fj51GBDYGEdxzwMuC0i7o6IVcDFZHd/36OBfV4F\n/CT9Xt4OvE8dn0NEnBIRpzRw3/njc26WEwenP8S90x/fuv6n3pQ0ZXvyarVlC6rNlVS4fHPgu9UC\n6cC0XZU3Cp4vB3o05o0ASNpP0jRJS9Mx9icLKETE68CDwFcl9Qb24+NZfjcHDqnWv88B/Qp2v/a9\nR8QHZH90vwUslHSbpE/V178UuMcDt6hx5602Kvh3urigz5cW9Hcp2VmT/umzOCuVLJel5b2qPotm\nKPz3r/Uza+Tn8xbrfs7VbUrB71JErEn9aNCgHOCtFPyrNOl3y8qDg1t5Wsi6M+FuVm1Zf2mdr2uF\ny+eRZX29Cx7dI6KwjNYsqcR5M9k3+74pWN9O9ge/yniyjOMQ4OGIqJqxdx5wfbX+rRcRFxVsu848\nTxExJSK+RPaH+Tng6gZ2tQLYhKx02hzzgJOq9blbRDyUzq+dTZZtb5A+i2V8/FnUNGfVB0D3gtef\nqGGdwu3q/Mwa8fncQ0EJuwavkwVSIBvQQ/Z7WPVvt7wB/a6N5+6qzmVJK0OTgPMkbSBpAFA48dPD\nZKW605QN1PgKsGvB8quBb0naTZn1JB0gqamj4SSpa+ED6ExWelsMrJa0H7BPte3+CewMnE52Dq7K\nX4ADJe0rqWPa54j0Pms6eF9Jo9O5pRVkpa41taz7FUmflNQhncP7DfBYyuKqBm7c24TP4Eqyf48h\naT+9JB2Slq1P9u+xGKiQ9CPWDaaLgEFad9Tn42QzHXeStAvZzMV1qfUza8znQ3Yudw9Jv5L0ifRe\ntpb0l5RhTwIOkLSXpE7Ad9M+Hyro9zdSH0aSnRdsqEXAlnWtIKki/X51BKreZ35vZOGypJWhH5OV\nh+aSncuqOl9FRKwkG9hwDFl57DDg7wXLZwInAL8H3gbm0LQBI1X2IBucUf1xGtkfw7eBb5BNM79W\nOld0M9mglcL+zQOqBmgsJstKvkftv+sdgDPJsoqlZH9QT4a1g0feLxhQ0h+4E3gPeIrsj/yXC/Y1\nkKxc2igR8Q/gF8AESe8CT5OVWgGmpGO+QPZv9hHrlhRvTD/fkjQrPf8h2WCht8n+rf9Wz/Hr+sxq\n/Xxq2M9LwGeAQcBsScvI/o1mAu9FxPNk2fbvgCXAgcCB6XcOsi8qBwLvkI1+/Gdd/a7mGmBwKqv+\nE0DSlZKuLFjnB2S/W+emfnyY2iyHPBO3tVspi9k2Io6od+VWIOlxYK+I8FBzK6kOGwyKLiOKF7c/\n+ucJnonbrDVI6kM2HPzIUvelSkQ0elSoWYtpp+XEYnFZ0todSSeQlc7uiIj7St0fM2t7nLlZuxMR\nV9PwEY1mZUllnrk5uJmZ5YxwcHNZ0szMcseZWxN17NYrKnpuUupuWDsxdECvUnfB2olXX32FJUuW\nNC/tEuve8qAMObg1UUXPTej39UtK3Q1rJx68eFSpu2DtxGd3K8aIe7ksWeoOmJmZFZszNzOzHCr3\nzM3Bzcwsh8o9uLksaWZmuePMzcwsh8o9c3NwMzPLG18K4LKkmZnljzM3M7Ocka9zc3AzM8ujcg9u\nLkuamVnuOHMzM8uhcs/cHNzMzHKo3IOby5JmZpY7ztzMzPLG17k5uJmZ5ZHLkmZmZjnjzM3MLGd8\nEbeDm5lZLpV7cHNZ0szMcseZm5lZHpV34ubgZmaWO3JZ0mVJMzPLHWduZmY5VO6Zm4ObmVkOlXtw\nc1nSzMxyx5mbmVnO+CJuZ25mZvmkIj7qO5R0raQ3JT1d0NZH0t2SXkw/NyhYdp6kOZKel7RvQfsw\nSU+lZZcpRWhJXSRNTO3TJQ2qr08ObmZm1lzjgJHV2s4FpkbENsDU9BpJg4ExwJC0zeWSOqZtrgBO\nALZJj6p9Hg+8HRFbA5cAv6ivQw5uZmZ5k65zK9ajPhFxH7C0WvNoYHx6Ph44uKB9QkSsiIi5wBxg\nV0n9gJ4RMS0iAriu2jZV+7oJ2Ev1dMzn3MzMcqgNnHPrGxEL0/M3gL7peX9gWsF681PbqvS8envV\nNvMAImK1pGXAhsCS2g7u4GZmZvXZSNLMgtdXRcRVDd04IkJStEC/auXgZmaWQ0XO3JZExC6N3GaR\npH4RsTCVHN9M7QuAgQXrDUhtC9Lz6u2F28yXVAH0At6q6+A+52ZmlketOFqyFpOBo9Pzo4FbCtrH\npBGQW5ANHJmRSpjvSto9nU87qto2Vfv6GvDvdF6uVs7czMysWSTdAIwgK1/OBy4ALgImSToeeBU4\nFCAiZkuaBDwDrAZOjYjKtKtTyEZedgPuSA+Aa4DrJc0hG7gypr4+ObiZmeVQaw4oiYiv17Jor1rW\nHwuMraF9JjC0hvaPgEMa0ycHNzOznGnoEP488zk3MzPLHWduZmY5VO6Zm4ObmVkOlXtwc1nSzMxy\nx5mbmVkelXfi5uBmZpZHLkuamZnljDM3M7O8kTM3Bzczs5wRUOaxzWVJMzPLH2duZma549tvObiZ\nmeVQmcc2lyXNzCx/nLmZmeWQy5JmZpYvclnSZUkzM8sdZ25mZjkjoEOH8k7dnLmZmVnuOHMzM8uh\ncj/n5uBmZpZD5T5a0mVJMzPLHWduZmZ540sBHNzMzPImmxWgvKOby5JmZpY7ztysTsfuuQVjPjMQ\nISZMe41r/zOX3x+9M1tush4APbt14t0PV7H/r+6nd/dOXHHsMLbfrDc3zZjPBTc/vXY/Z+3/Sb4y\nfAC9undiyDl3lurtWBtw15Q7OevM06msrOSY477J984+t9RdyiHPCuDgZrXa9hPrM+YzAxn9mwdY\nVRmMP2lXps5exLfHz1q7zvmjt+O9j1YDsGL1Gn59+/N8st/6bNuv5zr7mjp7EeMfeIV7z/9Cq74H\na1sqKys547RTue2Ou+k/YACf2304o0YdxHaDB5e6a7lT5rHNZUmr3dZ9e/D4q+/w0ao1VK4Jpr+0\nlJHb91tnnQN23JTJj74OwIcrK5k5921WrF7zX/t67NV3WPzuilbpt7Vdj8yYwVZbbc0WW25J586d\nOeSwMfzr1ltK3S3LIQc3q9Xzb7zH8C370Lt7J7p26sAXBm9Cv95d1y7fdcs+LHlvBa8s+aCEvbT2\n5PXXFzBgwMC1r/v3H8CCBQtK2KP8klS0R3vksqTV6qVF73Pl1Je4/uTdWL6ykmcWLGNNxNrlBw3b\nlMmzXi9hD82sRr4UoOUyN0kPNWGbVyTdXPD6a5LGFbVj9ffhQklnteYx27JJ0+dx4K8f4LDfPcyy\n5at4+c0sS+vYQey7fT/+9ZiDmzXcppv2Z/78eWtfL1gwn/79+5ewR5ZXLRbcImKPJm46TFKTzi5L\nciZaZBv26AzApr27MnL7fkyelZWQPrftRry86H3eWPZRKbtn7cwuw4czZ86LvDJ3LitXruTGiRM4\nYNRBpe5W7lRd5+ayZAuQ9H5E9JDUD5gI9EzHOzki7q9j018D5wOHV9tfH+BaYEtgOXBiRDwp6UJg\nq9T+mqQpwMHAesA2wMVAZ+BIYAWwf0QslXQCcGJaNgc4MiKWF+XN58gVxw5jg/U6s7oy+OFNT/Hu\nh9nIyAN33nRtoCv0wI++SI8uFXSq6MA+n+7LkVdMZ86i9zn3wO0YPWxTunXqyMMX7sXEafP47Z0v\ntPbbsRKrqKjgkkt/z4EH7EtlZSVHH3Mcg4cMKXW3cqmdxqSiaY1M5xvAlIgYK6kj0L2e9ScBp0ja\nulr7j4HHIuJgSV8ErgN2TMsGA5+LiA8lHQMMBXYCupIFrnMiYidJlwBHAb8F/h4RVwNI+ilwPPC7\nujom6USygEjH9Teu/53nwKG/e7jG9rP+9kSN7Z/7yb9rbL/o1me56NZni9Yva79G7rc/I/fbv9Td\nsJxrjeD2CHCtpE7APyPi8XrWrwR+BZwH3FHQ/jngqwAR8W9JG0qquphqckR8WLDu/0XEe8B7kpYB\nt6b2p4Dt0/OhKaj1BnoAU+p7IxFxFXAVQJe+20Q9q5uZlUx7LScWS4tfChAR9wF7AguAcZKOasBm\n16dtBta3YlJ9LHrhBVVrCl6v4eOAPg74dkR8miwr7IqZWU5IxXu0Ry0e3CRtDixKJcA/ATvXt01E\nrAIuAb5T0Hw/6TycpBHAkoh4txldWx9YmDLKw+tb2czM2o/WKEuOAL4naRXwPtk5r4a4BvhBwesL\nycqbT5INKDm6mf36ITAdWJx+rt/M/ZmZtQ1yWbLFgltE9Eg/xwPjG7jNoILnK4BNC14vJRsFWX2b\nC6u9HkdWcqxpn2uXRcQVwBX17c/MrL3JLgUodS9Ky7ffMjOz3CnJRc+SpgNdqjUfGRFPlaI/Zmb5\n0n4vvi6WkgS3iNitFMc1MysXZR7bXJY0M7P88b0YzcxyyGVJMzPLl3Z88XWxuCxpZma548zNzCxn\nqqa8KWcObmZmOVTuwc1lSTMzyx1nbmZmOVTmiZuDm5lZHrksaWZm1gySviNptqSnJd0gqaukPpLu\nlvRi+rlBwfrnSZoj6XlJ+xa0D5P0VFp2mZoRoR3czMzypogTldYXXiT1B04DdomIoUBHYAxwLjA1\nIrYBpqbXSBqclg8BRgKXS+qYdncFcAKwTXqMbOpH4OBmZpYzSjdOLtajASqAbpIqgO7A68BoPp7u\nbDwfT1k2GpgQESsiYi4wB9hVUj+gZ0RMi4gArqOGac4aysHNzMyaLCIWABcDrwELgWURcRfQNyIW\nptXeAPqm5/2BeQW7mJ/a+qfn1dubxMHNzCyHilyW3EjSzILHiR8fRxuQZWNbkE0wvZ6kIwr7kjKx\naL1379GSZma51KG4oyWXRMQutSzbG5gbEYsBJP0d2ANYJKlfRCxMJcc30/oLgIEF2w9IbQvS8+rt\nTeLMzczMmuM1YHdJ3dPoxr2AZ4HJwNFpnaOBW9LzycAYSV0kbUE2cGRGKmG+K2n3tJ+jCrZpNGdu\nZmY51FqXuUXEdEk3AbOA1cBjwFVAD2CSpOOBV4FD0/qzJU0CnknrnxoRlWl3pwDjgG7AHenRJA5u\nZmY5k50ra72LuCPiAuCCas0ryLK4mtYfC4ytoX0mMLQYfXJZ0szMcseZm5lZDnUo77tvObiZmeWR\n7y1pZmaWM87czMxyqMwTNwc3M7O8Edn9JcuZy5JmZpY7ztzMzHLIoyXNzCxfGj5VTW65LGlmZrnj\nzM3MLIfKPHFzcDMzyxtR9Clv2h2XJc3MLHecuZmZ5VCZJ24ObmZmeeTRkmZmZjnjzM3MLGeyyUpL\n3YvScnAzM8shj5Y0MzPLmVozN0k969owIt4tfnfMzKwYyjtvq7ssORsI1v2Mql4HsFkL9svMzJqh\n3EdL1hrcImJga3bEzMysWBp0zk3SGEnfT88HSBrWst0yM7Omym6/VbxHe1RvcJP0e+ALwJGpaTlw\nZUt2yszMmiFNeVOsR3vUkEsB9oiInSU9BhARSyV1buF+mZmZNVlDgtsqSR3IBpEgaUNgTYv2yszM\nmqWdJlxF05Dg9gfgZmBjST8GDgV+3KK9MjOzZmmv5cRiqTe4RcR1kh4F9k5Nh0TE0y3bLTMzs6Zr\n6O23OgKryEqTvquJmVkbVjVaspw1ZLTk+cANwKbAAOBvks5r6Y6ZmVnTebRk/Y4CdoqI5QCSxgKP\nAT9vyY6ZmZk1VUOC28Jq61WkNjMza6PaZ75VPHXdOPkSsnNsS4HZkqak1/sAj7RO98zMrLEkT3lT\nV+ZWNSJyNnBbQfu0luuOmZlZ89V14+RrWrMjZmZWPGWeuNV/zk3SVsBYYDDQtao9IrZtwX6ZmZk1\nWUOuWRsH/Jns/OR+wCRgYgv2yczMmqncLwVoSHDrHhFTACLipYj4AVmQMzOzNkoq3qM9asilACvS\njZNfkvQtYAGwfst2y8zMrOkaEty+A6wHnEZ27q0XcFxLdsrMzJpOyJcC1LdCRExPT9/j4wlLzcys\nrWrH5cRiqesi7n+Q5nCrSUR8pUV6ZGZm1kx1ZW6/b7VetENDB/TiwYtHlbob1k5sMPzbpe6CtRMr\nnn+tKPtpr6Mci6Wui7intmZHzMyseMp9brJyf/9mZpZDDZ2s1MzM2gnhsmSDg5ukLhGxoiU7Y2Zm\nxeGZuOshaVdJTwEvptc7SPpdi/fMzMysiRpyzu0yYBTwFkBEPAF8oSU7ZWZmzdNBxXu0Rw0pS3aI\niFer1W8rW6g/ZmbWTNk9IdtpVCqShgS3eZJ2BUJSR+B/gBdatltmZmZN15Cy5MnAmcBmwCJg99Rm\nZmZtVGuWJSX1lnSTpOckPSvpM5L6SLpb0ovp5wYF658naY6k5yXtW9A+TNJTadllakb6WW9wi4g3\nI2JMRGyUHmMiYklTD2hmZi2vlae8uRS4MyI+BewAPAucC0yNiG2Aqek1kgYDY4AhwEjg8lQVBLgC\nOAHYJj1GNvX9N2Qm7qup4R6TEXFiUw9qZmb5IKkXsCdwDEBErARWShoNjEirjQfuBc4BRgMT0qVl\ncyXNAXaV9ArQMyKmpf1eBxwM3NGUfjXknNs9Bc+7Al8G5jXlYGZm1vIErTnlzRbAYuDPknYAHgVO\nB/pGxMK0zhtA3/S8PzCtYPv5qW1Vel69vUkaMuXNxMLXkq4HHmjqAc3MrOUV+d6KG0maWfD6qoi4\nKj2vAHYG/icipku6lFSCrBIRIanWWWZaQlNuv7UFH0dgMzPLvyURsUsty+YD8wvm/ryJLLgtktQv\nIhZK6ge8mZYvAAYWbD8gtS1Iz6u3N0lD7lDytqSl6fEOcDdwXlMPaGZmLa+1BpRExBtkl4x9MjXt\nBTwDTAaOTm1HA7ek55OBMZK6SNqCbODIjFTCfFfS7mmU5FEF2zRanZlbOsAOfBw910REq6aWZmbW\nOJJa85wbZNc//1VSZ+Bl4Fiy5GmSpOOBV4FDASJitqRJZAFwNXBqRFTdGOQUYBzQjWwgSZMGk0A9\nwS3VSW+PiKFNPYCZmeVbRDwO1FS23KuW9ccCY2tonwkUJd405Jzj45J2KsbBzMysdbTydW5tTq2Z\nm6SKiFgN7AQ8Iukl4AOyUaYRETu3Uh/NzKyR2usNj4ulrrLkDLLhnQe1Ul/MzMyKoq7gJoCIeKmV\n+mJmZkXQyhdxt0l1BbeNJZ1Z28KI+E0L9MfMzIqgzGNbncGtI9CDlMGZmZm1F3UFt4UR8ZNW64mZ\nmRVHO55Bu1jqPedmZmbtj8r8T3hd17nVePGdmZlZW1dr5hYRS1uzI2ZmVhzZaMlS96K0mjIrgJmZ\ntXHlHtyKPOWPmZlZ6TlzMzPLIZX5hW4ObmZmOeNzbi5LmplZDjlzMzPLm3Y8VU2xOLiZmeVQud84\n2WVJMzPLHWduZmY54wElDm5mZrlU5lVJlyXNzCx/nLmZmeWO6FDmswI4uJmZ5YxwWdJlSTMzyx1n\nbmZmeeOZuB3czMzyyBdxm5mZ5YwzNzOznPGAEgc3M7NcclnSzMwsZ5y5mZnlUJknbg5uZmZ5I1yW\nK/f3b2ZmOeTMzcwsbwQq87qkg5uZWQ6Vd2hzWdLMzHLImZuZWc5kM3GXd+7m4GZmlkPlHdpcljQz\nsxxy5mZmlkNlXpV0cDMzyx+V/aUALkuamVnuOHMzM8sZ337Lwc3MLJdcljQzM8sZZ25WFHdNuZOz\nzjydyspKjjnum3zv7HNL3SVrBVdecDj77TmUxUvfY5dDfgbAz844mP33HMrKVZXMnb+EEy/4C8ve\n/5CKig5c8aPD2fFTA6no2IG/3jaDi6+9C4Bbfn8Kn9i4JxUdO/LgYy9xxs8nsmZN8M2vfY6TDt2T\nyjVr+GD5Ck796Q089/IbpXzL7UZ5523O3KwIKisrOeO0U7nl1jt47MlnuHHCDTz7zDOl7pa1gutv\nncboU/+wTtvUac8x7JCfsethP+fFV9/ke8ftA8BX996ZLp0rGH7oz9jj8F/wza9+ls369QHgiHOu\nZbfDLmLY18ay8QY9+OqXdgZg4h0zGX7oz9h9zEX8Zvw9/OLMr7TuG2yv0o2Ti/VojxzcrNkemTGD\nrbbami223JLOnTtzyGFj+Nett5S6W9YKHpz1EkuXLV+nbeq056isXAPAjKfm0r9vbwCCoHvXznTs\n2IFuXTqzclUl733wEcDanxUVHehU0ZGIWKcdYL1unQmixd+T5YPLktZsr7++gAEDBq593b//AGbM\nmF7CHllbcdToz3DTXbMA+Ps9jzFqxPbMvXss3bt25uyL/87b734cGCf/4VR2Gbo5dz34DH+/57G1\n7ScduienHfEFOneqYORJl7X6e2iPPFrS79/MWsjZx+9LZeUaJtz+CADDhwyisnINW+5zPtsdcAGn\nH/lFBvXfcO36B536B7b40vfp0rmCEcM/ubb9j5PuY8hBP+YHl97Cud8c2ervo71yWbKVSHqoidvt\nKCkkjSxo6y3plILXgyR9oxl9u1fSLk3dvtxtuml/5s+ft/b1ggXz6d+/fwl7ZKV2xIG7sf+eQznm\n/HFr2w7dbxfueugZVq9ew+K33+fhx19m2ODN1tluxcrV3Hrvkxw44tP/tc9JUx7lwBHbt3TXLSda\nLbhFxB6ZUDVkAAAU7ElEQVRN3PTrwAPpZ5XewCkFrwcBTQ5u1jy7DB/OnDkv8srcuaxcuZIbJ07g\ngFEHlbpbViJf2mM7zjxmb752xh/58KNVa9vnv7F0bUbWvWtndt1+EM+/soj1unXmExv1BKBjxw7s\n97khPP/KIgC22mzjtdvv9/khzJm3uBXfSfumIj7ao1Y75ybp/YjoIakfMBHomY5/ckTcX8s2Ag4B\nvgTcL6lrRHwEXARsJelx4G7g88B26fV44B/A9cB6aVffjoiH0j7PAY4A1gB3RMS5BcfrAFwLzI+I\nH9TQnxOBEwEGbrZZ9cVlq6Kigksu/T0HHrAvlZWVHH3McQweMqTU3bJWMP7nx/D5YduwUe8ezLnz\nf/nfK2/ne8fuQ5fOFfzrim8DMOOpVzht7ASunHgfV/34CB696XwkuP6WaTz94uts0md9bvrtSXTu\nVEGHDuK+mS9y9U0PAHDyYXvyhd0+xarVlbzz7nJO+OF1pXy77UprVxMldQRmAgsiYpSkPmR/6wcB\nrwCHRsTbad3zgOOBSuC0iJiS2ocB44BuwO3A6VE1uqix/Wnido0/0MfB7btA14gYmz6M7hHxXi3b\nfBb4SUTsJelvwM0RcbOkQcC/ImJoWm8EcFZEjEqvuwNrIuIjSdsAN0TELpL2A34I7B0RyyX1iYil\nku4FzgVOB56OiLH1vZ9hw3aJB6fPbNZnYuVjg+HfLnUXrJ1Y8fwk1ix/s1mhaeshO8SvJ0wpVpc4\nePt+j0ZEnaduJJ0J7AL0TMHtl8DSiLhI0rnABhFxjqTBwA3ArsCmwD3AthFRKWkGcBownSy4XRYR\ndzSlz6UYUPIIcKykC4FP1xbYkq8DE9LzCaxbmqxLJ+BqSU8BNwKDU/vewJ8jYjlARCwt2OaPNDCw\nmZm1ZdloSRXtUe/xpAHAAcCfCppHk1XSSD8PLmifEBErImIuMAfYNVX1ekbEtJStXVewTaO1enCL\niPuAPYEFwDhJR9W0Xsrqvgr8SNIrwO+AkZLWb8BhvgMsAnYg+ybRuQHbPAR8QVLXBqxrZlZONpI0\ns+BxYrXlvwXOJjvdU6VvRCxMz98A+qbn/YF5BevNT2390/Pq7U3S6sFN0ubAooi4mizK71zLqnsB\nT0bEwIgYFBGbAzcDXwbeAwqDXPXXvYCFEbEGOBLomNrvJssau6e+9CnY5hqyNHiSJF//Z2btmlS8\nB7AkInYpeFz18XE0CngzIh6trS8pE2vVK/BLUZYcATwh6THgMODSWtb7OtnAkEI3A1+PiLeAByU9\nLelXwJNApaQnJH0HuBw4WtITwKeADwAi4k5gMjAzDT45q3DnEfEb4DHg+jS4xMysHVJR/6vHZ4GD\nUoVtAvBFSX8BFqVSI+nnm2n9BcDAgu0HpLYF6Xn19qZ9Aq01oCRvPKDEGsMDSqyhijGgZJshO8Zv\nJ95VrC4x6tN96x1QAusO7kuJx1sFA0r6RMTZkoYAf+PjASVTgW1qGVDyu4i4vSl9dvnNzCyH2sCN\nRS4iO81zPPAqcChARMyWNAl4BlgNnBoRlWmbU/j4UoA70qNJ2kRwkzQd6FKt+ciIeKoU/TEza8+q\nRku2toi4F7g3PX+LbOxETeuNBf5rZHpEzASGFqMvbSK4RcRupe6DmZnlR5sIbmZmVkRqE2XJknJw\nMzPLoXIPbh7ubmZmuePMzcwshxpwfVquObiZmeWMgA7lHdtcljQzs/xx5mZmlkMuS5qZWe54tKSZ\nmVnOOHMzM8shlyXNzCxXPFrSZUkzM8shZ25mZrnToElGc83Bzcwsb3zjZJclzcwsf5y5mZnlUJkn\nbg5uZmZ5k42WLO/w5rKkmZnljjM3M7McKu+8zcHNzCyfyjy6uSxpZma548zNzCyHfBG3mZnlTpkP\nlnRZ0szM8seZm5lZDpV54ubgZmaWS2Ue3VyWNDOz3HHmZmaWM8KjJR3czMzyxlPeuCxpZmb548zN\nzCyHyjxxc3AzM8ulMo9uLkuamVnuOHMzM8sdebRkqTtgZmbF59GSZmZmOePMzcwsZ0TZjydxcDMz\ny6Uyj24uS5qZWe44czMzyyGPljQzs9zxaEkzM7OcceZmZpZDZZ64ObiZmeWOrwVwWdLMzPLHmZuZ\nWQ55tKSZmeWK8GhJlyXNzCx3nLmZmeVQmSduDm5mZrlU5tHNZUkzM2sySQMl/Z+kZyTNlnR6au8j\n6W5JL6afGxRsc56kOZKel7RvQfswSU+lZZdJTT9z6OBmZpZDKuJ/9VgNfDciBgO7A6dKGgycC0yN\niG2Aqek1adkYYAgwErhcUse0ryuAE4Bt0mNkU9+/g5uZWQ5JxXvUJSIWRsSs9Pw94FmgPzAaGJ9W\nGw8cnJ6PBiZExIqImAvMAXaV1A/oGRHTIiKA6wq2aTQHNzMzKwpJg4CdgOlA34hYmBa9AfRNz/sD\n8wo2m5/a+qfn1dubxANKzMxyqMjjSTaSNLPg9VURcdU6x5N6ADcDZ0TEu4WnyyIiJEVxu1Q3Bzcz\nszwqbnRbEhG71HooqRNZYPtrRPw9NS+S1C8iFqaS45upfQEwsGDzAaltQXpevb1JXJY0M7MmSyMa\nrwGejYjfFCyaDBydnh8N3FLQPkZSF0lbkA0cmZFKmO9K2j3t86iCbRrNmZuZWc5kkwK02oVunwWO\nBJ6S9Hhq+z5wETBJ0vHAq8ChABExW9Ik4BmykZanRkRl2u4UYBzQDbgjPZrEwc3MLG8aMMqxWCLi\nAWovgu5VyzZjgbE1tM8EhhajXy5LmplZ7jhza6JZsx5d0q2TXi11P9qYjYAlpe6EtRv+fanZ5sXY\nSZnffcvBrakiYuNS96GtkTSzrhFVZoX8+9LCyjy6uSxpZma548zNzCx3GnRPyFxzcLNiuqr+VczW\n8u9LC/JM3GZFUv12PGZ18e+LtSRnbmZmOSPKfjyJg5uZWS6VeXRzWdLMzHLHmZuVlKQ+wEYR8UKp\n+2LthySlCS2tFuU+WtKZm5WMpK7AacBxkrYrdX+s7ZM0ELL5wUrdl7autWbibqsc3KxkIuIj4J70\n8hBJg0vZH2t7JPWQ1Dk93w74paT1S9wtawcc3Kwk0nxNVXcUnwz0BL7mAGdVJK0H/BU4JDUtT4/3\n0+SYa3+P7L+piI/2yMHNWl3V+RJJW0iqiIiHgD8DvcgCnEuURkR8AEwEjpV0GDAI+DAyq9I6Lk9a\njTygxFpdCmwHAD8E7pf0PvBbsjtWHA8cIemvEfFMKftppSOpY0RURsTfJC0GzgEeBbaQdCkwH1gB\nVFSb/dmgVedza6ucuVmrk7Q78DPgMLIvWAcDvwQWA+OB9YCVJeuglVTK7CslfUnSLyPibuBSsokv\nVwKvpZ89gOkl7GobV96FSWdu1mokdQCCbB6vo4BPAXsC5wInAheTfUM/P5WkrAylzH4v4HLgpNR2\nq6TVwJnACxFxayn7aG2fMzdrcQUn/Xuk8yX/iognyDK2b0bEFOBNsi9bfR3YypcyFcBI4IcR8e+q\n0ZIRcQdwJXCOpP6l7GdbJ3wpgIObtbiCc2xTJV0o6Stp0SbAiZJ2A3YFLo6Ip0vWUSu59OVnNfAR\nsLukrhGxEkDScOB24KCIWFDKfrYH5V2UdHCzViCpH3A4WdlxKbBvCnbHAQOBHwE/j4gnS9dLK5Wq\nzF7SZpIGpOY7gE7A/0vLdgAuAbaNiKUl6ai1Kz7nZi1K0i7ADsCCiJgoaWNgX+DLQKeIGCWpe0Qs\n9y2VylNBZv9z4CFJfSLi0HRJyJGSziG7TOSnqZxtDdBey4nF4uBmLUbSCLLRj1PIhvffEBGzJN0B\ndAZGS5oREa+Dr1kqNwXXO+5ONlp2FFmmdq2keyJib0njyL4cLYuIl/wFqOHK/d6SDm7WIiRtAXwf\nODIi7pM0B/iLpMMj4jFJtwB3VgU2Kx/pnqKr0nD/vsBbwKHANmSjI3sB90p6KCL2AGZVbevAZg3l\nc25WNAXnToaTfQPvRTYikoj4JXANMFnSsIh4y4Gt/KTLQfYAzpA0iux863vAM8ABwLUR8R5Zxr9Z\n+l2ypijzESUOblY0qcS0J1mJ6SmyC7W7S/p2Wv5r4A9kF99a+XoS2Ae4HrgpIt4g+xO6ENhK0glk\nJcovRcQjpetm+1bmsc3BzYpH0ieBk4FxEfEocC8wFfiUpO8CRMRFEfEf3/C2vEhaT9KAiFgDbJ6a\n/w/YLw33X0M2Q8RyssB2ZUQ8W6LuWg74nJsV06eBvsDekm6PiMWS7iQb0j1C0uYR8Sr43EkZGgT8\nVNJMYCjwXeBtsvuL/gY4BXiZLOD9LCJWe/BI07Xni6+LxZmbNVnBObYBknpFxE1kf6zeJbu7/4bp\n/MmtwI+qApuVn4iYDcwhG2Q0PV2sv5jsFltdJE0ly/RXpYu4/QWomVTE/9ojBzdrEkkd0jm2/cgu\nuL1G0n3As8C/gKprlDaMiPfSeRUrI5J6S+pe0PQ08GvgKEl7RcTKdOH++cA44DsRMa0EXbUcclnS\nGkVSt4j4MCLWSNoa+F/gpIh4SNJlwD/JLtLulH6uRzbU28qIpD7AC8A9ku6PiD9ExPi0bB7wG0lH\nA+8AX6matsalyCJqnwlX0Ti4WYNJ6gVcJOkfEXEX2R+m58j+iBERp0m6ATg3Ii6Q9EhELCxhl610\n3gbuIhsBebikXYEHgBsj4mpJK4GbgdXAGVUbObAVT5nHNpclrVF6kp03+UaakuRdYENg74J1bifN\nxebAVr5SkJpFNsBoT7Ky457AfyR9gWzgyG7AV9Pd/s2Kypmb1UvS+um82TxJ1wFjyG56vJhsgMA4\nSZ8ClqX2s0vXW2srIuJiSbeTffl5GtiRLNMfA2wNHOZZIFpOuY+WdHCzOkkaBNwk6VFgEvAi8Gdg\nBdlw7l8AhwD7AZuSDQq4x+dOypukjhFRSZaxfZnsjv7XpIC3CdlNs5eUso/51n5HORaLg5vVpyvQ\nDxgNvEJ2h5ErgQ2Ah8iG/o+NiEsLN3JgK28psAFMBy4EHo6Ii1PbYv9+WEvzOTerVRru/xxZWWkZ\n8BpwGPA62b0jv5Ze/zIN+/bvk62VsvdXgTOBHlWzZzuwtTzPxO3MzeqQhvt3iIhnJR0BTCC7e8Q1\nkm4iu4v7aODxiHinpJ21kiiYtqZDuoXWWgVBbD6w5r+3Nms5Dm5Wp4IA94ikMcAN6V6AfwCeJ7tJ\nsq9PKkMFgW0vssxsSkR8VH29iHha0jkRsaAE3bQy5TKS1aswwJGVIX8o6dRq6ziwlZE0YCQkjQSu\nAN6uKbAp0yEiXpXUXdKGrd/b8lTuZUkHN1ur4F6R//V7URDgHgUOBGa3dv+s9CRtnS4NqZS0AdmA\nom+lCWk/L+nodMF2lQ7pd6c32bVtfUrS8TJU7veWdFnSgIaVmKplcC5Flqe+wCaSpkXE25L+Dzg+\nzcHWAVhFdi52hqSKdHf/XsCNwPci4sXSdd3KiTM3a3CJqWr1tE03sssBrIxExINkE9G+LKkn2XVs\nM4DfRcRhZNdCDpHUOQW2DYB/AD+JiPtK1e+yU8SSpMuS1u40tsRUdWFuKjHdS3brLSszaRqj08mu\nc1wSEZemG2d/nuxG2n+KiJVp9a8DP42I+0vU3bJUzFm422lsc1myzLnEZE0SEbdIWgU8KmkY8BHZ\ndY8/iIjbqkrWEXF5aXtq5crBrYxFxIOS1icrMW1PVmI6AHgkfRM/CDg2lZhWpuzuZuACfxO3iLhd\n0hqyOfw+CZwTER8VnL/1OdlSaq8pV5G4LFnmXGKy5oiIO4FvAjtVnaetCmgObKXl0ZJW9lxisuaI\niNvAo2etbXFwM8AlJms+/360Le11lGOxuCxpa7nEZJYfHi1pVsAlJjPLA2duViMHNrN2rhVTN0kj\nJT0vaY6kc4v9VprCmZuZWQ611ihHSR3JJjH+Etn0Ro9ImhwRz7RKB2rhzM3MzJpjV2BORLycLhua\nQDbPY0k5czMzy5mqmbhbSX9gXsHr+cBurXb0Wji4We5IqiS7uW8F2aUNR0fE8ibuawRwVkSMSnds\nGRwRF9Wybm/gG429HlDShcD7EXFxQ9qrrTMO+FdE3NTAYw1K6w9tTB+tfZk169Ep3TppoyLusquk\nmQWvr4qIq4q4/6JzcLM8+jAidgSQ9FfgW8BvqhameesUEWsas9OImAxMrmOV3sApgC92t5KKiJGt\neLgFwMCC1wNSW0n5nJvl3f3A1pIGpdFc1wFPAwMl7SPpYUmzJN0oqQesHfn1nKRZwFeqdiTpGEm/\nT8/7SvqHpCfSYw/gImArSY9L+lVa73uSHpH0pKQfF+zrfEkvSHqA7KL5Okk6Ie3nCUk3S+pesHhv\nSTPT/kal9TtK+lXBsU9q7gdpVotHgG0kbSGpMzCGur8EtgoHN8stSRXAfmQlSshmOLg8IoYAHwA/\nAPaOiJ2BmcCZkroCV5PNNj4M+EQtu78M+E9E7ADsTDYz+bnASxGxY0R8T9I+6Zi7AjsCwyTtmW5x\nNia17Q8Mb8Db+XtEDE/HexY4vmDZoHSMA4Ar03s4HlgWEcPT/k+QtEUDjmPWKBGxGvg2MIXsd3NS\nRMwuba9clrR86ibp8fT8fuAaYFPg1YiYltp3BwYDD2ZVSjoDDwOfAuZWTecj6S/AiTUc44vAUQAR\nUQksS7MmFNonPR5Lr3uQBbv1gX9UnQeU1JBvuUMl/ZSs9NmD7A9JlUmpxPqipJfTe9gH2F7S19I6\nvdKxX2jAscwaJSJuB24vdT8KObhZHq0951YlBbAPCpuAuyPi69XWW2e7ZhLw84j4Y7VjnNGEfY0D\nDo6IJyQdA4woWFb9gvtIx/6fiCgMglUDSsxyz2VJK1fTgM9K2hpA0nqStgWeAwZJ2iqt9/Vatp8K\nnJy27ZgmcX2PLCurMgU4ruBcXn9JmwD3AQdL6pbm0zuwAf1dH1goqRNweLVlh0jqkPq8JfB8OvbJ\naX0kbStpvQYcxywXnLlZWYqIxSkDukFSl9T8g4h4QdKJwG2SlpOVNdevYRenA1dJOh6oBE6OiIcl\nPSjpaeCOdN5tO+DhlDm+DxwREbMkTQSeAN4kOyFfnx8C04HF6Wdhn14DZgA9gW+l2Rz+RHYublYa\nHboYOLhhn45Z+yffQtDMzPLGZUkzM8sdBzczM8sdBzczM8sdBzczM8sdBzczM8sdBzczM8sdBzcz\nM8sdBzczM8ud/w/cOukuB/Y7FQAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7fab3c6efd68>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot(actual_value = Train.actual_value, pred_value = Train.pred_value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-07-17T21:26:38.779830Z",
     "start_time": "2017-07-17T21:26:38.489311Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion matrix, without normalization\n",
      "[[2152    0]\n",
      " [   0 9698]]\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAbUAAAGgCAYAAAAtsfn1AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAAIABJREFUeJzt3Xm8XePZ//HPN4lISGQwBBmEGIOaElJTFSWIoVoR81Qx\ntoZSWrTan6iiA1WUahO0iDlqrufx1EzMUxFzBiRmgiQn1++PdR/djpyTfZJ9zt57re/ba73OXvO1\nd45z7eu+77WWIgIzM7M86FDtAMzMzCrFSc3MzHLDSc3MzHLDSc3MzHLDSc3MzHLDSc3MzHLDSc3M\nzHLDSc3MzHLDSc3MzHKjU7UDMDOzttVxiRUi5nxWsePFZ9Nvj4jhFTtgBTmpmZnlXMz5jEVXG1mx\n433+xJ+WqtjBKsxJzcws9wQqRm9TMd6lmZkVgis1M7O8EyBVO4p24aRmZlYEbn40MzOrL67UzMyK\nwM2PZmaWDx79aGZmVndcqZmZFYGbH83MLBeEmx/NzMzqjSs1M7Pck5sfzcwsR9z8aGZmVl9cqZmZ\nFYGbH83MLB988bWZmVndcaVmZpZ3fvSMmZnlipsfzczM6osrNTOz3CvOQBEnNTOzIuhQjD61YqRu\nMzMrBFdqZmZ557v0m5mZ1R9XamZmReDr1MzMLB+KM/qxGO/SzMwKwZWamVkRuPnRzMxyw82PZmZm\n9cWVmplZ3klufjQzsxxx86OZmVl9cVIrGEnPStqimXVbSJrcwr5jJZ3WZsGZWdtpbIKsxFTDnNRy\nRNJrkrZusmx/Sfc2zkfEmhFxd7sH14KmMdY6Sd+W9LSkDyS9K+l6SX3L3HegpJD0Scn0ZAViOlXS\n5Qt7nEqRtKqkqyXNkPShpKckHSupYxufd75fvCQdKWmipC8kjW3LeGpHuvi6UlMNq+3ozNqBMq35\nf+E5YHugF7A88BJwQStP2zMiuqVpnVbuW3GSKta/LmkQ8BDwJrB2RPQAdgM2ALpX6jwLYSpwGvDX\nagdileekVjCl1Zykrumb7fuSngOGNtl2PUmPSfpY0lVAlybrR0h6IlUs90v6RpPzHJe+oX8o6SpJ\nX9m/zHgPkPR8iuEVSYeUrHtG0o4l84ukymC9ND8sxfWBpCdLm10l3S1pjKT7gJnASqlifCWd61VJ\ne80rpoh4OyLejIhIixqAlVv73pp5vwem9/u+pNslrVCy7hxJb0r6SNKjkjZLy4cDPwN2L638mlbu\npdVcScV4kKQ3gP8p4zMr6/MBfgncHxHHRsS09Jm9EBF7RcQH6Vg7pabwD9K/xRol5wlJK5fMf1l9\nKTWRS/qxpHckTZN0QFo3GtgL+En6HG6aV3ARcV1E3AC8W9Y/Sl64+dEK4BfAoDRtC+zXuEJSZ+AG\n4DKgN3A18L2S9euRfdM9BFgS+DMwQdKiJccfCQwHVgS+Aey/ADG+A4wAlgAOAH4vaf207lJg75Jt\ntwemRcTjqTnwZrJv5L2B44BrJS1dsv0+wGiy6mE6cC6wXUR0BzYGnkjvdUD64zug5P0PkPQB8Fk6\n9pkL8N6+QtLOZMlpV2Bp4B7gipJNHgHWTe/nH8DVkrpExG3A6cBVC1D5fQtYA9i2pc9M0uI08/nM\nw9bANS28z1XT+zo6vc9bgJvS71w5lgV6AH2Bg4A/SeoVERcBfwfOTJ/Djul850s6v8xj51Pjo2fc\n/Gh16Ib0B/iD9Ee3pf+ZRwJjIuK9iHiT7I9Wo2HAIsAfImJ2RFxD9ke10WjgzxHxUEQ0RMQ44Iu0\nX6NzI2JqRLwH3ET2B7lVIuLmiHg5Mv8H3AFsllZfDmwvaYk0vw9ZEoYs2d0SEbdExNyIuBOYSJb4\nGo2NiGcjYg4wB5gLrCWpa0RMi4hnUwxvRETPiHijJK43IqInsBRwMvCfVr61GSX/TselZYcCv46I\n51NMpwPrNlZrEXF5RLwbEXMi4rfAosBqrTxvU6dGxKcR8Rnz/8zm+fnMw5LAtBbOuTtwc0TcGRGz\ngbOBrmSJshyzgV+l38tbgE9o4XOIiMMj4vAyj211zkktf3ZJf4B7pj+6Lf3PvDxZv0ej15usm1LS\nxNZ0/QrAj5sk0P5pv0ZvlbyeCXRrzRsBkLSdpAclvZfOsT1ZIiEipgL3Ad+T1BPYjuybemN8uzWJ\nb1NguZLDf/neI+JTsj+2hwLTJN0safX5xZcS9jjgRrWuX2qpkn+ns0tiPqck3vfIvmP3TZ/Fcalp\n8sO0vkfjZ7EQSv/9m/3MWvn5vMtXP+emlqfkdyki5qY4yhpsA7ybkn6jBfrdKhYPFLFimEaWiBoN\naLKur/SVBvTS9W+SVXk9S6bFIqK0uWyhpKbMa8m+yfdJSfoWsj/0jcaRVRi7AQ9ExJSS+C5rEt/i\nEXFGyb6lCZuIuD0ivkP2B/k/wMVlhtoJWIasiXRhvAkc0iTmrhFxf+o/+wlZdd0rfRYf8t/PIuZx\nvE+BxUrml53HNqX7tfiZteLz+RclTdXzMJUsgQLZQB2y38PGf7uZZcTdnHl9DgbuU7NCGA/8VFIv\nSf2AH5ase4CsSe5HygZg7ApsWLL+YuBQSRsps7ikHSQt6Og2SepSOgGdyZrYpgNzJG0HbNNkvxuA\n9YGjyPrYGl0O7ChpW0kd0zG3SO9zXifvI2nn1Hf0BVmT1txmtt1V0mqSOqQ+ut8Bj6eqrXFAxt0L\n8BlcSPbvsWY6Tg9Ju6V13cn+PaYDnST9nK8m0beBgfrqKM4ngFHp328I8P35nL/Zz6w1nw9ZX+3G\nks6StGx6LytLujxV1OOBHSRtJWkR4MfpmPeXxL1nimE4Wb9fud4GVmppA0md0u9XR6DxffruSjnh\npFZsvyRrBnqVrK+qsT+KiJhFNmBhf7JmsN2B60rWTwQOBs4D3gcmsWADQRptTDbooun0I7I/gu8D\newITSndKfUHXkg1GKY3vTaBx4MV0sirkeJr/ne8AHEtWRbxH9of0MPhyUMgnJQNF+gK3AR8DT5P9\ncf9uybH6kzWLtkpEXA/8BrhS0kfAM2RNqgC3p3O+SPZv9jlfbTq8Ov18V9Jj6fUpZIOA3if7t/7H\nfM7f0mfW7Oczj+O8DHwTGAg8K+lDsn+jicDHEfECWXX9R2AGsCOwY/qdg+wLyo7AB2SjGW9oKe4m\nLgEGp+bTGwAkXSjpwpJtTib73ToxxfFZWpZvBWl+1Fe7TMzqT6paVo2Ivee7cTuQ9ASwVUQUa8i4\n1awOPVeIRbc4qWLH+/zGQx6NiCEVO2AFueS2uiapN9mw7n2qHUujiGj1KE8zq4zariPNWiDpYLIm\nslsj4t/VjsesZqk4ox9dqVndioiLKX+Eolmx1fioxUqp7ZRrZmbWCq7UzMwKQAWp1JzUFlDP3kvG\n8n0HzH9DsxJdO7fpk1csh15//TVmzJixUBlJOKnZfCzfdwCXTri72mFYnVmrf49qh2B1ZpONanLk\nfM1yUjMzyzvx1ZvL5ZiTmplZ7qkwzY8e/WhmZrnhSs3MrACKUqk5qZmZFUBRkpqbH83MLDdcqZmZ\nFUBRKjUnNTOzvCvQkH43P5qZWW64UjMzyzn5OjUzM8sTSRWbyjjXMZKelfSMpCskdZHUW9Kdkl5K\nP3uVbP9TSZMkvSBp25LlG0h6Oq07V2Wc3EnNzMwqRlJf4EfAkIhYC+gIjAJOBO6KiFWAu9I8kgan\n9WsCw4HzJTXe+fsC4GBglTQNn9/5ndTMzAqgPSs1sq6trpI6AYsBU4GdgXFp/Thgl/R6Z+DKiPgi\nIl4FJgEbSloOWCIiHoyIAC4t2afFE5uZWc61V59aREyRdDbwBvAZcEdE3CGpT0RMS5u9BfRJr/sC\nD5YcYnJaNju9brq8Ra7UzMystZaSNLFkGt24IvWV7QysCCwPLC5p79KdU+UVbRGYKzUzs7yr/HVq\nMyKiuQe9bQ28GhHTASRdB2wMvC1puYiYlpoW30nbTwH6l+zfLy2bkl43Xd4iV2pmZgXQjn1qbwDD\nJC2WRituBTwPTAD2S9vsB9yYXk8ARklaVNKKZANCHk5NlR9JGpaOs2/JPs1ypWZmZhUTEQ9JugZ4\nDJgDPA5cBHQDxks6CHgdGJm2f1bSeOC5tP0REdGQDnc4MBboCtyaphY5qZmZ5Vx7X3wdEb8AftFk\n8RdkVdu8th8DjJnH8onAWq05t5OamVkB+I4iZmZmdcaVmplZERSjUHNSMzPLPbn50czMrO64UjMz\nK4CiVGpOamZmBVCUpObmRzMzyw1XamZmOVekJ187qZmZFUExcpqbH83MLD9cqZmZ5V2BrlNzUjMz\nK4CiJDU3P5qZWW64UjMzK4CiVGpOamZmRVCMnObmRzMzyw9XamZmBeDmRzMzywWpOHcUcfOjmZnl\nhis1M7MCKEql5qRmZlYARUlqbn40M7PccKVmZlYExSjUnNTMzIrAzY9mZmZ1xpWamVne+dEzZmaW\nFwIKktPc/GhmZvnhSs3MLPeKc5ssJzUzswIoSE5z86OZmeWHKzUzswIoSvOjKzUzM8sNV2pmZnmn\n4vSpOamZmeWcgA4dipHV3PxoZma54UrNzKwA3PxoZma54dGPZmZmdcaVmplZ3nn0o5mZ5UV2l/5i\nZDU3P1qL3po6mUP3HMHIbTZi5LbDuOJvFwDwr1tuYOS2w9hwUC+ee+rxL7efOvl1Nl1jWfbcYVP2\n3GFTfn3SMQB8/tlMjj5wJN/feigjtx3GH39zajXejtWYO26/jW+suRprrr4yZ515RrXDsRxwpWYt\n6tSpE0f/7DRWX2tdPv3kY/bdaQs22vTbDFp1Dc684DJ+fdLRX9un7wor8o+b7/3a8r0PPpIh39yc\n2bNmcfjeO3Pf3XeyyRbfaY+3YTWooaGBo390BDffeid9+/Vj02FDGTFiJ9YYPLjaoeWQ79JvBsBS\nyyzLUsssC8Di3bozcOVVmf7WNDba7NutOk6Xrosx5JubA7BI586sttY3eOetqRWP1+rHIw8/zKBB\nK7PiSisBsNvuo/jnTTc6qbWRguQ0Nz9a+aZOfp0Xnn2aNdfdoOXt3nydPXfYlNGjtufxh+//2vqP\nP/qAe+66jaEbf6utQrU6MHXqFPr16//lfN++/ZgyZUoVI7I8cKVmZZn56SeccPi+HHvK6XTrvkSz\n2y219LLcdO8z9OzVm+effoLjDt2Lq2574Mt95syZw0lH/YDd9zuEfgMGtlP0ZlaU5sc2q9Qkff0r\n+vz3eU3StSXz35c0tqKBzT+GUyUd157nrHVzZs/mhMP3ZfhOu7Hl8J1a3LbzoovSs1dvANZYe136\nDRjIG6++/OX60392FAMGrsSeBx7epjFb7Vt++b5Mnvzml/NTpkymb9++VYwox9KQ/kpNtazNklpE\nbLyAu24gaYEa1SW58qywiOD/nXgkAwetyl4/OHK+27//7gwaGhoAmPzGa7z52iv0TRXZBb89jU8+\n/ohjT/EoN4MhQ4cyadJLvPbqq8yaNYurr7qSHUa0/KXJbH7aLAlI+iQiuklaDrgKWCKd77CIuKeF\nXX8LnATs1eR4vYG/AisBM4HREfGUpFOBQWn5G5JuB3YBFgdWAc4GOgP7AF8A20fEe5IOBkandZOA\nfSJiZkXefI48OfFBbrn+KlZebTB77rApAEcc93NmzfqCs395Au+/N4NjDhrJqoPX5o/jruPxh+/j\nwj/8mk6dOtGhQwdOPO139OjZi7enTeGvfzqbgYNWZe8dswEjI/cdzS6771vNt2dV1KlTJ35/znns\nuMO2NDQ0sN/+BzJ4zTWrHVYuFek6tfaobPYEbo+IMZI6AovNZ/vxwOGSVm6y/JfA4xGxi6QtgUuB\nddO6wcCmEfGZpP2BtYD1gC5kCeuEiFhP0u+BfYE/ANdFxMUAkk4DDgL+2FJgkkaTJUKWXb5/S5vm\nxrpDv8kjr3wwz3Xf3nbHry3bcrud2XK7nb+2vM9yfZs9jhXX8O22Z/h221c7jEIoSE5rl9GPjwAH\npIpq7Yj4eD7bNwBnAT9tsnxT4DKAiPgfYElJjSMWJkTEZyXb/m9EfBwR04EPgZvS8qeBgen1WpLu\nkfQ0WVU436+IEXFRRAyJiCG9ei85v83NzKydtXlSi4h/A5sDU4Cxksppb7os7VNuOfRpk/kvSl7P\nLZmfy3+r07HAkRGxNlkV2KXMc5mZ1R1JFZtqWZsnNUkrAG+npr6/AOvPb5+ImA38HjimZPE9pH42\nSVsAMyLio4UIrTswTdIiNOm/MzPLm6KMfmyPPrUtgOMlzQY+IevTKsclwMkl86cCf5X0FNlAkf0W\nMq5TgIeA6eln94U8npmZVVmbJbWI6JZ+jgPGlbnPwJLXXwDLl8y/Rzaqsek+pzaZH0vWtDivY365\nLiIuAC6Y3/HMzOqePPrRzMxyIhvSX+0o2kdVkpqkh4BFmyzeJyKerkY8ZmaWD1VJahGxUTXOa2ZW\nTLU/arFS3PxoZlYABclpfvSMmZnlhys1M7MCcPOjmZnlQx1cNF0pbn40M7PccKVmZpZzfvSMmZnl\nSlGSmpsfzcwsN1ypmZkVQEEKNSc1M7MicPOjmZlZnXGlZmaWd75OzczM8kLphsaVmso6p9RT0jWS\n/iPpeUnflNRb0p2SXko/e5Vs/1NJkyS9IGnbkuUbSHo6rTtX8wnASc3MzNrCOcBtEbE6sA7wPHAi\ncFdErALcleaRNBgYBawJDAfOl9QxHecC4GBglTQNb+mkTmpmZgUgVW6a/7nUA9gcuAQgImZFxAfA\nzsC4tNk4YJf0emfgyoj4IiJeBSYBG0paDlgiIh6MiAAuLdlnntynZmZWAB3at1NtRWA68DdJ6wCP\nAkcBfSJiWtrmLaBPet0XeLBk/8lp2ez0uunyZrlSMzOz1lpK0sSSaXST9Z2A9YELImI94FNSU2Oj\nVHlFpQNzpWZmVgAVLtRmRMSQFtZPBiZHxENp/hqypPa2pOUiYlpqWnwnrZ8C9C/Zv19aNiW9brq8\nWa7UzMxyLusLa7/RjxHxFvCmpNXSoq2A54AJwH5p2X7Ajen1BGCUpEUlrUg2IOTh1FT5kaRhadTj\nviX7zJMrNTMzaws/BP4uqTPwCnAAWSE1XtJBwOvASICIeFbSeLLENwc4IiIa0nEOB8YCXYFb09Qs\nJzUzswLo0M4XX0fEE8C8mii3amb7McCYeSyfCKxV7nmd1MzMCsD3fjQzM6szrtTMzAqgIIWak5qZ\nWd6J7P6PReDmRzMzyw1XamZmBdDeox+rxUnNzCzvWvHImHrn5kczM8sNV2pmZgVQkELNSc3MLO9E\nuz96pmrc/GhmZrnhSs3MrAAKUqg5qZmZFYFHP5qZmdUZV2pmZjmXPSS02lG0Dyc1M7MC8OhHMzOz\nOtNspSZpiZZ2jIiPKh+OmZm1hWLUaS03Pz4LBF/9LBrnAxjQhnGZmVkFFWX0Y7NJLSL6t2cgZmZm\nC6usPjVJoyT9LL3uJ2mDtg3LzMwqJbtNVuWmWjbfpCbpPODbwD5p0UzgwrYMyszMKig9eqZSUy0r\nZ0j/xhGxvqTHASLiPUmd2zguMzOzVisnqc2W1IFscAiSlgTmtmlUZmZWUTVeYFVMOUntT8C1wNKS\nfgmMBH7ZplGZmVlF1XqzYaXMN6lFxKWSHgW2Tot2i4hn2jYsMzOz1iv3NlkdgdlkTZC+C4mZWR1p\nHP1YBOWMfjwJuAJYHugH/EPST9s6MDMzqxyPfvyvfYH1ImImgKQxwOPAr9syMDMzs9YqJ6lNa7Jd\np7TMzMzqRG3XV5XT0g2Nf0/Wh/Ye8Kyk29P8NsAj7ROemZktLKk4j55pqVJrHOH4LHBzyfIH2y4c\nMzOzBdfSDY0vac9AzMys7RSkUJt/n5qkQcAYYDDQpXF5RKzahnGZmZm1WjnXnI0F/kbWz7gdMB64\nqg1jMjOzCivKkP5yktpiEXE7QES8HBEnkyU3MzOrE1LlplpWzpD+L9INjV+WdCgwBejetmGZmZm1\nXjlJ7RhgceBHZH1rPYAD2zIoMzOrHCEP6W8UEQ+llx/z3weFmplZvaiDZsNKaeni6+tJz1Cbl4jY\ntU0iMjMzW0AtVWrntVsUdahr546s1b9HtcOwOtNr6JHVDsHqzBcvvFGR49T6qMVKaeni67vaMxAz\nM2s7RXlmWFHep5mZFUC5Dwk1M7M6Jdz8+DWSFo2IL9oyGDMzaxt+8nUiaUNJTwMvpfl1JP2xzSMz\nMzNrpXL61M4FRgDvAkTEk8C32zIoMzOrrA6q3FTLyml+7BARrzdpj21oo3jMzKzCsns21ng2qpBy\nktqbkjYEQlJH4IfAi20blpmZWeuVk9QOI2uCHAC8DfwrLTMzszpR682GlVLOvR/fAUa1QyxmZtZG\nCtL6WNaTry9mHveAjIjRbRKRmZnZAiqn+fFfJa+7AN8F3mybcMzMrNIEfvRMo4i4qnRe0mXAvW0W\nkZmZVVxR7om4IO9zRaBPpQMxMzNbWOX0qb3Pf/vUOgDvASe2ZVBmZlZZBWl9bDmpKbtabx1gSlo0\nNyKafXComZnVHkmF6VNrsfkxJbBbIqIhTU5oZmZWs8rpU3tC0nptHomZmbWZ7FZZlZlqWbPNj5I6\nRcQcYD3gEUkvA5+SjQ6NiFi/nWI0M7OF5DuKwMPA+sBO7RSLmZnZQmkpqQkgIl5up1jMzKwN+OLr\nzNKSjm1uZUT8rg3iMTOzNlCQnNZiUusIdCNVbGZmZrWupaQ2LSJ+1W6RmJlZ26iDJ1ZXynz71MzM\nrP6pIH/SW7pObat2i8LMzKwCmq3UIuK99gzEzMzaRjb6sdpRtI9ynqdmZmZ1rihJrSiP2DEzswJw\npWZmVgAqyIVqrtTMzHKusU+tUlNZ55Q6Snpc0j/TfG9Jd0p6Kf3sVbLtTyVNkvSCpG1Llm8g6em0\n7lyVkZmd1MzMrC0cBTxfMn8icFdErALcleaRNBgYBawJDAfOl9Qx7XMBcDCwSpqGz++kTmpmZnlX\nwcfOlNOKKakfsAPwl5LFOwPj0utxwC4ly6+MiC8i4lVgErChpOWAJSLiwfQsz0tL9mmW+9TMzAqg\nwjc0XkrSxJL5iyLiopL5PwA/AbqXLOsTEdPS67eAPul1X+DBku0mp2Wz0+umy1vkpGZmZq01IyKG\nzGuFpBHAOxHxqKQt5rVNRISkaIvAnNTMzHKunS++3gTYSdL2QBdgCUmXA29LWi4ipqWmxXfS9lOA\n/iX790vLpqTXTZe3yH1qZmYF0F59ahHx04joFxEDyQaA/E9E7A1MAPZLm+0H3JheTwBGSVpU0opk\nA0IeTk2VH0kalkY97luyT7NcqZmZWXs4Axgv6SDgdWAkQEQ8K2k88BwwBzgiIhrSPocDY4GuwK1p\napGTmplZ7okOVbhLf0TcDdydXr9LMzfKj4gxwJh5LJ8IrNWaczqpmZnlnCjOk6/dp2ZmZrnhSs3M\nLO/85GszM8uTCl98XbPc/GhmZrnhSs3MLOeKNFDESc3MrADc/GhmZlZnXKmZmRVAQQo1JzUzs7wT\nxWmWK8r7NDOzAnClZmaWdwIVpP3RSc3MrACKkdLc/GhmZjniSs3MLOeyJ18Xo1ZzUjMzK4BipDQ3\nP5qZWY64UjMzK4CCtD46qZmZ5Z8KM6TfzY9mZpYbrtTMzHKuSLfJclIzMysANz+amZnVGVdqZmYF\nUIw6zUnNKuiO22/juGOPoqGhgf0P/AHH/+TEaodkVXTEHltwwK4bI4m/XXcf5/3jbgAOG/UtDhm5\nGQ1zg9vueYaTzrmRRTp15LyT92D9wQOYG3M57sxruefRlwAYOXwDjj9wWyKCadM/5MCTx/HuB59W\n743VI9/Q2Kx1GhoaOPpHR3DzrXfSt18/Nh02lBEjdmKNwYOrHZpVweBBy3HArhuz2T5nMWt2AxP+\ndDi33PMM/fr0YsQWa7Ph7mcwa/Yclu7VDYADd90EgKEjT2fpXt244bzD2XTvs+jQQZx1/PdZ/3un\n8e4HnzLmqJ05dPdvMebPt1Tz7VkNc5+aVcQjDz/MoEErs+JKK9G5c2d2230U/7zpxmqHZVWy+orL\n8sgzr/HZ57NpaJjLPY9OYpct12X0bptx9t/uZNbsOQBMf/+TbPuVluXuR174ctmHH3/GBoMHIGUX\nDS/etTMA3bt1Zdr0D6vzpupY4+jHSk21rNbjszoxdeoU+vXr/+V83779mDJlShUjsmp69uWpbLLe\nyvTusThduyzC8E3XpN+yvVh5hWXYZL1B/PvS47jjL0exweABADz94hRGfGttOnbswArLL8l6g/vT\nb9lezJkzl6NOv4pHxv+MV+4YwxorLcvYG+6v8rurT5IqNtUyNz+aWcW98Orb/Hbsndx0/hHM/HwW\nT74wmYaGuXTq2IHePRZn833PZsiaK3D5mQeyxohTGXfjA6y+Yh/u+/tPeGPaezz45KvZ9p06cPD3\nN2PYHr/h1ckz+P0Ju3H8gdvwm7/cXu23aDWq3So1SQv09UrSupJC0vCSZT0lHV4yP1DSngsR292S\nhizo/gbLL9+XyZPf/HJ+ypTJ9O3bt4oRWbWNu+EBNtnrTL5z0B/44KOZvPT6O0x5+wNuuOsJACY+\n+zpz5wZL9epGQ8NcfvLb6xg26gxGHnMRPbt35aU33mGdVfsB8OrkGQBcc+djDFtnpaq9p3qmCk61\nrN2SWkRsvIC77gHcm3426gkcXjI/EFjgpGYLb8jQoUya9BKvvfoqs2bN4uqrrmSHETtVOyyrosZB\nIP2X7cXOW67DVbdO5Ka7n+JbQ1cFYOUBy9B5kU7MeP8TunZZhMW6ZP1mW260OnMa5vKfV95i6vQP\nWX2lZVkqHWurYavzwqtvVecNWV1ot+ZHSZ9ERDdJywFXAUuk8x8WEfc0s4+A3YDvAPdI6hIRnwNn\nAIMkPQHcCWwGrJHmxwHXA5cBi6dDHRkR96djngDsDcwFbo2IE0vO1wH4KzA5Ik6eRzyjgdEA/QcM\nWKjPI286derE7885jx132JaGhgb22/9ABq+5ZrXDsiq64uwf0Lvn4sye08DRZ4znw08+Y9wND/Dn\nU/di4tU/Y9bsBn7w88sAWLpXd246/wjmzg2mTv+Ag04eB8C06R9y+kW3cudfjmb2nAbemPYeo39x\neTXfVt0itlDpAAASLUlEQVSq8a6wilFEtM+J/pvUfgx0iYgxkjoCi0XEx83sswnwq4jYStI/gGsj\n4lpJA4F/RsRaabstgOMiYkSaXwyYGxGfS1oFuCIihkjaDjgF2DoiZkrqHRHvSbobOBE4CngmIsbM\n7/1ssMGQuO+hiQv1mVjx9Bp6ZLVDsDrzxQvjmTvznYVKSausuU787so7KhUSO31j2Ucjoia7bKox\n+vER4ABJpwJrN5fQkj2AK9PrK/lqE2RLFgEulvQ0cDXQeLHU1sDfImImQES8V7LPnykzoZmZWW1q\n96QWEf8GNgemAGMl7Tuv7VIV9z3g55JeA/4IDJfUvYzTHAO8DawDDAE6l7HP/cC3JXUpY1szs7rS\neM1fJaZa1u5JTdIKwNsRcTHwF2D9ZjbdCngqIvpHxMCIWAG4Fvgu8DFQmtyazvcApkXEXGAfoGNa\nfidZlbhYiqV3yT6XALcA4yX5UgczyxFV9L9aVo3mxy2AJyU9DuwOnNPMdnuQDfgodS2wR0S8C9wn\n6RlJZwFPAQ2SnpR0DHA+sJ+kJ4HVgU8BIuI2YAIwMQ0qOa704BHxO+Bx4LI0aMTMzOpIu1UkEdEt\n/RxHNkJxftsfMI9lE8iSEhHRdAj/lk3mv1Hy+oSSY5xBNnqy9LhblLz+xfxiMzOrN7XebFgpbmYz\nM8u57N6PxchqNZHUJD0ELNpk8T4R8XQ14jEzs/pUE0ktIjaqdgxmZrlVB6MWK6UmkpqZmbWtoiQ1\nj/AzM7PccKVmZlYAtX59WaU4qZmZ5ZyADsXIaW5+NDOz/HClZmZWAG5+NDOz3PDoRzMzszrjSs3M\nrADc/GhmZrng0Y9mZmZ1yJWamVnu1f7DPSvFSc3MLO8KdENjNz+amVluuFIzMyuAghRqTmpmZnmX\njX4sRlpz86OZmeWGKzUzswIoRp3mpGZmVgwFyWpufjQzs9xwpWZmVgC++NrMzHKjIIMf3fxoZmb5\n4UrNzKwAClKoOamZmRVCQbKamx/NzCw3XKmZmeWc8OhHMzPLCz96xszMrP44qZmZFYAqOM33XFJ/\nSf8r6TlJz0o6Ki3vLelOSS+ln71K9vmppEmSXpC0bcnyDSQ9ndadK7VcczqpmZkVQXtmNZgD/Dgi\nBgPDgCMkDQZOBO6KiFWAu9I8ad0oYE1gOHC+pI7pWBcABwOrpGl4Syd2UjMzs4qKiGkR8Vh6/THw\nPNAX2BkYlzYbB+ySXu8MXBkRX0TEq8AkYENJywFLRMSDERHApSX7zJMHipiZ5Z6qNvpR0kBgPeAh\noE9ETEur3gL6pNd9gQdLdpucls1Or5sub5aTmplZAVR49ONSkiaWzF8UERd9/ZzqBlwLHB0RH5V2\nh0VESIqKRoWTmpmZtd6MiBjS0gaSFiFLaH+PiOvS4rclLRcR01LT4jtp+RSgf8nu/dKyKel10+XN\ncp+amVnOVXKMSJmjHwVcAjwfEb8rWTUB2C+93g+4sWT5KEmLSlqRbEDIw6mp8iNJw9Ix9y3ZZ55c\nqZmZFUH7dqltAuwDPC3pibTsZ8AZwHhJBwGvAyMBIuJZSeOB58hGTh4REQ1pv8OBsUBX4NY0NctJ\nzczMKioi7qX5NLpVM/uMAcbMY/lEYK1yz+2kZmZWAL73o5mZ5Ybv/WhmZlZnXKmZmRVAQQo1JzUz\ns9wr/56Ndc/Nj2Zmlhuu1MzMCsCjH83MLBeERz+amZnVHVdqZmYFUJBCzUnNzKwQCpLV3PxoZma5\n4UrNzKwAPPrRzMxyw6MfzczM6owrNTOzAihIoeakZmZWCAXJam5+NDOz3HClZmaWc9lN+otRqjmp\nmZnlnTz60czMrO64UjMzK4CCFGpOamZmhVCQrOaktoAee+zRGV0X0evVjqMGLQXMqHYQVnf8e9O8\nFaodQD1xUltAEbF0tWOoRZImRsSQasdh9cW/N21NHv1oZmb54dGPZmZmdcaVmlXaRdUOwOqSf2/a\nkCjMOBEnNausiPAfJ2s1/960g4JkNTc/mplZbrhSMzMrgKKMfnSlZmZmueFKzapOUm9gqYh4sdqx\nWP2RpIiIasdR6zyk36wdSOoC/Ag4UNIa1Y7H6oek/gBOaOVRBada5qRmVRURnwP/SrO7SRpczXis\ndknqJqlzer0GcKak7lUOy2qMk5pVjZQ1iETEvcAEYAng+05s1pSkxYG/A7ulRTPT9ImkRdI2tV5E\nVE96nlqlplrmpGZV0dgPImlFSZ0i4n7gb0APssTmpkj7UkR8ClwFHCBpd2Ag8FlkZqdt3AzZomI0\nQHqgiFVFSmg7AKcA90j6BPgD2Z0lDgL2lvT3iHiumnFa9UnqGBENEfEPSdOBE4BHgRUlnQNMBr4A\nOkXE76oZq1WfKzWrCknDgNOB3cm+XO0CnAlMB8YBiwOzqhag1YRU0TdI+o6kMyPiTuAcYCuy3483\n0s9uwENVDLWmieI0P7pSs3YlqQMQZM/P2hdYHdgcOBEYDZxN9k38pNTkZAWWKvqtgPOBQ9KymyTN\nAY4FXoyIm6oZY72o8VxUMa7UrF2UdOJ3S/0g/4yIJ8kqtB9ExO3AO2RftPo4oZkynYDhwCkR8T+N\nox8j4lbgQuAESX2rGafVFic1axclfWh3STpV0q5p1TLAaEkbARsCZ0fEM1UL1GpG+vIzB/gcGCap\nS0TMApA0FLgF2CkiplQzznpRlOZHJzVrF5KWA/Yia158D9g2JbkDgf7Az4FfR8RT1YvSqq2xopc0\nQFK/tPhWYBHgW2ndOsDvgVUj4r2qBFqHVMH/apn71KzNSRoCrANMiYirJC0NbAt8F1gkIkZIWiwi\nZvqWR8VWUtH/GrhfUu+IGJku8dhH0glkl32clpqvzb7CSc3alKQtyEYz3k42TP+KiHhM0q1AZ2Bn\nSQ9HxFTwtUZFVXLd4jCyUbAjyCqzv0r6V0RsLWks2ZejDyPiZX8BaqXaLrAqxknN2oykFYGfAftE\nxL8lTQIul7RXRDwu6UbgtsaEZsWT7v05Ow3b7wO8C4wEViEb7dgDuFvS/RGxMfBY475OaK1TkJzm\nPjWrrJI+kaFk37R7kI1wJCLOBC4BJkjaICLedUIrrnR5x8bA0ZJGkPWrfgw8B+wA/DUiPiar9Aek\n3ymzFjmpWUWlJqTNyZqQnia7wHoxSUem9b8F/kR2sazZU8A2wGXANRHxFllRMQ0YJOlgsqbI70TE\nI9ULs75VcuSjRz9aoUhaDTgMGBsRjwJ3A3cBq0v6MUBEnBER/+cb0BaTpMUl9YuIucAKafH/Atul\nYftzyZ7cMJMsoV0YEc9XKdzcKMroRyc1q7S1gT7A1pKWjogPgduA+4HVJDX+EXOfSHENBP4o6STg\nOODHwA/JntLQeO/GV8gS3fci4jp/AbJyOanZQinpQ+snqUdEXEN2k+KPyO62v2TqF7kJ+HlEvF7F\ncK0GRMSzwCSyQUQPpYvtp5PdCmtRSXeRVfiz08XX/gJUCcW4Sb9HP9qCk9QhIuZK2o6sD+0FScuQ\nDQz5J7Ad2bVFl0XEu2SDAKyAJPUEZkXEzLToGeC3wL6Sno6Iu4CnUvX2HWBqRDxYpXBzqcZzUcU4\nqVmrSeoaEZ+lhLYy8P+AQyLifknnAjeQXVy9SPq5ONlQbSsgSb2BF4F/SbonIv4UEePSujeB30na\nD/gA2LXx8TG+Ds0WhJOatYqkHsAZkq6PiDvI/hD9h+yPFhHxI0lXACdGxC8kPRIR06oYslXf+8Ad\nZCMa95K0IXAvcHVEXCxpFnAtMAc4unEnJ7TKKkqvpPvUrLWWIOsP2TM9EuQjYElg65JtbiE9C80J\nzVJyeoxsANHmwNj08/8kfZtsQMhGZINCbq1WnPlWybGPtZ0dXalZWSR1j4iPI+JNSZcCo8huRjyd\nrMN/rKTVgQ/T8p9UL1qrNRFxtqRbyL78PAOsS1bhjwJWBnb30xmsEpzUbL4kDQSukfQoMB54Cfgb\n8AXZcOzfALuRDQxZHjgmIv7lPhEDkNQxIhrIKrTvkt1h/5KU6JYhu6n1jGrGmHeNT74uAic1K0cX\nYDlgZ+A1sjuCXAj0Irv+7BRgTEScU7qTE5oBpIQG8BBwKvBARJydlk3374lVkvvUrEVp2P5/yJqN\nPgTeAHYHppLd2/H7af5MST3T/fzMviJV7a8DxwLdGp9W7YRmleZKzVqUhu13iIjnJe0NXAmcHhGX\nSLqG7G7qOwNPRMQHVQ3Wqqrk8TEd0q2uvlSSvCYDc7++t7U1Nz+aJSWJ7RFJo4Ar0j36/gS8QHbh\nta8rKrCShLYVWSV2e0R83nS7iHhG0gkRMaUKYRZarY9arBQ3FVlZShMbWXPjKZKOaLKNE1oBpYEg\nIWk4cAHw/rwSmjIdIuJ1SYtJWrL9o7W8c1Kzryi5l+PXfjdKEtujwI7As+0dn9UOSSunSz0aJPUi\nGzB0aHog7GaS9ksXWjdqvK1aT7Jr03pXJfAiKtCjZ9z8aF8qpwmpScXmJsdi6wMsI+nBiHhf0v8C\nB6VnoHUAZpP1uT4sqVNEzEl3pLkaOD4iXqpe6MVSB/chrhhXagaU34TUuHnapyvZsH4roIi4j+xB\nsK9IWoLsOrSHgT9GxO5k1zSuKalzSmi9gOuBX0XEv6sVt+Wbk1rBtbYJqfFC2tSEdDfZLbKsoNJj\nhY4iu15xRkSck25svRnZja7/EhGz0uZ7AKdFxD1VCrfY/OgZKwg3IdlCiYgbJc0GHpW0AfA52fWL\nJ0fEzY1N1BFxfnUjLbaijH50Uiu4iLhPUneyJqRvkDUh7QA8kr5x7wQckJqQZqVq7lrgF/7GbY0i\n4hZJc4HngdWAEyLi85J+Wve9Wrtw86O5CckqIiJuA34ArNfYH9uYyJzQqs+jH61Q3IRklRARN4NH\nxdaiGs9FFeOkZl9yE5JVin9PrFrc/Ghf4SYks5xqx9GPkoZLekHSJEknVvqttMSVmn2Nm5DM8qe9\nRj9K6kj2eKrvkN3A+hFJEyLiufY4vys1a5YTmpktgA2BSRHxShpgdiXZkzzahSs1M7Oca+cnX/cF\n3iyZnwxs1F4nd1IzM8u5xx579Paui2ipCh6yi6SJJfMXRcRFFTz+AnNSMzPLuYgY3o6nmwL0L5nv\nl5a1C/epWW5JapD0hKRnJF0tabGFONYWkv6ZXu/U0oguST0lHb4A5zhV0nHlLm+yzVhJ32/FuQZK\neqa1MZqV4RFgFUkrSuoMjAImtNfJndQszz6LiHUjYi1gFnBo6crGh1a29qARMSEizmhhk55Aq5Oa\nWR5ExBzgSOB2smtex0dEuz170UnNiuIeYOVUobwg6VLgGaC/pG0kPSDpsVTRdYMvr7X5j6THgF0b\nDyRpf0nnpdd9JF0v6ck0bQycAQxKVeJZabvjJT0i6SlJvyw51kmSXpR0L9kF7y2SdHA6zpOSrm1S\nfW4taWI63oi0fUdJZ5Wc+5CF/SDN5icibomIVSNiUESMac9zO6lZ7knqBGxH9uwvyJ46cH5ErAl8\nCpwMbB0R6wMTgWMldQEuJnvC9wbAss0c/lzg/yJiHWB9sqeBnwi8nKrE4yVtk865IbAusIGkzdPt\nyEalZdsDQ8t4O9dFxNB0vueBg0rWDUzn2AG4ML2Hg4API2JoOv7BklYs4zxmdckDRSzPukp6Ir2+\nB7gEWB54PSIeTMuHAYOB+5SNee4MPACsDrza+GgdSZcDo+dxji2BfQEiogH4MD3JoNQ2aXo8zXcj\nS3LdgesjYmY6Rzn9DmtJOo2sibMbWRNPo/ERMRd4SdIr6T1sA3yjpL+tRzr3i2Wcy6zuOKlZnn0W\nEeuWLkiJ69PSRcCdEbFHk+2+st9CEvDriPhzk3McvQDHGgvsEhFPStof2KJkXdOL5SOd+4cRUZr8\nkDRwAc5tVvPc/GhF9yCwiaSVASQtLmlV4D/AQEmD0nZ7NLP/XcBhad+Oyh6g+jFZFdboduDAkr66\nvpKWAf4N7CKpq7Jn2u1YRrzdgWmSFgH2arJuN0kdUswrAS+kcx+WtkfSqpIWL+M8ZnXJlZoVWkRM\nTxXPFZIWTYtPjogXJY0GbpY0k6z5svs8DnEUcJGkg4AG4LCIeEDSfWnI/K2pX20N4IFUKX4C7B0R\nj0m6CngSeIdsKPT8nAI8BExPP0tjegN4GFgCODQ9YeEvZH1tjyk7+XRgl/I+HbP6I9/ez8zM8sLN\nj2ZmlhtOamZmlhtOamZmlhtOamZmlhtOamZmlhtOamZmlhtOamZmlhtOamZmlhv/H8AVpG+Ukje5\nAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7fab3c2529e8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot(actual_value = Train.actual_value_, pred_value = Train.pred_value_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-07-17T21:26:38.875703Z",
     "start_time": "2017-07-17T21:26:38.781779Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#4.5 GB\n",
    "pd.Series(Train.pred_value).to_csv('LSTM_prediction_values.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-07-17T21:26:38.900961Z",
     "start_time": "2017-07-17T21:26:38.878159Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>epoch</th>\n",
       "      <th>train_score</th>\n",
       "      <th>test_score</th>\n",
       "      <th>f1_score</th>\n",
       "      <th>test_score_20</th>\n",
       "      <th>f1_score_20</th>\n",
       "      <th>time_taken</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>no_of_features</th>\n",
       "      <th>hidden_layers</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"23\" valign=\"top\">1</th>\n",
       "      <th>1</th>\n",
       "      <td>11</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.899175</td>\n",
       "      <td>0.907590</td>\n",
       "      <td>0.808186</td>\n",
       "      <td>0.875975</td>\n",
       "      <td>8.658957</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>11</td>\n",
       "      <td>0.999206</td>\n",
       "      <td>0.980704</td>\n",
       "      <td>0.983254</td>\n",
       "      <td>0.963291</td>\n",
       "      <td>0.977927</td>\n",
       "      <td>8.956038</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>11</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.899175</td>\n",
       "      <td>0.907590</td>\n",
       "      <td>0.808186</td>\n",
       "      <td>0.875975</td>\n",
       "      <td>8.658957</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>11</td>\n",
       "      <td>0.999206</td>\n",
       "      <td>0.980704</td>\n",
       "      <td>0.983254</td>\n",
       "      <td>0.963291</td>\n",
       "      <td>0.977927</td>\n",
       "      <td>8.956038</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>11</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.903699</td>\n",
       "      <td>0.912080</td>\n",
       "      <td>0.816793</td>\n",
       "      <td>0.882158</td>\n",
       "      <td>13.398739</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>11</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.999734</td>\n",
       "      <td>0.999766</td>\n",
       "      <td>0.999494</td>\n",
       "      <td>0.999691</td>\n",
       "      <td>12.354382</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>11</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.918559</td>\n",
       "      <td>0.924326</td>\n",
       "      <td>0.845063</td>\n",
       "      <td>0.897955</td>\n",
       "      <td>11.249477</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>11</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.999734</td>\n",
       "      <td>0.999766</td>\n",
       "      <td>0.999494</td>\n",
       "      <td>0.999691</td>\n",
       "      <td>6.295392</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>11</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.897667</td>\n",
       "      <td>0.905940</td>\n",
       "      <td>0.805316</td>\n",
       "      <td>0.873638</td>\n",
       "      <td>10.647751</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>11</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.993701</td>\n",
       "      <td>0.994492</td>\n",
       "      <td>0.988017</td>\n",
       "      <td>0.992722</td>\n",
       "      <td>27.259746</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>22</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.994633</td>\n",
       "      <td>0.995302</td>\n",
       "      <td>0.989789</td>\n",
       "      <td>0.993791</td>\n",
       "      <td>38.527330</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>11</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.906450</td>\n",
       "      <td>0.914591</td>\n",
       "      <td>0.822025</td>\n",
       "      <td>0.885524</td>\n",
       "      <td>7.625335</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>11</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.999290</td>\n",
       "      <td>0.999377</td>\n",
       "      <td>0.998650</td>\n",
       "      <td>0.999175</td>\n",
       "      <td>11.787666</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>11</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.899574</td>\n",
       "      <td>0.908087</td>\n",
       "      <td>0.808945</td>\n",
       "      <td>0.876702</td>\n",
       "      <td>9.361751</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>11</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.986914</td>\n",
       "      <td>0.988427</td>\n",
       "      <td>0.975105</td>\n",
       "      <td>0.984652</td>\n",
       "      <td>9.510270</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>11</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.891501</td>\n",
       "      <td>0.899655</td>\n",
       "      <td>0.793586</td>\n",
       "      <td>0.864907</td>\n",
       "      <td>11.260245</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>11</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.976579</td>\n",
       "      <td>0.979063</td>\n",
       "      <td>0.955443</td>\n",
       "      <td>0.972134</td>\n",
       "      <td>6.629817</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>11</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.899707</td>\n",
       "      <td>0.908250</td>\n",
       "      <td>0.809198</td>\n",
       "      <td>0.876939</td>\n",
       "      <td>6.418205</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>11</td>\n",
       "      <td>0.998810</td>\n",
       "      <td>0.991084</td>\n",
       "      <td>0.992140</td>\n",
       "      <td>0.983122</td>\n",
       "      <td>0.989639</td>\n",
       "      <td>8.618293</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>11</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.898776</td>\n",
       "      <td>0.907130</td>\n",
       "      <td>0.807426</td>\n",
       "      <td>0.875314</td>\n",
       "      <td>11.615757</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>11</td>\n",
       "      <td>0.998016</td>\n",
       "      <td>0.999379</td>\n",
       "      <td>0.999455</td>\n",
       "      <td>0.999156</td>\n",
       "      <td>0.999485</td>\n",
       "      <td>11.837164</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>11</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.893586</td>\n",
       "      <td>0.902110</td>\n",
       "      <td>0.797553</td>\n",
       "      <td>0.868454</td>\n",
       "      <td>8.407638</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>11</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.997072</td>\n",
       "      <td>0.997422</td>\n",
       "      <td>0.994430</td>\n",
       "      <td>0.996586</td>\n",
       "      <td>11.624922</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                              epoch  train_score  test_score  f1_score  \\\n",
       "no_of_features hidden_layers                                             \n",
       "1              1                 11     1.000000    0.899175  0.907590   \n",
       "               3                 11     0.999206    0.980704  0.983254   \n",
       "               1                 11     1.000000    0.899175  0.907590   \n",
       "               3                 11     0.999206    0.980704  0.983254   \n",
       "               1                 11     1.000000    0.903699  0.912080   \n",
       "               3                 11     1.000000    0.999734  0.999766   \n",
       "               1                 11     1.000000    0.918559  0.924326   \n",
       "               3                 11     1.000000    0.999734  0.999766   \n",
       "               1                 11     1.000000    0.897667  0.905940   \n",
       "               3                 11     1.000000    0.993701  0.994492   \n",
       "               3                 22     1.000000    0.994633  0.995302   \n",
       "               1                 11     1.000000    0.906450  0.914591   \n",
       "               3                 11     1.000000    0.999290  0.999377   \n",
       "               1                 11     1.000000    0.899574  0.908087   \n",
       "               3                 11     1.000000    0.986914  0.988427   \n",
       "               1                 11     1.000000    0.891501  0.899655   \n",
       "               3                 11     1.000000    0.976579  0.979063   \n",
       "               1                 11     1.000000    0.899707  0.908250   \n",
       "               3                 11     0.998810    0.991084  0.992140   \n",
       "               1                 11     1.000000    0.898776  0.907130   \n",
       "               3                 11     0.998016    0.999379  0.999455   \n",
       "               1                 11     1.000000    0.893586  0.902110   \n",
       "               3                 11     1.000000    0.997072  0.997422   \n",
       "\n",
       "                              test_score_20  f1_score_20  time_taken  \n",
       "no_of_features hidden_layers                                          \n",
       "1              1                   0.808186     0.875975    8.658957  \n",
       "               3                   0.963291     0.977927    8.956038  \n",
       "               1                   0.808186     0.875975    8.658957  \n",
       "               3                   0.963291     0.977927    8.956038  \n",
       "               1                   0.816793     0.882158   13.398739  \n",
       "               3                   0.999494     0.999691   12.354382  \n",
       "               1                   0.845063     0.897955   11.249477  \n",
       "               3                   0.999494     0.999691    6.295392  \n",
       "               1                   0.805316     0.873638   10.647751  \n",
       "               3                   0.988017     0.992722   27.259746  \n",
       "               3                   0.989789     0.993791   38.527330  \n",
       "               1                   0.822025     0.885524    7.625335  \n",
       "               3                   0.998650     0.999175   11.787666  \n",
       "               1                   0.808945     0.876702    9.361751  \n",
       "               3                   0.975105     0.984652    9.510270  \n",
       "               1                   0.793586     0.864907   11.260245  \n",
       "               3                   0.955443     0.972134    6.629817  \n",
       "               1                   0.809198     0.876939    6.418205  \n",
       "               3                   0.983122     0.989639    8.618293  \n",
       "               1                   0.807426     0.875314   11.615757  \n",
       "               3                   0.999156     0.999485   11.837164  \n",
       "               1                   0.797553     0.868454    8.407638  \n",
       "               3                   0.994430     0.996586   11.624922  "
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "past_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-07-17T21:26:38.922782Z",
     "start_time": "2017-07-17T21:26:38.903238Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>epoch</th>\n",
       "      <th>train_score</th>\n",
       "      <th>test_score</th>\n",
       "      <th>f1_score</th>\n",
       "      <th>test_score_20</th>\n",
       "      <th>f1_score_20</th>\n",
       "      <th>time_taken</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>no_of_features</th>\n",
       "      <th>hidden_layers</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">1</th>\n",
       "      <th>1</th>\n",
       "      <td>11.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.900715</td>\n",
       "      <td>0.908850</td>\n",
       "      <td>0.811116</td>\n",
       "      <td>0.877595</td>\n",
       "      <td>9.754801</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>11.916667</td>\n",
       "      <td>0.999603</td>\n",
       "      <td>0.991627</td>\n",
       "      <td>0.992643</td>\n",
       "      <td>0.984107</td>\n",
       "      <td>0.990285</td>\n",
       "      <td>13.529755</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                  epoch  train_score  test_score  f1_score  \\\n",
       "no_of_features hidden_layers                                                 \n",
       "1              1              11.000000     1.000000    0.900715  0.908850   \n",
       "               3              11.916667     0.999603    0.991627  0.992643   \n",
       "\n",
       "                              test_score_20  f1_score_20  time_taken  \n",
       "no_of_features hidden_layers                                          \n",
       "1              1                   0.811116     0.877595    9.754801  \n",
       "               3                   0.984107     0.990285   13.529755  "
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pgb = past_scores.groupby(by=['no_of_features', 'hidden_layers'])\n",
    "pgb.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-07-17T21:26:38.959564Z",
     "start_time": "2017-07-17T21:26:38.924552Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>epoch</th>\n",
       "      <th>train_score</th>\n",
       "      <th>test_score</th>\n",
       "      <th>f1_score</th>\n",
       "      <th>test_score_20</th>\n",
       "      <th>f1_score_20</th>\n",
       "      <th>time_taken</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>no_of_features</th>\n",
       "      <th>hidden_layers</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">1</th>\n",
       "      <th>1</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.007184</td>\n",
       "      <td>0.006545</td>\n",
       "      <td>0.013666</td>\n",
       "      <td>0.008775</td>\n",
       "      <td>2.051287</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3.175426</td>\n",
       "      <td>0.000655</td>\n",
       "      <td>0.008425</td>\n",
       "      <td>0.007418</td>\n",
       "      <td>0.016056</td>\n",
       "      <td>0.009842</td>\n",
       "      <td>9.564911</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                 epoch  train_score  test_score  f1_score  \\\n",
       "no_of_features hidden_layers                                                \n",
       "1              1              0.000000     0.000000    0.007184  0.006545   \n",
       "               3              3.175426     0.000655    0.008425  0.007418   \n",
       "\n",
       "                              test_score_20  f1_score_20  time_taken  \n",
       "no_of_features hidden_layers                                          \n",
       "1              1                   0.013666     0.008775    2.051287  \n",
       "               3                   0.016056     0.009842    9.564911  "
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pgb.std()"
   ]
  }
 ],
 "metadata": {
  "_draft": {
   "nbviewer_url": "https://gist.github.com/7d1ace18a82178e15ece8fc5252fce88"
  },
  "anaconda-cloud": {},
  "gist": {
   "data": {
    "description": "Hyper parameter tuning",
    "public": false
   },
   "id": "7d1ace18a82178e15ece8fc5252fce88"
  },
  "kernelspec": {
   "display_name": "Python [conda env:p3]",
   "language": "python",
   "name": "conda-env-p3-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
