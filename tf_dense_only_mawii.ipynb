{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Read Data Sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-10-17T22:30:49.237451Z",
     "start_time": "2017-10-17T22:30:48.834150Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "from collections import namedtuple\n",
    "pd.set_option(\"display.max_rows\",100)\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-10-17T22:30:49.250103Z",
     "start_time": "2017-10-17T22:30:49.238922Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "rm: cannot remove 'dataset/scores/tf_dense_only_nsl_kdd_scores_all.pkl': No such file or directory\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "rm dataset/scores/tf_dense_only_nsl_kdd_scores_all.pkl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-10-17T22:30:49.260866Z",
     "start_time": "2017-10-17T22:30:49.251607Z"
    }
   },
   "outputs": [],
   "source": [
    "train_paths = {\"20150304\":\"dataset/preprocessed_train_data.pkl\"}\n",
    "test_paths = {\"20150604\":\"dataset/preprocessed_train_data.pkl\"}\n",
    "\n",
    "class preprocess:\n",
    "    \n",
    "    def get_data(paths):\n",
    "        \n",
    "        for key, value in paths.items():\n",
    "            sample_data = pd.read_pickle(value)\n",
    "            x = sample_data.iloc[:,:-2]\n",
    "            y = sample_data.iloc[:,-2:]\n",
    "            yield key, x.values, y.values\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-10-17T22:30:50.316591Z",
     "start_time": "2017-10-17T22:30:49.262056Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-10-17T22:30:50.493137Z",
     "start_time": "2017-10-17T22:30:50.318033Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class network(object):\n",
    "    \n",
    "    input_dim = 10\n",
    "    classes = 2\n",
    "    hidden_encoder_dim = 10\n",
    "    hidden_layers = 1\n",
    "    latent_dim = 5\n",
    "\n",
    "    def __init__(self, classes, hidden_layers, num_of_features):\n",
    "        self.classes = classes\n",
    "        self.hidden_layers = hidden_layers\n",
    "        self.latent_dim = num_of_features\n",
    "            \n",
    "    def build_layers(self):\n",
    "        tf.reset_default_graph()\n",
    "        #learning_rate = tf.Variable(initial_value=0.001)\n",
    "\n",
    "        input_dim = self.input_dim\n",
    "        classes = self.classes\n",
    "        hidden_encoder_dim = self.hidden_encoder_dim\n",
    "        hidden_layers = self.hidden_layers\n",
    "        latent_dim = self.latent_dim\n",
    "        \n",
    "        with tf.variable_scope(\"Input\"):\n",
    "            self.x = tf.placeholder(\"float\", shape=[None, input_dim])\n",
    "            self.y_ = tf.placeholder(\"float\", shape=[None, classes])\n",
    "            self.keep_prob = tf.placeholder(\"float\")\n",
    "            self.lr = tf.placeholder(\"float\")\n",
    "        \n",
    "        with tf.variable_scope(\"Layer_Encoder\"):\n",
    "\n",
    "            hidden_encoder = tf.layers.dense(self.x, hidden_encoder_dim, activation = tf.nn.relu, kernel_regularizer=tf.nn.l2_loss)\n",
    "            hidden_encoder = tf.nn.dropout(hidden_encoder, self.keep_prob)\n",
    "            for h in range(hidden_layers - 1):\n",
    "                hidden_encoder = tf.layers.dense(hidden_encoder, latent_dim, activation = tf.nn.relu, kernel_regularizer=tf.nn.l2_loss)\n",
    "                hidden_encoder = tf.nn.dropout(hidden_encoder, self.keep_prob)\n",
    "            \n",
    "            #hidden_encoder = tf.layers.dense(self.x, latent_dim, activation = tf.nn.relu, kernel_regularizer=tf.nn.l2_loss)\n",
    "            #hidden_encoder = tf.nn.dropout(hidden_encoder, self.keep_prob)\n",
    "            \n",
    "        with tf.variable_scope(\"Layer_Dense_Softmax\"):\n",
    "            self.y = tf.layers.dense(hidden_encoder, classes, activation=tf.nn.softmax)\n",
    "            \n",
    "        with tf.variable_scope(\"Loss\"):\n",
    "            \n",
    "            loss = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(labels = self.y_, logits = self.y))\n",
    "            #loss = tf.losses.mean_squared_error(labels = self.y_, predictions = self.y)\n",
    "            #loss = tf.clip_by_value(loss, -1e-1, 1e-1)\n",
    "            #loss = tf.where(tf.is_nan(loss), 1e-1, loss)\n",
    "            #loss = tf.where(tf.equal(loss, -1e-1), tf.random_normal(loss.shape), loss)\n",
    "            #loss = tf.where(tf.equal(loss, 1e-1), tf.random_normal(loss.shape), loss)\n",
    "            \n",
    "            self.regularized_loss = loss\n",
    "            correct_prediction = tf.equal(tf.argmax(self.y_, 1), tf.argmax(self.y, 1))\n",
    "            self.tf_accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32), name = \"Accuracy\")\n",
    "            \n",
    "        with tf.variable_scope(\"Optimizer\"):\n",
    "            learning_rate=self.lr\n",
    "            optimizer = tf.train.AdamOptimizer(learning_rate)\n",
    "            gradients, variables = zip(*optimizer.compute_gradients(self.regularized_loss))\n",
    "            gradients = [\n",
    "                None if gradient is None else tf.clip_by_value(gradient, -1, 1)\n",
    "                for gradient in gradients]\n",
    "            self.train_op = optimizer.apply_gradients(zip(gradients, variables))\n",
    "            #self.train_op = optimizer.minimize(self.regularized_loss)\n",
    "            \n",
    "        # add op for merging summary\n",
    "        #self.summary_op = tf.summary.merge_all()\n",
    "        self.pred = tf.argmax(self.y, axis = 1)\n",
    "        self.actual = tf.argmax(self.y_, axis = 1)\n",
    "\n",
    "        # add Saver ops\n",
    "        self.saver = tf.train.Saver()\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-10-17T22:30:51.033298Z",
     "start_time": "2017-10-17T22:30:50.494666Z"
    },
    "collapsed": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import collections\n",
    "import time\n",
    "from sklearn import model_selection as ms\n",
    "from sklearn import metrics as me\n",
    "\n",
    "class Train:    \n",
    "    \n",
    "    result = namedtuple(\"score\", ['key', 'no_of_features','hidden_layers','train_score', 'test_score', 'quality_score', 'time_taken'])\n",
    "\n",
    "    predictions = {}\n",
    "    results = []\n",
    "    \n",
    "    best_acc = 0\n",
    "    best_acc_global = 0\n",
    "    \n",
    "    def train(epochs, net, h,f, lrs):\n",
    "        batch_iterations = 1000\n",
    "        train_loss = None\n",
    "        Train.best_acc = 0\n",
    "        os.makedirs(\"dataset/tf_dense_only_nsl_kdd/hidden layers_{}_features count_{}\".format(epochs,h,f),\n",
    "                    exist_ok = True)\n",
    "        with tf.Session() as sess:\n",
    "            #summary_writer_train = tf.summary.FileWriter('./logs/kdd/VAE/training', graph=sess.graph)\n",
    "            #summary_writer_valid = tf.summary.FileWriter('./logs/kdd/VAE/validation')\n",
    "\n",
    "            sess.run(tf.global_variables_initializer())\n",
    "            start_time = time.perf_counter()\n",
    "            for c, lr in enumerate(lrs):\n",
    "                for epoch in range(1, (epochs+1)):\n",
    "                    \n",
    "                    for key, x_train, y_train in preprocess.get_data(train_paths):\n",
    "                        x_train, x_valid, y_train, y_valid, = ms.train_test_split(x_train, \n",
    "                                                                                  y_train, \n",
    "                                                                                  test_size=0.33)\n",
    "                        batch_indices = np.array_split(np.arange(x_train.shape[0]), \n",
    "                                                   batch_iterations)\n",
    "\n",
    "                        for i in batch_indices:\n",
    "\n",
    "                            def train_batch():\n",
    "                                nonlocal train_loss\n",
    "                                _, train_loss = sess.run([net.train_op, \n",
    "                                                                   net.regularized_loss, \n",
    "                                                                   ], #net.summary_op\n",
    "                                                                  feed_dict={net.x: x_train[i,:], \n",
    "                                                                             net.y_: y_train[i,:], \n",
    "                                                                             net.keep_prob:0.5, net.lr:lr})\n",
    "\n",
    "                            train_batch()\n",
    "                            #summary_writer_train.add_summary(summary_str, epoch)\n",
    "                            #print(\"Step {} | Training Loss: {:.6f}\".format(epoch, train_loss))\n",
    "                            while((train_loss > 1e4 or np.isnan(train_loss)) and epoch > 1):\n",
    "                                print(\"Step {} | Training Loss: {:.6f}\".format(epoch, train_loss))\n",
    "                                net.saver.restore(sess, \n",
    "                                                  tf.train.latest_checkpoint('dataset/tf_dense_only_nsl_kdd/hidden_layers_{}_features_count_{}'\n",
    "                                                                             .format(epochs,h,f)))\n",
    "                                train_batch()\n",
    "\n",
    "\n",
    "                        valid_accuracy = sess.run(net.regularized_loss, #net.summary_op \n",
    "                                                              feed_dict={net.x: x_valid, \n",
    "                                                                         net.y_: y_valid, \n",
    "                                                                         net.keep_prob:1, net.lr:lr})\n",
    "                        #summary_writer_valid.add_summary(summary_str, epoch)\n",
    "                    \n",
    "                        print(\"Key {} | Training Loss: {:.6f} | Validation Loss: {:.6f}\".format(key, train_loss, valid_accuracy))\n",
    "                    \n",
    "                    end_time = time.perf_counter() \n",
    "                    for key, x_test, y_test in preprocess.get_data(test_paths):\n",
    "                        accuracy, pred_value, actual_value, y_pred = sess.run([net.tf_accuracy, \n",
    "                                                                               net.pred, \n",
    "                                                                               net.actual, net.y], \n",
    "                                                                              feed_dict={net.x: x_test, \n",
    "                                                                                         net.y_: y_test, \n",
    "                                                                                         net.keep_prob:1, net.lr:lr})\n",
    "\n",
    "\n",
    "                        q_score = me.matthews_corrcoef(actual_value, pred_value)\n",
    "                        recall = me.recall_score(actual_value, pred_value)\n",
    "                        prec = me.precision_score(actual_value, pred_value)\n",
    "                        accuracy = me.roc_auc_score(actual_value, pred_value)\n",
    "\n",
    "                        print(\"Key {} Test Accuracy: {} Quality score: {}, recall {}, precision {}\".format(key, accuracy, q_score, recall, prec))\n",
    "\n",
    "                        if accuracy > Train.best_acc_global:\n",
    "                            Train.best_acc_global = accuracy\n",
    "                            Train.pred_value = pred_value\n",
    "                            Train.actual_value = actual_value\n",
    "\n",
    "                            Train.best_parameters = \"Hidden Layers:{}, Features Count:{}\".format(h, f)\n",
    "\n",
    "                        curr_pred = pd.DataFrame({\"Attack_prob\":y_pred[:,-2], \"Normal_prob\":y_pred[:, -1], \"Prediction\":pred_value, \"Actual\": actual_value})\n",
    "                        Train.predictions.update({\"{}_{}_{}\".format(key,f,h):(curr_pred, \n",
    "                                                   Train.result(key, f, h, valid_accuracy, accuracy, q_score, end_time - start_time))})\n",
    "\n",
    "                        #Train.results.append(Train.result(epochs, f, h,valid_accuracy, accuracy))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-10-17T22:30:51.091960Z",
     "start_time": "2017-10-17T22:30:51.034787Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import itertools\n",
    "\n",
    "df_results = []\n",
    "past_scores = []\n",
    "\n",
    "class Hyperparameters:\n",
    "#    features_arr = [2, 4, 8, 16, 32, 64, 128, 256]\n",
    "#    hidden_layers_arr = [2, 4, 6, 10]\n",
    "\n",
    "    def start_training():\n",
    "        global df_results\n",
    "        global past_scores\n",
    "        print(\"********************************** Training ******************************\")\n",
    "        Train.predictions = {}\n",
    "        Train.results = []\n",
    "    \n",
    "        \n",
    "        features_arr = [1, 4, 10] #8, 16, 42\n",
    "        hidden_layers_arr = [1, 3]\n",
    "\n",
    "        epochs = [20]\n",
    "        lrs = [1e-5]\n",
    "        print(\"***************************** Entering Loop **********************\")\n",
    "        for e, h, f in itertools.product(epochs, hidden_layers_arr, features_arr):\n",
    "            print(\"Current Layer Attributes - hidden layers:{} features count:{}\".format(h,f))\n",
    "            n = network(2,h,f)\n",
    "            n.build_layers()\n",
    "            Train.train(e, n, h,f, lrs)\n",
    "            \n",
    "        dict1 = {}\n",
    "        dict2 = []\n",
    "        for k, (v1, v2) in Train.predictions.items():\n",
    "            dict1.update({k: v1})\n",
    "            dict2.append(v2)\n",
    "        Train.predictions = dict1\n",
    "        Train.results = dict2\n",
    "        df_results = pd.DataFrame(Train.results)\n",
    "\n",
    "        #temp = df_results.set_index(['no_of_features', 'hidden_layers'])\n",
    "\n",
    "        if not os.path.isfile('dataset/scores/tf_dense_only_nsl_kdd_scores_all.pkl'):\n",
    "            past_scores = df_results#temp\n",
    "        else:\n",
    "            past_scores = pd.read_pickle(\"dataset/scores/tf_dense_only_nsl_kdd_scores_all.pkl\")\n",
    "\n",
    "        past_scores.append(df_results, ignore_index=True).to_pickle(\"dataset/scores/tf_dense_only_nsl_kdd_scores_all.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-10-17T22:33:26.865857Z",
     "start_time": "2017-10-17T22:30:51.093381Z"
    },
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "********************************** Training ******************************\n",
      "***************************** Entering Loop **********************\n",
      "Current Layer Attributes - hidden layers:1 features count:1\n",
      "Key 20150304 | Training Loss: 0.829787 | Validation Loss: 0.928843\n",
      "Key 20150604 Test Accuracy: 0.5245585075939343 Quality score: 0.03622469991799979, recall 0.7214014817428118, precision 0.1460124068371491\n",
      "Key 20150304 | Training Loss: 0.823081 | Validation Loss: 0.927180\n",
      "Key 20150604 Test Accuracy: 0.5228536506472546 Quality score: 0.03369740867427632, recall 0.7180058211324749, precision 0.14542247231153985\n",
      "Key 20150304 | Training Loss: 0.861609 | Validation Loss: 0.929864\n",
      "Key 20150604 Test Accuracy: 0.5225807280171264 Quality score: 0.03324212036119979, recall 0.7155803492679484, precision 0.14534990482588736\n",
      "Key 20150304 | Training Loss: 0.803778 | Validation Loss: 0.926026\n",
      "Key 20150604 Test Accuracy: 0.5225772146963708 Quality score: 0.03323711085999627, recall 0.7155803492679484, precision 0.14534860285654141\n",
      "Key 20150304 | Training Loss: 0.791417 | Validation Loss: 0.927005\n",
      "Key 20150604 Test Accuracy: 0.5225807280171264 Quality score: 0.03324212036119979, recall 0.7155803492679484, precision 0.14534990482588736\n",
      "Key 20150304 | Training Loss: 0.851192 | Validation Loss: 0.923745\n",
      "Key 20150604 Test Accuracy: 0.5225807280171264 Quality score: 0.03324212036119979, recall 0.7155803492679484, precision 0.14534990482588736\n",
      "Key 20150304 | Training Loss: 0.815203 | Validation Loss: 0.921385\n",
      "Key 20150604 Test Accuracy: 0.522591752889238 Quality score: 0.033258431939321376, recall 0.7156023990121715, precision 0.14535373260001075\n",
      "Key 20150304 | Training Loss: 0.789078 | Validation Loss: 0.916509\n",
      "Key 20150604 Test Accuracy: 0.522591752889238 Quality score: 0.033258431939321376, recall 0.7156023990121715, precision 0.14535373260001075\n",
      "Key 20150304 | Training Loss: 0.796958 | Validation Loss: 0.903643\n",
      "Key 20150604 Test Accuracy: 0.5225624935245033 Quality score: 0.0332131645928772, recall 0.7154701005468337, precision 0.1453444360333081\n",
      "Key 20150304 | Training Loss: 0.794268 | Validation Loss: 0.867835\n",
      "Key 20150604 Test Accuracy: 0.5225677635056368 Quality score: 0.033220678623682706, recall 0.7154701005468337, precision 0.1453463891850246\n",
      "Key 20150304 | Training Loss: 0.671718 | Validation Loss: 0.708323\n",
      "Key 20150604 Test Accuracy: 0.602956977427721 Quality score: 0.14265652939156048, recall 0.6227729758334803, precision 0.19227339255931108\n",
      "Key 20150304 | Training Loss: 0.607319 | Validation Loss: 0.614435\n",
      "Key 20150604 Test Accuracy: 0.621510535731904 Quality score: 0.1984756103613626, recall 0.44079643676133357, precision 0.2620601961092759\n",
      "Key 20150304 | Training Loss: 0.701971 | Validation Loss: 0.585539\n",
      "Key 20150604 Test Accuracy: 0.618212690373126 Quality score: 0.19495918546295551, recall 0.4288675251367084, precision 0.2620410912765241\n",
      "Key 20150304 | Training Loss: 0.638503 | Validation Loss: 0.576381\n",
      "Key 20150604 Test Accuracy: 0.6182162036938816 Quality score: 0.19496684413534562, recall 0.4288675251367084, precision 0.262048152190022\n",
      "Key 20150304 | Training Loss: 0.668885 | Validation Loss: 0.568294\n",
      "Key 20150604 Test Accuracy: 0.6193141164300208 Quality score: 0.1973703147281843, recall 0.4288675251367084, precision 0.264273485692546\n",
      "Key 20150304 | Training Loss: 0.643010 | Validation Loss: 0.566930\n",
      "Key 20150604 Test Accuracy: 0.6192946101868643 Quality score: 0.1973552557171197, recall 0.42877932615981657, precision 0.2642837727643381\n",
      "Key 20150304 | Training Loss: 0.635405 | Validation Loss: 0.563094\n",
      "Key 20150604 Test Accuracy: 0.6190650824365885 Quality score: 0.19709406878882524, recall 0.4280075851120127, precision 0.2642534306251361\n",
      "Key 20150304 | Training Loss: 0.620356 | Validation Loss: 0.558794\n",
      "Key 20150604 Test Accuracy: 0.6190487875833436 Quality score: 0.1970651806164021, recall 0.4279855353677897, precision 0.26423262272318876\n",
      "Key 20150304 | Training Loss: 0.599608 | Validation Loss: 0.557951\n",
      "Key 20150604 Test Accuracy: 0.6190681108474997 Quality score: 0.19710769985394536, recall 0.4279855353677897, precision 0.2642721962775879\n",
      "Key 20150304 | Training Loss: 0.645214 | Validation Loss: 0.559082\n",
      "Key 20150604 Test Accuracy: 0.6016323350791104 Quality score: 0.16958517450008045, recall 0.393036690774387, precision 0.24812082405345212\n",
      "Current Layer Attributes - hidden layers:1 features count:4\n",
      "Key 20150304 | Training Loss: 1.168591 | Validation Loss: 1.175331\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ritesh_malaiya/anaconda3/envs/p3/lib/python3.6/site-packages/sklearn/metrics/classification.py:516: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  mcc = cov_ytyp / np.sqrt(var_yt * var_yp)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Key 20150604 Test Accuracy: 0.5 Quality score: 0.0, recall 1.0, precision 0.13743738313791923\n",
      "Key 20150304 | Training Loss: 1.079699 | Validation Loss: 1.175625\n",
      "Key 20150604 Test Accuracy: 0.5 Quality score: 0.0, recall 1.0, precision 0.13743738313791923\n",
      "Key 20150304 | Training Loss: 1.096524 | Validation Loss: 1.173914\n",
      "Key 20150604 Test Accuracy: 0.5 Quality score: 0.0, recall 1.0, precision 0.13743738313791923\n",
      "Key 20150304 | Training Loss: 1.039422 | Validation Loss: 1.174465\n",
      "Key 20150604 Test Accuracy: 0.5 Quality score: 0.0, recall 1.0, precision 0.13743738313791923\n",
      "Key 20150304 | Training Loss: 1.051768 | Validation Loss: 1.175483\n",
      "Key 20150604 Test Accuracy: 0.5 Quality score: 0.0, recall 1.0, precision 0.13743738313791923\n",
      "Key 20150304 | Training Loss: 1.061894 | Validation Loss: 1.175106\n",
      "Key 20150604 Test Accuracy: 0.5 Quality score: 0.0, recall 1.0, precision 0.13743738313791923\n",
      "Key 20150304 | Training Loss: 1.059021 | Validation Loss: 1.175427\n",
      "Key 20150604 Test Accuracy: 0.5 Quality score: 0.0, recall 1.0, precision 0.13743738313791923\n",
      "Key 20150304 | Training Loss: 1.016003 | Validation Loss: 1.174505\n",
      "Key 20150604 Test Accuracy: 0.5 Quality score: 0.0, recall 1.0, precision 0.13743738313791923\n",
      "Key 20150304 | Training Loss: 1.004702 | Validation Loss: 1.173928\n",
      "Key 20150604 Test Accuracy: 0.5000474298302012 Quality score: 0.0036108628218887123, recall 1.0, precision 0.13744862951423825\n",
      "Key 20150304 | Training Loss: 0.978446 | Validation Loss: 1.166651\n",
      "Key 20150604 Test Accuracy: 0.4995510635790275 Quality score: -0.013203474376986003, recall 0.998677015346622, precision 0.13733088337851196\n",
      "Key 20150304 | Training Loss: 0.952205 | Validation Loss: 1.152384\n",
      "Key 20150604 Test Accuracy: 0.5019468121627549 Quality score: 0.00711990998468568, recall 0.966550538013759, precision 0.1379166050522752\n",
      "Key 20150304 | Training Loss: 0.965875 | Validation Loss: 0.999265\n",
      "Key 20150604 Test Accuracy: 0.5265986237469834 Quality score: 0.04359580879320039, recall 0.8169650732051508, precision 0.14561611048447\n",
      "Key 20150304 | Training Loss: 0.938276 | Validation Loss: 0.936448\n",
      "Key 20150604 Test Accuracy: 0.5405916900228593 Quality score: 0.060738314370484006, recall 0.7655009701887459, precision 0.15127562691997648\n",
      "Key 20150304 | Training Loss: 0.922002 | Validation Loss: 0.935870\n",
      "Key 20150604 Test Accuracy: 0.5318544561183353 Quality score: 0.04749135149364698, recall 0.7464279414358793, precision 0.14835981154815384\n",
      "Key 20150304 | Training Loss: 0.885952 | Validation Loss: 0.936853\n",
      "Key 20150604 Test Accuracy: 0.5319182266239993 Quality score: 0.04753862040387621, recall 0.7454136532016229, precision 0.14839950132570104\n",
      "Key 20150304 | Training Loss: 0.834391 | Validation Loss: 0.932184\n",
      "Key 20150604 Test Accuracy: 0.5169735785602341 Quality score: 0.02499590684510424, recall 0.7063194566943023, precision 0.14338148076862822\n",
      "Key 20150304 | Training Loss: 0.809906 | Validation Loss: 0.932795\n",
      "Key 20150604 Test Accuracy: 0.5048613798069677 Quality score: 0.007122758241985471, recall 0.6789998236020462, precision 0.13915613377859923\n",
      "Key 20150304 | Training Loss: 0.804772 | Validation Loss: 0.904265\n",
      "Key 20150604 Test Accuracy: 0.5100709954555088 Quality score: 0.014468139512899063, recall 0.6596401481742812, precision 0.1411551545978286\n",
      "Key 20150304 | Training Loss: 0.803341 | Validation Loss: 0.728395\n",
      "Key 20150604 Test Accuracy: 0.5281061161507721 Quality score: 0.03876484106546932, recall 0.5215866995942847, precision 0.15152291579925056\n",
      "Key 20150304 | Training Loss: 0.756382 | Validation Loss: 0.561771\n",
      "Key 20150604 Test Accuracy: 0.627872088124169 Quality score: 0.20789494064243894, recall 0.4548862233198095, precision 0.26684085264900664\n",
      "Current Layer Attributes - hidden layers:1 features count:10\n",
      "Key 20150304 | Training Loss: 0.727429 | Validation Loss: 0.556723\n",
      "Key 20150604 Test Accuracy: 0.6200725266984629 Quality score: 0.19732026625317606, recall 0.4343579114482272, precision 0.26273040091760247\n",
      "Key 20150304 | Training Loss: 0.684484 | Validation Loss: 0.555813\n",
      "Key 20150604 Test Accuracy: 0.6152740819066771 Quality score: 0.19156404073194674, recall 0.4190553889574881, precision 0.2615606936416185\n",
      "Key 20150304 | Training Loss: 0.651532 | Validation Loss: 0.532507\n",
      "Key 20150604 Test Accuracy: 0.6004220735466148 Quality score: 0.18796141560493304, recall 0.33464896807197037, precision 0.2849498704517292\n",
      "Key 20150304 | Training Loss: 0.611612 | Validation Loss: 0.457505\n",
      "Key 20150604 Test Accuracy: 0.6299982427539654 Quality score: 0.3071356072072206, recall 0.3180014111836303, precision 0.46624854519591363\n",
      "Key 20150304 | Training Loss: 0.654729 | Validation Loss: 0.454313\n",
      "Key 20150604 Test Accuracy: 0.6293197879950578 Quality score: 0.3123959797111418, recall 0.31231257717410477, precision 0.48109778879793486\n",
      "Key 20150304 | Training Loss: 0.592690 | Validation Loss: 0.445019\n",
      "Key 20150604 Test Accuracy: 0.6111075149643402 Quality score: 0.3105361948324413, recall 0.25659287352266713, precision 0.5432265894874428\n",
      "Key 20150304 | Training Loss: 0.645331 | Validation Loss: 0.449794\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ritesh_malaiya/anaconda3/envs/p3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1113: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Key 20150604 Test Accuracy: 0.5 Quality score: 0.0, recall 0.0, precision 0.0\n",
      "Key 20150304 | Training Loss: 0.537821 | Validation Loss: 0.450546\n",
      "Key 20150604 Test Accuracy: 0.5 Quality score: 0.0, recall 0.0, precision 0.0\n",
      "Key 20150304 | Training Loss: 0.553412 | Validation Loss: 0.451199\n",
      "Key 20150604 Test Accuracy: 0.5 Quality score: 0.0, recall 0.0, precision 0.0\n",
      "Key 20150304 | Training Loss: 0.565181 | Validation Loss: 0.450877\n",
      "Key 20150604 Test Accuracy: 0.5 Quality score: 0.0, recall 0.0, precision 0.0\n",
      "Key 20150304 | Training Loss: 0.576323 | Validation Loss: 0.450253\n",
      "Key 20150604 Test Accuracy: 0.5 Quality score: 0.0, recall 0.0, precision 0.0\n",
      "Key 20150304 | Training Loss: 0.490941 | Validation Loss: 0.449656\n",
      "Key 20150604 Test Accuracy: 0.5 Quality score: 0.0, recall 0.0, precision 0.0\n",
      "Key 20150304 | Training Loss: 0.536110 | Validation Loss: 0.452494\n",
      "Key 20150604 Test Accuracy: 0.5 Quality score: 0.0, recall 0.0, precision 0.0\n",
      "Key 20150304 | Training Loss: 0.507190 | Validation Loss: 0.449141\n",
      "Key 20150604 Test Accuracy: 0.5 Quality score: 0.0, recall 0.0, precision 0.0\n",
      "Key 20150304 | Training Loss: 0.543265 | Validation Loss: 0.451071\n",
      "Key 20150604 Test Accuracy: 0.5 Quality score: 0.0, recall 0.0, precision 0.0\n",
      "Key 20150304 | Training Loss: 0.478752 | Validation Loss: 0.452099\n",
      "Key 20150604 Test Accuracy: 0.5 Quality score: 0.0, recall 0.0, precision 0.0\n",
      "Key 20150304 | Training Loss: 0.434107 | Validation Loss: 0.450942\n",
      "Key 20150604 Test Accuracy: 0.5 Quality score: 0.0, recall 0.0, precision 0.0\n",
      "Key 20150304 | Training Loss: 0.475991 | Validation Loss: 0.450427\n",
      "Key 20150604 Test Accuracy: 0.5 Quality score: 0.0, recall 0.0, precision 0.0\n",
      "Key 20150304 | Training Loss: 0.556257 | Validation Loss: 0.451070\n",
      "Key 20150604 Test Accuracy: 0.5 Quality score: 0.0, recall 0.0, precision 0.0\n",
      "Key 20150304 | Training Loss: 0.504355 | Validation Loss: 0.449619\n",
      "Key 20150604 Test Accuracy: 0.5 Quality score: 0.0, recall 0.0, precision 0.0\n",
      "Current Layer Attributes - hidden layers:3 features count:1\n",
      "Key 20150304 | Training Loss: 0.646230 | Validation Loss: 0.449998\n",
      "Key 20150604 Test Accuracy: 0.5 Quality score: 0.0, recall 0.0, precision 0.0\n",
      "Key 20150304 | Training Loss: 0.616443 | Validation Loss: 0.449837\n",
      "Key 20150604 Test Accuracy: 0.5 Quality score: 0.0, recall 0.0, precision 0.0\n",
      "Key 20150304 | Training Loss: 0.642240 | Validation Loss: 0.451721\n",
      "Key 20150604 Test Accuracy: 0.5 Quality score: 0.0, recall 0.0, precision 0.0\n",
      "Key 20150304 | Training Loss: 0.657942 | Validation Loss: 0.451402\n",
      "Key 20150604 Test Accuracy: 0.5 Quality score: 0.0, recall 0.0, precision 0.0\n",
      "Key 20150304 | Training Loss: 0.620911 | Validation Loss: 0.451503\n",
      "Key 20150604 Test Accuracy: 0.5 Quality score: 0.0, recall 0.0, precision 0.0\n",
      "Key 20150304 | Training Loss: 0.607190 | Validation Loss: 0.452000\n",
      "Key 20150604 Test Accuracy: 0.5 Quality score: 0.0, recall 0.0, precision 0.0\n",
      "Key 20150304 | Training Loss: 0.621847 | Validation Loss: 0.451402\n",
      "Key 20150604 Test Accuracy: 0.5 Quality score: 0.0, recall 0.0, precision 0.0\n",
      "Key 20150304 | Training Loss: 0.627315 | Validation Loss: 0.450648\n",
      "Key 20150604 Test Accuracy: 0.5 Quality score: 0.0, recall 0.0, precision 0.0\n",
      "Key 20150304 | Training Loss: 0.595124 | Validation Loss: 0.450854\n",
      "Key 20150604 Test Accuracy: 0.5 Quality score: 0.0, recall 0.0, precision 0.0\n",
      "Key 20150304 | Training Loss: 0.589636 | Validation Loss: 0.450499\n",
      "Key 20150604 Test Accuracy: 0.5 Quality score: 0.0, recall 0.0, precision 0.0\n",
      "Key 20150304 | Training Loss: 0.620751 | Validation Loss: 0.451663\n",
      "Key 20150604 Test Accuracy: 0.5 Quality score: 0.0, recall 0.0, precision 0.0\n",
      "Key 20150304 | Training Loss: 0.607180 | Validation Loss: 0.452020\n",
      "Key 20150604 Test Accuracy: 0.5 Quality score: 0.0, recall 0.0, precision 0.0\n",
      "Key 20150304 | Training Loss: 0.590195 | Validation Loss: 0.450845\n",
      "Key 20150604 Test Accuracy: 0.5 Quality score: 0.0, recall 0.0, precision 0.0\n",
      "Key 20150304 | Training Loss: 0.609950 | Validation Loss: 0.452653\n",
      "Key 20150604 Test Accuracy: 0.5 Quality score: 0.0, recall 0.0, precision 0.0\n",
      "Key 20150304 | Training Loss: 0.604721 | Validation Loss: 0.450934\n",
      "Key 20150604 Test Accuracy: 0.5 Quality score: 0.0, recall 0.0, precision 0.0\n",
      "Key 20150304 | Training Loss: 0.615192 | Validation Loss: 0.451256\n",
      "Key 20150604 Test Accuracy: 0.5 Quality score: 0.0, recall 0.0, precision 0.0\n",
      "Key 20150304 | Training Loss: 0.574549 | Validation Loss: 0.451541\n",
      "Key 20150604 Test Accuracy: 0.5 Quality score: 0.0, recall 0.0, precision 0.0\n",
      "Key 20150304 | Training Loss: 0.585573 | Validation Loss: 0.450676\n",
      "Key 20150604 Test Accuracy: 0.5 Quality score: 0.0, recall 0.0, precision 0.0\n",
      "Key 20150304 | Training Loss: 0.593009 | Validation Loss: 0.451540\n",
      "Key 20150604 Test Accuracy: 0.5 Quality score: 0.0, recall 0.0, precision 0.0\n",
      "Key 20150304 | Training Loss: 0.567228 | Validation Loss: 0.452137\n",
      "Key 20150604 Test Accuracy: 0.5 Quality score: 0.0, recall 0.0, precision 0.0\n",
      "Current Layer Attributes - hidden layers:3 features count:4\n",
      "Key 20150304 | Training Loss: 0.594456 | Validation Loss: 0.450025\n",
      "Key 20150604 Test Accuracy: 0.5 Quality score: 0.0, recall 0.0, precision 0.0\n",
      "Key 20150304 | Training Loss: 0.582993 | Validation Loss: 0.451664\n",
      "Key 20150604 Test Accuracy: 0.5 Quality score: 0.0, recall 0.0, precision 0.0\n",
      "Key 20150304 | Training Loss: 0.602470 | Validation Loss: 0.450898\n",
      "Key 20150604 Test Accuracy: 0.5 Quality score: 0.0, recall 0.0, precision 0.0\n",
      "Key 20150304 | Training Loss: 0.600673 | Validation Loss: 0.449693\n",
      "Key 20150604 Test Accuracy: 0.5 Quality score: 0.0, recall 0.0, precision 0.0\n",
      "Key 20150304 | Training Loss: 0.574595 | Validation Loss: 0.450711\n",
      "Key 20150604 Test Accuracy: 0.5 Quality score: 0.0, recall 0.0, precision 0.0\n",
      "Key 20150304 | Training Loss: 0.580322 | Validation Loss: 0.450864\n",
      "Key 20150604 Test Accuracy: 0.5 Quality score: 0.0, recall 0.0, precision 0.0\n",
      "Key 20150304 | Training Loss: 0.606562 | Validation Loss: 0.450580\n",
      "Key 20150604 Test Accuracy: 0.5 Quality score: 0.0, recall 0.0, precision 0.0\n",
      "Key 20150304 | Training Loss: 0.579941 | Validation Loss: 0.451984\n",
      "Key 20150604 Test Accuracy: 0.5 Quality score: 0.0, recall 0.0, precision 0.0\n",
      "Key 20150304 | Training Loss: 0.544718 | Validation Loss: 0.451305\n",
      "Key 20150604 Test Accuracy: 0.5 Quality score: 0.0, recall 0.0, precision 0.0\n",
      "Key 20150304 | Training Loss: 0.560713 | Validation Loss: 0.450322\n",
      "Key 20150604 Test Accuracy: 0.5 Quality score: 0.0, recall 0.0, precision 0.0\n",
      "Key 20150304 | Training Loss: 0.553238 | Validation Loss: 0.450254\n",
      "Key 20150604 Test Accuracy: 0.5 Quality score: 0.0, recall 0.0, precision 0.0\n",
      "Key 20150304 | Training Loss: 0.543760 | Validation Loss: 0.450308\n",
      "Key 20150604 Test Accuracy: 0.5 Quality score: 0.0, recall 0.0, precision 0.0\n",
      "Key 20150304 | Training Loss: 0.569108 | Validation Loss: 0.450877\n",
      "Key 20150604 Test Accuracy: 0.5 Quality score: 0.0, recall 0.0, precision 0.0\n",
      "Key 20150304 | Training Loss: 0.542802 | Validation Loss: 0.451970\n",
      "Key 20150604 Test Accuracy: 0.5 Quality score: 0.0, recall 0.0, precision 0.0\n",
      "Key 20150304 | Training Loss: 0.558237 | Validation Loss: 0.451024\n",
      "Key 20150604 Test Accuracy: 0.5 Quality score: 0.0, recall 0.0, precision 0.0\n",
      "Key 20150304 | Training Loss: 0.543713 | Validation Loss: 0.449849\n",
      "Key 20150604 Test Accuracy: 0.5 Quality score: 0.0, recall 0.0, precision 0.0\n",
      "Key 20150304 | Training Loss: 0.550326 | Validation Loss: 0.450409\n",
      "Key 20150604 Test Accuracy: 0.5 Quality score: 0.0, recall 0.0, precision 0.0\n",
      "Key 20150304 | Training Loss: 0.545887 | Validation Loss: 0.451189\n",
      "Key 20150604 Test Accuracy: 0.5 Quality score: 0.0, recall 0.0, precision 0.0\n",
      "Key 20150304 | Training Loss: 0.569975 | Validation Loss: 0.449849\n",
      "Key 20150604 Test Accuracy: 0.5 Quality score: 0.0, recall 0.0, precision 0.0\n",
      "Key 20150304 | Training Loss: 0.557002 | Validation Loss: 0.451070\n",
      "Key 20150604 Test Accuracy: 0.5 Quality score: 0.0, recall 0.0, precision 0.0\n",
      "Current Layer Attributes - hidden layers:3 features count:10\n",
      "Key 20150304 | Training Loss: 0.759752 | Validation Loss: 0.452037\n",
      "Key 20150604 Test Accuracy: 0.5 Quality score: 0.0, recall 0.0, precision 0.0\n",
      "Key 20150304 | Training Loss: 0.716522 | Validation Loss: 0.450583\n",
      "Key 20150604 Test Accuracy: 0.5 Quality score: 0.0, recall 0.0, precision 0.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Key 20150304 | Training Loss: 0.767828 | Validation Loss: 0.451510\n",
      "Key 20150604 Test Accuracy: 0.5 Quality score: 0.0, recall 0.0, precision 0.0\n",
      "Key 20150304 | Training Loss: 0.740418 | Validation Loss: 0.448870\n",
      "Key 20150604 Test Accuracy: 0.5 Quality score: 0.0, recall 0.0, precision 0.0\n",
      "Key 20150304 | Training Loss: 0.677291 | Validation Loss: 0.450615\n",
      "Key 20150604 Test Accuracy: 0.5 Quality score: 0.0, recall 0.0, precision 0.0\n",
      "Key 20150304 | Training Loss: 0.689781 | Validation Loss: 0.453313\n",
      "Key 20150604 Test Accuracy: 0.5 Quality score: 0.0, recall 0.0, precision 0.0\n",
      "Key 20150304 | Training Loss: 0.641253 | Validation Loss: 0.449703\n",
      "Key 20150604 Test Accuracy: 0.5 Quality score: 0.0, recall 0.0, precision 0.0\n",
      "Key 20150304 | Training Loss: 0.642313 | Validation Loss: 0.450826\n",
      "Key 20150604 Test Accuracy: 0.5 Quality score: 0.0, recall 0.0, precision 0.0\n",
      "Key 20150304 | Training Loss: 0.619955 | Validation Loss: 0.451385\n",
      "Key 20150604 Test Accuracy: 0.5 Quality score: 0.0, recall 0.0, precision 0.0\n",
      "Key 20150304 | Training Loss: 0.594155 | Validation Loss: 0.451071\n",
      "Key 20150604 Test Accuracy: 0.5 Quality score: 0.0, recall 0.0, precision 0.0\n",
      "Key 20150304 | Training Loss: 0.638491 | Validation Loss: 0.451739\n",
      "Key 20150604 Test Accuracy: 0.5 Quality score: 0.0, recall 0.0, precision 0.0\n",
      "Key 20150304 | Training Loss: 0.602038 | Validation Loss: 0.451850\n",
      "Key 20150604 Test Accuracy: 0.5 Quality score: 0.0, recall 0.0, precision 0.0\n",
      "Key 20150304 | Training Loss: 0.600070 | Validation Loss: 0.449738\n",
      "Key 20150604 Test Accuracy: 0.5 Quality score: 0.0, recall 0.0, precision 0.0\n",
      "Key 20150304 | Training Loss: 0.592732 | Validation Loss: 0.452419\n",
      "Key 20150604 Test Accuracy: 0.5 Quality score: 0.0, recall 0.0, precision 0.0\n",
      "Key 20150304 | Training Loss: 0.543883 | Validation Loss: 0.451878\n",
      "Key 20150604 Test Accuracy: 0.5 Quality score: 0.0, recall 0.0, precision 0.0\n",
      "Key 20150304 | Training Loss: 0.571651 | Validation Loss: 0.451042\n",
      "Key 20150604 Test Accuracy: 0.5 Quality score: 0.0, recall 0.0, precision 0.0\n",
      "Key 20150304 | Training Loss: 0.579215 | Validation Loss: 0.450004\n",
      "Key 20150604 Test Accuracy: 0.5 Quality score: 0.0, recall 0.0, precision 0.0\n",
      "Key 20150304 | Training Loss: 0.545922 | Validation Loss: 0.450647\n",
      "Key 20150604 Test Accuracy: 0.5 Quality score: 0.0, recall 0.0, precision 0.0\n",
      "Key 20150304 | Training Loss: 0.550426 | Validation Loss: 0.451382\n",
      "Key 20150604 Test Accuracy: 0.5 Quality score: 0.0, recall 0.0, precision 0.0\n",
      "Key 20150304 | Training Loss: 0.586514 | Validation Loss: 0.449784\n",
      "Key 20150604 Test Accuracy: 0.5 Quality score: 0.0, recall 0.0, precision 0.0\n"
     ]
    }
   ],
   "source": [
    "#%%timeit\n",
    "Hyperparameters.start_training()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-10-17T22:33:27.314138Z",
     "start_time": "2017-10-17T22:33:26.867315Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pd.Panel(Train.predictions).to_pickle(\"dataset/tf_dense_only_nsl_kdd_predictions.pkl\")\n",
    "df_results.to_pickle(\"dataset/tf_dense_only_nsl_kdd_scores.pkl\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-10-17T22:33:27.317870Z",
     "start_time": "2017-10-17T22:33:27.315657Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#df_results = pd.read_pickle(\"dataset/tf_dense_only_nsl_kdd_scores.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-10-17T22:33:27.419332Z",
     "start_time": "2017-10-17T22:33:27.319187Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#df_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-10-17T22:33:27.423332Z",
     "start_time": "2017-10-17T22:33:27.420816Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#g = df_results.groupby(by=['no_of_features'])\n",
    "#idx = g['test_score'].transform(max) == df_results['test_score']\n",
    "#df_results[idx].sort_values(by = 'test_score', ascending = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-10-17T22:33:27.428483Z",
     "start_time": "2017-10-17T22:33:27.424543Z"
    },
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#df_results.sort_values(by = 'test_score', ascending = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-10-17T22:33:27.501298Z",
     "start_time": "2017-10-17T22:33:27.429732Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import itertools\n",
    "\n",
    "def plot_confusion_matrix(cm, classes,\n",
    "                          normalize=False,\n",
    "                          title='Confusion matrix',\n",
    "                          cmap=plt.cm.Blues):\n",
    "    \"\"\"\n",
    "    This function prints and plots the confusion matrix.\n",
    "    Normalization can be applied by setting `normalize=True`.\n",
    "    \"\"\"\n",
    "    np.set_printoptions(precision=4)\n",
    "\n",
    "    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n",
    "    plt.title(title)\n",
    "    plt.colorbar()\n",
    "    tick_marks = np.arange(len(classes))\n",
    "    plt.xticks(tick_marks, classes, rotation=45)\n",
    "    plt.yticks(tick_marks, classes)\n",
    "\n",
    "    if normalize:\n",
    "        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "        #print(\"Normalized confusion matrix\")\n",
    "    else:\n",
    "        #print('Confusion matrix, without normalization')\n",
    "        pass\n",
    "    \n",
    "    #print(cm)\n",
    "\n",
    "    label = [[\"\\n True Negative\", \"\\n False Positive \\n Type II Error\"],\n",
    "             [\"\\n False Negative \\n Type I Error\", \"\\n True Positive\"]\n",
    "            ]\n",
    "    \n",
    "    thresh = cm.max() / 2.\n",
    "    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
    "        \n",
    "        plt.text(j, i, \"{} {}\".format(cm[i, j].round(4), label[i][j]),\n",
    "                 horizontalalignment=\"center\",\n",
    "                 color=\"white\" if cm[i, j] > thresh else \"black\")\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.ylabel('True label')\n",
    "    plt.xlabel('Predicted label')\n",
    "\n",
    "def plot(actual_value, pred_value):\n",
    "    from sklearn.metrics import confusion_matrix\n",
    "\n",
    "    cm_2labels = confusion_matrix(y_pred = pred_value, y_true = actual_value)\n",
    "    plt.figure(figsize=[6,6])\n",
    "    plot_confusion_matrix(cm_2labels, ['Normal', 'Attack'], normalize = False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-10-17T22:33:27.506182Z",
     "start_time": "2017-10-17T22:33:27.502875Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#plot(actual_value = Train.actual_value, pred_value = Train.pred_value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-10-17T22:33:27.511233Z",
     "start_time": "2017-10-17T22:33:27.507386Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "past_scores = pd.read_pickle(\"dataset/scores/tf_dense_only_nsl_kdd_scores_all.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-10-17T22:33:27.531062Z",
     "start_time": "2017-10-17T22:33:27.512510Z"
    },
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>key</th>\n",
       "      <th>no_of_features</th>\n",
       "      <th>hidden_layers</th>\n",
       "      <th>train_score</th>\n",
       "      <th>test_score</th>\n",
       "      <th>quality_score</th>\n",
       "      <th>time_taken</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>20150604</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>0.561771</td>\n",
       "      <td>0.627872</td>\n",
       "      <td>0.207895</td>\n",
       "      <td>22.350658</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>20150604</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>0.561771</td>\n",
       "      <td>0.627872</td>\n",
       "      <td>0.207895</td>\n",
       "      <td>22.350658</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>20150604</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.559082</td>\n",
       "      <td>0.601632</td>\n",
       "      <td>0.169585</td>\n",
       "      <td>22.996205</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>20150604</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.559082</td>\n",
       "      <td>0.601632</td>\n",
       "      <td>0.169585</td>\n",
       "      <td>22.996205</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>20150604</td>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "      <td>0.449619</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>23.028763</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>20150604</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0.452137</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>25.447692</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>20150604</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>0.451070</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>26.785682</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>20150604</td>\n",
       "      <td>10</td>\n",
       "      <td>3</td>\n",
       "      <td>0.449784</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>29.890475</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>20150604</td>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "      <td>0.449619</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>23.028763</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>20150604</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0.452137</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>25.447692</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>20150604</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>0.451070</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>26.785682</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>20150604</td>\n",
       "      <td>10</td>\n",
       "      <td>3</td>\n",
       "      <td>0.449784</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>29.890475</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         key  no_of_features  hidden_layers  train_score  test_score  \\\n",
       "1   20150604               4              1     0.561771    0.627872   \n",
       "7   20150604               4              1     0.561771    0.627872   \n",
       "0   20150604               1              1     0.559082    0.601632   \n",
       "6   20150604               1              1     0.559082    0.601632   \n",
       "2   20150604              10              1     0.449619    0.500000   \n",
       "3   20150604               1              3     0.452137    0.500000   \n",
       "4   20150604               4              3     0.451070    0.500000   \n",
       "5   20150604              10              3     0.449784    0.500000   \n",
       "8   20150604              10              1     0.449619    0.500000   \n",
       "9   20150604               1              3     0.452137    0.500000   \n",
       "10  20150604               4              3     0.451070    0.500000   \n",
       "11  20150604              10              3     0.449784    0.500000   \n",
       "\n",
       "    quality_score  time_taken  \n",
       "1        0.207895   22.350658  \n",
       "7        0.207895   22.350658  \n",
       "0        0.169585   22.996205  \n",
       "6        0.169585   22.996205  \n",
       "2        0.000000   23.028763  \n",
       "3        0.000000   25.447692  \n",
       "4        0.000000   26.785682  \n",
       "5        0.000000   29.890475  \n",
       "8        0.000000   23.028763  \n",
       "9        0.000000   25.447692  \n",
       "10       0.000000   26.785682  \n",
       "11       0.000000   29.890475  "
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "past_scores.sort_values(by='quality_score', ascending = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-10-17T22:33:27.549063Z",
     "start_time": "2017-10-17T22:33:27.532353Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>key</th>\n",
       "      <th>train_score</th>\n",
       "      <th>test_score</th>\n",
       "      <th>quality_score</th>\n",
       "      <th>time_taken</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>no_of_features</th>\n",
       "      <th>hidden_layers</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <th>1</th>\n",
       "      <td>20150604</td>\n",
       "      <td>0.561771</td>\n",
       "      <td>0.627872</td>\n",
       "      <td>0.207895</td>\n",
       "      <td>22.350658</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">1</th>\n",
       "      <th>1</th>\n",
       "      <td>20150604</td>\n",
       "      <td>0.559082</td>\n",
       "      <td>0.601632</td>\n",
       "      <td>0.169585</td>\n",
       "      <td>22.996205</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>20150604</td>\n",
       "      <td>0.452137</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>25.447692</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <th>3</th>\n",
       "      <td>20150604</td>\n",
       "      <td>0.451070</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>26.785682</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">10</th>\n",
       "      <th>1</th>\n",
       "      <td>20150604</td>\n",
       "      <td>0.449619</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>23.028763</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>20150604</td>\n",
       "      <td>0.449784</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>29.890475</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                   key  train_score  test_score  \\\n",
       "no_of_features hidden_layers                                      \n",
       "4              1              20150604     0.561771    0.627872   \n",
       "1              1              20150604     0.559082    0.601632   \n",
       "               3              20150604     0.452137    0.500000   \n",
       "4              3              20150604     0.451070    0.500000   \n",
       "10             1              20150604     0.449619    0.500000   \n",
       "               3              20150604     0.449784    0.500000   \n",
       "\n",
       "                              quality_score  time_taken  \n",
       "no_of_features hidden_layers                             \n",
       "4              1                   0.207895   22.350658  \n",
       "1              1                   0.169585   22.996205  \n",
       "               3                   0.000000   25.447692  \n",
       "4              3                   0.000000   26.785682  \n",
       "10             1                   0.000000   23.028763  \n",
       "               3                   0.000000   29.890475  "
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "psg = past_scores.sort_values(by='quality_score', ascending=False).groupby(by=['no_of_features', 'hidden_layers'])\n",
    "psg.first().sort_values(by='quality_score', ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-10-17T22:33:27.591246Z",
     "start_time": "2017-10-17T22:33:27.550602Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#key_nof_hidden '20151201_16_1'\n",
    "Train.predictions = pd.read_pickle(\"dataset/tf_dense_only_nsl_kdd_predictions.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-10-17T22:33:27.612773Z",
     "start_time": "2017-10-17T22:33:27.592720Z"
    }
   },
   "outputs": [],
   "source": [
    "df = Train.predictions['20150604_1_3'].dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-10-17T22:33:27.620673Z",
     "start_time": "2017-10-17T22:33:27.614208Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, ..., 0, 0, 0])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Train.predictions['20151219_42_1'].loc[:,'Prediction']\n",
    "df.loc[:,'Prediction'].values.astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-10-17T22:33:27.676993Z",
     "start_time": "2017-10-17T22:33:27.621919Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ritesh_malaiya/anaconda3/envs/p3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1113: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.0"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn import metrics as me\n",
    "me.f1_score(df.loc[:,'Actual'].values.astype(int),\n",
    "            df.loc[:,'Prediction'].values.astype(int) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-10-17T22:33:27.694331Z",
     "start_time": "2017-10-17T22:33:27.678392Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Actual\n",
       "0.0    284631\n",
       "1.0     45352\n",
       "Name: Actual, dtype: int64"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.groupby(by=\"Actual\").Actual.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-10-17T22:33:28.178242Z",
     "start_time": "2017-10-17T22:33:27.695614Z"
    }
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAbcAAAGkCAYAAACy1WveAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nFhERjZPgFhERjZPgFhERjfN/odBTi2khuJ8AAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f9124636a58>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot(actual_value = df.loc[:,'Actual'].values.astype(int),\n",
    "     pred_value = df.loc[:,'Prediction'].values.astype(int))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-10-17T22:33:28.191280Z",
     "start_time": "2017-10-17T22:33:28.179647Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>train_score</th>\n",
       "      <th>test_score</th>\n",
       "      <th>quality_score</th>\n",
       "      <th>time_taken</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>no_of_features</th>\n",
       "      <th>hidden_layers</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <th>1</th>\n",
       "      <td>0.561771</td>\n",
       "      <td>0.627872</td>\n",
       "      <td>0.207895</td>\n",
       "      <td>22.350658</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">1</th>\n",
       "      <th>1</th>\n",
       "      <td>0.559082</td>\n",
       "      <td>0.601632</td>\n",
       "      <td>0.169585</td>\n",
       "      <td>22.996205</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.452137</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>25.447692</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <th>3</th>\n",
       "      <td>0.451070</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>26.785682</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">10</th>\n",
       "      <th>1</th>\n",
       "      <td>0.449619</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>23.028763</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.449784</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>29.890475</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                              train_score  test_score  quality_score  \\\n",
       "no_of_features hidden_layers                                           \n",
       "4              1                 0.561771    0.627872       0.207895   \n",
       "1              1                 0.559082    0.601632       0.169585   \n",
       "               3                 0.452137    0.500000       0.000000   \n",
       "4              3                 0.451070    0.500000       0.000000   \n",
       "10             1                 0.449619    0.500000       0.000000   \n",
       "               3                 0.449784    0.500000       0.000000   \n",
       "\n",
       "                              time_taken  \n",
       "no_of_features hidden_layers              \n",
       "4              1               22.350658  \n",
       "1              1               22.996205  \n",
       "               3               25.447692  \n",
       "4              3               26.785682  \n",
       "10             1               23.028763  \n",
       "               3               29.890475  "
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "psg.mean().sort_values(by='quality_score', ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-10-17T22:33:28.204801Z",
     "start_time": "2017-10-17T22:33:28.192519Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>train_score</th>\n",
       "      <th>test_score</th>\n",
       "      <th>quality_score</th>\n",
       "      <th>time_taken</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>no_of_features</th>\n",
       "      <th>hidden_layers</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">1</th>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">4</th>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">10</th>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                              train_score  test_score  quality_score  \\\n",
       "no_of_features hidden_layers                                           \n",
       "1              1                      0.0         0.0            0.0   \n",
       "               3                      0.0         0.0            0.0   \n",
       "4              1                      0.0         0.0            0.0   \n",
       "               3                      0.0         0.0            0.0   \n",
       "10             1                      0.0         0.0            0.0   \n",
       "               3                      0.0         0.0            0.0   \n",
       "\n",
       "                              time_taken  \n",
       "no_of_features hidden_layers              \n",
       "1              1                     0.0  \n",
       "               3                     0.0  \n",
       "4              1                     0.0  \n",
       "               3                     0.0  \n",
       "10             1                     0.0  \n",
       "               3                     0.0  "
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "psg.std()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-10-17T22:33:28.222033Z",
     "start_time": "2017-10-17T22:33:28.206136Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ritesh_malaiya/anaconda3/envs/p3/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:1907: RuntimeWarning: invalid value encountered in multiply\n",
      "  lower_bound = self.a * scale + loc\n",
      "/home/ritesh_malaiya/anaconda3/envs/p3/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:1908: RuntimeWarning: invalid value encountered in multiply\n",
      "  upper_bound = self.b * scale + loc\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "no_of_features  hidden_layers\n",
       "1               1                (nan, nan)\n",
       "                3                (nan, nan)\n",
       "4               1                (nan, nan)\n",
       "                3                (nan, nan)\n",
       "10              1                (nan, nan)\n",
       "                3                (nan, nan)\n",
       "dtype: object"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from scipy import stats\n",
    "\n",
    "def fn(x):\n",
    "    #print(x)\n",
    "    return stats.norm.interval(0.95, loc=x.quality_score.mean(), scale=x.quality_score.std())\n",
    "psg.apply(fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "_draft": {
   "nbviewer_url": "https://gist.github.com/7d1ace18a82178e15ece8fc5252fce88"
  },
  "anaconda-cloud": {},
  "gist": {
   "data": {
    "description": "Hyper parameter tuning",
    "public": false
   },
   "id": "7d1ace18a82178e15ece8fc5252fce88"
  },
  "kernelspec": {
   "display_name": "Python [conda env:p3]",
   "language": "python",
   "name": "conda-env-p3-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
