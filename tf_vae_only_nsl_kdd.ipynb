{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Read Data Sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-05-13T19:58:43.714742Z",
     "start_time": "2017-05-13T19:58:43.302995Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from collections import namedtuple\n",
    "pd.set_option(\"display.max_rows\",35)\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-05-13T19:58:43.801356Z",
     "start_time": "2017-05-13T19:58:43.716453Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class dataset:\n",
    "    kdd_train_2labels = pd.read_pickle(\"dataset/kdd_train_2labels.pkl\")\n",
    "    kdd_test_2labels = pd.read_pickle(\"dataset/kdd_test_2labels.pkl\")\n",
    "    \n",
    "    kdd_train_5labels = pd.read_pickle(\"dataset/kdd_train_5labels.pkl\")\n",
    "    kdd_test_5labels = pd.read_pickle(\"dataset/kdd_test_5labels.pkl\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-05-13T19:58:43.807456Z",
     "start_time": "2017-05-13T19:58:43.802940Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(125973, 124)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.kdd_train_2labels.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-05-13T19:58:43.813706Z",
     "start_time": "2017-05-13T19:58:43.808835Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(22544, 124)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.kdd_test_2labels.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-05-13T19:58:44.682851Z",
     "start_time": "2017-05-13T19:58:43.815139Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.99186991653217393"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn import model_selection as ms\n",
    "from sklearn import preprocessing as pp\n",
    "\n",
    "class preprocess:\n",
    "    \n",
    "    output_columns_2labels = ['is_Attack','is_Normal']\n",
    "    \n",
    "    x_input = dataset.kdd_train_2labels.drop(output_columns_2labels, axis = 1)\n",
    "    y_output = dataset.kdd_train_2labels.loc[:,output_columns_2labels]\n",
    "\n",
    "    x_test_input = dataset.kdd_test_2labels.drop(output_columns_2labels, axis = 1)\n",
    "    y_test = dataset.kdd_test_2labels.loc[:,output_columns_2labels]\n",
    "\n",
    "    ss = pp.StandardScaler()\n",
    "\n",
    "    x_train = ss.fit_transform(x_input)\n",
    "    x_test = ss.transform(x_test_input)\n",
    "\n",
    "    y_train = y_output.values\n",
    "    y_test = y_test.values\n",
    "\n",
    "    x_train = np.hstack((x_train, y_train))\n",
    "    x_test = np.hstack((x_test, np.random.normal(size = (x_test.shape[0], y_train.shape[1]))))\n",
    "    #x_test = np.hstack((x_test, y_test))\n",
    "    \n",
    "preprocess.x_train.std()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-05-13T19:58:45.755939Z",
     "start_time": "2017-05-13T19:58:44.684646Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-05-13T19:58:46.132258Z",
     "start_time": "2017-05-13T19:58:45.757576Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class network(object):\n",
    "    \n",
    "    input_dim = 124\n",
    "    classes = 2\n",
    "    hidden_encoder_dim = 124\n",
    "    hidden_layers = 1\n",
    "    latent_dim = 10\n",
    "\n",
    "    hidden_decoder_dim = 124\n",
    "    lam = 0.01\n",
    "    \n",
    "    def __init__(self, classes, hidden_layers, num_of_features):\n",
    "        self.classes = classes\n",
    "        self.hidden_layers = hidden_layers\n",
    "        self.latent_dim = num_of_features\n",
    "            \n",
    "    def build_layers(self):\n",
    "        tf.reset_default_graph()\n",
    "        #learning_rate = tf.Variable(initial_value=0.001)\n",
    "\n",
    "        input_dim = self.input_dim\n",
    "        classes = self.classes\n",
    "        hidden_encoder_dim = self.hidden_encoder_dim\n",
    "        hidden_layers = self.hidden_layers\n",
    "        latent_dim = self.latent_dim\n",
    "        hidden_decoder_dim = self.hidden_decoder_dim\n",
    "        lam = self.lam\n",
    "        \n",
    "        with tf.variable_scope(\"Input\"):\n",
    "            self.x = tf.placeholder(\"float\", shape=[None, input_dim])\n",
    "            self.y_ = tf.placeholder(\"float\", shape=[None, classes])\n",
    "            self.keep_prob = tf.placeholder(\"float\")\n",
    "        \n",
    "        with tf.variable_scope(\"Layer_Encoder\"):\n",
    "\n",
    "            hidden_encoder = tf.layers.dense(self.x, hidden_encoder_dim, activation = tf.nn.relu, kernel_regularizer=tf.nn.l2_loss)\n",
    "            hidden_encoder = tf.nn.dropout(hidden_encoder, self.keep_prob)\n",
    "            for h in range(hidden_layers - 1):\n",
    "                hidden_encoder = tf.layers.dense(hidden_encoder, hidden_encoder_dim, activation = tf.nn.relu, kernel_regularizer=tf.nn.l2_loss)\n",
    "                hidden_encoder = tf.nn.dropout(hidden_encoder, self.keep_prob)\n",
    "                \n",
    "        with tf.variable_scope(\"Layer_Mean\"):\n",
    "            mu_encoder = tf.layers.dense(hidden_encoder, latent_dim, activation = None, kernel_regularizer=tf.nn.l2_loss)\n",
    "\n",
    "        with tf.variable_scope(\"Layer_Variance\"):\n",
    "            logvar_encoder = tf.layers.dense(hidden_encoder, latent_dim, activation = None, kernel_regularizer=tf.nn.l2_loss)\n",
    "\n",
    "        with tf.variable_scope(\"Sampling_Distribution\"):\n",
    "            # Sample epsilon\n",
    "            epsilon = tf.random_normal(tf.shape(logvar_encoder), mean=0, stddev=1, name='epsilon')\n",
    "\n",
    "            # Sample latent variable\n",
    "            std_encoder = tf.exp(0.5 * logvar_encoder)\n",
    "            z = mu_encoder + tf.multiply(std_encoder, epsilon)\n",
    "            \n",
    "            #tf.summary.histogram(\"Sample_Distribution\", z)\n",
    "\n",
    "        with tf.variable_scope(\"Layer_Decoder\"):\n",
    "            hidden_decoder = tf.layers.dense(z, hidden_decoder_dim, activation = tf.nn.relu, kernel_regularizer=tf.nn.l2_loss)\n",
    "            hidden_decoder = tf.nn.dropout(hidden_decoder, self.keep_prob)\n",
    "            for h in range(hidden_layers - 1):\n",
    "                hidden_decoder = tf.layers.dense(hidden_decoder, hidden_decoder_dim, activation = tf.nn.relu, kernel_regularizer=tf.nn.l2_loss)\n",
    "                hidden_decoder = tf.nn.dropout(hidden_decoder, self.keep_prob)\n",
    "                \n",
    "        with tf.variable_scope(\"Layer_Reconstruction\"):\n",
    "            self.x_hat = tf.layers.dense(hidden_decoder, input_dim, activation = None)\n",
    "            \n",
    "            self.y = tf.slice(self.x_hat, [0,input_dim-2], [-1,-1])\n",
    "\n",
    "        with tf.variable_scope(\"Loss\"):\n",
    "            \n",
    "            self.regularized_loss = tf.losses.mean_squared_error(self.x, self.x_hat) #tf.reduce_mean((BCE + KLD + softmax_loss) * lam)\n",
    "\n",
    "            correct_prediction = tf.equal(tf.argmax(self.y, 1), tf.argmax(self.y_, 1))\n",
    "            self.tf_accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32), name = \"Accuracy\")\n",
    "\n",
    "        with tf.variable_scope(\"Optimizer\"):\n",
    "            learning_rate=1e-2\n",
    "            optimizer = tf.train.GradientDescentOptimizer(learning_rate)\n",
    "            gradients, variables = zip(*optimizer.compute_gradients(self.regularized_loss))\n",
    "            gradients = [\n",
    "                None if gradient is None else tf.clip_by_value(gradient, -1, 1)\n",
    "                for gradient in gradients]\n",
    "            self.train_op = optimizer.apply_gradients(zip(gradients, variables))\n",
    "            #self.train_op = optimizer.minimize(self.regularized_loss)\n",
    "            \n",
    "        # add op for merging summary\n",
    "        #self.summary_op = tf.summary.merge_all()\n",
    "        self.pred = tf.argmax(self.y, axis = 1)\n",
    "        self.actual = tf.argmax(self.y_, axis = 1)\n",
    "\n",
    "        # add Saver ops\n",
    "        self.saver = tf.train.Saver()\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2017-05-13T19:58:45.195Z"
    },
    "collapsed": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import collections\n",
    "\n",
    "class Train:    \n",
    "    \n",
    "    result = namedtuple(\"score\", ['epoch', 'no_of_features','hidden_layers','train_score', 'test_score'])\n",
    "\n",
    "    predictions = {}\n",
    "\n",
    "    results = []\n",
    "    best_acc = 0\n",
    "    \n",
    "    def train(epochs, net, h,f):\n",
    "        batch_iterations = 100 # 200\n",
    "    \n",
    "        with tf.Session() as sess:\n",
    "            #summary_writer_train = tf.summary.FileWriter('./logs/kdd/VAE/training', graph=sess.graph)\n",
    "            #summary_writer_valid = tf.summary.FileWriter('./logs/kdd/VAE/validation')\n",
    "\n",
    "            sess.run(tf.global_variables_initializer())\n",
    "\n",
    "            for epoch in range(1, (epochs+1)):\n",
    "                x_train, x_valid, y_train, y_valid, = ms.train_test_split(preprocess.x_train, \n",
    "                                                                          preprocess.y_train, \n",
    "                                                                          test_size=0.1)\n",
    "                batch_indices = np.array_split(np.arange(x_train.shape[0]), \n",
    "                                           batch_iterations)\n",
    "                                                                          \n",
    "                for i in batch_indices:\n",
    "                    _, train_loss = sess.run([net.train_op, \n",
    "                                                           net.regularized_loss, \n",
    "                                                           ], #net.summary_op\n",
    "                                                          feed_dict={net.x: x_train[i,:], \n",
    "                                                                     net.y_: y_train[i,:], \n",
    "                                                                     net.keep_prob:1})\n",
    "                    \n",
    "                    #summary_writer_train.add_summary(summary_str, epoch)\n",
    "                    if(train_loss > 1e9):\n",
    "                        print(\"Step {} | Training Loss: {:.6f}\".format(epoch, train_loss))\n",
    "                    \n",
    "\n",
    "                valid_accuracy, valid_loss = sess.run([net.tf_accuracy, net.regularized_loss], #net.summary_op \n",
    "                                                      feed_dict={net.x: preprocess.x_test, \n",
    "                                                                 net.y_: preprocess.y_test, \n",
    "                                                                 net.keep_prob:1})\n",
    "                #summary_writer_valid.add_summary(summary_str, epoch)\n",
    "\n",
    "                if epoch % 1 == 0:\n",
    "                    print(\"Step {} | Training Loss: {:.6f} | Test Loss: {:6f} | Test Accuracy: {:.6f}\".format(epoch, train_loss, valid_loss, valid_accuracy))\n",
    "\n",
    "            accuracy, pred_value, actual_value, y_pred = sess.run([net.tf_accuracy, \n",
    "                                                           net.pred, \n",
    "                                                           net.actual, net.y], \n",
    "                                                          feed_dict={net.x: preprocess.x_test, \n",
    "                                                                     net.y_: preprocess.y_test, \n",
    "                                                                     net.keep_prob:1})\n",
    "\n",
    "\n",
    "            print(\"Accuracy on Test data: {}\".format(accuracy))\n",
    "            \n",
    "            curr_pred = pd.DataFrame({\"Attack_prob\":y_pred[:,-2], \"Normal_prob\":y_pred[:, -1]})\n",
    "            Train.predictions.update({\"{}_{}_{}\".format(epochs,f,h):curr_pred})\n",
    "            \n",
    "            if accuracy > Train.best_acc:\n",
    "                Train.best_acc = accuracy\n",
    "                Train.pred_value = pred_value\n",
    "                Train.actual_value = actual_value\n",
    "                Train.best_parameters = \"Hidden Layers:{}, Features Count:{}\".format(h, f)\n",
    "                #net.saver.save(sess, \"dataset/epochs_{}_hidden layers_{}_features count_{}\".format(epochs,h,f))\n",
    "            Train.results.append(Train.result(epochs, f, h,valid_accuracy, accuracy))\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2017-05-13T19:58:45.199Z"
    },
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current Layer Attributes - epochs:20 hidden layers:2 features count:4\n",
      "Step 1 | Training Loss: 1.214356 | Test Loss: 1.982258 | Test Accuracy: 0.481503\n",
      "Step 2 | Training Loss: 0.875935 | Test Loss: 1.977551 | Test Accuracy: 0.480571\n",
      "Step 3 | Training Loss: 0.851946 | Test Loss: 1.973582 | Test Accuracy: 0.480793\n",
      "Step 4 | Training Loss: 0.758416 | Test Loss: 1.969069 | Test Accuracy: 0.475426\n",
      "Step 5 | Training Loss: 0.743617 | Test Loss: 1.964341 | Test Accuracy: 0.490507\n",
      "Step 6 | Training Loss: 0.851204 | Test Loss: 1.958684 | Test Accuracy: 0.517211\n",
      "Step 7 | Training Loss: 0.946568 | Test Loss: 1.951311 | Test Accuracy: 0.609519\n",
      "Step 8 | Training Loss: 0.706446 | Test Loss: 1.944075 | Test Accuracy: 0.706042\n",
      "Step 9 | Training Loss: 0.882124 | Test Loss: 1.939642 | Test Accuracy: 0.737048\n",
      "Step 10 | Training Loss: 0.944677 | Test Loss: 1.929276 | Test Accuracy: 0.753194\n",
      "Step 11 | Training Loss: 0.987415 | Test Loss: 1.916247 | Test Accuracy: 0.764106\n",
      "Step 12 | Training Loss: 0.743682 | Test Loss: 1.900553 | Test Accuracy: 0.776748\n",
      "Step 13 | Training Loss: 0.624241 | Test Loss: 1.882329 | Test Accuracy: 0.780651\n",
      "Step 14 | Training Loss: 0.735581 | Test Loss: 1.861983 | Test Accuracy: 0.786506\n",
      "Step 15 | Training Loss: 0.563232 | Test Loss: 1.845253 | Test Accuracy: 0.785797\n",
      "Step 16 | Training Loss: 1.227020 | Test Loss: 1.839258 | Test Accuracy: 0.775417\n",
      "Step 17 | Training Loss: 0.776132 | Test Loss: 1.830048 | Test Accuracy: 0.785708\n",
      "Step 18 | Training Loss: 0.565799 | Test Loss: 1.821210 | Test Accuracy: 0.796975\n",
      "Step 19 | Training Loss: 0.755419 | Test Loss: 1.816826 | Test Accuracy: 0.798217\n",
      "Step 20 | Training Loss: 0.690149 | Test Loss: 1.807116 | Test Accuracy: 0.795289\n",
      "Accuracy on Test data: 0.7948899865150452\n",
      "Current Layer Attributes - epochs:20 hidden layers:2 features count:8\n",
      "Step 1 | Training Loss: 0.849452 | Test Loss: 1.977410 | Test Accuracy: 0.487535\n",
      "Step 2 | Training Loss: 0.879981 | Test Loss: 1.969606 | Test Accuracy: 0.509537\n",
      "Step 3 | Training Loss: 1.383445 | Test Loss: 1.961931 | Test Accuracy: 0.513440\n",
      "Step 4 | Training Loss: 2.849638 | Test Loss: 1.952995 | Test Accuracy: 0.524219\n",
      "Step 5 | Training Loss: 0.746576 | Test Loss: 1.941661 | Test Accuracy: 0.594127\n",
      "Step 6 | Training Loss: 0.841406 | Test Loss: 1.926515 | Test Accuracy: 0.689230\n",
      "Step 7 | Training Loss: 0.873131 | Test Loss: 1.912065 | Test Accuracy: 0.763396\n",
      "Step 8 | Training Loss: 1.544984 | Test Loss: 1.902573 | Test Accuracy: 0.821638\n",
      "Step 9 | Training Loss: 0.785862 | Test Loss: 1.880634 | Test Accuracy: 0.837518\n",
      "Step 10 | Training Loss: 1.604903 | Test Loss: 1.857457 | Test Accuracy: 0.830465\n",
      "Step 11 | Training Loss: 0.559758 | Test Loss: 1.838614 | Test Accuracy: 0.806334\n",
      "Step 12 | Training Loss: 1.209791 | Test Loss: 1.804549 | Test Accuracy: 0.797241\n",
      "Step 13 | Training Loss: 0.505316 | Test Loss: 1.792352 | Test Accuracy: 0.806068\n",
      "Step 14 | Training Loss: 5.466165 | Test Loss: 1.762382 | Test Accuracy: 0.785486\n",
      "Step 15 | Training Loss: 0.780559 | Test Loss: 1.759518 | Test Accuracy: 0.795644\n",
      "Step 16 | Training Loss: 0.521902 | Test Loss: 1.747007 | Test Accuracy: 0.793426\n",
      "Step 17 | Training Loss: 0.513381 | Test Loss: 1.730601 | Test Accuracy: 0.795112\n",
      "Step 18 | Training Loss: 1.066691 | Test Loss: 1.710999 | Test Accuracy: 0.787527\n",
      "Step 19 | Training Loss: 0.642649 | Test Loss: 1.708134 | Test Accuracy: 0.797551\n",
      "Step 20 | Training Loss: 0.471520 | Test Loss: 1.694013 | Test Accuracy: 0.796443\n",
      "Accuracy on Test data: 0.7971078753471375\n",
      "Current Layer Attributes - epochs:20 hidden layers:2 features count:16\n",
      "Step 1 | Training Loss: 1.131932 | Test Loss: 1.982778 | Test Accuracy: 0.507275\n",
      "Step 2 | Training Loss: 1.003328 | Test Loss: 1.975551 | Test Accuracy: 0.459280\n",
      "Step 3 | Training Loss: 0.690350 | Test Loss: 1.963619 | Test Accuracy: 0.539212\n",
      "Step 4 | Training Loss: 0.705750 | Test Loss: 1.953533 | Test Accuracy: 0.632142\n",
      "Step 5 | Training Loss: 0.851760 | Test Loss: 1.943569 | Test Accuracy: 0.688698\n",
      "Step 6 | Training Loss: 0.827021 | Test Loss: 1.931425 | Test Accuracy: 0.737802\n",
      "Step 7 | Training Loss: 0.809894 | Test Loss: 1.915598 | Test Accuracy: 0.754258\n",
      "Step 8 | Training Loss: 0.799163 | Test Loss: 1.896879 | Test Accuracy: 0.729374\n",
      "Step 9 | Training Loss: 0.949088 | Test Loss: 1.875581 | Test Accuracy: 0.733144\n",
      "Step 10 | Training Loss: 0.631965 | Test Loss: 1.854162 | Test Accuracy: 0.753859\n",
      "Step 11 | Training Loss: 0.516191 | Test Loss: 1.824981 | Test Accuracy: 0.760779\n",
      "Step 12 | Training Loss: 4.913429 | Test Loss: 1.801716 | Test Accuracy: 0.767388\n",
      "Step 13 | Training Loss: 0.840333 | Test Loss: 1.775723 | Test Accuracy: 0.789833\n",
      "Step 14 | Training Loss: 0.722915 | Test Loss: 1.770574 | Test Accuracy: 0.797374\n",
      "Step 15 | Training Loss: 2.719255 | Test Loss: 1.759096 | Test Accuracy: 0.801810\n",
      "Step 16 | Training Loss: 0.727300 | Test Loss: 1.739155 | Test Accuracy: 0.804294\n",
      "Step 17 | Training Loss: 0.656417 | Test Loss: 1.721520 | Test Accuracy: 0.801100\n",
      "Step 18 | Training Loss: 0.514731 | Test Loss: 1.703516 | Test Accuracy: 0.805492\n",
      "Step 19 | Training Loss: 0.596557 | Test Loss: 1.689045 | Test Accuracy: 0.806201\n",
      "Step 20 | Training Loss: 0.540185 | Test Loss: 1.668197 | Test Accuracy: 0.806246\n",
      "Accuracy on Test data: 0.8047817349433899\n",
      "Current Layer Attributes - epochs:20 hidden layers:2 features count:32\n",
      "Step 1 | Training Loss: 1.411845 | Test Loss: 5.347696 | Test Accuracy: 0.484120\n",
      "Step 2 | Training Loss: 0.825559 | Test Loss: 1.986791 | Test Accuracy: 0.541430\n",
      "Step 3 | Training Loss: 1.255484 | Test Loss: 1.973054 | Test Accuracy: 0.571549\n",
      "Step 4 | Training Loss: 0.839512 | Test Loss: 1.969957 | Test Accuracy: 0.598518\n",
      "Step 5 | Training Loss: 0.808980 | Test Loss: 1.961840 | Test Accuracy: 0.637686\n",
      "Step 6 | Training Loss: 1.007348 | Test Loss: 1.954449 | Test Accuracy: 0.683996\n",
      "Step 7 | Training Loss: 0.731875 | Test Loss: 1.944918 | Test Accuracy: 0.731281\n",
      "Step 8 | Training Loss: 1.145368 | Test Loss: 1.934248 | Test Accuracy: 0.765303\n",
      "Step 9 | Training Loss: 0.827973 | Test Loss: 1.928161 | Test Accuracy: 0.775373\n",
      "Step 10 | Training Loss: 0.737810 | Test Loss: 1.910916 | Test Accuracy: 0.786196\n",
      "Step 11 | Training Loss: 0.642469 | Test Loss: 1.894863 | Test Accuracy: 0.787793\n",
      "Step 12 | Training Loss: 0.776170 | Test Loss: 1.866707 | Test Accuracy: 0.787615\n",
      "Step 13 | Training Loss: 0.670059 | Test Loss: 1.849448 | Test Accuracy: 0.783668\n",
      "Step 14 | Training Loss: 4.122633 | Test Loss: 1.828149 | Test Accuracy: 0.789656\n",
      "Step 15 | Training Loss: 0.780850 | Test Loss: 1.795956 | Test Accuracy: 0.790454\n",
      "Step 16 | Training Loss: 0.761672 | Test Loss: 1.774832 | Test Accuracy: 0.792716\n",
      "Step 17 | Training Loss: 0.709907 | Test Loss: 1.753293 | Test Accuracy: 0.793337\n",
      "Step 18 | Training Loss: 0.544212 | Test Loss: 1.729369 | Test Accuracy: 0.796088\n",
      "Step 19 | Training Loss: 0.723441 | Test Loss: 1.702005 | Test Accuracy: 0.796975\n",
      "Step 20 | Training Loss: 0.526737 | Test Loss: 1.684524 | Test Accuracy: 0.797330\n",
      "Accuracy on Test data: 0.7991039752960205\n",
      "Current Layer Attributes - epochs:20 hidden layers:4 features count:4\n",
      "Step 1 | Training Loss: 1.430802 | Test Loss: 1.979681 | Test Accuracy: 0.444198\n",
      "Step 2 | Training Loss: 0.828981 | Test Loss: 1.979079 | Test Accuracy: 0.430491\n",
      "Step 3 | Training Loss: 0.857619 | Test Loss: 1.978221 | Test Accuracy: 0.438032\n",
      "Step 4 | Training Loss: 1.020781 | Test Loss: 1.978145 | Test Accuracy: 0.438831\n",
      "Step 5 | Training Loss: 0.721198 | Test Loss: 1.977826 | Test Accuracy: 0.441625\n",
      "Step 6 | Training Loss: 0.767941 | Test Loss: 1.977502 | Test Accuracy: 0.441936\n",
      "Step 7 | Training Loss: 0.845891 | Test Loss: 1.977121 | Test Accuracy: 0.444730\n",
      "Step 8 | Training Loss: 1.204856 | Test Loss: 1.976543 | Test Accuracy: 0.446505\n",
      "Step 9 | Training Loss: 0.898426 | Test Loss: 1.975706 | Test Accuracy: 0.448501\n",
      "Step 10 | Training Loss: 0.806747 | Test Loss: 1.975196 | Test Accuracy: 0.452582\n",
      "Step 11 | Training Loss: 1.007725 | Test Loss: 1.974000 | Test Accuracy: 0.469260\n",
      "Step 12 | Training Loss: 0.686879 | Test Loss: 1.972338 | Test Accuracy: 0.534466\n",
      "Step 13 | Training Loss: 0.872708 | Test Loss: 1.969943 | Test Accuracy: 0.628416\n",
      "Step 14 | Training Loss: 1.584720 | Test Loss: 1.966463 | Test Accuracy: 0.691891\n",
      "Step 15 | Training Loss: 0.662463 | Test Loss: 1.963478 | Test Accuracy: 0.727732\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 16 | Training Loss: 0.771923 | Test Loss: 1.960411 | Test Accuracy: 0.747161\n",
      "Step 17 | Training Loss: 0.711522 | Test Loss: 1.959039 | Test Accuracy: 0.752307\n",
      "Step 18 | Training Loss: 0.816268 | Test Loss: 1.959966 | Test Accuracy: 0.745032\n",
      "Step 19 | Training Loss: 0.854931 | Test Loss: 1.952275 | Test Accuracy: 0.736293\n",
      "Step 20 | Training Loss: 0.736558 | Test Loss: 1.949057 | Test Accuracy: 0.727910\n",
      "Accuracy on Test data: 0.7297728657722473\n",
      "Current Layer Attributes - epochs:20 hidden layers:4 features count:8\n",
      "Step 1 | Training Loss: 0.860117 | Test Loss: 41.061165 | Test Accuracy: 0.440295\n",
      "Step 2 | Training Loss: 0.745568 | Test Loss: 1.980454 | Test Accuracy: 0.471700\n",
      "Step 3 | Training Loss: 0.820645 | Test Loss: 1.980141 | Test Accuracy: 0.476757\n",
      "Step 4 | Training Loss: 0.893605 | Test Loss: 1.980076 | Test Accuracy: 0.462385\n",
      "Step 5 | Training Loss: 0.916214 | Test Loss: 1.979962 | Test Accuracy: 0.460832\n",
      "Step 6 | Training Loss: 0.967814 | Test Loss: 1.979807 | Test Accuracy: 0.458215\n",
      "Step 7 | Training Loss: 0.922424 | Test Loss: 1.979685 | Test Accuracy: 0.461187\n",
      "Step 8 | Training Loss: 0.876021 | Test Loss: 1.979749 | Test Accuracy: 0.457417\n",
      "Step 9 | Training Loss: 0.611682 | Test Loss: 1.979608 | Test Accuracy: 0.455908\n",
      "Step 10 | Training Loss: 0.820350 | Test Loss: 1.979414 | Test Accuracy: 0.459768\n",
      "Step 11 | Training Loss: 0.931464 | Test Loss: 1.979452 | Test Accuracy: 0.459368\n",
      "Step 12 | Training Loss: 1.134220 | Test Loss: 1.979371 | Test Accuracy: 0.455332\n",
      "Step 13 | Training Loss: 0.671356 | Test Loss: 1.979143 | Test Accuracy: 0.464336\n",
      "Step 14 | Training Loss: 0.910072 | Test Loss: 1.978948 | Test Accuracy: 0.467752\n",
      "Step 15 | Training Loss: 0.735123 | Test Loss: 1.978718 | Test Accuracy: 0.482301\n",
      "Step 16 | Training Loss: 0.895777 | Test Loss: 1.978146 | Test Accuracy: 0.492548\n",
      "Step 17 | Training Loss: 0.814053 | Test Loss: 1.977646 | Test Accuracy: 0.510114\n",
      "Step 18 | Training Loss: 0.715903 | Test Loss: 1.976963 | Test Accuracy: 0.534954\n",
      "Step 19 | Training Loss: 0.751702 | Test Loss: 1.976210 | Test Accuracy: 0.558375\n",
      "Step 20 | Training Loss: 0.868388 | Test Loss: 1.975377 | Test Accuracy: 0.595990\n",
      "Accuracy on Test data: 0.6009137630462646\n",
      "Current Layer Attributes - epochs:20 hidden layers:4 features count:16\n",
      "Step 1 | Training Loss: 0.724196 | Test Loss: 1.980515 | Test Accuracy: 0.542938\n",
      "Step 2 | Training Loss: 2.089069 | Test Loss: 1.979709 | Test Accuracy: 0.517699\n",
      "Step 3 | Training Loss: 0.986857 | Test Loss: 1.978379 | Test Accuracy: 0.503903\n",
      "Step 4 | Training Loss: 0.868392 | Test Loss: 1.977174 | Test Accuracy: 0.487713\n",
      "Step 5 | Training Loss: 0.865516 | Test Loss: 1.976547 | Test Accuracy: 0.471655\n",
      "Step 6 | Training Loss: 4.551815 | Test Loss: 1.975729 | Test Accuracy: 0.459102\n",
      "Step 7 | Training Loss: 0.911725 | Test Loss: 1.974949 | Test Accuracy: 0.452005\n",
      "Step 8 | Training Loss: 0.872091 | Test Loss: 1.974028 | Test Accuracy: 0.440161\n",
      "Step 9 | Training Loss: 0.823203 | Test Loss: 1.972607 | Test Accuracy: 0.446638\n",
      "Step 10 | Training Loss: 0.816101 | Test Loss: 1.970835 | Test Accuracy: 0.461187\n",
      "Step 11 | Training Loss: 0.987708 | Test Loss: 1.968653 | Test Accuracy: 0.496451\n",
      "Step 12 | Training Loss: 0.751612 | Test Loss: 1.965726 | Test Accuracy: 0.570662\n",
      "Step 13 | Training Loss: 0.809250 | Test Loss: 1.961717 | Test Accuracy: 0.696549\n",
      "Step 14 | Training Loss: 0.835736 | Test Loss: 1.958520 | Test Accuracy: 0.763130\n",
      "Step 15 | Training Loss: 0.739006 | Test Loss: 1.959201 | Test Accuracy: 0.816581\n",
      "Step 16 | Training Loss: 0.864546 | Test Loss: 1.950161 | Test Accuracy: 0.841998\n",
      "Step 17 | Training Loss: 0.908390 | Test Loss: 1.938463 | Test Accuracy: 0.850470\n",
      "Step 18 | Training Loss: 1.555523 | Test Loss: 1.913882 | Test Accuracy: 0.841066\n",
      "Step 19 | Training Loss: 0.867000 | Test Loss: 1.902317 | Test Accuracy: 0.827981\n",
      "Step 20 | Training Loss: 0.741017 | Test Loss: 1.886831 | Test Accuracy: 0.817069\n",
      "Accuracy on Test data: 0.817379355430603\n",
      "Current Layer Attributes - epochs:20 hidden layers:4 features count:32\n",
      "Step 1 | Training Loss: 0.901256 | Test Loss: 1.980451 | Test Accuracy: 0.536018\n",
      "Step 2 | Training Loss: 0.761460 | Test Loss: 1.979990 | Test Accuracy: 0.565383\n",
      "Step 3 | Training Loss: 0.899781 | Test Loss: 1.979625 | Test Accuracy: 0.539744\n",
      "Step 4 | Training Loss: 1.443424 | Test Loss: 1.979494 | Test Accuracy: 0.515791\n",
      "Step 5 | Training Loss: 0.804114 | Test Loss: 1.979689 | Test Accuracy: 0.499202\n",
      "Step 6 | Training Loss: 0.776413 | Test Loss: 1.979924 | Test Accuracy: 0.486914\n",
      "Step 7 | Training Loss: 0.809113 | Test Loss: 1.977468 | Test Accuracy: 0.483011\n",
      "Step 8 | Training Loss: 1.254413 | Test Loss: 2.397069 | Test Accuracy: 0.470546\n",
      "Step 9 | Training Loss: 0.914877 | Test Loss: 1.980026 | Test Accuracy: 0.510380\n",
      "Step 10 | Training Loss: 0.741891 | Test Loss: 1.979902 | Test Accuracy: 0.506343\n",
      "Step 11 | Training Loss: 1.052894 | Test Loss: 1.982701 | Test Accuracy: 0.456618\n",
      "Step 12 | Training Loss: 0.731087 | Test Loss: 1.984459 | Test Accuracy: 0.451916\n",
      "Step 13 | Training Loss: 0.854422 | Test Loss: 1.982169 | Test Accuracy: 0.451694\n",
      "Step 14 | Training Loss: 0.923598 | Test Loss: 1.988045 | Test Accuracy: 0.510513\n",
      "Step 15 | Training Loss: 0.856223 | Test Loss: 1.983156 | Test Accuracy: 0.496052\n",
      "Step 16 | Training Loss: 0.694452 | Test Loss: 1.982370 | Test Accuracy: 0.487846\n",
      "Step 17 | Training Loss: 0.697433 | Test Loss: 1.981735 | Test Accuracy: 0.486471\n",
      "Step 18 | Training Loss: 0.989711 | Test Loss: 1.981795 | Test Accuracy: 0.434306\n",
      "Step 19 | Training Loss: 3.032374 | Test Loss: 1.981369 | Test Accuracy: 0.437367\n",
      "Step 20 | Training Loss: 0.764096 | Test Loss: 1.981071 | Test Accuracy: 0.444065\n",
      "Accuracy on Test data: 0.4440649449825287\n",
      "Current Layer Attributes - epochs:20 hidden layers:6 features count:4\n",
      "Step 1 | Training Loss: 0.966853 | Test Loss: 1.981143 | Test Accuracy: 0.538148\n",
      "Step 2 | Training Loss: 0.950849 | Test Loss: 1.980703 | Test Accuracy: 0.511888\n",
      "Step 3 | Training Loss: 0.778077 | Test Loss: 1.980641 | Test Accuracy: 0.499956\n",
      "Step 4 | Training Loss: 0.805805 | Test Loss: 1.980522 | Test Accuracy: 0.489975\n",
      "Step 5 | Training Loss: 0.793483 | Test Loss: 1.980657 | Test Accuracy: 0.480704\n",
      "Step 6 | Training Loss: 0.959255 | Test Loss: 1.980943 | Test Accuracy: 0.472764\n",
      "Step 7 | Training Loss: 0.888033 | Test Loss: 1.981078 | Test Accuracy: 0.474760\n",
      "Step 8 | Training Loss: 0.782836 | Test Loss: 1.981181 | Test Accuracy: 0.472942\n",
      "Step 9 | Training Loss: 5.327986 | Test Loss: 1.981273 | Test Accuracy: 0.469792\n",
      "Step 10 | Training Loss: 0.807368 | Test Loss: 1.981259 | Test Accuracy: 0.465712\n",
      "Step 11 | Training Loss: 0.910756 | Test Loss: 1.981423 | Test Accuracy: 0.465135\n",
      "Step 12 | Training Loss: 1.103438 | Test Loss: 1.981791 | Test Accuracy: 0.466599\n",
      "Step 13 | Training Loss: 0.928752 | Test Loss: 1.981781 | Test Accuracy: 0.456796\n",
      "Step 14 | Training Loss: 0.764525 | Test Loss: 1.981851 | Test Accuracy: 0.456884\n",
      "Step 15 | Training Loss: 0.888794 | Test Loss: 1.982006 | Test Accuracy: 0.460389\n",
      "Step 16 | Training Loss: 0.812141 | Test Loss: 1.982149 | Test Accuracy: 0.456973\n",
      "Step 17 | Training Loss: 0.883160 | Test Loss: 1.982255 | Test Accuracy: 0.465578\n",
      "Step 18 | Training Loss: 0.822172 | Test Loss: 1.982401 | Test Accuracy: 0.472365\n",
      "Step 19 | Training Loss: 1.856727 | Test Loss: 1.982412 | Test Accuracy: 0.478176\n",
      "Step 20 | Training Loss: 0.699791 | Test Loss: 1.982404 | Test Accuracy: 0.487890\n",
      "Accuracy on Test data: 0.4878016412258148\n",
      "Current Layer Attributes - epochs:20 hidden layers:6 features count:8\n",
      "Step 1 | Training Loss: 0.761132 | Test Loss: 1.980198 | Test Accuracy: 0.510247\n",
      "Step 2 | Training Loss: 0.772379 | Test Loss: 1.979942 | Test Accuracy: 0.476313\n",
      "Step 3 | Training Loss: 0.805316 | Test Loss: 1.979870 | Test Accuracy: 0.453646\n",
      "Step 4 | Training Loss: 0.781012 | Test Loss: 1.980129 | Test Accuracy: 0.446283\n",
      "Step 5 | Training Loss: 0.769111 | Test Loss: 1.980276 | Test Accuracy: 0.438165\n",
      "Step 6 | Training Loss: 0.855894 | Test Loss: 1.980691 | Test Accuracy: 0.433907\n",
      "Step 7 | Training Loss: 0.663694 | Test Loss: 1.980419 | Test Accuracy: 0.432709\n",
      "Step 8 | Training Loss: 0.936290 | Test Loss: 1.982541 | Test Accuracy: 0.432532\n",
      "Step 9 | Training Loss: 0.901324 | Test Loss: 1.981236 | Test Accuracy: 0.432000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 10 | Training Loss: 0.817564 | Test Loss: 1.981450 | Test Accuracy: 0.431201\n",
      "Step 11 | Training Loss: 1.268507 | Test Loss: 1.981647 | Test Accuracy: 0.431334\n",
      "Step 12 | Training Loss: 0.831214 | Test Loss: 1.981780 | Test Accuracy: 0.430758\n",
      "Step 13 | Training Loss: 0.919483 | Test Loss: 1.981920 | Test Accuracy: 0.431246\n",
      "Step 14 | Training Loss: 0.682634 | Test Loss: 1.982109 | Test Accuracy: 0.430669\n",
      "Step 15 | Training Loss: 1.076697 | Test Loss: 1.982235 | Test Accuracy: 0.431068\n",
      "Step 16 | Training Loss: 0.888673 | Test Loss: 1.982230 | Test Accuracy: 0.430979\n",
      "Step 17 | Training Loss: 0.693784 | Test Loss: 1.982355 | Test Accuracy: 0.430802\n",
      "Step 18 | Training Loss: 0.890204 | Test Loss: 1.982413 | Test Accuracy: 0.430758\n",
      "Step 19 | Training Loss: 0.750134 | Test Loss: 1.982535 | Test Accuracy: 0.431112\n",
      "Step 20 | Training Loss: 2.940468 | Test Loss: 1.982503 | Test Accuracy: 0.430891\n",
      "Accuracy on Test data: 0.43080198764801025\n",
      "Current Layer Attributes - epochs:20 hidden layers:6 features count:16\n",
      "Step 1 | Training Loss: 0.878165 | Test Loss: 1.978152 | Test Accuracy: 0.558951\n",
      "Step 2 | Training Loss: 0.768877 | Test Loss: 1.976705 | Test Accuracy: 0.510557\n",
      "Step 3 | Training Loss: 0.826794 | Test Loss: 1.972977 | Test Accuracy: 0.496141\n",
      "Step 4 | Training Loss: 0.981239 | Test Loss: 1.973889 | Test Accuracy: 0.484475\n",
      "Step 5 | Training Loss: 0.813717 | Test Loss: 1.980554 | Test Accuracy: 0.453912\n",
      "Step 6 | Training Loss: 0.702637 | Test Loss: 1.980960 | Test Accuracy: 0.451473\n",
      "Step 7 | Training Loss: 0.908874 | Test Loss: 1.981088 | Test Accuracy: 0.451295\n",
      "Step 8 | Training Loss: 0.803953 | Test Loss: 1.980944 | Test Accuracy: 0.453824\n",
      "Step 9 | Training Loss: 0.747659 | Test Loss: 1.981353 | Test Accuracy: 0.449920\n",
      "Step 10 | Training Loss: 0.980753 | Test Loss: 1.981518 | Test Accuracy: 0.451872\n",
      "Step 11 | Training Loss: 0.848785 | Test Loss: 1.981561 | Test Accuracy: 0.444331\n",
      "Step 12 | Training Loss: 0.920968 | Test Loss: 1.981832 | Test Accuracy: 0.446327\n",
      "Step 13 | Training Loss: 0.887231 | Test Loss: 1.982153 | Test Accuracy: 0.444863\n",
      "Step 14 | Training Loss: 1.037157 | Test Loss: 1.982059 | Test Accuracy: 0.445218\n",
      "Step 15 | Training Loss: 1.183670 | Test Loss: 1.982285 | Test Accuracy: 0.446948\n",
      "Step 16 | Training Loss: 0.935438 | Test Loss: 1.982452 | Test Accuracy: 0.448323\n",
      "Step 17 | Training Loss: 0.705437 | Test Loss: 1.982326 | Test Accuracy: 0.455376\n",
      "Step 18 | Training Loss: 0.780105 | Test Loss: 1.990208 | Test Accuracy: 0.455731\n",
      "Step 19 | Training Loss: 0.934769 | Test Loss: 1.983743 | Test Accuracy: 0.431822\n",
      "Step 20 | Training Loss: 0.690786 | Test Loss: 1.983164 | Test Accuracy: 0.433153\n",
      "Accuracy on Test data: 0.43359652161598206\n",
      "Current Layer Attributes - epochs:20 hidden layers:6 features count:32\n",
      "Step 1 | Training Loss: 0.788104 | Test Loss: 1.996003 | Test Accuracy: 0.485983\n",
      "Step 2 | Training Loss: 0.729035 | Test Loss: 2.445278 | Test Accuracy: 0.495786\n",
      "Step 3 | Training Loss: 0.849955 | Test Loss: 1.977540 | Test Accuracy: 0.486604\n",
      "Step 4 | Training Loss: 0.818195 | Test Loss: 118.971672 | Test Accuracy: 0.483455\n",
      "Step 5 | Training Loss: 1.084712 | Test Loss: 1.980789 | Test Accuracy: 0.450142\n",
      "Step 6 | Training Loss: 1.137498 | Test Loss: 1.980549 | Test Accuracy: 0.453070\n",
      "Step 7 | Training Loss: 0.771307 | Test Loss: 1.980692 | Test Accuracy: 0.459102\n",
      "Step 8 | Training Loss: 0.899425 | Test Loss: 1.980103 | Test Accuracy: 0.458392\n",
      "Step 9 | Training Loss: 0.870060 | Test Loss: 1.982416 | Test Accuracy: 0.462562\n",
      "Step 10 | Training Loss: 0.816445 | Test Loss: 1.979398 | Test Accuracy: 0.454445\n",
      "Step 11 | Training Loss: 0.665155 | Test Loss: 1.979912 | Test Accuracy: 0.456840\n",
      "Step 12 | Training Loss: 0.918267 | Test Loss: 1.980127 | Test Accuracy: 0.451517\n",
      "Step 13 | Training Loss: 0.818896 | Test Loss: 1.980305 | Test Accuracy: 0.448279\n",
      "Step 14 | Training Loss: 0.680671 | Test Loss: 1.980935 | Test Accuracy: 0.443400\n",
      "Step 15 | Training Loss: 0.841932 | Test Loss: 1.981127 | Test Accuracy: 0.431112\n",
      "Step 16 | Training Loss: 0.736926 | Test Loss: 1.981197 | Test Accuracy: 0.431290\n",
      "Step 17 | Training Loss: 0.711551 | Test Loss: 1.981181 | Test Accuracy: 0.431512\n",
      "Step 18 | Training Loss: 0.871361 | Test Loss: 1.981331 | Test Accuracy: 0.431600\n"
     ]
    }
   ],
   "source": [
    "import itertools\n",
    "class Hyperparameters:\n",
    "#    features_arr = [2, 4, 8, 16, 32, 64, 128, 256]\n",
    "#    hidden_layers_arr = [2, 4, 6, 10]\n",
    "    features_arr = [4, 8, 16, 32]\n",
    "    hidden_layers_arr = [2, 4]\n",
    "\n",
    "    epochs = [20]\n",
    "    \n",
    "    for e, h, f in itertools.product(epochs, hidden_layers_arr, features_arr):\n",
    "        print(\"Current Layer Attributes - epochs:{} hidden layers:{} features count:{}\".format(e,h,f))\n",
    "        n = network(2,h,f)\n",
    "        n.build_layers()\n",
    "        Train.train(e, n, h,f)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2017-05-13T19:58:45.203Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_results = pd.DataFrame(Train.results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2017-05-13T19:58:45.206Z"
    }
   },
   "outputs": [],
   "source": [
    "df_results.sort_values(by = 'test_score', ascending = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2017-05-13T19:58:45.213Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pd.Panel(Train.predictions).to_pickle(\"dataset/tf_vae_only_nsl_kdd_predictions.pkl\")\n",
    "df_results.to_pickle(\"dataset/tf_vae_only_nsl_kdd_scores.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2017-05-13T19:58:45.216Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import itertools\n",
    "\n",
    "def plot_confusion_matrix(cm, classes,\n",
    "                          normalize=False,\n",
    "                          title='Confusion matrix',\n",
    "                          cmap=plt.cm.Blues):\n",
    "    \"\"\"\n",
    "    This function prints and plots the confusion matrix.\n",
    "    Normalization can be applied by setting `normalize=True`.\n",
    "    \"\"\"\n",
    "    np.set_printoptions(precision=4)\n",
    "\n",
    "    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n",
    "    plt.title(title)\n",
    "    plt.colorbar()\n",
    "    tick_marks = np.arange(len(classes))\n",
    "    plt.xticks(tick_marks, classes, rotation=45)\n",
    "    plt.yticks(tick_marks, classes)\n",
    "\n",
    "    if normalize:\n",
    "        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "        print(\"Normalized confusion matrix\")\n",
    "    else:\n",
    "        print('Confusion matrix, without normalization')\n",
    "\n",
    "    print(cm)\n",
    "\n",
    "    thresh = cm.max() / 2.\n",
    "    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
    "        plt.text(j, i, cm[i, j].round(4),\n",
    "                 horizontalalignment=\"center\",\n",
    "                 color=\"white\" if cm[i, j] > thresh else \"black\")\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.ylabel('True label')\n",
    "    plt.xlabel('Predicted label')\n",
    "\n",
    "def plot(actual_value, pred_value):\n",
    "    from sklearn.metrics import confusion_matrix\n",
    "    cm_2labels = confusion_matrix(y_pred = pred_value, y_true = actual_value)\n",
    "    plt.figure(figsize=[6,6])\n",
    "    plot_confusion_matrix(cm_2labels, preprocess.output_columns_2labels, normalize = True,\n",
    "                         title = Train.best_parameters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2017-05-13T19:58:45.218Z"
    }
   },
   "outputs": [],
   "source": [
    "plot(actual_value = Train.actual_value, pred_value = Train.pred_value)"
   ]
  }
 ],
 "metadata": {
  "_draft": {
   "nbviewer_url": "https://gist.github.com/7d1ace18a82178e15ece8fc5252fce88"
  },
  "anaconda-cloud": {},
  "gist": {
   "data": {
    "description": "Hyper parameter tuning",
    "public": false
   },
   "id": "7d1ace18a82178e15ece8fc5252fce88"
  },
  "kernelspec": {
   "display_name": "Python [conda env:p3]",
   "language": "python",
   "name": "conda-env-p3-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
