{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Read Data Sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-05-14T14:40:00.459309Z",
     "start_time": "2017-05-14T14:40:00.062583Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from collections import namedtuple\n",
    "pd.set_option(\"display.max_rows\",35)\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-05-14T14:40:00.543989Z",
     "start_time": "2017-05-14T14:40:00.461212Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class dataset:\n",
    "    kdd_train_2labels = pd.read_pickle(\"dataset/kdd_train_2labels.pkl\")\n",
    "    kdd_test_2labels = pd.read_pickle(\"dataset/kdd_test_2labels.pkl\")\n",
    "    \n",
    "    kdd_train_5labels = pd.read_pickle(\"dataset/kdd_train_5labels.pkl\")\n",
    "    kdd_test_5labels = pd.read_pickle(\"dataset/kdd_test_5labels.pkl\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-05-14T14:40:00.550312Z",
     "start_time": "2017-05-14T14:40:00.545629Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(125973, 124)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.kdd_train_2labels.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-05-14T14:40:00.556151Z",
     "start_time": "2017-05-14T14:40:00.551815Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(22544, 124)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.kdd_test_2labels.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-05-14T14:40:01.438627Z",
     "start_time": "2017-05-14T14:40:00.557618Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.99186991653217393"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn import model_selection as ms\n",
    "from sklearn import preprocessing as pp\n",
    "\n",
    "class preprocess:\n",
    "    \n",
    "    output_columns_2labels = ['is_Attack','is_Normal']\n",
    "    \n",
    "    x_input = dataset.kdd_train_2labels.drop(output_columns_2labels, axis = 1)\n",
    "    y_output = dataset.kdd_train_2labels.loc[:,output_columns_2labels]\n",
    "\n",
    "    x_test_input = dataset.kdd_test_2labels.drop(output_columns_2labels, axis = 1)\n",
    "    y_test = dataset.kdd_test_2labels.loc[:,output_columns_2labels]\n",
    "\n",
    "    ss = pp.StandardScaler()\n",
    "\n",
    "    x_train = ss.fit_transform(x_input)\n",
    "    x_test = ss.transform(x_test_input)\n",
    "\n",
    "    y_train = y_output.values\n",
    "    y_test = y_test.values\n",
    "\n",
    "    x_train = np.hstack((x_train, y_train))\n",
    "    x_test = np.hstack((x_test, np.random.normal(size = (x_test.shape[0], y_train.shape[1]))))\n",
    "    #x_test = np.hstack((x_test, y_test))\n",
    "    \n",
    "preprocess.x_train.std()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-05-14T14:40:02.496098Z",
     "start_time": "2017-05-14T14:40:01.440405Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-05-14T14:40:02.859928Z",
     "start_time": "2017-05-14T14:40:02.497976Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class network(object):\n",
    "    \n",
    "    input_dim = 124\n",
    "    classes = 2\n",
    "    hidden_encoder_dim = 124\n",
    "    hidden_layers = 1\n",
    "    latent_dim = 10\n",
    "\n",
    "    hidden_decoder_dim = 124\n",
    "    lam = 0.01\n",
    "    \n",
    "    def __init__(self, classes, hidden_layers, num_of_features):\n",
    "        self.classes = classes\n",
    "        self.hidden_layers = hidden_layers\n",
    "        self.latent_dim = num_of_features\n",
    "            \n",
    "    def build_layers(self):\n",
    "        tf.reset_default_graph()\n",
    "        #learning_rate = tf.Variable(initial_value=0.001)\n",
    "\n",
    "        input_dim = self.input_dim\n",
    "        classes = self.classes\n",
    "        hidden_encoder_dim = self.hidden_encoder_dim\n",
    "        hidden_layers = self.hidden_layers\n",
    "        latent_dim = self.latent_dim\n",
    "        hidden_decoder_dim = self.hidden_decoder_dim\n",
    "        lam = self.lam\n",
    "        \n",
    "        with tf.variable_scope(\"Input\"):\n",
    "            self.x = tf.placeholder(\"float\", shape=[None, input_dim])\n",
    "            self.y_ = tf.placeholder(\"float\", shape=[None, classes])\n",
    "            self.keep_prob = tf.placeholder(\"float\")\n",
    "        \n",
    "        with tf.variable_scope(\"Layer_Encoder\"):\n",
    "\n",
    "            hidden_encoder = tf.layers.dense(self.x, hidden_encoder_dim, activation = tf.nn.relu, kernel_regularizer=tf.nn.l2_loss)\n",
    "            hidden_encoder = tf.nn.dropout(hidden_encoder, self.keep_prob)\n",
    "            for h in range(hidden_layers - 1):\n",
    "                hidden_encoder = tf.layers.dense(hidden_encoder, hidden_encoder_dim, activation = tf.nn.relu, kernel_regularizer=tf.nn.l2_loss)\n",
    "                hidden_encoder = tf.nn.dropout(hidden_encoder, self.keep_prob)\n",
    "                \n",
    "        with tf.variable_scope(\"Layer_Mean\"):\n",
    "            mu_encoder = tf.layers.dense(hidden_encoder, latent_dim, activation = None, kernel_regularizer=tf.nn.l2_loss)\n",
    "\n",
    "        with tf.variable_scope(\"Layer_Variance\"):\n",
    "            logvar_encoder = tf.layers.dense(hidden_encoder, latent_dim, activation = None, kernel_regularizer=tf.nn.l2_loss)\n",
    "\n",
    "        with tf.variable_scope(\"Sampling_Distribution\"):\n",
    "            # Sample epsilon\n",
    "            epsilon = tf.random_normal(tf.shape(logvar_encoder), mean=0, stddev=1, name='epsilon')\n",
    "\n",
    "            # Sample latent variable\n",
    "            std_encoder = tf.exp(0.5 * logvar_encoder)\n",
    "            z = mu_encoder + tf.multiply(std_encoder, epsilon)\n",
    "            \n",
    "            #tf.summary.histogram(\"Sample_Distribution\", z)\n",
    "\n",
    "        with tf.variable_scope(\"Layer_Decoder\"):\n",
    "            hidden_decoder = tf.layers.dense(z, hidden_decoder_dim, activation = tf.nn.relu, kernel_regularizer=tf.nn.l2_loss)\n",
    "            hidden_decoder = tf.nn.dropout(hidden_decoder, self.keep_prob)\n",
    "            for h in range(hidden_layers - 1):\n",
    "                hidden_decoder = tf.layers.dense(hidden_decoder, hidden_decoder_dim, activation = tf.nn.relu, kernel_regularizer=tf.nn.l2_loss)\n",
    "                hidden_decoder = tf.nn.dropout(hidden_decoder, self.keep_prob)\n",
    "                \n",
    "        with tf.variable_scope(\"Layer_Reconstruction\"):\n",
    "            self.x_hat = tf.layers.dense(hidden_decoder, input_dim, activation = None)\n",
    "            \n",
    "            self.y = tf.slice(self.x_hat, [0,input_dim-2], [-1,-1])\n",
    "\n",
    "        with tf.variable_scope(\"Loss\"):\n",
    "            \n",
    "            self.regularized_loss = tf.losses.mean_squared_error(self.x, self.x_hat) #tf.reduce_mean((BCE + KLD + softmax_loss) * lam)\n",
    "\n",
    "            correct_prediction = tf.equal(tf.argmax(self.y, 1), tf.argmax(self.y_, 1))\n",
    "            self.tf_accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32), name = \"Accuracy\")\n",
    "\n",
    "        with tf.variable_scope(\"Optimizer\"):\n",
    "            learning_rate=1e-2\n",
    "            optimizer = tf.train.AdamOptimizer(learning_rate)\n",
    "            gradients, variables = zip(*optimizer.compute_gradients(self.regularized_loss))\n",
    "            gradients = [\n",
    "                None if gradient is None else tf.clip_by_value(gradient, -1, 1)\n",
    "                for gradient in gradients]\n",
    "            self.train_op = optimizer.apply_gradients(zip(gradients, variables))\n",
    "            #self.train_op = optimizer.minimize(self.regularized_loss)\n",
    "            \n",
    "        # add op for merging summary\n",
    "        #self.summary_op = tf.summary.merge_all()\n",
    "        self.pred = tf.argmax(self.y, axis = 1)\n",
    "        self.actual = tf.argmax(self.y_, axis = 1)\n",
    "\n",
    "        # add Saver ops\n",
    "        self.saver = tf.train.Saver()\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2017-05-14T14:40:01.642Z"
    },
    "collapsed": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import collections\n",
    "\n",
    "class Train:    \n",
    "    \n",
    "    result = namedtuple(\"score\", ['epoch', 'no_of_features','hidden_layers','train_score', 'test_score'])\n",
    "\n",
    "    predictions = {}\n",
    "\n",
    "    results = []\n",
    "    best_acc = 0\n",
    "    \n",
    "    def train(epochs, net, h,f):\n",
    "        batch_iterations = 200\n",
    "    \n",
    "        with tf.Session() as sess:\n",
    "            #summary_writer_train = tf.summary.FileWriter('./logs/kdd/VAE/training', graph=sess.graph)\n",
    "            #summary_writer_valid = tf.summary.FileWriter('./logs/kdd/VAE/validation')\n",
    "\n",
    "            sess.run(tf.global_variables_initializer())\n",
    "\n",
    "            for epoch in range(1, (epochs+1)):\n",
    "                print(\"Step {} | Training Loss:\".format(epoch), end = \" \" )\n",
    "                x_train, x_valid, y_train, y_valid, = ms.train_test_split(preprocess.x_train, \n",
    "                                                                          preprocess.y_train, \n",
    "                                                                          test_size=0.1)\n",
    "                batch_indices = np.array_split(np.arange(x_train.shape[0]), \n",
    "                                           batch_iterations)\n",
    "                                                                          \n",
    "                for i in batch_indices:\n",
    "                    _, train_loss = sess.run([net.train_op, \n",
    "                                                           net.regularized_loss, \n",
    "                                                           ], #net.summary_op\n",
    "                                                          feed_dict={net.x: x_train[i,:], \n",
    "                                                                     net.y_: y_train[i,:], \n",
    "                                                                     net.keep_prob:1})\n",
    "                    \n",
    "                    #summary_writer_train.add_summary(summary_str, epoch)\n",
    "                    #if(train_loss > 1e9):\n",
    "                    \n",
    "                    print(\"{:.6f}\".format(train_loss), end = \", \" )\n",
    "                    \n",
    "                print(\"\")\n",
    "                valid_loss, valid_accuracy = sess.run([net.regularized_loss, net.tf_accuracy], feed_dict={net.x: x_valid, \n",
    "                                                                     net.y_: y_valid, \n",
    "                                                                     net.keep_prob:1})\n",
    "                    \n",
    "                \n",
    "                accuracy, test_loss, pred_value, actual_value, y_pred = sess.run([net.tf_accuracy, net.regularized_loss, \n",
    "                                                               net.pred, \n",
    "                                                               net.actual, net.y], \n",
    "                                                              feed_dict={net.x: preprocess.x_test, \n",
    "                                                                         net.y_: preprocess.y_test, \n",
    "                                                                         net.keep_prob:1})\n",
    "                print(\"*************** \\n\")\n",
    "                print(\"Step {} | Training Loss: {:.6f} | Test Loss: {:6f} | Test Accuracy: {:.6f}\".format(epoch, train_loss, test_loss, accuracy))\n",
    "                print(\"*************** \\n\")\n",
    "                #print(\"Accuracy on Test data: {}\".format(accuracy))\n",
    "\n",
    "                curr_pred = pd.DataFrame({\"Attack_prob\":y_pred[:,-2], \"Normal_prob\":y_pred[:, -1]})\n",
    "                Train.predictions.update({\"{}_{}_{}\".format(epochs,f,h):curr_pred})\n",
    "\n",
    "                if accuracy > Train.best_acc:\n",
    "                    Train.best_acc = accuracy\n",
    "                    Train.pred_value = pred_value\n",
    "                    Train.actual_value = actual_value\n",
    "                    Train.best_parameters = \"Hidden Layers:{}, Features Count:{}\".format(h, f)\n",
    "                    net.saver.save(sess, \"dataset/epochs_{}_hidden layers_{}_features count_{}\".format(epochs,h,f))\n",
    "                Train.results.append(Train.result(epochs, f, h,valid_accuracy, accuracy))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2017-05-14T14:40:01.651Z"
    },
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current Layer Attributes - epochs:10 hidden layers:2 features count:4\n",
      "Step 1 | Training Loss: 0.971501, 1.769891, 0.813020, 0.920106, 1.034283, 0.784548, 0.716328, 1.102496, 1.555409, 0.934219, 1.725376, 1.268553, 1.567037, 1.379751, 0.669478, 0.634062, 0.651623, 0.612105, 1.491173, 0.719726, 0.591719, 0.613716, 0.672678, 0.616118, 0.686778, 0.801340, 0.663362, 0.555497, 0.554710, 0.508633, 0.506480, 0.738296, 0.928209, 0.519698, 0.647949, 0.585307, 0.467132, 0.566249, 0.605008, 0.586546, 0.594530, 0.461908, 0.515174, 0.489698, 0.494205, 0.568092, 0.549056, 0.508087, 0.561938, 0.613239, 0.396013, 0.518483, 0.483804, 0.479938, 0.489826, 0.469826, 0.657302, 0.670278, 1.176635, 0.453557, 0.471253, 0.652278, 0.572935, 0.480496, 0.381861, 0.566263, 0.476033, 2.752830, 0.470846, 0.468438, 0.441266, 0.614431, 0.480909, 0.569877, 0.501382, 0.662693, 1.446235, 0.456929, 0.485116, 0.418191, 0.577189, 0.600844, 0.341357, 1.347631, 0.598851, 0.725326, 0.548304, 0.541225, 0.471126, 0.445154, 0.358881, 0.539061, 0.345073, 0.336689, 0.637768, 0.471920, 0.364428, 0.566843, 0.501903, 0.380541, 0.486750, 0.478188, 0.373822, 0.582021, 0.401845, 0.362627, 0.464544, 0.561543, 0.371116, 0.334314, 0.357639, 0.521417, 0.353606, 0.311778, 0.334964, 0.571242, 0.458556, 0.313106, 0.359052, 0.440676, 0.453759, 0.380151, 0.446423, 0.317701, 0.379043, 0.366233, 0.398589, 0.530076, 0.415515, 0.383277, 0.653605, 0.398955, 0.243376, 0.396378, 0.434998, 0.472046, 0.426272, 0.437205, 0.336250, 0.378495, 0.337298, 1.212002, 0.357789, 0.352282, 0.307458, 0.402914, 0.612814, 0.475214, 1.491028, 0.375285, 0.448851, 1.052382, 0.315145, 0.596032, 0.370952, 0.397133, 0.415771, 0.417768, 0.336697, 0.460663, 0.292654, 0.526070, 0.391032, 0.328599, 0.451174, 1.870700, 0.385499, 0.339776, 0.719042, 0.467628, 0.379657, 0.257267, 0.363966, 1.242522, 0.356211, 0.571936, 0.361485, 0.353333, 0.423537, 0.498945, 0.314726, 0.520500, 0.366205, 0.335315, 0.579991, 0.334727, 0.271094, 0.317367, 0.414850, 0.361739, 0.266957, 0.386598, 0.304504, 0.606201, 0.266480, 0.294422, 0.237678, 0.455830, 0.648631, 0.427082, \n",
      "*************** \n",
      "\n",
      "Step 1 | Training Loss: 0.427082 | Test Loss: 1.403199 | Test Accuracy: 0.801721\n",
      "*************** \n",
      "\n",
      "Step 2 | Training Loss: 0.554231, 0.371010, 0.228373, 0.304177, 0.469647, 0.269224, 0.352361, 0.536314, 0.332364, 0.233624, 0.266911, 0.664029, 0.506389, 0.263253, 0.221999, 0.333243, 0.277021, 0.459273, 0.378567, 0.455297, 0.266110, 0.299574, 0.364636, 0.301044, 0.351732, 0.582303, 1.146638, 0.429897, 0.534108, 0.184114, 0.294187, 0.446676, 0.225515, 0.401520, 0.274057, 0.296898, 0.310907, 0.184877, 0.789801, 0.398931, 0.239878, 0.413929, 0.318397, 0.277192, 0.284142, 0.298377, 0.276183, 0.248871, 0.233491, 0.311267, 0.355427, 0.339921, 0.269701, 0.520213, 0.322246, 0.272553, 0.252043, 2.206942, 0.364025, 0.245162, 0.283353, 0.247736, 0.201546, 0.367825, 0.319101, 0.205872, 0.339064, 0.232393, 0.820556, 0.372569, 0.318967, 0.223270, 0.322958, 0.259336, 0.226886, 1.129853, 0.284209, 0.396373, 0.266761, 0.330621, 0.549290, 0.489590, 0.323705, 0.333637, 0.266230, 0.207944, 0.387073, 0.418664, 1.252883, 0.466396, 0.518815, 0.802219, 0.884531, 0.384782, 0.543676, 0.602867, 0.332139, 0.269383, 0.323453, 0.321343, 0.362900, 0.296850, 0.267457, 0.362029, 0.275859, 0.320100, 0.268965, 0.272754, 0.301329, 0.304691, 0.283777, 0.320693, 0.273197, 0.240482, 0.225378, 0.928780, 0.241690, 0.222761, 0.260529, 0.377960, 0.510393, 0.243169, 0.518419, 0.431136, 0.270829, 0.449603, 0.316774, 0.248095, 0.532630, 0.502214, 0.198401, 2.028506, 0.335776, 0.290883, 0.183641, 0.211046, 0.265179, 0.235331, 0.246099, 0.189958, 0.267672, 0.301729, 0.612770, 0.286334, 0.169895, 0.190659, 0.230725, 0.188430, 0.240541, 0.334220, 0.399065, 0.220082, 0.280932, 0.178486, 0.240264, 0.192050, 0.233678, 0.203375, 0.215117, 0.390750, 0.486311, 0.191739, 0.540076, 0.214597, 0.234899, 1.418192, 0.278679, 0.260373, 0.540115, 0.229453, 0.433058, 2.112450, 0.285051, 0.341707, 0.248782, 0.535978, 1.039727, 0.311228, 0.239917, 0.214173, 0.246329, 0.310618, 0.201527, 0.460704, 0.211465, 0.355741, 0.202252, 0.234669, 1.122025, 0.303883, 0.281486, 0.165796, 0.287548, 0.388176, 2.629315, 0.358274, 0.259158, 0.393075, 0.265657, 0.278969, \n",
      "*************** \n",
      "\n",
      "Step 2 | Training Loss: 0.278969 | Test Loss: 1.202989 | Test Accuracy: 0.795733\n",
      "*************** \n",
      "\n",
      "Step 3 | Training Loss: 0.317639, 0.197972, 0.262777, 0.370062, 0.472251, 0.256091, 0.180096, 0.248938, 0.541635, 0.305981, 0.263117, 0.213022, 0.424739, 0.210325, 0.178651, 0.237797, 0.291785, 0.525438, 0.248343, 0.408067, 0.466671, 0.206755, 0.223102, 2.208614, 0.214874, 0.197427, 0.464893, 0.244283, 0.194694, 0.277965, 0.219960, 0.191522, 0.866819, 0.296180, 0.267925, 0.207447, 0.361354, 0.208183, 0.165284, 0.180565, 0.261514, 0.259422, 0.255652, 0.554824, 0.218405, 0.207587, 0.314259, 0.658828, 0.234904, 0.290924, 0.360992, 0.252646, 0.206863, 0.204097, 0.179238, 0.182054, 0.268797, 0.230952, 0.594169, 0.213909, 0.185763, 0.393640, 0.362303, 0.230200, 0.251960, 0.228109, 0.190234, 0.185537, 0.208693, 0.223565, 0.227151, 0.213972, 0.461107, 0.343560, 1.103964, 0.218093, 0.213692, 0.251038, 0.174625, 0.213626, 0.307584, 0.238533, 0.168333, 0.466589, 0.243152, 0.204912, 0.217092, 0.217627, 0.158167, 0.603815, 0.265647, 0.410852, 1.120779, 0.218112, 0.447002, 0.177531, 2.361320, 0.184063, 0.534669, 1.093762, 0.546190, 0.393097, 0.332553, 0.262656, 0.278305, 0.320188, 0.416827, 0.292310, 0.542827, 0.416705, 0.269452, 0.457864, 1.154472, 0.275892, 0.457845, 0.305997, 0.213400, 0.255287, 0.378277, 0.247935, 0.243285, 1.173340, 0.514833, 0.502107, 0.484686, 0.282565, 0.322498, 0.196647, 0.280700, 0.200191, 0.329167, 0.286092, 0.211099, 1.091711, 0.420378, 0.248163, 0.267154, 0.266860, 0.341885, 0.485802, 0.316432, 1.143605, 0.373269, 0.187599, 2.263920, 0.323281, 0.298396, 0.293972, 0.389248, 0.275367, 0.319827, 0.293522, 0.284623, 0.250760, 0.470121, 0.263584, 0.233166, 0.266031, 0.886885, 0.244979, 0.264548, 0.381199, 0.296280, 0.330702, 0.437559, 0.331499, 0.231758, 0.169014, 0.188400, 0.315394, 1.311389, 0.162993, 0.241606, 0.320659, 0.300721, 0.969365, 0.193709, 0.240078, 0.173801, 0.314794, 0.276929, 0.318303, 0.681747, 0.167304, 0.187304, 0.218883, 0.193650, 0.152641, 0.177998, 0.259752, 0.848447, 0.495346, 0.255573, 0.582127, 0.247154, 0.538825, 1.723325, 0.241972, 0.226557, 0.219556, \n",
      "*************** \n",
      "\n",
      "Step 3 | Training Loss: 0.219556 | Test Loss: 1.262539 | Test Accuracy: 0.779897\n",
      "*************** \n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 4 | Training Loss: 0.247930, 0.193174, 0.251176, 0.204257, 0.196545, 0.187073, 0.465880, 0.146251, 0.210282, 0.264850, 0.209689, 0.809455, 0.213775, 0.234652, 1.743278, 0.478237, 0.168511, 0.213383, 0.216214, 0.206927, 0.196451, 0.182526, 0.190993, 0.197488, 0.270691, 0.141550, 0.224051, 0.384397, 0.269666, 0.252732, 0.192753, 0.210235, 0.165506, 0.415742, 0.475951, 0.686665, 0.340975, 0.157834, 0.254277, 0.176588, 1.147309, 0.190426, 0.234498, 0.615482, 0.270300, 0.283483, 0.151178, 0.233665, 0.192874, 0.213353, 0.373384, 0.205219, 0.131909, 0.192161, 0.248365, 7.469510, 0.321683, 1.037201, 0.321234, 0.576882, 0.300922, 1.272202, 0.320863, 0.445553, 1.174125, 0.280577, 0.330580, 0.303385, 0.573202, 0.560988, 0.265268, 0.306998, 0.361048, 0.279242, 0.830612, 0.277911, 0.338294, 0.314642, 0.294014, 0.254477, 0.483950, 0.374114, 0.444830, 0.651788, 0.220149, 0.274019, 0.260692, 0.296120, 0.571433, 0.260659, 0.375830, 0.256680, 0.623103, 0.272155, 0.381444, 0.209596, 0.271789, 0.249584, 0.272605, 0.249723, 0.341728, 0.265720, 0.271845, 0.412478, 1.189623, 0.281104, 0.753436, 0.326507, 0.258700, 3.015707, 0.406780, 0.445153, 0.195569, 1.129543, 0.240096, 0.502948, 0.259987, 0.245475, 0.272234, 0.262464, 0.202160, 0.180683, 0.278644, 0.484120, 0.267475, 0.224843, 0.349453, 0.225027, 0.406270, 0.250272, 0.485845, 0.380879, 0.262170, 0.262479, 0.247378, 0.359921, 0.227313, 0.425739, 0.200315, 0.250179, 0.452339, 0.192909, 0.320544, 0.227366, 0.237702, 0.269016, 0.268440, 0.293507, 0.265142, 0.210949, 0.152720, 0.418663, 0.242610, 0.217712, 0.415914, 69400.500000, 0.267438, 0.449813, 0.361736, 0.430159, 2.339085, 0.349908, 0.317128, 0.324055, 0.360016, 0.553773, 0.732937, 0.411796, 0.387423, 0.360176, 0.611283, 0.429554, 0.389197, 0.502047, 0.562136, 0.349786, 0.609110, 0.385856, 0.325746, 0.594692, 0.393322, 0.234191, 0.486566, 0.286583, 0.281078, 0.890960, 0.224500, 0.316599, 0.298511, 0.286876, 0.471755, 0.256179, 0.557778, 0.644796, 0.397411, 0.258972, 1.397687, 0.347371, 0.254575, 0.215570, \n",
      "*************** \n",
      "\n",
      "Step 4 | Training Loss: 0.215570 | Test Loss: 1.473255 | Test Accuracy: 0.794801\n",
      "*************** \n",
      "\n",
      "Step 5 | Training Loss: 0.272852, 0.314701, 0.215856, 0.375368, 0.240156, 0.307729, 0.325909, 0.225548, 0.651506, 0.196503, 0.253867, 0.284902, 0.186121, 0.304748, 0.255754, 0.283520, 0.236255, 1.963387, 0.534870, 0.398617, 0.412897, 0.298516, 0.372222, 0.250859, 0.471921, 0.257204, 0.203440, 0.288766, 0.209023, 0.361203, 0.609173, 0.356323, 0.463071, 0.315829, 0.282019, 0.430686, 0.278454, 0.393250, 0.434879, 0.360154, 0.452365, 0.291904, 0.279785, 0.218692, 0.252773, 1.221891, 0.296272, 0.297450, 0.243961, 0.220139, 0.286234, 0.514480, 0.331792, 0.291853, 0.254293, 0.345822, 0.849452, 0.361303, 1.149138, 0.251648, 0.422208, 0.860709, 0.214426, 0.240071, 0.246707, 0.486616, 0.312274, 0.371844, 0.581365, 0.423834, 0.405419, 1.190386, 0.468655, 0.279715, 1.282995, 0.216699, 0.582207, 0.200566, 0.162984, 0.283782, 0.454272, 0.179407, 0.345571, 0.356028, 0.194909, 2.008105, 0.360214, 0.204336, 0.364024, 0.262274, 0.440307, 0.203720, 0.304995, 0.953289, 0.161300, 0.239043, 0.568193, 0.216079, 0.251080, 0.266115, 0.332818, 0.498040, 2.154455, 1.472877, 0.488556, 0.178773, 0.449431, 0.149230, 0.184694, 0.236015, 0.183209, 0.193466, 0.172303, 0.293971, 0.210682, 0.160533, 0.229548, 0.155020, 0.297335, 1.067618, 0.295518, 0.290193, 0.212269, 0.210298, 0.266908, 0.211009, 0.133251, 0.232601, 0.420132, 0.219574, 0.194519, 0.260495, 0.155390, 0.242024, 0.168638, 0.312201, 0.585441, 0.460460, 0.264097, 0.218922, 0.185778, 0.462870, 0.275875, 0.257031, 0.147226, 1.083903, 0.184564, 0.190304, 0.223770, 0.118765, 0.222082, 0.116959, 0.331568, 0.302098, 0.255875, 0.496756, 0.812670, 0.481629, 0.289999, 0.649390, 0.141601, 0.193440, 0.118415, 0.342374, 0.234192, 0.233626, 0.163840, 0.270316, 0.241048, 0.281588, 0.293077, 0.246929, 0.230450, 0.214885, 0.138766, 0.163090, 0.267918, 0.217993, 0.343727, 0.347681, 0.229443, 0.439380, 0.223789, 0.167801, 0.126238, 0.302024, 0.215092, 0.439099, 0.338984, 0.189171, 0.163126, 0.300232, 0.533851, 0.773795, 0.178786, 0.136000, 0.264707, 0.220673, 0.585721, 1.279429, \n",
      "*************** \n",
      "\n",
      "Step 5 | Training Loss: 1.279429 | Test Loss: 1.244414 | Test Accuracy: 0.819021\n",
      "*************** \n",
      "\n",
      "Step 6 | Training Loss: 0.161075, 0.450187, 1.971811, 0.195738, 0.184953, 0.167218, 0.237795, 0.190269, 0.318010, 0.272185, 0.315989, 0.258363, 0.337380, 0.417753, 0.204742, 0.174509, 0.210455, 0.303217, 0.265906, 0.239885, 0.242289, 0.520657, 0.438048, 0.143959, 0.216998, 0.205717, 0.264445, 0.343256, 0.534324, 0.150764, 0.173877, 0.280130, 0.166332, 0.154899, 1.066503, 0.210523, 0.159543, 0.331127, 0.201331, 0.192484, 0.160668, 0.185804, 0.154153, 0.155642, 0.387619, 1.155024, 0.231337, 0.150219, 0.282905, 0.210685, 0.493188, 0.200142, 0.138052, 0.198772, 0.154859, 1.690268, 0.169838, 1.693628, 0.170637, 0.184510, 0.286393, 0.427109, 0.174086, 0.230294, 0.264542, 0.410324, 0.162502, 0.200753, 0.248510, 0.526396, 0.170509, 0.332549, 0.513708, 0.470224, 0.357180, 0.267262, 0.183735, 0.299562, 0.264146, 1.150192, 0.185889, 0.204059, 0.267851, 0.317864, 0.737224, 0.290467, 0.392737, 0.317863, 0.178860, 0.557244, 0.234479, 0.459788, 0.239978, 0.264158, 0.186935, 0.186506, 0.581487, 1.161222, 0.160093, 0.134053, 0.341544, 0.131510, 0.359221, 0.983979, 0.210205, 0.218791, 0.316999, 0.204988, 0.347368, 0.334162, 0.192429, 0.239986, 0.170991, 0.161874, 0.145000, 0.177250, 0.235502, 0.185983, 0.321783, 0.184033, 0.267773, 0.392227, 0.138037, 0.567123, 0.153494, 0.166799, 0.150847, 0.151184, 0.137930, 0.416335, 0.287411, 0.202874, 0.142398, 1.045806, 0.267082, 0.204318, 0.219101, 0.428446, 0.194189, 0.162930, 0.217246, 0.972552, 0.235406, 0.198898, 0.233228, 0.167431, 0.228202, 0.167318, 0.202806, 0.199874, 0.179080, 1.037041, 0.204038, 0.454378, 0.190932, 0.194395, 0.259204, 0.273056, 0.849938, 0.161997, 0.127288, 0.145428, 0.221090, 0.161091, 0.186558, 0.218386, 0.477940, 0.311051, 0.496272, 0.193830, 0.113336, 0.208260, 0.471773, 0.144014, 0.284385, 0.476112, 0.321548, 0.155207, 0.182366, 0.181952, 0.147154, 0.144422, 0.289468, 0.187598, 0.194676, 0.288003, 0.172953, 0.282912, 0.149762, 0.338675, 0.158551, 0.324897, 0.195638, 0.392852, 0.479222, 0.206537, 0.226662, 0.179971, 0.160395, 0.390272, \n",
      "*************** \n",
      "\n",
      "Step 6 | Training Loss: 0.390272 | Test Loss: 1.235765 | Test Accuracy: 0.777324\n",
      "*************** \n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 7 | Training Loss: 0.123688, 0.482307, 0.461445, 0.140491, 0.153191, 0.309774, 0.158581, 0.290383, 0.190606, 0.107874, 0.147204, 0.189012, 0.177504, 0.157950, 0.218667, 0.278544, 0.270474, 0.468054, 0.144012, 0.147310, 0.230683, 0.253060, 0.256852, 0.339807, 0.145313, 0.309278, 0.161671, 0.124160, 2.846088, 0.262508, 0.209204, 0.176134, 0.232422, 0.123967, 0.270846, 0.392910, 0.160316, 0.285755, 0.233655, 0.214507, 0.397086, 1.032239, 0.248731, 0.230018, 0.211227, 0.283544, 0.182613, 0.205945, 0.128767, 0.236918, 0.122504, 0.298837, 0.486477, 0.277277, 0.177490, 0.125853, 0.227330, 0.296105, 0.116079, 0.370562, 0.357918, 1.662213, 0.168111, 0.174696, 0.153471, 1.999687, 0.314943, 0.165246, 0.207701, 0.570708, 0.143808, 0.884933, 1.038702, 0.233883, 1.203412, 0.351083, 0.206936, 0.211820, 0.254004, 0.173388, 0.171686, 0.615452, 0.168592, 0.147281, 0.175078, 0.177534, 0.295009, 0.209765, 0.155115, 0.223394, 0.146950, 0.166647, 0.184356, 1.014064, 0.193948, 0.164820, 0.388850, 0.440775, 0.321232, 0.535098, 0.116530, 0.191987, 0.236853, 0.175674, 0.184694, 0.213417, 0.130437, 0.212168, 1.954827, 0.191267, 0.196472, 0.147187, 0.179696, 0.208715, 0.127364, 0.238422, 0.138800, 0.154428, 0.130078, 0.121879, 0.144032, 0.234563, 0.132191, 0.322749, 0.152416, 0.172216, 0.160614, 0.816828, 1.083578, 0.200564, 0.451684, 0.587204, 0.262259, 0.245968, 0.386247, 0.419221, 0.280929, 0.324417, 0.145639, 0.137406, 0.139954, 0.338838, 0.172219, 0.297669, 0.220182, 0.196544, 0.142598, 0.188788, 0.536885, 0.194312, 0.167004, 0.121967, 0.148431, 0.422719, 0.149078, 0.233076, 0.492820, 0.280780, 0.116449, 0.158894, 0.180013, 0.205568, 1.113602, 0.197279, 0.197266, 0.247667, 0.397608, 0.190094, 0.140147, 0.219711, 0.206445, 0.310727, 0.166450, 0.151835, 0.335102, 0.861484, 0.162766, 0.519140, 0.664754, 0.163320, 0.322637, 0.214839, 0.561459, 0.159023, 0.136295, 0.239127, 0.233201, 0.306477, 0.127694, 1.103618, 0.419131, 0.149123, 0.164527, 0.216261, 0.142108, 0.274354, 0.203247, 0.209101, 0.204561, 0.210923, \n",
      "*************** \n",
      "\n",
      "Step 7 | Training Loss: 0.210923 | Test Loss: 1.222361 | Test Accuracy: 0.776836\n",
      "*************** \n",
      "\n",
      "Step 8 | Training Loss: 0.120584, 0.118612, 0.146784, 0.160371, 0.948952, 0.170609, 0.125130, 0.216008, 0.196533, 1.069644, 0.219872, 0.162000, 0.257110, 0.216552, 0.169346, 0.159723, 0.232253, 0.220540, 0.516133, 0.114088, 0.215126, 0.499687, 0.153804, 0.318756, 0.194819, 1.192384, 0.110748, 0.173095, 0.278677, 0.133632, 0.152875, 0.244369, 0.226292, 0.129259, 0.106329, 0.137621, 0.099834, 0.144609, 0.602554, 0.164368, 0.333025, 0.450567, 0.218862, 0.126510, 0.201677, 0.120901, 0.174133, 0.170922, 0.114962, 0.180014, 0.216570, 0.156261, 0.285410, 0.179648, 0.316947, 0.434174, 0.165416, 0.125403, 0.103503, 0.154870, 2.278932, 0.240710, 0.283736, 0.399605, 0.867065, 0.147406, 0.197297, 0.759224, 0.189630, 0.748883, 0.763605, 0.120154, 0.125694, 0.256382, 0.135318, 0.260010, 0.168527, 0.153113, 0.168939, 0.184096, 0.140861, 0.215581, 0.397649, 0.101952, 0.136104, 0.186741, 0.140163, 0.426641, 0.217225, 0.151414, 0.141926, 0.160171, 0.195250, 0.261806, 0.114745, 0.387576, 0.181594, 0.124490, 1.312029, 0.371716, 0.268904, 0.483654, 0.180314, 0.339788, 0.833095, 0.363090, 0.328842, 0.154972, 0.126845, 0.120663, 0.225795, 0.711200, 0.147517, 0.187675, 0.097464, 0.134672, 0.164321, 0.151076, 0.232805, 0.402228, 0.253012, 0.347666, 0.174888, 0.135150, 0.452394, 0.211421, 0.148330, 0.087433, 0.148658, 0.155415, 0.242670, 0.151768, 0.115670, 0.147552, 0.165063, 0.764399, 0.150966, 0.493118, 0.180165, 1.080711, 0.169654, 0.143059, 0.145905, 0.223365, 0.311550, 0.314198, 0.138415, 0.145569, 0.153043, 0.153136, 0.140072, 0.173178, 0.188035, 0.176663, 1.161602, 0.180853, 0.156241, 0.158050, 0.125332, 0.168445, 0.179880, 1.042174, 0.170272, 0.962735, 0.207044, 0.340304, 0.176253, 0.141988, 0.130454, 0.179018, 0.231321, 0.131110, 0.177920, 0.162648, 0.138400, 0.621650, 0.223459, 0.126083, 0.426447, 0.156882, 1.865088, 0.145930, 0.179071, 0.149786, 0.126026, 0.348380, 0.140244, 0.377807, 0.197254, 0.421867, 0.181860, 0.252317, 0.249475, 1.971992, 0.130078, 0.133232, 0.141831, 0.188191, 0.222891, 0.146611, \n",
      "*************** \n",
      "\n",
      "Step 8 | Training Loss: 0.146611 | Test Loss: 1082060390326171860992.000000 | Test Accuracy: 0.786728\n",
      "*************** \n",
      "\n",
      "Step 9 | Training Loss: 0.124793, 1.058757, 0.294879, 0.159082, 0.179236, 0.127731, 0.151309, 0.191991, 0.363720, 1.759345, 0.621036, 0.219020, 0.362913, 0.121874, 0.493799, 0.175109, 0.099335, 1.007301, 0.264535, 0.181951, 0.542612, 0.317946, 0.142737, 0.153866, 0.277670, 0.158774, 0.149727, 0.138192, 0.100753, 0.171539, 0.148223, 0.183360, 1.013134, 0.132720, 0.114275, 0.144352, 0.125759, 0.115595, 0.290317, 0.159237, 0.196741, 0.146671, 0.085061, 0.383089, 0.141677, 0.138464, 0.115846, 0.163889, 0.104245, 0.094833, 0.135027, 0.126188, 0.134023, 0.519500, 0.732335, 0.129321, 0.209510, 0.141031, 0.090172, 0.101411, 0.101293, 0.150449, 0.384884, 0.281796, 0.128238, 0.149743, 0.128008, 3.174492, 0.161069, 0.178991, 0.134386, 0.438763, 0.128510, 0.257965, 0.123197, 0.253682, 1810062376960.000000, 0.250501, 0.525078, 2.326427, 0.514724, 0.421158, 0.522530, 0.410881, 0.436913, 0.546261, 0.657524, 0.339084, 0.381109, 0.373584, 0.403470, 0.273348, 0.371975, 1.207230, 1.233747, 0.403277, 0.382672, 0.409362, 0.448643, 0.482248, 0.412321, 0.463801, 0.482925, 0.352141, 0.403860, 0.639746, 0.391832, 0.365690, 0.323818, 0.293539, 0.351986, 0.424049, 0.297764, 0.474980, 0.366634, 0.558635, 0.635171, 0.305158, 0.575248, 0.343448, 0.307636, 0.307587, 0.433217, 0.359651, 0.398142, 0.804812, 0.234245, 0.218172, 0.386858, 0.256616, 0.247861, 0.189754, 0.309664, 0.231294, 0.201588, 0.362397, 0.854959, 0.221453, 0.234499, 0.179633, 0.280615, 0.981447, 0.196075, 0.356121, 0.330863, 0.855246, 0.264490, 0.192371, 0.199579, 0.257881, 0.845335, 1.080290, 0.385487, 0.345712, 0.432537, 0.181982, 0.255903, 0.661800, 0.280343, 0.816918, 0.189203, 0.319100, 0.175347, 0.280701, 0.203852, 0.227400, 0.282021, 0.157298, 0.449579, 0.185353, 0.219681, 0.296378, 0.183175, 0.206986, 0.190452, 0.282911, 0.220673, 0.199240, 0.166271, 0.216302, 0.228874, 0.326672, 0.175235, 0.272446, 0.156336, 0.227474, 0.371922, 0.189022, 0.208053, 0.388969, 0.282575, 0.235272, 0.172872, 0.483076, 0.564832, 0.400886, 0.216721, 0.235454, 0.195748, 0.235543, \n",
      "*************** \n",
      "\n",
      "Step 9 | Training Loss: 0.235543 | Test Loss: 1.379875 | Test Accuracy: 0.820440\n",
      "*************** \n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 10 | Training Loss: 1.949907, 0.209671, 0.218378, 0.182337, 0.680451, 0.363967, 0.241531, 0.133498, 0.531765, 0.171386, 0.238498, 0.124953, 0.340621, 0.138585, 0.139183, 0.348668, 0.204655, 0.229441, 0.202168, 0.797820, 0.143123, 1.976646, 0.249359, 0.470436, 0.280857, 0.162085, 0.368719, 0.152648, 0.283807, 0.134708, 0.271147, 0.651960, 0.129479, 0.120918, 0.784716, 0.159339, 0.234779, 0.157491, 0.195674, 0.270466, 0.163953, 0.143127, 2.854458, 0.180615, 0.178919, 0.195513, 0.280408, 0.179077, 0.273922, 0.297222, 0.318111, 0.229170, 0.227062, 0.733911, 0.196004, 0.266095, 0.195990, 0.231966, 0.268435, 0.162669, 0.271232, 0.199848, 0.245750, 0.249931, 0.387615, 0.223393, 0.207829, 0.282704, 0.306499, 0.302272, 0.364034, 0.210445, 0.185823, 0.231627, 0.199112, 0.414809, 0.157774, 0.177759, 0.286159, 1.083805, 0.316621, 0.236276, 0.226583, 0.163468, 0.198230, 0.187064, 0.276364, 0.375610, 0.259046, 0.140643, 0.253871, 0.243653, 0.169466, 0.289317, 1.727436, 0.817277, 0.182200, 0.176919, 0.380715, 0.462120, 0.266557, 0.402330, 0.424218, 0.150691, 0.372752, 0.193295, 0.147785, 0.167478, 0.394234, 0.292515, 0.135544, 0.215342, 0.417477, 0.109436, 0.313300, 0.576945, 0.271211, 1.043834, 0.165337, 0.142686, 0.165445, 1.501676, 1.051810, 0.588032, 0.203052, 0.191651, 0.230260, 0.135216, 0.149818, 0.159082, 0.185977, 0.258008, 0.303851, 0.156450, 0.215157, 0.137905, 0.226950, 0.316527, 0.160715, 0.210311, 0.236767, 0.170836, 0.284586, 0.125516, 0.208237, 0.264845, 0.237546, 0.468689, 1.470420, 0.377661, 0.393866, 0.159764, 0.178026, 1.431702, 0.184440, 0.158384, 0.193182, 0.447330, 0.246628, 0.421241, 0.286044, 0.199559, 0.405823, 0.160043, 0.190363, 0.650028, 0.182978, 0.180389, 0.185110, 0.231402, 0.301217, 0.124582, 0.194868, 0.204651, 0.215759, 0.200693, 0.174965, 0.408547, 0.281755, 0.295209, 0.220266, 0.295523, 0.256444, 0.172349, 0.172956, 0.213407, 0.265130, 0.217408, 0.154379, 0.132218, 0.202621, 1.203011, 0.236800, 0.135183, 0.361938, 0.095902, 0.379902, 0.168680, 0.489356, 0.192655, \n",
      "*************** \n",
      "\n",
      "Step 10 | Training Loss: 0.192655 | Test Loss: 1.452568 | Test Accuracy: 0.812633\n",
      "*************** \n",
      "\n",
      "Current Layer Attributes - epochs:10 hidden layers:2 features count:8\n",
      "Step 1 | Training Loss: 1.199734, 0.803618, 0.848686, 0.696337, 0.728539, 1.161631, 0.868774, 1.081935, 3.478359, 0.850710, 0.627069, 60283813888.000000, 0.641504, 0.903358, 0.591603, 0.869269, 0.695175, 1.396207, 0.652662, 0.749792, 0.766554, 0.797555, 0.623671, 0.714319, 0.752753, 0.605265, 0.736166, 0.540695, 0.678661, 0.625978, 0.777406, 0.551588, 0.578629, 0.623244, 0.479108, 0.499870, 0.644182, 0.514321, 0.569910, 0.610704, 0.479800, 0.815008, 0.551049, 0.580300, 0.460483, 0.519283, 0.828230, 1.471243, 0.588794, 0.439531, 1.079762, 0.485027, 0.521072, 0.640603, 1.547735, 0.703800, 0.510160, 1.414096, 0.497866, 0.702327, 0.510340, 0.478806, 0.528628, 0.403389, 1.109934, 0.464788, 0.527961, 0.507258, 0.431395, 0.433258, 0.511958, 0.738013, 0.609961, 0.467916, 0.431984, 0.694180, 0.552641, 0.666042, 0.443494, 0.529144, 0.542399, 0.507404, 0.581421, 0.661447, 0.446395, 0.372271, 0.379194, 0.435617, 0.633680, 0.359114, 0.650826, 0.501838, 0.647965, 0.513836, 0.674569, 0.406408, 0.442774, 0.494751, 0.574529, 0.458745, 0.389903, 0.950121, 0.444401, 0.376138, 2.260588, 0.409624, 0.706846, 0.380546, 0.514712, 0.427592, 2.161613, 0.362231, 0.505042, 0.526327, 0.497626, 0.991513, 0.448333, 0.395102, 0.724113, 0.455416, 0.411300, 0.679984, 0.469084, 1.432590, 0.441390, 0.441807, 0.547696, 0.520153, 1.492018, 0.774065, 0.423290, 0.456223, 0.408501, 0.438667, 0.585514, 0.428944, 0.850683, 0.330508, 0.633297, 0.463694, 0.412593, 0.536734, 0.402448, 0.392744, 0.397817, 0.443395, 0.525894, 0.578041, 0.384934, 0.352049, 0.430737, 0.395336, 0.413962, 0.438782, 0.434875, 0.345203, 0.577483, 0.442395, 0.305516, 0.346634, 0.299844, 0.323256, 0.403022, 1.435819, 0.428943, 0.556732, 0.418593, 2.188664, 0.367878, 0.694015, 0.474635, 0.416717, 0.402378, 0.418252, 0.572860, 0.313782, 0.688781, 0.437942, 0.428271, 0.374418, 0.414375, 0.489493, 0.475268, 0.398409, 0.484436, 0.786890, 0.460021, 0.394328, 0.419784, 0.373438, 0.486426, 0.295278, 0.390470, 0.369897, 0.376279, 0.352223, 0.328562, 0.341383, 0.350312, 0.323898, \n",
      "*************** \n",
      "\n",
      "Step 1 | Training Loss: 0.323898 | Test Loss: 1.512243 | Test Accuracy: 0.762908\n",
      "*************** \n",
      "\n",
      "Step 2 | Training Loss: 0.332244, 0.271219, 0.489351, 0.411330, 0.354876, 0.442996, 0.466589, 0.300157, 0.308817, 0.406471, 0.396086, 0.387704, 0.270939, 0.335760, 0.373012, 0.352143, 0.344095, 0.348013, 0.483770, 0.331341, 0.356046, 1.361405, 0.397337, 0.525499, 1.763155, 0.800185, 1.550231, 0.447091, 0.484900, 0.393629, 0.776178, 0.598109, 1.389646, 0.504820, 0.342600, 0.515433, 0.580037, 0.376383, 3.344313, 1.182349, 0.368965, 0.642558, 0.772477, 0.395247, 0.756971, 0.443020, 0.511878, 0.446467, 0.519735, 0.683502, 0.365341, 0.646744, 0.607351, 0.272270, 0.606729, 0.347094, 0.326805, 0.599355, 0.342547, 0.379209, 0.564129, 0.323385, 0.540263, 0.234872, 0.349176, 0.516113, 0.487509, 2.594077, 0.410103, 0.460635, 0.833197, 0.381395, 0.334837, 0.450603, 0.392932, 0.284295, 0.330444, 0.381564, 0.689611, 0.288586, 0.299183, 0.371212, 0.312625, 1.134115, 0.361654, 0.282632, 2.212748, 0.279131, 0.365136, 0.383492, 0.371605, 0.699643, 0.405937, 0.395677, 0.331443, 0.375001, 0.783763, 0.379074, 0.404307, 1.151935, 0.609422, 0.982741, 0.255318, 0.527588, 0.618909, 0.504812, 0.314115, 0.368636, 0.430295, 0.368287, 0.401083, 0.421417, 0.484055, 0.510071, 0.499017, 0.343082, 0.357557, 0.384477, 1.195396, 0.373459, 0.496045, 0.379345, 0.318747, 0.317863, 0.385805, 0.337642, 0.441306, 0.306242, 0.330625, 0.605913, 0.276220, 0.302804, 0.338391, 0.443644, 0.402430, 0.338037, 0.297973, 0.346590, 0.365369, 0.729234, 0.454000, 1.486539, 0.338545, 0.381184, 0.420471, 0.417487, 0.309465, 0.639203, 0.288163, 0.378464, 0.440942, 0.415439, 0.390372, 0.459782, 0.358486, 0.402941, 0.422231, 0.465696, 0.362406, 0.371834, 0.357444, 0.444996, 0.323312, 0.257689, 0.334202, 0.441323, 0.303282, 0.417986, 0.466256, 0.390915, 0.294557, 0.368382, 0.437609, 0.380268, 0.269135, 0.338317, 0.390619, 0.537273, 0.542694, 0.397018, 0.388271, 0.409337, 0.514788, 0.361874, 0.390298, 0.952618, 0.338008, 0.298718, 0.367541, 0.497898, 0.468814, 0.610577, 0.360949, 0.384342, 0.372930, 0.285813, 0.381691, 0.349701, 0.625937, 0.412296, \n",
      "*************** \n",
      "\n",
      "Step 2 | Training Loss: 0.412296 | Test Loss: 1.425956 | Test Accuracy: 0.766679\n",
      "*************** \n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 3 | Training Loss: 0.513799, 0.713420, 0.336167, 1.390616, 0.383645, 0.571628, 0.358146, 0.628287, 0.317724, 0.330600, 0.307522, 0.361569, 0.365036, 0.271829, 0.297472, 1.790995, 1.395936, 1.284532, 0.407617, 0.411209, 1.217149, 0.500334, 0.353615, 0.493070, 0.381593, 0.365084, 0.370592, 0.365905, 0.566411, 0.332461, 0.395173, 0.404468, 0.348940, 0.545503, 0.304568, 0.555094, 0.364397, 0.377381, 0.695355, 0.414831, 0.442955, 0.355576, 0.351998, 0.474762, 0.332516, 0.550570, 0.700029, 0.392890, 0.339149, 0.438686, 1.021916, 0.320315, 0.288258, 0.443783, 0.592279, 0.292803, 0.383245, 0.360804, 0.879984, 0.309770, 0.238005, 0.342000, 0.367600, 0.342535, 0.554014, 0.311960, 0.655360, 0.331959, 0.307008, 0.669843, 0.599775, 0.354835, 0.475470, 0.313848, 0.288590, 0.283025, 0.323555, 2.452042, 0.279226, 0.365384, 0.336404, 0.397023, 0.397730, 0.474317, 0.440389, 0.510107, 0.317445, 0.288256, 0.339512, 0.525241, 0.281856, 0.315640, 0.393383, 0.281408, 0.401997, 0.336335, 1.010684, 0.409633, 0.446494, 2.139961, 0.542003, 0.273644, 0.283400, 0.380611, 0.404024, 0.573370, 0.366148, 0.864099, 0.349238, 0.400374, 0.314849, 0.479714, 0.293596, 0.539479, 0.383144, 0.379620, 0.312929, 0.261636, 0.440071, 0.349766, 0.382597, 0.346488, 0.365334, 0.349787, 0.320793, 0.567721, 0.911570, 0.279333, 0.498580, 0.284866, 0.357872, 0.624427, 0.341728, 0.300981, 0.691292, 0.320259, 0.414315, 0.297273, 0.326504, 0.317143, 0.421117, 0.292592, 0.273175, 0.449473, 0.529945, 0.302054, 0.437425, 2.116120, 0.258489, 0.345061, 0.474671, 0.294783, 0.254327, 0.310803, 0.250342, 0.349516, 0.258298, 0.484174, 0.207083, 0.288108, 0.434143, 0.442947, 0.338760, 0.495182, 0.520715, 0.265889, 0.279661, 0.854658, 0.360344, 0.331733, 0.259532, 0.454577, 0.347310, 0.433642, 0.371151, 0.364889, 0.290189, 0.331767, 0.565626, 0.503354, 0.607112, 0.294137, 0.249211, 1.200469, 0.267119, 0.250780, 0.300456, 0.726220, 0.346176, 0.361259, 0.265179, 0.256778, 0.310520, 0.453906, 0.347029, 0.350997, 0.381188, 0.323763, 0.236368, 0.280659, \n",
      "*************** \n",
      "\n",
      "Step 3 | Training Loss: 0.280659 | Test Loss: 1.378349 | Test Accuracy: 0.767033\n",
      "*************** \n",
      "\n",
      "Step 4 | Training Loss: 0.246663, 0.288162, 0.375812, 0.447461, 0.262580, 0.265760, 0.412957, 0.227040, 0.541034, 0.253745, 0.289238, 1.230205, 1.920822, 0.303053, 0.304738, 0.666909, 0.375662, 0.600877, 0.390319, 0.481880, 0.776235, 0.300043, 0.273252, 0.353874, 0.287966, 0.242260, 2.737019, 0.261132, 0.387283, 0.345954, 0.449441, 0.458051, 0.580513, 0.330091, 0.468741, 0.544292, 0.357462, 0.526783, 0.606544, 1.255241, 0.511449, 0.332899, 0.620663, 0.506095, 1.207171, 0.547038, 0.361920, 0.274201, 0.495469, 0.311743, 0.515251, 0.233961, 0.760783, 0.359416, 0.336702, 0.313949, 0.406820, 0.474286, 0.310737, 0.397295, 0.299227, 0.294492, 0.382142, 0.317040, 0.223436, 0.577181, 0.208535, 0.428891, 0.318076, 0.414997, 0.317859, 0.252705, 0.488111, 0.388898, 1.115935, 0.292276, 0.411350, 0.223265, 0.402932, 0.343999, 0.711619, 0.493200, 1.202479, 0.214825, 0.234809, 0.246458, 0.364244, 0.328662, 0.563286, 4.496922, 0.311458, 0.299020, 0.364994, 0.375061, 0.568133, 0.509050, 0.440050, 0.314374, 0.992155, 0.343308, 0.938637, 0.340279, 0.383563, 0.511565, 0.290051, 0.357710, 0.267658, 0.479099, 0.878901, 0.315600, 0.336436, 0.392766, 0.517016, 0.306496, 1.109147, 0.300736, 0.286913, 0.286113, 0.220212, 0.275642, 0.330354, 0.306761, 0.235059, 0.223694, 0.315882, 0.313065, 0.256417, 0.360009, 0.452857, 0.267509, 0.320631, 0.276922, 0.388880, 0.376561, 0.293539, 0.335819, 0.389199, 2.085339, 0.632430, 0.272011, 0.237810, 0.284978, 0.475686, 0.312282, 0.629115, 0.278273, 0.711011, 0.395851, 0.275181, 0.518899, 0.239926, 0.451524, 0.356770, 0.295618, 0.302538, 0.332585, 0.311774, 0.490255, 0.273959, 0.379577, 0.294528, 0.316576, 0.516733, 0.377788, 0.269769, 0.357253, 0.281781, 0.235723, 0.198914, 0.235409, 0.205574, 0.371974, 0.226818, 0.242535, 0.370441, 0.359860, 0.260987, 0.215576, 0.309298, 0.331159, 0.400050, 0.208967, 0.311475, 0.195159, 0.861336, 0.319892, 0.833375, 0.334496, 0.315881, 0.361763, 1.355890, 0.269793, 0.456653, 0.361749, 0.380378, 0.247246, 0.214277, 0.339162, 0.272609, 1.344774, \n",
      "*************** \n",
      "\n",
      "Step 4 | Training Loss: 1.344774 | Test Loss: 1.404593 | Test Accuracy: 0.764727\n",
      "*************** \n",
      "\n",
      "Step 5 | Training Loss: 0.322073, 0.633669, 0.312892, 0.302071, 0.221399, 0.242445, 0.319785, 0.550308, 0.344813, 0.255009, 0.336898, 0.496725, 0.687604, 0.247164, 0.333940, 0.231723, 0.247999, 0.496316, 0.245724, 0.366006, 0.291307, 0.234162, 1.256784, 0.283392, 0.270441, 0.247566, 0.326187, 0.328104, 0.248797, 0.260823, 2.066346, 0.288369, 0.223402, 0.454116, 0.244569, 0.202200, 0.310655, 0.186773, 0.232592, 1.839271, 0.288234, 0.242130, 0.193288, 0.341379, 0.299672, 0.354959, 0.208331, 0.200435, 0.225231, 0.239719, 0.448934, 0.268572, 0.775670, 0.288502, 0.304457, 1.137371, 0.373374, 1.486975, 0.237795, 0.495874, 0.284396, 0.254490, 0.437040, 0.258529, 0.295945, 0.270381, 0.240150, 0.503100, 0.251033, 0.508591, 0.211797, 1.058115, 0.276774, 0.433444, 0.210903, 0.288256, 0.252595, 0.335322, 0.208774, 0.190275, 0.308148, 0.468749, 0.338697, 0.283606, 0.593206, 0.343315, 0.246446, 0.248530, 0.258345, 0.196653, 0.252318, 0.377479, 0.276009, 0.266660, 0.238331, 0.209790, 0.277969, 0.426041, 0.236766, 0.625113, 1.548962, 0.273204, 0.320870, 0.285343, 0.230191, 0.287745, 0.214803, 0.153746, 0.169411, 0.192163, 0.264970, 0.288165, 2.406362, 0.235956, 0.452221, 0.274651, 0.448752, 0.275145, 0.403542, 0.273580, 0.376530, 0.850711, 0.194000, 0.245640, 0.243216, 0.496813, 0.245288, 0.280558, 0.498852, 0.187597, 0.302333, 1.109931, 0.525972, 0.199379, 0.444808, 0.463915, 0.344850, 0.259934, 0.303243, 0.217180, 0.273778, 0.249099, 0.416375, 0.221021, 0.194251, 0.415962, 0.213807, 0.193232, 0.209918, 0.276602, 0.294923, 0.451437, 0.256233, 0.221228, 0.552217, 0.438932, 0.234930, 0.213500, 0.242026, 2.017688, 0.568037, 0.199653, 0.246708, 0.244608, 0.235008, 1.205309, 0.181392, 0.314710, 0.406780, 0.240585, 0.327481, 0.336390, 0.165971, 0.216383, 0.304131, 0.250409, 0.726569, 0.217407, 0.329277, 1.794586, 0.855720, 0.287374, 0.289085, 0.147489, 0.221281, 0.260406, 0.223520, 0.289087, 0.204299, 0.261683, 0.261896, 0.226490, 0.176976, 0.356834, 0.233216, 0.251906, 0.248506, 0.255560, 0.272607, 0.150820, \n",
      "*************** \n",
      "\n",
      "Step 5 | Training Loss: 0.150820 | Test Loss: 1.298670 | Test Accuracy: 0.764549\n",
      "*************** \n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 6 | Training Loss: 0.339994, 0.320378, 0.244950, 0.665734, 0.244138, 0.223647, 0.183616, 0.309800, 0.200742, 0.282752, 0.254892, 0.177900, 0.249481, 0.156019, 0.270133, 0.248943, 0.203041, 0.420201, 0.441252, 0.570926, 0.229144, 0.319470, 0.436937, 0.182768, 1.114122, 0.469745, 0.289718, 0.357227, 0.212969, 0.196961, 0.214803, 0.255871, 0.190717, 0.506384, 0.251827, 0.261890, 0.209896, 0.237712, 0.239074, 2.432002, 0.546936, 0.296706, 0.531166, 0.272431, 0.302322, 0.522685, 0.276795, 0.235013, 0.243732, 0.348514, 0.342863, 1.282573, 0.848885, 0.281658, 0.350589, 0.277405, 0.346967, 0.542013, 0.165860, 0.321875, 0.323513, 0.244373, 0.474341, 0.526083, 0.853277, 0.304319, 0.444179, 0.266671, 0.331525, 0.232472, 0.189036, 0.450231, 0.248632, 0.934607, 0.241253, 0.498503, 0.377276, 0.591151, 0.387326, 0.576775, 0.221922, 0.249279, 0.234987, 0.216252, 0.496106, 0.436476, 0.198344, 0.215015, 1.284153, 0.259241, 1.146718, 0.257548, 0.225273, 0.232866, 0.282906, 0.298243, 0.271403, 0.332175, 0.193545, 0.171213, 0.175370, 1.346879, 0.222331, 0.438806, 0.315535, 0.166071, 0.266820, 0.212298, 0.242791, 0.358118, 0.296795, 0.227359, 0.183200, 0.225322, 0.228976, 0.215028, 0.190436, 0.209067, 0.255413, 1.729478, 0.249521, 0.197029, 0.260203, 1.712882, 0.376791, 0.144466, 0.209801, 0.254456, 0.233875, 0.534228, 0.202589, 0.187993, 0.182953, 0.241220, 0.299066, 0.550433, 0.193454, 0.409707, 0.198149, 0.237811, 0.239653, 0.222876, 0.311874, 0.276055, 0.213893, 0.313374, 0.261330, 0.231637, 0.274539, 0.239071, 0.313776, 0.327643, 1.126133, 0.251942, 0.229495, 0.289415, 0.852839, 0.202748, 0.205734, 0.344939, 0.185614, 0.227402, 0.567732, 0.183549, 0.226653, 0.403082, 0.629382, 0.262341, 0.321437, 0.188635, 1.978778, 0.231016, 0.214275, 0.207077, 0.410221, 0.282559, 0.222795, 0.176671, 0.282548, 0.250235, 0.193126, 0.234256, 0.135766, 0.231886, 0.254956, 0.428595, 0.371953, 0.247513, 0.215334, 0.190852, 0.280830, 0.211956, 0.286965, 0.258019, 0.160369, 0.176006, 0.144682, 0.223802, 0.200514, 0.242690, \n",
      "*************** \n",
      "\n",
      "Step 6 | Training Loss: 0.242690 | Test Loss: 1.237229 | Test Accuracy: 0.777191\n",
      "*************** \n",
      "\n",
      "Step 7 | Training Loss: 0.847866, 0.212580, 0.224305, 0.344980, 0.363302, 0.435008, 0.232118, 0.203381, 0.201732, 0.430179, 0.145009, 0.219432, 0.330262, 0.226821, 0.192569, 0.270913, 0.629966, 0.201336, 0.223436, 0.192079, 0.265969, 0.260933, 0.201939, 0.211798, 0.248490, 0.239317, 0.201884, 0.211786, 1.075139, 0.257413, 0.141033, 0.173673, 0.347223, 0.200993, 0.216998, 0.199138, 0.264911, 1.052424, 0.996292, 0.463191, 0.229481, 0.929236, 1.091391, 0.373859, 0.251234, 0.206194, 0.271574, 0.152597, 0.235631, 1.090453, 0.191490, 0.177416, 0.166618, 0.202931, 0.414777, 0.164597, 0.859237, 0.785325, 0.185842, 0.436008, 0.188994, 0.172868, 0.215461, 0.191162, 0.196980, 0.165340, 0.199599, 0.174943, 0.154705, 2.770671, 0.176985, 0.216385, 0.311777, 0.221862, 0.242130, 0.186895, 0.158276, 0.230740, 0.231489, 0.377217, 0.681486, 0.203490, 0.210919, 0.313482, 0.482710, 0.254472, 0.506724, 0.191578, 0.238564, 0.234772, 0.274849, 0.287255, 0.247600, 0.249929, 0.136867, 0.224290, 0.233459, 0.222464, 0.256445, 0.161884, 0.282317, 0.462889, 0.337704, 0.244253, 0.230939, 0.277637, 0.205057, 0.187837, 0.214710, 0.194656, 0.355063, 0.222100, 0.165410, 0.238615, 1.020398, 0.233830, 0.168809, 2.061955, 0.165888, 0.374015, 0.235602, 0.296206, 0.199993, 0.306384, 0.557696, 0.222847, 0.340533, 0.456644, 0.427401, 0.227574, 0.267436, 0.167782, 0.261269, 0.195835, 0.291064, 0.222730, 0.212831, 0.178856, 0.485461, 2.365272, 0.189584, 0.514412, 0.648838, 0.176688, 0.246727, 0.182149, 0.231894, 0.376025, 0.380711, 0.244511, 0.755556, 0.282435, 0.240263, 0.225671, 0.236654, 0.249646, 0.216714, 0.340261, 1.127395, 0.257659, 0.212758, 1.102502, 0.216545, 0.291583, 0.216649, 0.335906, 0.356565, 1.087752, 0.236239, 0.173410, 0.214889, 0.222463, 0.262870, 0.287556, 0.291691, 0.139375, 0.447524, 0.213317, 0.228956, 0.218385, 0.293564, 0.250422, 0.242459, 0.239728, 1.064272, 0.218233, 0.272362, 1.786142, 0.202222, 0.275908, 0.205713, 0.220634, 0.252337, 0.144004, 0.234812, 0.579861, 0.725899, 0.308711, 0.281850, 0.157259, \n",
      "*************** \n",
      "\n",
      "Step 7 | Training Loss: 0.157259 | Test Loss: 1.261362 | Test Accuracy: 0.766812\n",
      "*************** \n",
      "\n",
      "Step 8 | Training Loss: 0.432104, 0.186785, 0.253351, 0.206231, 0.216315, 0.155280, 0.206641, 0.236394, 0.174681, 0.273944, 0.476908, 0.313894, 0.240251, 0.180155, 0.217372, 0.287892, 0.228653, 0.428873, 0.222801, 0.136488, 0.167477, 0.292609, 0.249069, 0.259516, 0.226856, 0.937803, 0.175043, 0.150737, 0.130033, 1.204537, 0.301470, 1.005374, 0.303191, 0.187389, 0.527315, 0.159725, 0.417890, 0.477425, 0.202253, 0.368974, 2.489403, 0.199721, 0.204795, 0.225209, 0.148818, 0.310436, 0.295340, 0.413629, 0.305054, 0.466936, 0.474039, 0.364036, 0.232037, 0.183369, 0.190095, 0.201686, 0.140383, 0.195489, 0.590306, 0.287057, 0.348303, 1.166465, 0.150878, 0.251889, 0.235705, 0.166897, 0.340793, 0.342048, 0.158037, 0.265589, 0.248429, 0.223012, 0.215824, 0.495458, 0.148698, 0.477497, 0.308659, 0.205968, 0.186617, 0.240830, 0.163395, 0.199525, 0.442876, 0.163050, 0.227225, 0.397180, 0.206017, 0.252404, 0.226391, 0.374097, 0.553344, 0.275530, 0.173196, 0.244027, 0.258170, 1.104490, 0.501291, 0.273128, 0.193022, 0.251579, 0.187554, 0.221116, 0.170946, 0.144722, 0.202626, 0.532444, 0.199734, 0.170016, 0.177623, 0.185170, 0.253712, 0.169056, 0.465188, 0.243853, 0.227332, 0.248192, 0.692520, 0.225321, 0.512280, 0.142515, 0.230843, 0.495898, 1.080609, 0.162637, 0.252210, 0.204570, 0.229181, 2.120389, 0.452296, 0.355033, 0.258905, 0.259695, 0.206313, 0.347613, 0.266014, 0.292966, 0.278390, 0.242150, 0.218756, 0.258146, 1.144700, 0.860752, 0.273325, 0.308440, 0.254550, 0.245395, 0.211956, 0.227518, 0.428407, 0.401313, 0.262488, 0.251167, 0.421754, 0.199555, 0.238573, 0.208364, 0.409244, 0.378373, 0.425495, 0.210072, 0.238735, 0.540211, 0.212122, 0.240651, 0.166152, 0.846251, 0.203633, 0.196336, 0.482332, 0.403953, 0.236988, 0.479186, 0.145517, 0.188795, 0.793397, 1.832414, 0.239123, 0.216995, 0.184603, 0.162008, 0.227412, 0.433174, 0.176969, 0.139715, 0.400146, 0.820508, 0.168056, 0.236665, 0.322932, 0.279153, 0.327648, 0.229278, 0.212823, 0.221486, 2.210653, 0.169758, 0.221941, 0.299412, 0.187357, 1.151653, \n",
      "*************** \n",
      "\n",
      "Step 8 | Training Loss: 1.151653 | Test Loss: 1.222753 | Test Accuracy: 0.789257\n",
      "*************** \n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 9 | Training Loss: 0.441391, 0.410422, 1.079174, 0.221735, 0.161425, 0.179196, 0.163167, 0.123255, 0.446733, 0.211509, 0.278356, 0.271241, 0.420693, 0.314416, 0.189232, 0.243100, 0.239323, 0.266051, 0.236013, 0.196421, 0.162226, 0.214216, 0.225229, 0.172203, 1.677759, 0.499142, 0.283642, 0.248426, 0.150284, 0.167471, 0.164917, 0.168723, 0.462129, 0.194982, 0.194422, 0.140436, 0.297069, 0.249296, 0.214543, 0.136049, 0.149091, 0.288017, 0.864872, 2.709644, 0.139203, 0.297935, 0.161691, 0.227055, 0.336817, 0.381123, 0.412266, 0.227766, 0.271526, 0.365945, 0.178877, 0.186991, 0.210211, 0.180128, 0.525147, 0.214728, 0.188748, 0.278161, 0.255552, 0.214747, 1.078581, 0.159337, 0.276548, 0.113173, 0.187276, 0.181383, 0.192579, 0.254165, 0.150710, 0.252070, 0.200529, 0.217043, 0.160210, 0.203831, 0.217632, 0.179376, 0.190403, 0.169407, 0.457530, 0.407185, 0.242372, 0.157288, 0.182214, 0.205531, 0.226663, 0.286607, 0.181377, 0.158933, 0.145413, 0.191725, 0.133841, 0.208444, 0.178899, 0.221837, 0.202367, 0.159366, 0.167139, 0.174884, 0.443000, 0.184606, 0.239380, 0.234696, 0.131145, 0.163952, 0.185208, 0.243147, 0.326637, 0.118321, 0.380911, 0.420434, 0.533192, 0.150932, 0.303933, 0.095288, 0.147664, 0.389958, 0.363058, 0.138253, 0.939249, 0.160416, 0.191586, 0.205537, 0.185906, 0.134342, 0.212382, 0.172276, 1.044418, 0.243199, 0.165190, 0.384920, 0.164870, 0.136525, 0.201966, 0.512673, 0.160959, 0.137476, 0.430179, 0.225996, 0.120412, 0.169175, 0.168062, 0.273974, 0.340001, 0.237085, 0.476474, 0.119505, 0.234198, 0.131874, 0.331307, 0.182534, 0.147496, 0.974921, 0.136262, 0.160741, 0.506215, 1.914772, 0.188567, 0.108532, 0.306232, 0.171770, 0.143589, 0.193942, 0.182267, 0.159725, 2.241296, 0.182115, 0.345319, 0.154549, 0.183622, 1.239251, 0.187000, 0.202331, 0.355271, 0.381947, 0.122462, 0.190750, 0.201882, 0.174089, 0.208351, 0.228534, 0.820436, 0.158061, 0.272309, 0.445347, 0.166489, 0.138233, 0.135760, 0.412493, 0.159255, 0.246731, 0.336260, 0.190094, 0.168487, 0.203695, 0.204166, 0.111337, \n",
      "*************** \n",
      "\n",
      "Step 9 | Training Loss: 0.111337 | Test Loss: 1.176080 | Test Accuracy: 0.783534\n",
      "*************** \n",
      "\n",
      "Step 10 | Training Loss: 0.161383, 0.125243, 0.192757, 0.275861, 0.120580, 0.248346, 0.147972, 0.128285, 0.985056, 0.130821, 0.269353, 0.176073, 0.474152, 0.222311, 0.171786, 0.177383, 0.168154, 0.236350, 1.005828, 0.189302, 0.213875, 0.132488, 0.423857, 0.163115, 0.145948, 0.166641, 0.189324, 0.252827, 0.163463, 0.270702, 0.188087, 0.152095, 0.141814, 0.917483, 0.319009, 0.408255, 0.521502, 0.135149, 0.688184, 0.155304, 0.411700, 0.094802, 0.162573, 0.167979, 0.110111, 0.221679, 0.302095, 0.287133, 0.329565, 0.134339, 0.203567, 0.175032, 1.255193, 0.106939, 0.180673, 0.389566, 0.252578, 0.777066, 0.162779, 0.204244, 0.418720, 0.183923, 0.141334, 0.343655, 0.151002, 0.591972, 0.174610, 0.174008, 0.217673, 0.099717, 1.979318, 0.131249, 0.193054, 0.169517, 0.190688, 0.138148, 0.161335, 0.177875, 0.166064, 0.251919, 0.187637, 0.348644, 0.142127, 0.332189, 0.109038, 0.195574, 0.133675, 0.115060, 0.163414, 0.109007, 0.235581, 0.336127, 0.183211, 0.163820, 0.196611, 0.121761, 1.062697, 0.157590, 0.199577, 0.170107, 0.144698, 0.157161, 0.260155, 0.217834, 0.163853, 0.174635, 0.117911, 0.168244, 0.163096, 0.119050, 0.433948, 0.333058, 0.157686, 0.165435, 0.272498, 0.219380, 0.139297, 1.029784, 0.163861, 0.132226, 0.291403, 0.207374, 0.272531, 0.208594, 0.155760, 0.150358, 0.148060, 0.208402, 0.145060, 0.157809, 0.420654, 0.384729, 0.178200, 0.202230, 0.153105, 0.160355, 0.148353, 0.745913, 0.912326, 0.137795, 0.131508, 0.112209, 0.242596, 0.177515, 0.171999, 0.145872, 0.169557, 1.056240, 0.155514, 0.615558, 0.326732, 0.184210, 0.150144, 0.190226, 0.172700, 0.176295, 0.179329, 1.666811, 0.134009, 0.186320, 0.310932, 0.281278, 0.272072, 0.509354, 0.142572, 0.174958, 0.239842, 0.171172, 0.180200, 0.122302, 0.121593, 0.108268, 0.347080, 0.372839, 0.252484, 0.330118, 0.222580, 0.194543, 0.147410, 0.147532, 0.130816, 0.117944, 0.204422, 0.405840, 0.152308, 0.202339, 0.167750, 4.376598, 0.579212, 0.150248, 0.245997, 0.306260, 0.184947, 0.250999, 0.259724, 0.293109, 0.388734, 0.528852, 0.220626, 0.343290, \n",
      "*************** \n",
      "\n",
      "Step 10 | Training Loss: 0.343290 | Test Loss: 1.332453 | Test Accuracy: 0.759936\n",
      "*************** \n",
      "\n",
      "Current Layer Attributes - epochs:10 hidden layers:2 features count:16\n",
      "Step 1 | Training Loss: 0.902815, 0.848456, 0.886521, 0.816472, 0.822430, 0.967508, 1.375289, 0.683573, 0.967172, 0.807588, 0.692781, 0.716821, 1.021769, 0.892647, 0.748874, 0.714250, 0.619107, 0.704755, 0.698781, 0.720696, 0.571848, 0.932853, 0.912453, 0.792704, 0.710258, 0.717607, 0.953809, 0.560760, 0.570473, 0.592593, 0.660584, 0.668178, 0.510847, 0.603478, 0.493218, 0.503574, 0.546808, 1.316597, 0.526442, 0.676807, 0.795326, 0.545222, 0.524068, 0.573051, 0.507998, 0.639598, 0.643019, 0.715115, 0.505079, 0.446748, 0.772748, 2.339822, 0.580585, 0.470635, 0.510097, 0.659474, 0.555689, 0.881346, 0.655173, 0.404352, 0.659346, 1.326048, 0.587026, 0.412895, 0.448469, 0.511786, 0.523868, 0.448606, 0.463582, 0.335916, 0.469824, 0.609109, 0.423051, 0.537226, 0.795376, 0.504939, 0.386175, 0.810946, 0.313794, 0.388680, 0.451350, 0.584364, 0.369412, 0.604320, 0.428222, 0.370792, 0.366233, 1.019413, 0.452552, 0.876850, 0.372120, 0.427220, 0.393092, 0.332633, 0.427304, 0.421838, 0.350177, 0.395641, 0.432914, 0.407912, 0.335437, 0.392983, 0.655465, 0.986814, 0.463848, 0.385916, 0.322869, 0.326854, 1.567488, 0.415616, 0.374467, 0.444048, 1.042380, 0.388073, 0.372597, 0.345795, 0.335033, 0.362750, 1.051718, 0.346215, 0.328797, 0.351663, 1.252176, 0.352609, 0.373104, 0.437774, 0.416299, 0.480314, 0.408289, 0.569226, 0.423462, 0.353747, 0.433322, 0.352541, 0.349642, 0.265947, 0.411171, 0.722159, 0.438053, 0.742352, 0.565102, 0.324623, 2.693880, 0.321502, 0.286742, 0.487668, 0.390286, 0.499489, 0.332999, 1.317527, 0.513764, 0.638854, 0.393921, 0.704755, 0.304946, 0.826526, 0.403941, 0.764447, 0.326728, 0.392537, 0.400268, 0.695445, 0.432745, 0.358475, 0.390413, 0.369689, 0.425464, 0.335883, 0.332699, 0.878290, 0.305975, 0.441565, 0.316177, 0.807361, 0.322082, 0.347443, 0.753036, 0.360402, 0.432756, 0.389870, 0.510036, 0.559737, 0.400748, 0.313766, 0.305892, 0.345555, 0.284069, 0.370947, 0.303313, 0.283062, 0.387880, 0.312036, 0.334298, 0.293297, 2.285682, 0.600000, 0.383018, 0.446270, 0.373941, 0.386359, \n",
      "*************** \n",
      "\n",
      "Step 1 | Training Loss: 0.386359 | Test Loss: 1.464162 | Test Accuracy: 0.795511\n",
      "*************** \n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 2 | Training Loss: 0.606134, 0.834234, 0.360488, 0.354943, 0.373931, 2.089626, 0.306837, 0.514774, 0.347750, 0.313200, 0.385516, 0.702055, 0.294732, 0.501061, 0.429432, 0.335378, 0.510956, 0.329338, 0.356971, 0.520395, 0.363660, 0.355445, 0.577149, 0.462772, 0.634912, 0.590378, 0.687088, 0.357017, 0.354466, 0.252796, 0.299380, 0.292694, 0.370260, 0.415515, 0.327734, 0.374117, 0.362346, 0.300467, 0.364370, 0.296365, 0.247237, 0.343767, 0.923239, 1.244077, 2.010368, 0.275318, 0.314617, 0.304425, 0.546777, 0.362728, 0.341950, 0.379856, 0.287518, 0.419515, 0.353466, 0.327338, 0.358580, 0.340150, 0.302376, 0.379639, 0.334266, 0.269962, 0.326156, 0.312369, 0.328409, 0.261569, 0.561821, 0.313695, 0.892331, 0.275721, 0.276065, 0.514722, 0.344456, 1.197170, 0.344920, 0.505197, 0.279615, 0.333339, 0.637785, 0.366420, 0.475475, 0.328956, 2.500804, 0.263121, 0.626088, 0.339275, 0.514919, 0.266731, 0.323193, 0.601045, 0.297018, 1.092242, 0.483326, 0.303577, 0.321185, 0.580826, 0.401240, 0.270719, 0.315832, 0.295631, 0.307917, 0.299377, 0.283555, 0.302061, 0.869094, 0.259430, 0.638983, 0.235868, 0.242484, 0.350957, 0.182232, 0.258335, 0.373859, 0.330947, 0.288092, 0.226882, 0.243694, 0.228470, 1.370568, 0.283218, 0.242048, 0.268218, 0.270895, 0.571855, 0.335932, 0.833640, 0.286518, 0.640140, 0.312464, 0.269275, 0.270691, 0.473429, 0.212483, 0.280484, 0.293041, 0.244227, 0.223551, 0.345907, 0.471878, 0.324471, 0.199188, 0.202140, 0.307433, 0.185000, 0.311104, 0.251541, 0.548435, 0.261460, 0.315307, 0.184770, 0.223362, 0.232241, 0.351115, 0.194825, 0.209330, 0.269653, 0.543712, 0.631884, 0.230966, 0.244025, 0.235325, 1.501297, 0.326325, 0.241892, 0.262361, 0.421375, 0.244821, 0.924144, 0.195291, 0.270857, 0.237418, 0.322603, 0.199393, 0.208050, 0.244868, 0.381552, 0.445034, 0.614894, 0.203948, 1.276225, 0.277007, 0.375154, 0.292862, 0.427359, 0.293807, 0.241115, 0.262221, 0.273712, 0.215702, 0.287807, 0.280148, 0.249210, 0.299402, 0.214431, 0.222049, 0.212273, 0.423474, 0.468923, 0.271129, 0.579300, \n",
      "*************** \n",
      "\n",
      "Step 2 | Training Loss: 0.579300 | Test Loss: 1.346721 | Test Accuracy: 0.784776\n",
      "*************** \n",
      "\n",
      "Step 3 | Training Loss: 0.315274, 0.295367, 0.248348, 0.464183, 1.200100, 0.413807, 0.318224, 0.239796, 0.220362, 0.174978, 0.915172, 0.249102, 0.203801, 0.357726, 0.461943, 0.173179, 0.305623, 0.304209, 0.261796, 0.428468, 0.258353, 0.189439, 0.365972, 0.316402, 0.683148, 0.297651, 0.234614, 0.251244, 0.259018, 0.245747, 0.327278, 0.227625, 0.281933, 0.573335, 0.543493, 0.285473, 0.311075, 0.747560, 0.218016, 0.458205, 0.250712, 0.287416, 0.262474, 0.231332, 0.402271, 0.283503, 0.202820, 0.240321, 0.220997, 0.335737, 0.241966, 0.335009, 0.249237, 0.299618, 0.211280, 0.250291, 0.407212, 0.171625, 0.295844, 0.310538, 0.196191, 0.252053, 0.191021, 0.195842, 0.212571, 0.184579, 0.392706, 0.249376, 0.240745, 0.334481, 0.552357, 0.385551, 0.472041, 0.176054, 0.370101, 0.269413, 0.873612, 0.195535, 0.256006, 0.240669, 0.161996, 0.213763, 0.169786, 0.196730, 0.204675, 0.264193, 0.316294, 0.254423, 0.291804, 0.264428, 0.361925, 0.210047, 0.496973, 0.187195, 0.208866, 0.197111, 0.265573, 0.245012, 0.164328, 0.212725, 0.210282, 0.190188, 0.232966, 1.102463, 0.204078, 0.197590, 0.280482, 0.258357, 0.187035, 0.190811, 0.381383, 0.437516, 0.324862, 0.670936, 0.412426, 0.266078, 0.181029, 0.486513, 0.202801, 0.272833, 0.137880, 1.957464, 0.514467, 0.219877, 0.217865, 0.249109, 0.177177, 0.213816, 0.435940, 0.583607, 2.060550, 0.212440, 0.182894, 0.214892, 0.899418, 1.119004, 0.153028, 0.184357, 2.144861, 0.295647, 1.378438, 0.239560, 0.308644, 0.523654, 0.205057, 0.288158, 0.194579, 0.201536, 0.172677, 0.264786, 0.415310, 0.226386, 0.448717, 0.187738, 0.510993, 0.307932, 0.256805, 3.006688, 0.404573, 0.381987, 0.189890, 0.372764, 0.165544, 0.318537, 0.233747, 0.227797, 0.217097, 0.300869, 0.236907, 0.261260, 0.433431, 0.308473, 0.178376, 1.066552, 0.189527, 0.348964, 0.247731, 0.207925, 0.900463, 0.298388, 0.275478, 0.404215, 0.466414, 0.264172, 0.491237, 0.254921, 0.316887, 0.244771, 0.267077, 0.230654, 0.318205, 0.411477, 0.508147, 0.164378, 0.151160, 0.296040, 0.271839, 0.453427, 0.283742, 0.294261, \n",
      "*************** \n",
      "\n",
      "Step 3 | Training Loss: 0.294261 | Test Loss: 1.305266 | Test Accuracy: 0.766856\n",
      "*************** \n",
      "\n",
      "Step 4 | Training Loss: 0.239348, 1.403900, 0.257394, 0.307930, 0.193535, 0.362741, 0.244861, 0.274830, 0.210895, 0.297392, 0.274072, 0.246856, 0.176992, 0.280421, 0.216084, 0.179212, 0.249715, 0.223895, 0.333555, 1.916311, 0.309304, 1.248222, 0.230509, 0.308449, 0.280406, 0.315837, 1.198918, 0.297594, 0.366396, 0.228686, 0.435255, 0.300730, 0.229997, 0.449481, 0.218080, 0.387825, 0.323759, 0.203763, 0.248439, 0.265577, 0.342249, 0.491350, 0.244262, 0.347946, 0.238952, 0.264135, 0.281424, 0.524962, 0.243629, 0.227833, 0.303280, 0.161165, 0.188125, 0.224000, 0.133143, 0.194342, 0.254484, 0.171002, 0.222548, 0.276749, 0.173205, 0.159093, 0.354547, 0.263564, 0.493421, 0.481947, 0.190472, 0.345724, 0.241183, 0.159310, 0.357616, 0.304323, 0.187420, 0.135632, 0.258036, 0.198175, 0.241226, 0.276785, 0.198789, 0.363826, 0.371993, 0.131403, 0.163210, 0.162983, 0.321100, 0.160933, 0.295527, 0.251240, 0.335824, 0.178398, 0.690808, 0.194863, 0.199835, 1.044442, 0.578974, 0.270915, 0.151147, 0.240695, 0.653412, 0.178759, 1.187464, 0.135551, 0.194230, 0.162625, 2.889371, 0.772982, 0.308220, 0.363910, 0.211895, 0.321109, 0.452509, 0.165802, 0.441702, 0.350757, 0.198965, 0.374082, 0.422503, 2.176460, 1.249398, 0.435324, 0.402772, 0.203648, 0.385284, 0.541682, 0.203954, 0.238035, 0.357132, 0.466181, 0.192849, 0.342396, 0.194633, 0.153301, 0.208878, 0.229195, 0.247290, 0.572334, 0.372600, 0.194695, 0.216533, 0.365515, 0.335994, 0.195778, 0.313007, 0.663630, 0.231502, 0.504864, 0.309144, 0.219161, 0.252338, 0.256443, 0.299040, 0.411017, 0.316131, 0.246902, 0.415926, 0.204848, 0.209345, 0.219691, 0.170814, 1.646932, 0.458259, 0.293088, 0.199777, 0.319343, 0.179663, 0.393697, 0.430883, 0.765298, 0.259843, 0.254371, 0.356461, 0.149402, 0.214540, 0.123612, 0.119874, 0.273110, 0.329338, 0.233248, 0.182037, 2.096864, 0.259077, 0.497258, 0.151647, 0.178438, 0.290449, 0.189733, 0.791699, 0.202941, 0.157514, 0.180955, 0.168198, 0.251023, 0.149387, 0.351570, 0.229315, 0.238407, 0.107359, 0.292511, 0.358427, 0.143766, \n",
      "*************** \n",
      "\n",
      "Step 4 | Training Loss: 0.143766 | Test Loss: 1.352249 | Test Accuracy: 0.811480\n",
      "*************** \n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 5 | Training Loss: 0.197336, 0.258278, 1.090607, 0.429099, 2.239456, 0.159015, 0.155819, 0.234164, 0.157360, 0.166647, 0.220945, 0.158602, 0.580102, 0.249457, 0.112096, 0.148851, 0.136639, 1.152743, 0.373787, 0.176598, 0.210404, 0.223979, 0.497483, 0.109634, 0.149375, 0.155430, 0.328099, 0.220348, 0.114414, 0.167796, 0.208731, 0.484172, 0.144916, 1.982699, 0.197052, 0.237402, 0.387428, 0.152059, 0.359943, 0.193026, 0.182583, 0.210981, 0.307647, 0.202497, 0.115184, 0.182092, 0.290421, 0.157145, 0.110111, 0.231332, 0.292739, 0.346685, 0.410707, 0.106328, 0.252221, 0.142353, 0.208484, 0.163008, 0.149270, 0.165805, 0.277450, 0.239213, 0.372184, 0.327515, 1.043632, 0.130589, 0.163456, 0.472918, 0.127749, 0.374200, 0.140339, 0.106379, 0.395154, 0.355995, 0.146666, 0.143843, 0.126202, 0.276262, 0.235460, 0.406926, 0.126762, 0.196747, 0.337584, 0.144778, 0.236493, 0.175919, 0.324592, 0.164914, 0.140782, 0.167327, 0.714178, 0.149907, 0.390800, 0.091503, 0.252298, 0.099297, 0.136064, 0.280595, 0.210157, 1.144466, 0.163428, 0.162469, 0.177810, 0.218825, 1.257639, 0.425535, 0.138720, 0.318303, 0.154857, 0.172451, 0.486139, 0.346492, 0.096564, 0.292449, 0.130909, 1.007629, 0.128098, 0.173006, 0.132812, 0.218929, 0.245027, 0.145215, 0.092710, 0.118246, 0.241479, 0.467617, 0.281161, 0.104839, 0.140508, 0.197704, 0.390239, 0.181656, 0.327556, 0.168215, 0.185257, 0.132479, 0.223894, 0.195101, 0.179847, 0.384291, 0.137468, 0.166483, 0.233544, 0.525187, 0.197105, 0.098364, 0.177501, 0.364065, 0.125979, 0.247286, 3.636021, 0.085260, 0.112854, 0.113796, 0.162810, 0.749023, 0.130124, 0.215606, 0.123179, 0.362672, 0.181121, 0.322292, 0.179932, 0.172231, 0.140950, 1.307306, 0.167997, 0.077756, 0.131366, 0.120086, 2.475869, 0.141461, 0.168990, 0.341912, 0.176573, 0.118095, 0.496730, 0.260742, 0.180870, 0.270992, 0.096760, 0.392625, 0.240209, 0.106052, 0.114988, 0.143028, 0.207989, 0.158638, 0.129063, 0.148239, 0.107982, 0.117601, 0.083467, 0.177810, 0.121289, 0.180991, 0.250374, 0.210668, 0.179474, 0.499629, \n",
      "*************** \n",
      "\n",
      "Step 5 | Training Loss: 0.499629 | Test Loss: 1.363150 | Test Accuracy: 0.752395\n",
      "*************** \n",
      "\n",
      "Step 6 | Training Loss: 0.224824, 1.085782, 0.232097, 0.244799, 0.133580, 1.131337, 0.204595, 0.115891, 0.391505, 0.166889, 0.195438, 0.182760, 0.791493, 0.224504, 0.739588, 0.080194, 0.135414, 0.180853, 0.135558, 0.190667, 0.252564, 0.385876, 0.165611, 0.102142, 0.329158, 0.327483, 0.088090, 0.410924, 0.154872, 0.572677, 0.123571, 0.393853, 0.229585, 0.273608, 0.113433, 0.225634, 0.137621, 0.072538, 0.199602, 0.320742, 0.166661, 0.137960, 0.153762, 0.358462, 0.257706, 0.162811, 0.916367, 0.118306, 0.212796, 0.096727, 0.123968, 0.195188, 0.133588, 0.119998, 0.117420, 0.187835, 0.992921, 0.075527, 0.173763, 0.107847, 0.098140, 0.178329, 0.122231, 0.186138, 0.129774, 0.146752, 0.076711, 0.248015, 0.108998, 0.935176, 0.140742, 0.086742, 0.098812, 0.517808, 0.446179, 0.194808, 0.121206, 0.075560, 1.074406, 0.160894, 0.494888, 0.094229, 0.146203, 0.139751, 0.123834, 0.175386, 0.061189, 0.091643, 0.085801, 0.121633, 1.998966, 0.190156, 0.173746, 0.106967, 0.179311, 0.243882, 0.094068, 0.363667, 0.133872, 0.090219, 0.097312, 0.333145, 0.128326, 0.093196, 0.236863, 0.253161, 1.073815, 0.152842, 0.136473, 0.176079, 0.437569, 0.228658, 0.113838, 0.083769, 0.159617, 0.292054, 0.129214, 0.148362, 0.145744, 0.114076, 0.148500, 0.105612, 0.257930, 0.179610, 0.214396, 0.255106, 0.259215, 0.342394, 0.113425, 0.570488, 0.151329, 0.185130, 0.184954, 0.256980, 0.158833, 0.153343, 0.157525, 0.168442, 0.116892, 0.113164, 0.255999, 0.083207, 0.179091, 10.241274, 0.231839, 0.440042, 0.414638, 0.256283, 0.378059, 0.153417, 0.135130, 0.373264, 0.630262, 0.276068, 0.175657, 0.283653, 0.222037, 0.712702, 0.362402, 0.116026, 0.107602, 0.342670, 1.912910, 0.428429, 0.268416, 0.125331, 0.158489, 0.173744, 0.325726, 0.145235, 0.235511, 0.558506, 0.617889, 0.118551, 0.147599, 0.645162, 0.178690, 0.261595, 0.553363, 0.201390, 0.231194, 0.175628, 0.183994, 0.272580, 0.329512, 0.506450, 0.292165, 0.251638, 0.141643, 0.225222, 0.206475, 0.169870, 0.189306, 0.196792, 0.095013, 0.249753, 0.172017, 0.130320, 1.024216, 0.270128, \n",
      "*************** \n",
      "\n",
      "Step 6 | Training Loss: 0.270128 | Test Loss: 1.371611 | Test Accuracy: 0.807754\n",
      "*************** \n",
      "\n",
      "Step 7 | Training Loss: 0.110870, 0.699054, 1.197240, 0.081778, 0.506776, 0.579141, 0.194660, 0.486185, 0.474213, 0.187595, 0.123160, 0.095667, 0.075501, 0.129890, 0.101603, 0.156530, 0.360310, 1.962628, 0.439804, 0.268660, 0.233342, 0.183015, 0.168049, 0.075829, 0.084373, 0.181110, 0.265306, 0.162343, 0.165043, 0.127992, 0.188723, 1.181530, 0.075054, 0.999155, 0.131535, 0.235379, 0.108303, 0.086386, 0.203261, 0.081773, 0.371420, 0.157594, 0.159517, 0.136477, 0.088118, 0.287047, 0.291211, 0.139147, 0.217338, 0.140365, 0.147375, 0.555128, 0.223515, 0.132717, 0.158641, 0.197934, 0.106244, 0.167670, 0.218462, 0.073757, 0.218759, 0.101810, 0.288635, 0.073671, 0.059933, 0.128254, 0.236935, 0.081251, 0.186912, 0.519717, 0.285745, 0.152741, 0.214842, 0.127906, 0.209986, 0.195118, 1.051147, 0.228432, 0.241580, 0.869710, 0.171405, 0.909544, 0.275961, 0.511308, 0.290711, 0.153525, 0.079093, 0.414476, 0.091260, 0.253713, 0.205183, 0.096398, 0.118376, 0.171874, 0.130648, 0.115632, 0.147660, 0.070098, 0.160602, 0.200617, 0.128327, 0.106537, 0.103350, 0.152073, 0.164222, 0.134066, 0.244650, 0.285470, 0.120845, 0.313947, 0.065466, 0.099142, 0.090528, 0.493137, 0.067538, 0.080118, 0.125480, 2.021177, 0.140788, 0.081564, 0.333627, 0.807151, 0.053704, 1.758097, 0.166327, 0.192829, 0.798738, 0.147340, 0.173738, 0.168021, 0.129874, 0.189289, 0.171853, 0.283718, 0.091764, 0.275112, 0.479609, 0.085888, 0.228223, 0.315660, 0.182182, 0.111660, 0.338520, 0.143024, 0.456830, 0.126382, 0.145810, 0.126734, 0.089973, 0.069920, 0.177398, 0.110824, 0.230040, 0.155328, 0.156446, 0.382699, 0.919262, 0.183641, 0.202623, 0.319506, 0.127659, 0.339602, 1.001304, 0.142129, 0.391254, 2.846523, 0.105976, 0.924281, 0.188848, 0.153586, 0.200667, 0.206389, 0.074502, 0.151352, 0.285650, 0.116484, 0.264225, 1.487047, 0.205959, 0.190381, 0.071832, 0.206398, 0.236422, 0.068434, 0.075549, 0.075710, 0.069049, 0.092740, 0.194232, 0.116103, 0.125126, 0.121811, 0.143049, 0.182497, 0.138557, 0.264806, 0.711061, 0.306851, 0.104543, 0.280886, \n",
      "*************** \n",
      "\n",
      "Step 7 | Training Loss: 0.280886 | Test Loss: 1.308234 | Test Accuracy: 0.752129\n",
      "*************** \n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 8 | Training Loss: 0.056171, 0.339282, 0.110370, 0.331817, 1.388112, 0.298813, 0.070789, 0.113692, 0.099678, 0.185786, 0.308462, 0.596223, 0.312749, 0.143027, 0.078756, 0.184825, 0.398076, 0.115445, 0.175120, 0.203192, 0.117679, 0.154098, 0.072111, 0.201410, 0.091429, 0.118597, 0.097626, 0.071519, 0.563769, 0.065677, 1.423138, 0.221876, 0.255352, 0.119311, 0.059487, 0.409528, 0.145880, 0.071065, 0.332069, 0.074480, 0.160541, 0.291592, 0.158668, 0.197630, 0.157416, 0.373345, 0.355425, 0.197139, 0.091473, 0.996394, 0.076826, 0.125455, 0.082729, 0.163179, 0.132362, 0.126346, 0.330244, 0.313010, 0.111840, 0.281944, 0.069771, 0.069248, 0.104924, 0.171961, 0.127228, 0.169517, 0.264861, 0.128315, 0.101883, 0.506976, 0.974730, 0.116818, 0.147610, 0.123228, 0.144642, 0.124478, 0.108033, 0.180503, 0.093427, 0.142160, 0.136036, 0.164573, 0.361891, 0.152479, 0.408768, 0.089173, 0.139089, 0.117874, 0.133446, 0.137952, 0.144468, 0.103399, 0.974424, 0.422433, 0.093171, 0.229954, 0.397671, 0.083781, 0.131290, 0.189767, 0.169530, 0.136921, 0.172647, 0.157270, 0.193308, 0.271943, 1.876093, 0.211923, 0.105962, 0.187372, 0.137996, 0.141390, 0.193535, 0.092339, 0.230361, 0.207241, 0.448025, 0.769080, 0.149390, 0.651101, 0.194562, 0.162516, 0.338933, 0.080684, 0.056227, 0.130281, 0.348944, 0.144833, 0.350001, 0.737461, 0.084092, 0.184389, 0.080660, 0.188052, 0.136562, 0.130627, 0.066690, 0.060404, 0.079343, 0.450007, 0.080308, 0.369042, 0.156950, 0.163435, 0.131347, 0.078867, 0.090391, 0.205377, 0.123522, 0.116643, 1.130576, 0.281607, 0.055552, 0.172171, 0.305683, 0.106061, 0.132360, 0.116941, 0.121545, 0.157184, 0.095552, 0.082083, 0.304320, 0.469000, 0.120815, 0.096708, 0.314494, 1.914883, 0.204190, 0.082791, 1.069158, 0.075875, 0.284013, 0.493934, 0.182065, 0.122761, 0.139331, 0.070599, 0.506191, 2.791112, 0.850052, 0.130077, 0.202954, 0.360310, 0.194166, 0.098122, 0.108274, 0.164243, 0.138324, 0.129366, 0.233806, 0.096621, 0.810295, 0.283789, 0.079355, 0.120703, 0.078913, 0.229750, 0.117225, 0.099822, \n",
      "*************** \n",
      "\n",
      "Step 8 | Training Loss: 0.099822 | Test Loss: 1.342917 | Test Accuracy: 0.747383\n",
      "*************** \n",
      "\n",
      "Step 9 | Training Loss: 0.175267, 0.109253, 0.046008, 0.137003, 0.419512, 0.125528, 0.229327, 0.516295, 0.108200, 0.119714, 0.094915, 0.228043, 0.198704, 0.127249, 1.087866, 0.325068, 0.054869, 0.129869, 0.149185, 0.174120, 0.047240, 0.207581, 0.143092, 1.849498, 0.078708, 0.094492, 0.044424, 0.119844, 0.438989, 0.046767, 0.667756, 0.060407, 0.351661, 2.023874, 0.075221, 0.390587, 0.048565, 0.168321, 0.332144, 0.119260, 0.774724, 0.206720, 0.117088, 0.186689, 1.025994, 0.175917, 0.185787, 0.235582, 0.170236, 0.092307, 0.189634, 0.072971, 0.050622, 0.163918, 0.085043, 0.092864, 0.739101, 3.024860, 0.119059, 0.148165, 0.099798, 0.391380, 0.059459, 0.085742, 0.109408, 0.082616, 1.905249, 0.113015, 0.229325, 0.102782, 0.082486, 0.444831, 0.320682, 0.058752, 0.082639, 0.133755, 0.219486, 0.076511, 0.056178, 0.230894, 0.201074, 0.046528, 0.132057, 0.228009, 0.072959, 0.288690, 0.338672, 0.106145, 0.076960, 0.158635, 0.084847, 0.165406, 0.146475, 0.055009, 0.234465, 1.019974, 0.124694, 0.124117, 0.199991, 0.172764, 0.106593, 0.106460, 0.054791, 0.098840, 0.293772, 0.370689, 0.085079, 0.212142, 0.079931, 0.207842, 0.097139, 0.084253, 0.317446, 0.270975, 0.069555, 0.131265, 0.073025, 0.092628, 0.047251, 0.230169, 0.125609, 0.270401, 0.063672, 0.083903, 0.220164, 0.089131, 0.203521, 0.142424, 0.985625, 0.103681, 0.271902, 0.111966, 0.322773, 0.091973, 0.069502, 0.053060, 0.227380, 0.116363, 0.655638, 0.171858, 0.274068, 0.205290, 0.076278, 0.302852, 0.067724, 0.074159, 0.105891, 0.197065, 0.128433, 0.073710, 0.126673, 0.085094, 0.166551, 0.074433, 0.143556, 0.176234, 0.169381, 0.077096, 0.083262, 0.074645, 0.094819, 0.184337, 0.104061, 0.565173, 0.046939, 0.087406, 0.105107, 0.371332, 0.244670, 0.083872, 0.660606, 0.073749, 0.153235, 1.166000, 0.078541, 0.206949, 0.143922, 0.076145, 0.078302, 0.149755, 0.065022, 0.086093, 0.214643, 0.111215, 0.113866, 0.688657, 0.185415, 0.160969, 0.354169, 0.621403, 0.085930, 0.082611, 0.390687, 0.190411, 0.326947, 0.113383, 0.173152, 0.122256, 0.210063, 0.076524, \n",
      "*************** \n",
      "\n",
      "Step 9 | Training Loss: 0.076524 | Test Loss: 1.433483 | Test Accuracy: 0.732479\n",
      "*************** \n",
      "\n",
      "Step 10 | Training Loss: 0.124978, 0.188862, 0.135616, 0.206798, 0.115329, 0.254459, 0.111508, 0.244847, 0.237134, 0.143121, 0.176199, 0.091610, 0.449006, 0.210539, 0.323196, 0.145200, 0.294113, 0.367570, 0.169382, 0.389646, 0.126964, 0.127562, 0.276797, 0.400147, 0.146421, 0.133837, 0.262532, 0.177505, 0.151546, 1.229913, 0.166893, 0.194664, 0.541703, 0.422769, 0.310238, 0.177683, 0.230230, 0.227695, 0.255889, 0.230752, 0.232421, 0.158633, 0.134019, 0.282074, 0.179231, 0.142824, 0.087230, 0.193677, 2.342937, 0.162067, 0.153233, 0.181916, 0.713582, 0.232826, 0.217424, 0.273662, 0.145227, 0.443448, 0.246146, 0.234601, 0.438488, 0.313399, 0.261628, 0.185843, 0.455043, 0.137619, 0.133483, 0.252877, 1.141822, 1.020776, 0.172884, 0.232923, 0.173524, 0.364265, 0.462766, 0.270139, 0.183985, 0.401045, 0.191771, 0.218439, 0.748571, 0.215015, 0.132614, 0.155817, 0.149487, 0.351032, 0.155823, 0.179394, 0.237494, 0.254427, 0.185413, 0.104681, 0.139656, 0.139571, 0.115904, 0.130233, 0.217668, 0.065936, 0.115805, 0.160911, 0.318175, 0.849858, 0.158621, 0.163235, 0.349281, 0.152532, 0.233651, 0.185369, 0.136553, 0.083986, 0.383106, 0.091896, 0.134505, 0.174980, 0.189616, 0.325022, 0.173112, 0.994855, 0.082809, 0.123642, 0.184276, 0.074780, 0.228210, 0.370929, 0.308228, 0.265685, 0.126635, 0.112887, 0.111935, 0.065163, 0.161997, 0.137977, 0.103812, 0.158146, 0.327855, 0.546924, 0.158383, 0.131694, 1.038517, 0.067246, 0.137316, 0.814836, 0.135176, 0.212563, 0.239634, 0.393668, 0.760131, 0.175248, 0.161327, 0.420173, 0.057823, 0.082604, 0.692380, 0.090586, 0.143003, 0.129119, 1.673698, 0.104063, 0.352874, 0.188378, 0.100622, 0.500603, 0.076066, 2.789298, 0.131585, 0.332455, 0.293778, 0.083541, 0.222380, 0.096656, 0.162704, 0.195024, 0.081746, 0.266241, 0.279469, 0.197292, 0.098297, 0.154699, 0.101399, 0.206467, 0.133355, 1.224829, 0.325838, 0.070877, 0.097381, 1.102712, 0.079280, 0.185993, 0.123847, 0.072133, 0.106714, 0.178059, 1.126736, 0.091801, 0.254166, 0.120265, 0.192063, 0.102078, 0.090881, 0.165942, \n",
      "*************** \n",
      "\n",
      "Step 10 | Training Loss: 0.165942 | Test Loss: 1.382395 | Test Accuracy: 0.758650\n",
      "*************** \n",
      "\n",
      "Current Layer Attributes - epochs:10 hidden layers:2 features count:32\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 1 | Training Loss: 1.138798, 1.016529, 0.899578, 0.879859, 0.838077, 1.039701, 0.879935, 0.820347, 1.031440, 0.803016, 0.996499, 0.830363, 0.766591, 0.765810, 0.779187, 0.801342, 0.816854, 0.897426, 0.585009, 0.673095, 0.665167, 0.627085, 1.879869, 0.698166, 0.703581, 0.631050, 0.671544, 0.691557, 0.732676, 0.490253, 0.651983, 1.473012, 0.750620, 0.499232, 0.661946, 0.688558, 0.523041, 0.609908, 0.702618, 0.549302, 0.600876, 0.650264, 0.664152, 0.571193, 0.522376, 0.748291, 0.511338, 0.508479, 0.609610, 0.604348, 0.515289, 0.523804, 0.496498, 0.532008, 0.570093, 0.512660, 0.640131, 0.802606, 0.530980, 0.819089, 0.523919, 0.585223, 0.452620, 0.528637, 0.483042, 0.650416, 0.420160, 0.584220, 0.493350, 1.144559, 0.523349, 0.470852, 0.465852, 1.261213, 0.550375, 0.531444, 0.771726, 0.725162, 2.278675, 0.584134, 0.584625, 0.475631, 0.799474, 0.517623, 1.341204, 0.430970, 0.689505, 0.520422, 0.494944, 0.539632, 0.435115, 0.754632, 2.329490, 0.423207, 0.466036, 0.465530, 0.684498, 0.591226, 0.569788, 0.460278, 0.436055, 0.980222, 0.647341, 0.465526, 0.612626, 0.508005, 0.493612, 1.387030, 0.412567, 0.553332, 0.361218, 0.526060, 2.840774, 0.566999, 0.540565, 0.645297, 0.448680, 0.503329, 0.437024, 0.529117, 0.393247, 0.708585, 0.698126, 1.061467, 0.469650, 0.419203, 0.518337, 0.789600, 0.583470, 0.388569, 0.669516, 1.098430, 1.381475, 0.679908, 0.876649, 0.554970, 0.463886, 0.502849, 0.518478, 0.648058, 0.494863, 1.010004, 0.702426, 1.391395, 0.329051, 0.443527, 0.491949, 0.573644, 1.049846, 0.771639, 0.431323, 0.556033, 0.434524, 0.497807, 0.441574, 0.521980, 0.607430, 0.397496, 0.362295, 1.283987, 0.432937, 0.459120, 0.541224, 0.474554, 0.377764, 0.408131, 0.333234, 0.784440, 0.506375, 0.332322, 0.397293, 0.356826, 0.479030, 0.394511, 0.345312, 0.417086, 0.508626, 1.057548, 0.764811, 0.389545, 0.377394, 0.389373, 0.471603, 0.490507, 0.508550, 0.463626, 0.336455, 0.351273, 0.808250, 0.424240, 0.430407, 0.423144, 0.409280, 0.655913, 0.381182, 0.755943, 0.418923, 0.379429, 0.407873, 0.327451, \n",
      "*************** \n",
      "\n",
      "Step 1 | Training Loss: 0.327451 | Test Loss: 1.420331 | Test Accuracy: 0.828114\n",
      "*************** \n",
      "\n",
      "Step 2 | Training Loss: 0.444845, 0.478916, 0.320313, 0.702657, 0.396714, 0.983457, 0.371206, 0.513044, 0.325157, 0.454061, 0.417764, 0.446962, 0.472812, 0.432722, 0.348919, 0.364742, 0.411074, 0.382782, 0.387303, 0.394963, 0.414453, 0.622435, 0.380469, 0.318603, 0.472425, 0.400103, 0.986350, 0.485338, 0.434102, 0.493812, 0.402224, 0.382632, 0.297284, 0.646789, 1.058407, 0.629044, 0.314031, 0.387275, 0.453525, 0.417155, 0.346332, 0.280006, 0.438360, 0.320819, 0.513596, 0.356173, 0.446497, 0.548146, 0.358180, 1.252625, 0.369575, 0.445002, 0.600245, 0.406071, 0.560418, 0.322020, 0.348304, 0.307543, 0.299829, 0.386659, 0.348317, 0.373368, 0.275539, 0.456355, 0.304874, 0.335456, 0.315907, 1.241099, 0.718887, 1.219964, 0.317448, 0.402894, 0.310570, 0.369365, 0.356849, 0.347649, 0.516293, 0.338137, 0.666541, 0.491147, 0.339403, 0.456657, 0.406073, 0.300739, 1.744296, 0.483595, 2.083013, 0.311465, 0.397338, 0.331648, 0.449542, 0.562132, 0.604918, 0.522069, 0.373136, 0.354621, 0.398418, 0.309056, 0.294302, 0.470999, 4.478501, 0.607795, 0.368332, 0.365917, 0.302233, 0.419311, 0.544386, 0.316157, 0.364930, 0.378849, 0.406579, 0.457474, 0.349941, 0.348341, 0.411036, 0.325930, 0.502346, 0.478531, 0.294758, 0.294377, 0.370804, 1.371865, 0.254782, 0.983430, 0.623187, 0.329787, 0.385089, 0.346688, 0.522827, 0.310950, 0.313296, 0.316953, 0.504386, 0.416151, 0.466122, 0.395793, 0.351948, 0.296849, 0.291407, 0.318872, 0.331886, 0.303918, 0.391598, 0.401483, 0.324068, 0.276991, 0.277098, 0.303725, 0.209604, 0.416996, 0.303091, 0.302818, 0.297917, 1.269617, 0.285436, 0.318337, 0.959738, 0.537461, 0.410818, 0.767268, 0.446436, 0.339213, 0.536923, 0.297344, 0.904230, 0.268892, 0.339340, 0.324679, 0.266691, 0.308955, 0.343944, 0.289956, 0.320244, 0.403737, 0.236594, 0.303897, 0.514736, 0.285177, 0.288065, 0.250209, 0.480068, 0.350707, 0.387315, 0.344910, 0.291014, 0.295749, 0.347544, 0.457498, 0.526408, 0.721926, 0.306994, 0.417411, 0.237678, 0.448063, 0.633867, 0.323247, 0.329329, 0.352731, 0.484021, 0.677068, \n",
      "*************** \n",
      "\n",
      "Step 2 | Training Loss: 0.677068 | Test Loss: 1.471125 | Test Accuracy: 0.765658\n",
      "*************** \n",
      "\n",
      "Step 3 | Training Loss: 1.160463, 0.269813, 0.600774, 0.430163, 0.296461, 0.390252, 0.360100, 0.320283, 0.270971, 0.473010, 0.328153, 0.413153, 0.339952, 0.282102, 0.351436, 0.443979, 0.452255, 0.306301, 0.263846, 0.279844, 0.562544, 0.383335, 0.381961, 0.384887, 0.377310, 0.308899, 0.283952, 0.248821, 0.326284, 0.230104, 0.324904, 0.234288, 0.506130, 0.302610, 0.251017, 0.290320, 0.533627, 0.358280, 0.498452, 0.370214, 0.264007, 0.324347, 0.358356, 0.248154, 0.292816, 0.199592, 0.264176, 0.261781, 0.238254, 0.324853, 0.179815, 0.282391, 0.296902, 0.566679, 0.254009, 0.181455, 1.544420, 0.287629, 0.208980, 0.226099, 0.282015, 0.401274, 0.292482, 0.295327, 0.244126, 0.492194, 0.252846, 0.238994, 0.274677, 0.299240, 0.275547, 0.310810, 0.195181, 0.337073, 0.226371, 0.336724, 0.578386, 0.283781, 0.293472, 0.346278, 1.389332, 0.435974, 0.244969, 0.200176, 0.236072, 0.243678, 0.243704, 0.244447, 0.164755, 0.660600, 0.335639, 0.366556, 0.237278, 0.238700, 0.229490, 0.211776, 2.046592, 0.284279, 0.609933, 0.502926, 0.542396, 0.296064, 0.284644, 0.734355, 0.248031, 0.282871, 0.236321, 0.233957, 0.353154, 0.560593, 0.221326, 0.286266, 0.192178, 0.414070, 0.302798, 0.325956, 0.208776, 0.194268, 0.384333, 0.318705, 0.925306, 0.176583, 0.843859, 0.184694, 0.236672, 0.215932, 3.641264, 0.388369, 0.257379, 0.215384, 0.473571, 0.556187, 0.243724, 0.305791, 0.359901, 0.618072, 0.344892, 0.466855, 0.452649, 0.343711, 0.294175, 0.248693, 0.419668, 0.202665, 0.227967, 0.429768, 0.238129, 0.254681, 0.256600, 0.251223, 0.187018, 0.281764, 1.870430, 0.265771, 0.210595, 0.309204, 0.295781, 0.436462, 0.250870, 0.227772, 0.344091, 0.257599, 0.243605, 0.203187, 0.299766, 0.215431, 0.228663, 0.734308, 0.260097, 0.258290, 0.173299, 0.271509, 1.069864, 0.812426, 0.227668, 0.275074, 0.156244, 0.238329, 0.413498, 0.377748, 0.248546, 0.512680, 0.404941, 0.203247, 0.340324, 0.250777, 0.154581, 0.410479, 0.611508, 0.260694, 0.962299, 0.912784, 0.253174, 0.301395, 0.490331, 0.391577, 0.342905, 0.219453, 0.956425, 0.601046, \n",
      "*************** \n",
      "\n",
      "Step 3 | Training Loss: 0.601046 | Test Loss: 1.342545 | Test Accuracy: 0.764594\n",
      "*************** \n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 4 | Training Loss: 0.483122, 0.230428, 0.333526, 0.332661, 0.182700, 0.275626, 0.657026, 0.181219, 0.228578, 0.261690, 0.258353, 0.553542, 0.158943, 0.307559, 0.375156, 0.176672, 0.323634, 0.213043, 0.842820, 0.214221, 0.661165, 0.155006, 0.285878, 0.164790, 0.360981, 0.231929, 0.229458, 0.191845, 0.241470, 0.415909, 0.164808, 0.209823, 0.285896, 0.300374, 0.214123, 0.276104, 0.245837, 0.182039, 0.240428, 0.216247, 0.188068, 0.731257, 0.434911, 0.614238, 0.222634, 0.155754, 1.232787, 0.222538, 0.223159, 0.353368, 0.181486, 0.221105, 0.266049, 0.231318, 0.342241, 0.229681, 0.334168, 0.190719, 0.227409, 0.287610, 0.183242, 0.239565, 0.505592, 0.348976, 0.203558, 0.207940, 1.213486, 0.396928, 0.244879, 0.229366, 0.472285, 0.460709, 0.237128, 0.319919, 0.213355, 2.045307, 0.804016, 0.215258, 0.287671, 0.187213, 0.208849, 1.090967, 0.234944, 0.301756, 0.183935, 0.153099, 0.269167, 0.312217, 0.252673, 0.253372, 0.225569, 0.157207, 0.311724, 2.086646, 0.245637, 0.234126, 0.256397, 0.400985, 0.311375, 0.494474, 0.456536, 0.372455, 0.275861, 0.192604, 0.355920, 0.263050, 0.194478, 0.181724, 0.319447, 0.205212, 0.177115, 0.244841, 0.264016, 0.233102, 0.200650, 0.156552, 0.229069, 0.274747, 0.595360, 0.449335, 0.204852, 0.262894, 0.240604, 0.556032, 0.306291, 0.312827, 0.262409, 0.249405, 0.514189, 0.198397, 0.323562, 0.481087, 0.221220, 1.097899, 0.416892, 0.274057, 0.181856, 0.696381, 0.452152, 0.210106, 0.816475, 0.330104, 0.165664, 0.221057, 0.246222, 0.861462, 0.209995, 1.669140, 0.263692, 0.464397, 0.165293, 0.230205, 0.744571, 0.185535, 0.226693, 0.303623, 0.351715, 0.187513, 0.304744, 0.417928, 1.586515, 3.271697, 0.197773, 0.273184, 0.189982, 0.363419, 0.728137, 0.276166, 0.236258, 1.210661, 0.330905, 0.204270, 0.283782, 0.141634, 0.353328, 0.139591, 0.252596, 0.217952, 0.193645, 0.242650, 0.346107, 0.147894, 1.241648, 0.697573, 0.146986, 0.297904, 0.505602, 0.143828, 0.197988, 0.180102, 0.405922, 0.270922, 0.196975, 0.170152, 0.173670, 0.177685, 0.174596, 0.781332, 0.360443, 0.295085, \n",
      "*************** \n",
      "\n",
      "Step 4 | Training Loss: 0.295085 | Test Loss: 1.421765 | Test Accuracy: 0.750754\n",
      "*************** \n",
      "\n",
      "Step 5 | Training Loss: 0.250430, 0.213686, 0.618923, 0.233898, 0.485494, 0.286403, 0.131878, 0.288113, 0.248437, 0.743939, 1.373982, 0.269989, 0.161999, 0.371461, 0.422208, 0.129589, 0.263231, 0.210736, 0.201485, 0.250765, 0.248275, 0.533278, 0.321545, 1.739251, 0.252489, 0.606415, 0.101299, 0.264822, 0.215984, 0.455900, 0.348454, 0.152079, 0.264112, 0.240752, 0.259555, 0.278945, 0.138516, 0.201188, 0.282090, 0.138330, 0.377410, 0.229314, 0.331373, 0.548007, 0.221835, 0.438100, 0.286543, 0.974482, 0.219080, 0.263184, 0.194455, 1.927784, 0.147171, 0.169957, 0.126707, 0.220622, 0.379427, 0.178714, 0.234789, 0.218749, 0.171855, 0.263229, 0.129417, 0.139485, 0.260282, 0.425187, 0.373285, 0.365472, 0.167566, 0.482315, 0.206063, 0.255107, 0.153428, 0.220717, 0.214674, 0.723660, 0.269653, 0.244271, 0.159296, 0.174270, 0.167329, 0.220823, 0.260625, 0.492210, 0.164911, 0.365952, 0.328430, 0.185710, 0.238047, 0.422057, 0.201383, 0.230366, 0.141204, 0.315003, 0.225161, 0.265312, 1.967116, 0.155197, 0.188029, 0.178728, 0.165642, 0.113197, 0.340376, 0.224331, 0.585230, 0.180248, 0.080889, 0.183614, 0.131157, 0.292261, 0.444453, 0.097340, 0.611007, 0.159234, 0.198372, 0.164733, 0.238586, 0.274844, 0.286356, 0.267972, 0.143676, 0.141780, 0.336040, 0.216866, 0.934130, 0.147895, 0.216631, 0.145579, 0.234511, 0.369190, 0.155321, 0.199067, 0.209898, 0.140997, 0.196101, 0.248520, 0.197661, 0.192454, 0.101851, 0.144817, 0.189833, 0.152895, 0.424782, 0.283750, 0.122661, 1.183004, 0.256280, 0.092900, 0.291915, 0.205917, 0.215829, 0.432331, 0.122765, 0.222799, 0.349469, 0.226891, 0.181594, 0.179270, 0.267091, 0.254672, 1.166885, 0.572089, 0.197292, 0.249087, 0.217108, 0.196979, 1.062170, 0.777229, 0.154937, 0.539346, 0.216129, 0.114260, 0.115299, 0.182247, 0.343949, 0.344378, 2.144137, 0.299044, 0.231599, 0.906726, 3.139529, 0.161680, 0.242540, 0.165005, 0.169250, 0.314362, 0.211217, 0.230974, 0.188634, 0.858180, 0.317317, 0.350495, 0.682339, 0.211623, 0.195578, 0.547428, 0.348441, 0.394020, 1.133432, 0.150778, \n",
      "*************** \n",
      "\n",
      "Step 5 | Training Loss: 0.150778 | Test Loss: 1.432011 | Test Accuracy: 0.729241\n",
      "*************** \n",
      "\n",
      "Step 6 | Training Loss: 0.222753, 3.186747, 0.765669, 0.247820, 0.160721, 0.242047, 0.175756, 0.164552, 0.208980, 0.582785, 0.153612, 1.710978, 0.137105, 1.398867, 0.319828, 0.143075, 0.143890, 0.182501, 0.275136, 0.295860, 0.184668, 0.269050, 0.126539, 0.591312, 0.264412, 0.174945, 0.288969, 0.380155, 0.164644, 0.267756, 0.166601, 0.274824, 0.369539, 0.162061, 0.228484, 0.479767, 0.167215, 0.164736, 0.196651, 0.299351, 0.490598, 0.349005, 0.396918, 1.020199, 0.180657, 0.239566, 0.387064, 0.571571, 0.199112, 0.106832, 1.641227, 0.346467, 0.604265, 0.232229, 0.222577, 0.155835, 0.251363, 0.244445, 0.872015, 0.264558, 0.169881, 0.246710, 0.297653, 0.137202, 0.280825, 0.187953, 0.179699, 0.459587, 0.159417, 0.251434, 0.082362, 0.280953, 0.448378, 0.221685, 0.175925, 0.195514, 0.129596, 0.175058, 0.274373, 0.187783, 0.257895, 0.133788, 0.134629, 0.152109, 0.219322, 0.262682, 0.249922, 0.199193, 0.118579, 0.219075, 0.162577, 1.174065, 0.111785, 0.230765, 0.166630, 0.317198, 0.596288, 0.384257, 0.164229, 0.194103, 0.255847, 0.212001, 0.225081, 0.175462, 0.248216, 0.241750, 0.240749, 0.118381, 0.210386, 0.235244, 0.285689, 0.257315, 0.250516, 0.118681, 0.156325, 3.604342, 0.457678, 0.409966, 0.233633, 0.221687, 2.140236, 0.325460, 0.437489, 0.342595, 0.237335, 0.278502, 0.266907, 0.181422, 0.304385, 0.281530, 0.294482, 0.263759, 0.412874, 0.299392, 0.300122, 0.278908, 0.516589, 0.299282, 0.241509, 0.183769, 0.151884, 0.881924, 0.248587, 0.539185, 0.243569, 0.249784, 0.502509, 0.225086, 0.219333, 0.162275, 0.225321, 0.276157, 0.412006, 0.343186, 0.170184, 0.502002, 0.407930, 0.211870, 0.226047, 0.153151, 0.362921, 0.357532, 0.177839, 0.178581, 0.360045, 0.196209, 0.280581, 0.227036, 0.196977, 0.201496, 0.223751, 0.581530, 0.230855, 0.176390, 0.404020, 0.254058, 0.247310, 0.104399, 1.141904, 0.612868, 0.188068, 0.122534, 0.083966, 0.223858, 0.510612, 1.378134, 0.298446, 0.219761, 0.622194, 0.102454, 0.415348, 0.212992, 0.326424, 0.595732, 0.296036, 0.233410, 2.807551, 0.353691, 0.257274, 0.193397, \n",
      "*************** \n",
      "\n",
      "Step 6 | Training Loss: 0.193397 | Test Loss:    inf | Test Accuracy: 0.728620\n",
      "*************** \n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 7 | Training Loss: 0.323332, 0.622844, 0.251896, 0.196582, 0.290100, 0.237005, 0.533033, 0.299097, 0.375503, 0.427774, 0.471508, 0.221235, 0.286818, 2.282728, 0.223398, 0.208344, 0.237706, 0.339949, 0.293065, 3.072207, 0.162219, 0.451180, 0.190170, 0.701316, 0.381086, 0.168542, 0.296267, 0.314269, 1.053899, 0.246058, 0.102887, 1.121636, 0.122045, 0.332738, 0.257782, 0.205949, 0.186751, 0.171717, 0.192589, 0.333577, 0.184621, 0.154323, 0.184043, 0.505190, 0.343743, 1.704844, 0.201180, 0.200277, 0.334313, 1.041049, 0.158465, 0.242115, 0.144030, 0.324465, 0.146019, 0.162794, 0.291995, 0.176319, 0.239652, 0.267230, 0.192815, 0.141663, 0.290145, 0.285039, 0.391936, 0.432493, 0.367664, 0.225312, 0.148676, 0.284015, 0.172572, 0.152951, 0.261402, 0.297019, 0.379328, 0.349420, 0.306706, 0.120869, 0.133876, 0.325365, 0.100604, 0.805789, 0.834646, 0.102689, 0.462433, 0.256175, 0.144838, 0.279629, 0.231997, 0.473877, 0.170702, 1.045120, 0.202315, 0.684725, 0.244302, 0.283281, 0.576553, 0.159630, 0.243958, 0.467749, 0.306293, 0.118792, 0.203272, 0.210306, 0.364349, 0.322036, 0.244620, 0.242089, 0.135959, 0.145443, 0.290646, 0.210380, 0.807877, 0.499644, 0.231946, 0.148758, 0.199938, 0.283954, 1.216951, 0.150875, 0.260785, 0.257282, 0.289621, 0.204400, 0.174837, 0.339488, 0.453779, 0.189722, 0.096903, 1.083271, 0.116640, 0.277678, 0.239547, 0.180679, 0.117736, 0.151416, 0.142599, 0.711479, 0.101142, 0.150083, 0.702834, 0.400090, 0.150836, 0.225876, 0.301417, 0.164349, 0.274061, 0.218152, 0.098757, 0.111193, 0.237037, 0.147932, 0.130407, 0.144612, 0.451558, 0.162287, 0.173924, 0.264970, 2.058609, 0.238796, 0.100715, 0.085679, 0.123842, 0.495545, 0.204353, 0.167760, 0.276482, 0.176695, 0.147430, 0.208057, 0.200324, 0.313584, 0.236362, 0.224036, 0.122738, 0.436764, 0.198176, 0.202991, 0.471870, 0.375182, 0.241814, 0.344473, 0.324784, 0.346311, 0.123009, 0.067452, 0.184387, 0.363115, 0.164249, 0.381409, 0.126945, 0.158312, 0.223169, 0.214507, 0.376198, 0.433868, 0.719179, 0.291673, 1.116536, 0.175622, \n",
      "*************** \n",
      "\n",
      "Step 7 | Training Loss: 0.175622 | Test Loss:    nan | Test Accuracy: 0.723607\n",
      "*************** \n",
      "\n",
      "Step 8 | Training Loss: 0.191741, 0.329054, 0.542276, 0.156885, 0.441694, 0.769209, 0.245080, 0.094667, 0.332320, 0.205002, 0.082432, 0.240402, 0.440241, 0.344542, 0.122478, 0.205431, 0.231368, 0.131233, 1.139857, 0.204977, 0.132315, 0.122236, 0.183072, 0.227214, 0.078302, 0.440266, 0.383758, 0.093547, 0.181635, 2.978693, 1.171603, 0.351980, 0.078201, 0.102154, 0.062423, 0.076080, 0.789567, 0.291173, 0.251309, 0.414251, 0.221977, 0.150393, 0.170353, 0.251867, 0.063575, 0.090049, 0.648396, 0.553708, 0.202922, 0.172306, 1.451059, 1.656309, 0.156024, 0.418368, 0.122362, 0.369788, 0.118078, 1.107223, 0.219970, 0.253385, 0.124561, 0.268661, 0.198802, 0.648669, 0.136913, 0.192033, 0.689080, 0.196187, 0.191534, 0.330849, 0.303905, 0.164205, 0.226318, 0.172942, 0.285339, 0.217892, 0.093481, 0.426465, 0.188632, 0.219874, 0.133327, 0.095367, 0.195121, 0.317493, 0.177898, 0.137578, 0.281453, 0.157199, 0.166880, 0.245390, 0.222945, 0.222028, 0.195391, 0.291805, 0.109799, 0.401049, 0.167809, 0.229916, 0.132219, 0.109479, 0.200055, 0.137469, 0.188478, 0.341058, 0.317772, 0.572402, 0.178604, 0.160042, 1.050451, 0.179167, 0.213885, 0.137067, 0.121441, 0.142681, 1.968277, 0.254119, 0.126395, 0.235989, 0.088667, 0.119863, 0.453184, 0.320545, 0.097429, 0.223283, 0.424204, 0.282099, 0.109422, 0.109566, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, \n",
      "*************** \n",
      "\n",
      "Step 8 | Training Loss: nan | Test Loss:    nan | Test Accuracy: 0.569242\n",
      "*************** \n",
      "\n",
      "Step 9 | Training Loss: nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, \n",
      "*************** \n",
      "\n",
      "Step 9 | Training Loss: nan | Test Loss:    nan | Test Accuracy: 0.569242\n",
      "*************** \n",
      "\n",
      "Step 10 | Training Loss: nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, \n",
      "*************** \n",
      "\n",
      "Step 10 | Training Loss: nan | Test Loss:    nan | Test Accuracy: 0.569242\n",
      "*************** \n",
      "\n",
      "Current Layer Attributes - epochs:10 hidden layers:4 features count:4\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 1 | Training Loss: 1.010585, 0.873021, 0.927889, 0.819256, 0.968025, 0.794460, 0.774875, 0.776060, 0.913199, 0.779056, 0.851197, 0.825045, 0.960910, 1.496892, 0.754238, 0.662547, 0.716630, 0.704985, 0.593704, 0.981000, 0.720500, 0.678568, 0.629846, 0.723939, 0.751916, 0.902907, 0.700434, 0.703134, 0.675154, 0.833661, 0.731274, 0.831954, 0.927355, 0.822111, 3.260721, 0.653868, 0.673116, 0.565471, 0.547872, 0.762650, 0.626420, 0.571604, 2.110939, 1.151979, 0.721584, 0.605122, 0.694757, 0.615063, 0.680931, 0.750299, 1.648340, 0.682709, 1.549184, 0.924336, 0.550620, 1.251981, 0.505473, 0.808086, 0.567750, 0.664759, 0.614266, 0.669878, 0.597706, 0.982185, 0.688126, 0.746334, 0.583799, 0.780463, 0.568943, 0.883510, 0.617080, 0.649913, 0.932862, 1.396577, 0.616425, 0.615159, 0.572858, 2.478108, 0.614673, 0.510003, 0.619200, 0.563169, 1.137067, 0.890781, 0.667569, 0.724817, 0.540101, 0.573632, 0.610671, 0.868643, 0.709444, 2.568058, 0.623345, 0.575609, 0.542795, 0.715586, 0.608633, 0.754678, 1.484623, 0.731659, 0.609831, 0.519616, 0.566640, 0.605739, 0.597363, 0.844776, 0.625005, 0.749439, 0.548951, 0.649383, 0.470317, 0.387459, 0.658649, 0.463839, 0.847456, 0.580088, 0.570519, 0.538501, 0.517692, 0.408907, 0.541527, 0.581305, 1.357796, 0.929433, 0.477409, 0.462073, 0.569753, 0.585561, 0.496411, 0.542808, 0.541602, 0.639188, 0.514428, 0.487629, 0.480664, 0.629236, 0.604684, 0.427957, 0.446557, 0.686802, 0.409553, 0.555548, 0.731594, 0.415699, 0.486596, 0.513598, 0.448664, 0.721629, 0.590912, 0.413946, 0.514598, 0.467842, 0.605935, 0.388787, 1.582898, 1.247431, 0.549283, 0.707680, 0.502473, 0.697038, 0.614626, 0.365721, 0.516324, 0.790672, 0.584795, 0.508617, 0.446887, 0.807833, 0.444284, 0.542374, 0.703653, 0.714083, 0.328622, 0.478595, 0.972894, 1.163918, 0.483869, 0.467911, 0.473906, 0.587817, 0.898247, 0.575571, 0.814834, 0.410519, 0.465165, 0.632909, 0.533605, 0.469941, 0.464941, 0.424525, 0.446726, 0.464458, 0.451154, 0.418129, 0.378144, 0.442113, 1.252475, 0.438704, 0.568281, 0.582331, \n",
      "*************** \n",
      "\n",
      "Step 1 | Training Loss: 0.582331 | Test Loss: 1.679448 | Test Accuracy: 0.760025\n",
      "*************** \n",
      "\n",
      "Step 2 | Training Loss: 0.301042, 0.383385, 0.511967, 0.388877, 0.583311, 1.255832, 0.400890, 0.474269, 0.525082, 0.591456, 0.377794, 0.418972, 0.726228, 0.384658, 0.394420, 0.397625, 0.377481, 0.425436, 0.421774, 0.490561, 0.455338, 0.374815, 0.436517, 0.429672, 0.396817, 0.432591, 0.647693, 0.381749, 0.695143, 0.373862, 0.565313, 0.390571, 0.451386, 0.722951, 0.399964, 0.445309, 0.448918, 0.397141, 0.328622, 0.429472, 0.626967, 0.355652, 0.419641, 0.412221, 0.446073, 0.474118, 0.610598, 0.392683, 0.349284, 0.401745, 0.265588, 0.396027, 0.526336, 0.503948, 0.412714, 0.533081, 0.710329, 0.313531, 0.425591, 0.404636, 0.332406, 0.404359, 0.396408, 0.460007, 0.439955, 0.423498, 0.401101, 0.548121, 0.458327, 0.393090, 0.354030, 0.357172, 0.344659, 0.448606, 0.326537, 0.452155, 1.257589, 0.470332, 0.497902, 0.446236, 0.594273, 0.704327, 0.398850, 0.354396, 0.410045, 0.492298, 0.351938, 0.383739, 0.467989, 0.395912, 0.317336, 0.288772, 0.687099, 0.701465, 2.318702, 0.371255, 1.003126, 0.304866, 0.476451, 0.334343, 0.538706, 0.414265, 0.433122, 0.366382, 0.313430, 0.367233, 0.412442, 0.314126, 0.710823, 0.667562, 0.357226, 0.455169, 0.538298, 1.138807, 0.820819, 0.420443, 0.573481, 0.661795, 0.505724, 0.359032, 0.414017, 0.351824, 0.584200, 0.402721, 1.952027, 0.355382, 0.998292, 0.396898, 0.604648, 0.314494, 0.414684, 0.387940, 0.416883, 0.338197, 0.660646, 0.770479, 0.572908, 0.589330, 0.409922, 0.341950, 0.256234, 0.360901, 0.338346, 0.401069, 1.219632, 0.382592, 1.291848, 0.523957, 0.884428, 0.372826, 0.334609, 0.396994, 0.829321, 0.332963, 0.701513, 0.432144, 0.355056, 0.469738, 0.806523, 0.378139, 0.370819, 0.400931, 0.456830, 0.488978, 0.577822, 1.028469, 0.334965, 1.164421, 1.328745, 0.374163, 0.305207, 0.446490, 0.534725, 3.044327, 0.459545, 0.397625, 0.586810, 0.589315, 0.393047, 1.265399, 0.325436, 0.474882, 0.378040, 0.734057, 0.415577, 0.392030, 0.536593, 0.399312, 0.421887, 0.331624, 0.291025, 0.376190, 0.376581, 0.348328, 0.337545, 0.426436, 0.346130, 0.338704, 0.557505, 0.549160, \n",
      "*************** \n",
      "\n",
      "Step 2 | Training Loss: 0.549160 | Test Loss: 1.504035 | Test Accuracy: 0.789079\n",
      "*************** \n",
      "\n",
      "Step 3 | Training Loss: 0.587650, 0.289389, 0.319992, 0.454418, 0.363284, 0.316799, 0.490836, 1.504348, 0.349259, 0.352762, 0.781340, 0.501605, 0.325266, 0.278025, 0.479317, 0.401706, 0.381979, 1.948689, 0.363854, 0.351162, 0.400075, 0.353789, 0.464246, 0.380047, 0.272146, 0.342090, 0.392979, 1.034991, 0.341517, 1.025192, 0.397771, 0.444392, 0.470989, 0.358474, 0.684753, 0.295266, 0.390213, 0.367645, 0.283649, 0.416242, 0.418234, 0.366997, 0.324217, 0.326152, 0.453850, 0.509755, 0.297463, 0.365616, 0.315031, 0.586332, 0.251257, 0.409043, 0.456310, 0.303632, 0.298813, 0.274816, 0.407153, 0.331079, 0.374607, 0.387717, 0.235584, 0.239868, 0.333397, 0.254308, 0.343745, 0.389773, 0.942765, 0.299881, 0.230557, 0.340605, 0.845572, 0.334195, 0.361120, 0.329942, 0.333917, 0.248578, 0.499091, 0.419663, 0.358204, 0.297591, 0.491837, 0.429696, 0.584609, 0.328207, 0.328400, 0.338774, 2.337465, 0.258852, 0.291111, 1.219797, 0.240222, 0.243008, 0.318856, 0.362538, 0.712722, 0.671560, 0.277084, 0.400497, 0.528408, 0.305913, 0.293086, 0.346595, 0.581005, 0.296688, 0.309564, 0.354797, 0.663324, 0.682045, 0.249838, 0.249708, 0.420818, 1.202257, 1.099787, 0.251937, 0.346998, 0.401265, 0.287707, 0.311797, 0.433609, 0.261486, 0.227294, 3.186276, 0.292838, 0.334254, 0.316287, 0.243362, 0.270172, 0.246329, 0.264064, 0.321078, 0.239420, 0.268691, 0.395544, 0.380998, 0.394267, 0.621268, 0.362722, 0.310973, 0.249335, 0.379211, 0.229855, 0.420647, 1.164432, 0.232470, 0.266843, 0.400533, 0.289246, 0.243875, 0.286239, 0.184508, 0.217440, 0.501706, 0.321736, 0.372726, 0.249317, 0.370678, 0.581609, 0.282108, 0.294342, 0.398516, 0.516051, 0.534066, 0.519655, 0.201222, 0.534173, 0.256800, 0.251265, 0.310057, 0.353528, 0.581287, 0.229570, 0.457069, 0.441840, 0.361345, 0.222344, 0.270780, 0.437845, 0.477462, 0.470024, 0.326031, 0.421067, 0.234353, 0.680612, 0.338284, 0.462520, 0.327651, 0.374478, 0.320438, 0.267734, 0.736192, 0.422565, 0.897973, 0.369295, 0.581649, 0.497589, 0.355540, 0.550760, 0.593379, 0.420613, 0.676559, \n",
      "*************** \n",
      "\n",
      "Step 3 | Training Loss: 0.676559 | Test Loss: 1.542640 | Test Accuracy: 0.775994\n",
      "*************** \n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 4 | Training Loss: 0.426678, 0.570461, 1.271139, 0.613242, 0.425549, 0.384362, 0.407461, 0.506358, 0.374807, 0.401268, 0.409038, 0.600450, 0.483382, 0.316156, 0.386801, 0.680761, 0.395486, 0.605254, 0.608718, 0.436818, 0.563431, 0.399457, 0.400765, 0.377137, 0.344410, 0.297104, 0.298713, 0.412406, 0.354524, 0.368223, 0.412930, 0.421899, 0.301667, 0.394089, 0.341837, 0.490594, 0.348024, 0.276231, 0.334165, 0.417639, 0.440506, 0.582388, 0.657275, 0.321523, 0.363614, 0.296154, 0.317820, 0.320326, 0.392409, 0.213835, 0.217500, 0.562856, 0.309918, 0.494136, 1.150005, 0.292866, 0.344847, 0.331685, 0.346844, 0.545349, 1.155499, 0.305531, 0.267022, 0.427756, 1.211382, 0.223538, 0.188394, 2.232603, 0.218232, 0.499745, 0.634984, 0.264210, 0.224479, 0.855361, 0.305462, 0.547114, 0.275121, 0.250468, 0.344161, 0.793068, 0.236126, 0.240522, 0.292166, 0.555884, 0.235352, 0.303117, 0.322673, 0.719176, 0.326141, 0.305898, 0.379114, 1.032209, 0.314737, 0.331845, 0.297334, 0.410995, 0.230523, 0.293917, 0.297455, 0.761876, 0.353521, 0.282039, 0.357757, 0.261996, 1.312668, 0.318753, 0.265463, 0.210629, 0.275200, 0.251926, 1.836300, 0.428505, 0.211664, 0.616221, 0.277967, 0.259953, 0.300244, 1.091106, 0.490092, 0.241989, 0.223827, 0.308170, 0.576125, 0.266131, 0.453407, 0.407030, 0.285692, 0.208807, 0.227514, 0.437485, 0.192578, 0.553230, 0.258121, 0.180070, 0.205406, 0.265019, 0.443715, 0.460614, 0.303833, 0.429540, 0.406679, 1.966562, 0.296085, 0.280843, 0.925259, 0.203238, 0.273809, 0.282057, 0.255038, 0.322604, 0.271100, 0.511679, 0.205135, 0.182827, 0.324940, 0.176952, 0.311373, 0.238715, 0.294010, 0.228249, 0.216770, 0.284749, 0.271892, 0.174970, 0.285034, 1.410239, 0.226045, 0.452476, 0.245800, 0.254429, 0.286548, 0.388086, 1.129167, 0.610358, 0.263192, 0.559757, 0.206592, 0.708483, 0.200559, 0.549749, 0.202883, 0.219413, 0.265378, 1.437335, 0.254206, 0.275388, 0.309462, 0.343214, 0.511650, 0.274749, 0.243117, 0.250404, 0.276741, 0.401423, 0.495806, 0.212205, 0.208427, 0.308285, 0.298064, 0.272944, \n",
      "*************** \n",
      "\n",
      "Step 4 | Training Loss: 0.272944 | Test Loss: 1.486877 | Test Accuracy: 0.792140\n",
      "*************** \n",
      "\n",
      "Step 5 | Training Loss: 0.196620, 0.990039, 1.857789, 0.280080, 0.289440, 0.377387, 0.255891, 0.239503, 0.631734, 0.274178, 0.175234, 0.422768, 1.147896, 0.213272, 0.328988, 0.294912, 0.207011, 0.316815, 0.496498, 0.275533, 0.267164, 0.168185, 0.198908, 0.209335, 0.300405, 0.541942, 0.442185, 0.453148, 0.262648, 0.294598, 0.174911, 0.256843, 0.173632, 0.282097, 0.461363, 0.264720, 0.232802, 0.190824, 0.193321, 0.251401, 0.182507, 0.269384, 0.337093, 0.452779, 0.168239, 0.197901, 1.963953, 0.294079, 0.175528, 3.056958, 0.196418, 0.189016, 0.175261, 0.212968, 0.608835, 0.210107, 0.173937, 0.221554, 0.206479, 0.165086, 0.171575, 0.175040, 0.419677, 0.247109, 0.189477, 0.155178, 0.279399, 0.189498, 1.304726, 0.197943, 0.311291, 0.524408, 0.230144, 0.391682, 1.247452, 0.513492, 0.190952, 0.512176, 0.532249, 0.491602, 0.897263, 0.355647, 0.248645, 0.331191, 0.334393, 0.270707, 0.186542, 0.607122, 0.424544, 0.298440, 0.242816, 0.302402, 0.244055, 0.379924, 1.153504, 0.174570, 0.543796, 0.638395, 0.316536, 0.295213, 0.350040, 0.295092, 0.273563, 0.458760, 0.294287, 0.250323, 0.221698, 0.191055, 0.440859, 0.373180, 0.343549, 2.490759, 0.241731, 0.342352, 0.349725, 0.472596, 0.245063, 0.299832, 0.415968, 0.446084, 0.258260, 0.259706, 0.435337, 0.245904, 0.191862, 0.428745, 0.295459, 0.273540, 0.298817, 0.254688, 1.125364, 0.399175, 0.282121, 0.235685, 0.728699, 0.268592, 0.330631, 0.257506, 0.237625, 0.328498, 0.275771, 0.335562, 1.182972, 0.277904, 0.542961, 0.418427, 0.263788, 0.310512, 0.315894, 0.202952, 0.423109, 0.275799, 0.543852, 0.354546, 0.156158, 0.279007, 0.554577, 0.418035, 0.186708, 0.222435, 0.462773, 0.275061, 0.273887, 0.264725, 0.208888, 0.258465, 0.577852, 0.233816, 0.264154, 0.261626, 0.424448, 0.378359, 0.184431, 0.192326, 0.785837, 0.330648, 0.140475, 0.223878, 0.274000, 0.188294, 0.163293, 0.220835, 0.435874, 0.410469, 0.223658, 0.196042, 0.151599, 0.320129, 0.401621, 0.275929, 0.357357, 0.343634, 0.765798, 0.504146, 0.301281, 0.377136, 1.305944, 0.137913, 0.343380, 0.253654, \n",
      "*************** \n",
      "\n",
      "Step 5 | Training Loss: 0.253654 | Test Loss: 1.541113 | Test Accuracy: 0.802475\n",
      "*************** \n",
      "\n",
      "Step 6 | Training Loss: 0.747303, 0.303085, 0.262352, 0.222681, 0.223731, 0.241117, 0.466395, 0.321325, 0.201654, 0.239870, 0.252757, 0.200607, 0.317827, 3.079473, 0.185027, 0.232972, 0.272108, 0.494251, 0.674637, 0.207194, 0.211653, 0.289559, 0.352108, 0.300890, 0.302871, 0.182309, 0.486405, 0.305271, 0.234703, 0.315017, 0.723883, 0.186143, 0.312344, 0.579617, 0.974440, 0.228780, 0.232919, 0.952790, 0.224895, 1.985084, 0.301190, 0.545596, 0.176225, 0.210408, 0.891715, 0.214946, 0.231943, 0.272825, 0.220375, 0.499114, 0.319559, 0.225817, 0.213742, 0.208315, 0.227830, 0.314310, 0.300522, 0.163305, 0.210965, 0.287621, 0.240539, 0.243821, 0.215030, 0.214856, 0.271560, 0.433346, 0.178711, 0.452737, 0.257006, 0.304100, 0.297046, 0.344738, 0.248850, 0.237885, 0.224048, 0.483015, 0.679583, 0.231464, 0.230211, 0.244994, 0.297927, 0.183744, 0.233357, 0.414815, 0.170163, 0.181206, 0.377447, 0.189818, 1.293866, 0.237725, 0.828103, 0.216154, 0.198043, 0.146900, 0.181113, 0.326201, 0.222142, 0.192377, 0.283544, 0.460572, 1.666963, 0.277704, 0.234270, 0.275793, 0.373174, 0.145647, 0.233330, 0.272253, 0.200224, 0.127117, 0.263982, 0.341275, 0.204363, 0.189271, 0.405383, 0.178522, 0.429980, 0.150699, 0.222893, 0.222849, 0.177480, 1.052740, 0.131375, 0.382088, 0.417987, 0.296883, 0.313956, 0.427421, 0.272187, 0.576246, 0.574327, 0.488431, 0.264126, 0.206910, 0.238274, 0.365727, 0.307837, 0.216272, 0.671525, 0.387601, 0.260273, 0.231429, 0.321495, 0.193603, 0.202074, 0.253545, 0.223310, 1.064817, 0.220383, 0.588168, 0.244968, 0.250618, 0.300408, 0.182091, 0.237594, 0.595252, 0.264052, 0.191597, 0.460243, 0.329720, 0.762389, 0.330099, 0.251576, 0.592623, 1.213272, 0.541651, 0.250157, 0.238463, 0.396396, 0.502296, 0.325668, 0.389725, 0.535147, 0.223496, 0.248859, 0.258604, 0.323410, 0.195135, 0.305312, 0.835745, 0.688165, 0.462656, 0.511874, 0.831699, 0.202250, 0.240111, 0.232070, 0.459725, 0.426165, 0.185598, 0.211131, 0.259337, 0.124894, 0.595220, 0.684512, 0.194450, 0.423558, 0.245105, 0.171053, 0.460920, \n",
      "*************** \n",
      "\n",
      "Step 6 | Training Loss: 0.460920 | Test Loss: 1.578418 | Test Accuracy: 0.787970\n",
      "*************** \n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 7 | Training Loss: 1.284014, 0.280896, 0.336915, 0.299119, 0.179472, 0.342791, 0.627792, 0.218736, 0.179545, 0.227470, 0.199576, 0.207943, 0.145134, 0.421975, 0.300844, 0.351145, 0.236216, 0.206587, 0.258501, 1.131154, 0.273256, 0.265694, 0.129208, 0.183121, 0.700907, 0.168153, 0.198720, 0.254961, 2.405489, 0.223160, 0.145476, 0.338782, 0.165589, 0.210047, 0.325370, 0.199785, 0.342395, 0.155153, 0.192786, 0.642114, 0.131640, 0.155533, 0.455283, 0.301326, 0.226307, 0.121342, 0.259108, 0.371525, 0.183111, 0.184865, 0.180841, 0.202153, 0.505417, 0.246437, 0.192885, 0.241943, 0.143513, 0.211358, 0.145068, 0.165015, 0.157487, 0.137056, 0.385230, 0.246586, 0.162165, 3.042391, 1.214331, 2.667938, 0.224843, 1.160044, 0.268214, 0.279917, 0.221035, 0.293843, 0.273504, 0.339822, 0.240760, 0.258355, 0.525343, 0.161470, 0.255923, 0.228249, 0.987835, 0.274689, 0.924545, 0.328541, 0.179954, 0.414843, 0.327362, 0.499224, 0.220902, 0.679870, 0.350533, 0.346037, 0.408824, 0.301475, 0.342539, 0.372959, 0.400133, 0.226848, 0.203615, 0.394335, 0.328230, 0.188102, 0.203187, 0.593327, 0.509628, 0.492141, 0.347324, 0.184066, 0.267618, 0.309812, 0.224103, 0.237240, 0.215372, 0.168191, 0.262366, 0.200757, 0.207951, 0.360593, 0.278142, 1.124341, 0.598659, 0.233153, 0.436087, 0.613237, 0.179637, 0.182217, 0.262905, 0.183353, 0.200516, 1.177271, 0.225609, 0.198592, 0.192827, 0.349859, 0.482387, 0.308167, 0.512756, 0.300640, 0.231505, 0.231158, 0.234741, 0.278357, 0.221031, 0.232871, 0.396150, 0.235608, 0.273645, 0.133935, 0.499428, 0.300026, 0.769738, 0.233869, 0.187148, 0.395359, 0.290339, 0.206601, 0.377457, 0.744056, 0.262108, 0.291232, 0.208776, 0.147761, 0.261267, 0.326592, 0.297924, 0.342401, 0.261711, 0.273944, 0.994564, 0.610223, 0.369817, 0.307918, 0.447087, 0.352566, 0.318723, 0.293751, 2.330348, 0.247519, 0.399418, 0.268842, 0.216155, 0.176091, 0.248545, 0.344172, 0.199609, 0.322018, 0.624114, 0.273963, 0.191505, 0.246685, 0.293908, 0.203426, 0.279121, 0.366193, 0.230502, 0.183097, 0.191034, 0.791964, \n",
      "*************** \n",
      "\n",
      "Step 7 | Training Loss: 0.791964 | Test Loss: 1.651915 | Test Accuracy: 0.790676\n",
      "*************** \n",
      "\n",
      "Step 8 | Training Loss: 0.237761, 0.662657, 0.414268, 0.207838, 0.253252, 0.330050, 2.570291, 0.437125, 0.202383, 0.277660, 0.298668, 0.513401, 0.298167, 0.257104, 0.258086, 0.198533, 0.259687, 0.192978, 0.246155, 0.208522, 0.419118, 0.253408, 0.203342, 0.401535, 0.333384, 0.190186, 0.546064, 0.243955, 0.288299, 0.369877, 0.230185, 0.284186, 0.298587, 0.559995, 0.183254, 0.246867, 0.131516, 0.327017, 0.171652, 0.482599, 0.336561, 0.226873, 0.206621, 0.408152, 0.273168, 0.170943, 0.320963, 0.278200, 0.241402, 0.806417, 0.422323, 0.239479, 0.294526, 0.170665, 0.345032, 0.376405, 0.261222, 0.156009, 0.363028, 0.139538, 0.178233, 0.220241, 0.192999, 0.465756, 0.207278, 0.281967, 0.307607, 0.271866, 0.256018, 0.286089, 0.442783, 0.477691, 0.288799, 0.377925, 0.216040, 1.247508, 0.367250, 0.181155, 0.318536, 0.196064, 0.147352, 0.175304, 0.275309, 0.157830, 0.328772, 0.229357, 0.392477, 0.388603, 0.480564, 0.253004, 0.272044, 0.290892, 0.257769, 0.403877, 0.325168, 0.383009, 0.245292, 0.519907, 0.221664, 0.194159, 1.079999, 0.259507, 0.247611, 0.429042, 0.580585, 0.229671, 0.351654, 2.210903, 0.303476, 0.476520, 0.228564, 0.194412, 0.313125, 0.452097, 0.381739, 0.277218, 0.214951, 0.198597, 0.219726, 0.201048, 0.779999, 0.169603, 0.213482, 0.236568, 0.312968, 0.257984, 0.497629, 0.223526, 0.408765, 1.179053, 0.199051, 0.300412, 0.362134, 0.492458, 0.221432, 0.148350, 0.216063, 0.199989, 0.171057, 0.196694, 0.145231, 1.266767, 0.207535, 0.808193, 0.191339, 0.550080, 0.249221, 1.307682, 0.194725, 0.204560, 0.180136, 0.159066, 1.163787, 0.186986, 0.198356, 0.243312, 0.135735, 0.128881, 0.365468, 0.171981, 0.311772, 0.260637, 0.170670, 0.275056, 0.330866, 0.275744, 0.197012, 0.287757, 0.336273, 0.854471, 0.412501, 0.220384, 0.218735, 0.268414, 0.138463, 0.209524, 0.301990, 0.137090, 0.158720, 0.212690, 1.721816, 0.156926, 0.421194, 0.445026, 0.370438, 0.155257, 0.393479, 2.961822, 0.962343, 0.163671, 0.150258, 0.191905, 0.203410, 0.341480, 0.294607, 0.287123, 0.249469, 0.902943, 0.255700, 0.450379, \n",
      "*************** \n",
      "\n",
      "Step 8 | Training Loss: 0.450379 | Test Loss: 1.631584 | Test Accuracy: 0.805270\n",
      "*************** \n",
      "\n",
      "Step 9 | Training Loss: 0.206830, 1.106368, 0.903406, 0.252975, 0.136354, 0.218655, 0.210576, 0.187524, 0.390530, 0.582464, 0.236465, 0.366340, 0.281822, 0.174006, 0.201472, 0.188906, 0.144318, 0.185894, 0.214329, 0.281193, 0.152640, 0.256378, 0.271447, 0.266126, 0.229443, 0.284749, 0.265775, 1.636967, 0.186449, 0.174777, 0.289648, 0.160905, 0.240152, 0.308950, 0.434661, 0.488934, 0.254487, 0.184699, 0.201199, 0.251273, 0.427411, 0.227402, 0.183858, 0.565570, 0.152126, 0.272045, 0.185496, 0.865705, 0.173412, 0.324910, 2.105366, 0.374824, 0.565956, 0.258474, 0.263046, 0.513465, 0.259315, 0.182466, 0.193950, 0.322947, 0.158894, 0.158078, 0.233170, 0.718958, 0.367668, 0.171792, 0.609745, 0.368700, 0.230760, 0.240695, 0.441220, 0.194569, 0.303515, 0.208913, 0.286737, 0.276633, 0.346177, 0.178456, 0.738623, 0.218078, 0.214649, 0.564415, 0.184556, 0.230747, 0.417708, 0.163967, 0.383857, 0.382957, 0.327914, 0.218695, 0.225190, 0.747086, 0.141278, 0.231052, 0.204870, 0.218123, 0.624013, 0.156429, 0.178058, 0.325957, 0.156216, 0.158425, 0.241788, 0.185086, 0.193847, 0.138417, 0.188284, 0.132695, 0.208341, 0.226687, 0.312925, 0.447604, 0.286437, 0.174881, 0.169212, 0.303457, 0.238100, 0.307465, 0.480773, 1.143234, 0.363073, 0.482055, 0.191120, 0.174011, 0.225956, 0.347468, 3.956619, 0.339175, 0.255333, 0.197566, 0.196838, 0.302036, 0.255909, 0.371520, 0.191323, 0.367051, 0.283442, 1.362409, 0.192414, 0.706532, 0.237433, 0.178847, 0.222133, 1.156356, 0.272793, 0.278261, 0.440657, 0.343866, 0.186048, 0.889457, 0.386428, 0.259037, 0.450768, 0.358234, 0.281865, 0.190933, 0.533170, 0.414929, 0.199060, 0.619582, 0.780594, 0.549755, 0.362160, 0.172830, 1.189306, 0.416899, 0.408182, 0.170084, 0.281837, 0.264877, 0.177081, 1.160648, 0.167549, 0.997833, 0.313048, 0.557968, 0.676055, 0.438914, 0.272032, 0.313801, 0.184877, 1.009768, 0.227985, 0.309958, 0.281033, 0.270499, 0.514304, 0.294839, 0.313015, 0.217058, 2.040017, 0.247809, 0.186151, 0.276856, 0.318412, 0.202448, 0.270671, 0.227270, 0.195508, 0.394534, \n",
      "*************** \n",
      "\n",
      "Step 9 | Training Loss: 0.394534 | Test Loss: 1.796796 | Test Accuracy: 0.803939\n",
      "*************** \n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 10 | Training Loss: 0.196942, 0.242777, 0.371620, 0.484571, 0.286585, 1.210881, 0.201753, 0.601194, 0.205399, 0.513027, 0.297142, 0.687800, 0.214281, 0.184339, 0.352456, 0.408056, 0.400145, 0.238422, 0.486043, 0.451808, 0.461348, 0.231937, 1.443874, 0.399223, 0.299850, 0.446399, 0.565933, 0.594121, 1.249300, 0.247960, 0.363531, 0.312446, 1.210557, 0.818098, 0.342925, 0.515668, 0.379598, 0.363786, 0.458961, 0.362322, 0.360760, 0.720734, 0.494208, 0.459615, 0.809084, 0.525125, 0.305241, 0.529521, 0.432513, 0.233253, 0.562416, 0.380710, 0.272739, 0.473156, 0.300758, 0.744366, 0.401827, 0.679898, 0.382149, 0.350922, 0.908290, 0.315777, 0.317555, 0.294973, 0.298205, 0.383620, 0.815104, 0.288941, 0.434753, 0.319019, 0.234674, 0.214740, 0.544802, 0.252505, 0.473891, 0.372662, 0.510168, 0.237725, 0.388155, 0.233898, 0.500984, 0.229192, 0.437272, 0.637654, 0.246890, 0.405914, 0.425421, 0.384151, 0.276922, 0.341131, 0.303877, 0.289736, 0.330204, 0.247630, 0.257709, 0.345848, 0.262049, 0.309976, 0.295287, 0.212546, 0.375990, 0.474754, 0.295505, 0.282675, 0.525460, 0.353506, 0.305721, 0.512045, 0.164927, 0.223447, 0.191855, 0.306312, 0.212268, 0.411468, 0.339040, 0.442211, 0.282909, 0.501789, 0.356641, 2.387697, 2.046834, 0.334552, 0.218410, 0.228871, 0.423225, 0.271249, 0.483477, 0.202138, 0.190092, 0.272069, 2.307529, 0.473903, 0.396092, 0.132707, 0.253679, 0.351279, 0.375395, 0.254877, 0.159065, 0.386590, 0.284579, 0.198335, 0.252380, 0.408947, 0.259364, 0.210004, 0.339028, 0.268913, 0.432520, 0.262601, 0.392835, 0.153982, 0.368555, 0.155902, 0.391604, 0.193622, 0.284109, 0.199683, 0.184464, 0.241558, 0.202974, 1.094030, 0.692710, 0.293912, 0.178082, 0.122483, 0.178774, 0.323862, 0.182835, 1.300824, 0.861184, 0.442571, 0.620180, 0.193412, 0.275206, 0.225753, 0.217688, 0.245035, 0.168051, 0.419342, 0.217460, 0.431991, 2.871309, 0.122689, 1.055765, 0.178524, 0.403788, 0.164936, 0.275127, 0.174562, 0.252646, 0.459632, 0.397612, 0.318863, 0.317948, 0.204229, 0.181919, 0.256676, 0.220867, 0.245513, \n",
      "*************** \n",
      "\n",
      "Step 10 | Training Loss: 0.245513 | Test Loss: 1.851914 | Test Accuracy: 0.781804\n",
      "*************** \n",
      "\n",
      "Current Layer Attributes - epochs:10 hidden layers:4 features count:8\n",
      "Step 1 | Training Loss: 1.392380, 1.006950, 0.782809, 0.859454, 0.943681, 0.754631, 0.963827, 0.784681, 1.821492, 0.938938, 0.873639, 0.800059, 0.876776, 0.966081, 0.778635, 0.751593, 0.704983, 0.735237, 1.329664, 0.955905, 1.590717, 0.959144, 0.728056, 1.148006, 0.629969, 0.810685, 0.809122, 0.868715, 0.866071, 0.657900, 0.717117, 0.583928, 0.575463, 0.692653, 0.688053, 0.647605, 0.861450, 0.812455, 0.716882, 1.289709, 0.669173, 0.642498, 0.560931, 0.809161, 0.867814, 0.616561, 0.590587, 0.628887, 0.837673, 0.653918, 0.684989, 0.615720, 0.660303, 0.800052, 0.581092, 0.566017, 0.553108, 0.555448, 0.658964, 1.448419, 0.648465, 1.495732, 0.716744, 0.945774, 0.716033, 0.557012, 0.806034, 0.647218, 0.534182, 0.550819, 0.556640, 0.670671, 0.564239, 0.619699, 0.636213, 0.574531, 0.817725, 0.722852, 0.660296, 0.490919, 0.693755, 0.951744, 0.763729, 0.783251, 0.510323, 0.723527, 0.725630, 0.501613, 0.551769, 0.644384, 0.691339, 0.688966, 0.610027, 0.783419, 0.893175, 0.620151, 0.570834, 0.543424, 0.516736, 0.784555, 0.533907, 0.570094, 0.639326, 0.562078, 0.685427, 0.670102, 0.504618, 1.620788, 0.742113, 0.582533, 0.539756, 0.798786, 0.602151, 0.456006, 0.431697, 0.657114, 0.554107, 0.613038, 0.539331, 0.520667, 0.529356, 0.622656, 0.427976, 0.615868, 0.494150, 0.627496, 0.689067, 0.554527, 1.698467, 0.786148, 0.603145, 0.582449, 0.691104, 4.850925, 0.600934, 0.570301, 0.697589, 1.462016, 0.387574, 0.505103, 0.574619, 1.139728, 0.384402, 1.131464, 0.479735, 0.469605, 0.502841, 0.504394, 0.527944, 0.585973, 0.400794, 0.648221, 0.469905, 0.527152, 2.061822, 0.452471, 0.413605, 1.167557, 0.410613, 0.523210, 0.496348, 0.671571, 0.588618, 0.696673, 0.465553, 0.472488, 0.403911, 0.519938, 0.528071, 0.473237, 0.560197, 0.682638, 0.481167, 0.574652, 0.709465, 1.533372, 0.726076, 0.395506, 0.430309, 0.430383, 0.426089, 0.594478, 0.406954, 0.602540, 0.398661, 0.479107, 0.441169, 0.477432, 0.611919, 0.804655, 0.404349, 2.657581, 0.507587, 0.446787, 0.427984, 0.451024, 0.432213, 0.478799, 0.379212, 1.339769, \n",
      "*************** \n",
      "\n",
      "Step 1 | Training Loss: 1.339769 | Test Loss: 1.672934 | Test Accuracy: 0.765614\n",
      "*************** \n",
      "\n",
      "Step 2 | Training Loss: 0.643162, 0.715801, 0.468471, 0.398157, 0.386613, 0.617555, 0.490660, 0.571530, 0.454535, 0.671796, 0.940901, 0.498254, 1.402839, 0.405877, 0.361275, 0.421934, 0.707241, 0.417414, 0.563014, 0.471726, 0.464485, 0.425701, 0.544288, 0.380216, 2.264151, 0.372172, 0.618359, 0.858608, 0.342717, 0.396010, 0.389705, 0.503864, 0.428768, 0.336448, 0.858743, 0.781872, 0.646020, 0.432767, 0.531674, 0.488411, 0.622216, 0.336643, 0.524452, 0.704704, 0.536194, 0.356003, 0.392615, 0.402039, 0.455159, 0.535383, 0.445151, 0.515366, 0.292154, 0.443304, 2.440676, 0.582226, 0.299026, 0.380388, 0.360252, 0.411497, 1.234852, 0.323023, 0.436062, 0.432906, 0.411510, 0.465787, 1.251666, 0.396556, 0.462751, 0.298534, 0.424652, 0.422089, 0.312407, 0.353669, 0.466295, 0.358794, 0.370573, 0.526013, 1.009803, 0.720193, 0.439419, 1.249147, 0.404340, 0.768724, 0.411985, 0.428288, 0.574428, 0.666116, 0.447057, 0.376971, 0.571225, 0.551173, 0.342815, 0.304944, 0.419121, 0.640818, 0.324109, 0.548227, 0.330376, 0.404888, 0.440418, 0.308068, 0.280894, 0.607260, 0.357177, 0.412220, 0.309445, 0.407515, 0.294720, 0.431665, 0.315591, 0.360439, 0.413344, 0.309445, 0.328522, 1.345742, 0.325890, 0.631118, 0.270870, 0.330353, 0.341223, 0.390052, 0.318696, 0.343192, 0.417355, 0.677794, 0.353029, 0.269518, 0.352051, 0.332709, 0.395681, 0.357017, 0.343381, 0.267234, 0.615832, 1.282994, 0.361937, 1.263141, 0.421494, 0.440184, 0.367447, 0.302413, 0.375983, 0.409575, 0.578310, 0.404067, 0.440315, 0.285746, 0.345838, 0.311900, 0.327108, 0.497336, 1.222979, 0.366619, 0.286960, 0.500026, 0.507787, 0.345716, 0.251476, 0.418836, 0.361338, 0.254410, 0.258886, 0.428644, 0.283529, 0.384945, 0.295530, 2.995490, 0.416618, 0.271627, 0.243145, 0.415476, 0.472190, 0.357612, 0.286889, 0.622378, 0.277527, 0.380884, 0.436615, 1.263111, 0.469423, 0.353387, 0.312110, 0.309768, 0.278754, 0.344289, 0.383346, 0.302493, 0.302854, 0.503952, 0.389840, 0.292543, 0.324089, 0.222658, 0.547133, 0.304128, 0.349027, 0.406243, 1.449035, 0.291167, \n",
      "*************** \n",
      "\n",
      "Step 2 | Training Loss: 0.291167 | Test Loss: 1.569818 | Test Accuracy: 0.791386\n",
      "*************** \n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 3 | Training Loss: 1.301746, 0.333846, 0.327603, 0.237182, 0.306569, 0.279673, 0.280648, 0.310594, 0.370365, 0.302818, 0.501042, 0.332950, 0.297992, 1.291276, 0.267123, 0.366375, 0.486711, 1.387494, 0.610307, 0.326221, 0.264636, 0.264857, 0.280310, 1.412929, 0.315591, 0.275488, 0.270812, 0.282386, 0.298821, 0.373879, 0.388874, 0.368486, 3.035858, 0.388566, 0.432029, 0.313149, 0.557335, 0.301287, 0.266842, 0.251787, 0.343480, 0.364180, 0.269101, 0.542767, 0.266930, 0.311229, 0.258674, 0.258134, 0.448516, 0.339929, 0.230357, 0.431208, 0.307922, 0.336037, 0.552736, 0.343848, 0.308719, 0.301512, 0.628487, 0.259101, 0.319872, 0.260678, 0.367629, 0.309097, 0.236542, 0.353789, 0.246128, 0.279821, 0.245177, 0.331952, 0.277813, 0.220487, 0.221625, 0.508501, 0.344641, 0.232820, 0.352005, 0.387532, 0.248351, 0.295182, 0.207682, 0.228119, 0.308145, 0.259613, 0.251074, 0.267337, 0.257126, 0.219037, 0.259944, 0.251562, 0.294741, 0.238735, 0.411902, 1.842089, 0.251607, 0.277863, 0.376996, 0.395805, 0.231859, 0.498053, 0.480605, 0.321060, 0.231486, 0.531088, 0.332997, 0.806685, 0.389005, 0.438522, 0.504184, 0.246135, 0.329992, 0.262266, 0.379563, 0.429546, 0.299027, 0.272932, 0.239664, 0.284669, 0.281369, 0.226494, 0.878388, 0.269545, 0.252151, 0.229515, 0.394196, 2.036915, 0.467154, 0.188950, 0.533628, 2.156847, 0.285551, 0.590398, 0.331888, 0.206060, 0.333988, 0.262976, 0.580903, 0.450531, 0.699681, 0.350894, 0.646593, 0.439919, 0.398798, 1.133411, 0.590177, 0.266475, 0.231989, 0.383025, 0.264200, 0.335064, 0.282468, 0.221508, 0.312939, 0.220394, 0.929525, 0.522380, 0.230973, 0.286634, 0.269181, 0.245580, 0.392272, 1.094874, 0.269073, 1.178388, 0.297476, 0.263860, 0.275817, 0.582630, 0.777012, 0.294951, 0.337888, 0.572040, 0.260157, 0.524039, 0.749632, 0.385923, 0.792559, 0.318951, 0.215430, 0.354876, 0.391745, 0.490797, 0.270427, 0.260118, 0.298270, 0.413544, 0.371330, 0.213839, 0.244080, 0.234714, 0.383323, 0.445499, 0.253438, 1.485542, 0.335432, 0.236700, 0.267584, 0.279879, 0.904461, 0.202031, \n",
      "*************** \n",
      "\n",
      "Step 3 | Training Loss: 0.202031 | Test Loss: 1.291127 | Test Accuracy: 0.796531\n",
      "*************** \n",
      "\n",
      "Step 4 | Training Loss: 0.403919, 0.282227, 0.417513, 0.260832, 0.234125, 0.293707, 0.312401, 0.489766, 0.591580, 0.313804, 0.288849, 0.254187, 0.208377, 0.424399, 0.319578, 0.199085, 0.242419, 0.224247, 0.309634, 0.215229, 0.475211, 0.633614, 0.242153, 0.168056, 0.234923, 0.235653, 0.243601, 0.321601, 0.244390, 0.223765, 0.225640, 0.218963, 0.347679, 0.323033, 0.211361, 0.211008, 0.208818, 0.225573, 0.369379, 0.743760, 0.343318, 0.284098, 1.160882, 0.215699, 0.242212, 0.165726, 0.197978, 0.217858, 0.340960, 0.421835, 0.237594, 0.215295, 0.493260, 0.164868, 0.190138, 0.245755, 0.267264, 0.246110, 0.273744, 0.217103, 0.356065, 0.168761, 0.197715, 0.225731, 0.291323, 0.311359, 0.223947, 0.362658, 0.198038, 0.188216, 0.323485, 0.285663, 0.288167, 0.475816, 0.538053, 0.189908, 0.388444, 0.984764, 0.232842, 0.216741, 0.208043, 0.258515, 0.244843, 0.218739, 0.187326, 0.475520, 0.195285, 0.450287, 0.207789, 0.255969, 0.392179, 0.264722, 0.179375, 0.184322, 0.232613, 0.498297, 0.255530, 0.200622, 0.245419, 1.726657, 0.323088, 0.168907, 0.183624, 0.146348, 0.389649, 0.182654, 0.206869, 0.178994, 0.284911, 0.285187, 0.301045, 0.256214, 0.208167, 0.251372, 0.316632, 0.241815, 0.272568, 1.026799, 0.268253, 2.421875, 0.311286, 0.270659, 0.301482, 0.237591, 0.330619, 2.954484, 0.244615, 1.266063, 0.292801, 0.336529, 0.240648, 0.245557, 0.204100, 0.191970, 0.549440, 0.361311, 0.238951, 0.463920, 0.189154, 0.595949, 0.847904, 0.219523, 0.264565, 0.242639, 0.316497, 0.314050, 0.373282, 0.176555, 0.199713, 1.936266, 0.223435, 0.324068, 0.495613, 0.475044, 0.500328, 0.381590, 0.671967, 0.241203, 0.340251, 0.278520, 0.469526, 0.229883, 0.379622, 0.268558, 0.256521, 0.220106, 0.254037, 0.330600, 0.238651, 0.175705, 0.221799, 0.167020, 0.234303, 0.316841, 0.374260, 0.185222, 0.660513, 0.253651, 0.298981, 0.193350, 0.510041, 1.129905, 0.313919, 0.481131, 0.230481, 0.478925, 0.231940, 0.307126, 1.711266, 0.333024, 0.212069, 0.520032, 0.270607, 0.253124, 0.175517, 0.183515, 0.201349, 0.161022, 2.122367, 0.296252, \n",
      "*************** \n",
      "\n",
      "Step 4 | Training Loss: 0.296252 | Test Loss: 1.296679 | Test Accuracy: 0.767433\n",
      "*************** \n",
      "\n",
      "Step 5 | Training Loss: 0.166025, 0.238097, 0.250439, 0.193978, 0.551924, 0.226776, 0.249566, 0.183798, 0.487852, 0.289713, 0.579241, 0.248765, 1.947144, 0.242583, 0.556876, 0.184140, 0.239639, 0.254369, 0.198269, 0.185438, 0.359002, 0.253838, 0.206746, 0.200461, 0.197081, 0.571343, 0.248152, 0.406006, 0.293423, 0.274951, 0.232075, 1.084012, 1.237584, 0.273593, 0.280257, 0.328841, 0.488507, 0.172785, 0.157791, 0.235012, 0.263453, 0.194860, 0.164453, 0.217814, 0.542436, 0.782769, 0.252765, 0.235844, 0.236253, 0.362738, 6.453408, 0.581700, 0.377092, 2.695925, 0.382700, 0.560096, 0.472822, 0.496435, 0.410536, 0.443181, 0.568981, 0.505138, 0.359954, 0.407139, 0.463389, 0.520858, 0.494581, 0.437379, 0.400707, 0.668176, 0.412242, 0.554234, 0.379731, 0.375940, 0.647822, 0.525709, 0.349847, 0.360086, 0.344149, 1.211444, 0.743552, 0.763296, 0.333720, 0.673082, 0.392632, 0.384696, 0.540183, 0.296255, 0.408990, 0.699044, 0.385103, 0.342537, 0.316331, 0.370268, 0.476167, 0.397722, 0.272862, 0.302004, 0.366789, 0.786319, 0.227067, 0.398585, 0.346390, 0.315305, 0.518463, 0.329599, 0.377172, 0.468049, 1.270548, 0.322285, 0.429598, 0.549072, 0.295120, 0.364688, 0.328111, 0.273610, 0.542274, 0.871970, 0.262173, 0.391802, 0.560780, 0.199648, 0.254610, 0.318538, 0.275670, 0.708732, 0.489785, 0.231240, 0.209761, 0.655780, 0.343794, 0.428878, 0.334761, 0.620836, 0.322410, 0.264972, 0.275795, 1.199120, 0.182765, 0.248184, 0.925141, 0.296891, 0.243383, 0.198999, 0.273106, 0.207816, 0.561810, 0.332579, 0.246148, 0.308845, 0.354262, 0.489906, 0.200879, 0.365538, 0.372700, 0.202188, 0.245127, 0.255744, 0.199109, 0.375263, 0.251578, 0.215807, 0.359090, 0.528423, 0.293593, 0.310585, 0.184700, 0.276632, 0.292590, 0.278566, 0.278255, 0.225119, 0.219510, 0.194431, 0.318029, 0.219927, 1.195153, 0.210477, 0.226052, 0.612626, 0.259345, 0.255342, 0.272318, 0.313409, 0.502718, 2.026696, 0.225960, 0.364303, 0.202846, 0.242195, 0.131047, 0.278179, 0.270904, 1.274240, 0.167997, 1.145478, 0.211416, 0.282047, 0.304405, 0.237882, \n",
      "*************** \n",
      "\n",
      "Step 5 | Training Loss: 0.237882 | Test Loss: 1.281201 | Test Accuracy: 0.774663\n",
      "*************** \n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 6 | Training Loss: 0.281873, 0.176509, 0.205587, 0.174912, 0.175995, 0.189863, 0.208656, 0.231763, 0.259788, 0.290866, 0.255049, 0.332014, 0.184831, 0.194268, 0.313269, 0.161504, 0.209709, 0.470162, 0.247318, 0.310289, 0.244861, 0.169151, 0.589548, 0.417939, 0.208600, 1.210214, 0.249679, 0.226650, 0.197305, 0.157061, 0.447188, 0.329680, 0.399617, 0.516951, 0.617009, 0.353573, 0.538702, 0.226259, 0.280164, 0.412624, 1.939012, 0.202281, 0.205672, 0.328984, 0.271387, 0.381550, 0.502303, 0.200721, 0.211182, 0.299166, 0.331835, 0.210206, 0.487436, 0.843552, 0.134431, 0.261936, 0.182672, 0.300188, 0.423598, 0.219427, 0.315790, 0.154474, 0.314803, 0.223396, 0.255057, 0.230347, 0.255846, 0.548379, 1.116077, 0.576051, 0.323246, 0.554728, 0.225454, 0.260197, 0.335976, 0.301416, 3.794763, 0.605549, 0.376429, 0.297818, 0.776875, 0.429411, 0.463282, 0.459426, 0.397784, 0.527331, 0.415086, 0.646701, 0.603668, 1.440183, 0.736364, 0.766336, 1.429247, 1.300931, 0.580173, 0.625622, 0.702199, 0.640567, 0.540020, 0.850100, 0.659853, 0.694966, 2.430462, 0.603117, 0.683186, 0.674886, 0.821991, 0.606698, 0.677368, 0.565848, 0.699127, 1.470225, 0.541810, 0.577639, 0.711745, 0.623325, 0.545880, 0.577244, 0.567346, 0.697010, 0.678408, 0.775537, 1.038991, 0.527841, 0.607558, 0.576147, 0.580537, 0.655020, 0.926219, 0.439274, 0.568493, 0.626182, 3.254995, 0.480711, 0.451306, 0.549928, 0.843788, 0.583166, 0.888935, 0.637732, 0.570841, 0.435477, 0.480253, 0.648265, 0.704524, 0.545540, 0.531519, 0.682095, 0.445493, 0.659814, 1.169563, 0.481932, 0.494211, 0.627426, 0.875284, 0.495552, 0.918506, 1.367272, 0.526138, 0.499752, 0.648698, 0.603337, 0.425008, 0.538622, 0.689022, 0.727340, 0.626719, 0.698382, 0.514544, 0.537121, 0.633655, 0.889770, 0.428638, 0.651450, 0.680854, 0.387067, 0.387528, 0.520737, 0.457969, 0.533091, 0.591516, 0.579892, 0.462520, 0.492970, 0.596559, 2.298337, 0.663258, 0.527994, 0.649557, 0.540696, 0.489128, 1.710718, 0.397213, 0.539193, 0.511736, 0.754268, 0.469767, 0.440585, 1.244934, 0.702058, \n",
      "*************** \n",
      "\n",
      "Step 6 | Training Loss: 0.702058 | Test Loss: 1.742644 | Test Accuracy: 0.811081\n",
      "*************** \n",
      "\n",
      "Step 7 | Training Loss: 0.487026, 0.526057, 1.441480, 0.615336, 0.744181, 0.542495, 0.466205, 0.535005, 0.596503, 0.526901, 0.427589, 1.375360, 0.527991, 0.567302, 0.540667, 0.541798, 0.803458, 0.483216, 0.536368, 0.475470, 0.486072, 0.638347, 0.460049, 0.494146, 0.446759, 0.514051, 0.469627, 0.399210, 0.435647, 0.484636, 0.611480, 0.540460, 0.723765, 0.397374, 0.563478, 0.380505, 0.504994, 0.488185, 1.412933, 0.444365, 0.616618, 0.440522, 0.936064, 0.595344, 0.382047, 0.390017, 0.924199, 1.369943, 2.435345, 0.547346, 0.454155, 0.451556, 0.542932, 0.484290, 0.559557, 0.617503, 0.380011, 0.441282, 0.553535, 0.369225, 0.490112, 0.705334, 0.677251, 0.365079, 1.066023, 0.528375, 0.464072, 0.457314, 0.369016, 0.456856, 0.412091, 0.453425, 0.497009, 0.518770, 0.470191, 0.398738, 2.004189, 0.501213, 0.585784, 0.466475, 0.426330, 0.423337, 0.510898, 0.827242, 0.515963, 0.773162, 0.682447, 0.480141, 0.471637, 0.468098, 0.404911, 0.490675, 0.826940, 0.422787, 0.350598, 0.588117, 0.465992, 0.458507, 0.525491, 0.332462, 0.638858, 0.973120, 0.394800, 0.457961, 0.516218, 0.507741, 0.472914, 0.602460, 0.485640, 0.383575, 0.589011, 0.355021, 0.431347, 0.501942, 0.369688, 0.481154, 0.644519, 0.408350, 0.555101, 0.421305, 0.423823, 0.429620, 0.819073, 3.086055, 0.384041, 0.755802, 0.476156, 0.466682, 0.401251, 0.488637, 1.916884, 0.632999, 0.954735, 0.466490, 0.448888, 1.034441, 0.408404, 0.648174, 0.438350, 0.481157, 0.396991, 0.740436, 0.552293, 0.323062, 0.406924, 0.728938, 0.343227, 0.535205, 0.342787, 0.413273, 0.588256, 0.489868, 0.500927, 0.437417, 0.519359, 0.463868, 0.427306, 1.250640, 2.309656, 0.407277, 0.590117, 1.423774, 0.380450, 0.338297, 0.339683, 0.344405, 0.441607, 0.507351, 0.436376, 0.725770, 0.423352, 0.555160, 0.488967, 0.451478, 0.535012, 0.456410, 0.662002, 0.422936, 0.381054, 1.424942, 0.342528, 0.459435, 0.467835, 0.425400, 0.380122, 0.461068, 0.389072, 0.316674, 0.405039, 0.633815, 0.404266, 0.419577, 0.377954, 0.412154, 0.395901, 0.331529, 0.352267, 0.622409, 0.506715, 0.616470, \n",
      "*************** \n",
      "\n",
      "Step 7 | Training Loss: 0.616470 | Test Loss: 1.706938 | Test Accuracy: 0.778034\n",
      "*************** \n",
      "\n",
      "Step 8 | Training Loss: 0.547242, 0.388608, 0.384226, 0.644012, 0.542068, 1.330042, 0.911967, 0.369609, 0.416195, 0.333601, 0.431030, 0.430658, 0.316224, 0.418452, 0.526879, 0.565220, 0.428011, 0.408267, 0.372593, 0.395726, 0.365936, 0.298519, 0.399887, 0.337981, 0.516731, 0.752573, 0.582661, 0.335048, 0.434508, 0.328762, 0.326845, 0.461567, 0.457024, 1.254494, 0.970632, 0.492661, 0.343981, 0.343921, 0.436577, 0.495478, 0.551978, 0.450094, 0.531408, 0.945502, 0.657116, 0.441494, 0.528236, 0.398948, 1.912294, 0.421541, 0.395699, 0.416444, 0.479892, 0.762755, 0.488622, 0.340762, 0.560619, 0.442378, 0.494349, 0.514784, 0.569249, 0.454603, 0.371999, 0.335939, 0.410505, 0.696690, 0.454928, 0.343327, 0.511460, 0.348912, 0.441613, 0.485464, 0.380289, 0.417545, 2.178971, 0.467184, 0.347822, 0.552517, 0.299095, 0.515260, 0.301512, 0.441671, 0.838446, 0.507005, 0.513656, 0.508965, 0.514804, 0.405528, 0.649701, 0.336209, 0.411945, 0.434328, 0.441142, 0.739449, 0.415465, 0.679977, 0.443203, 0.382452, 0.398825, 0.383227, 0.381373, 0.431269, 0.489727, 0.592997, 0.444252, 0.327924, 0.299769, 0.354116, 0.428441, 0.382114, 0.496713, 0.398266, 1.295880, 0.330486, 0.377081, 0.337175, 1.551410, 0.475254, 0.414136, 0.277121, 0.385878, 0.396280, 0.401643, 0.332546, 0.526087, 0.575598, 0.468233, 0.404008, 0.357303, 0.541533, 0.415908, 0.285033, 0.937462, 0.475086, 0.582861, 0.359882, 0.502587, 0.323260, 0.289885, 0.399533, 0.614827, 0.424187, 1.285291, 0.398940, 0.395482, 0.429175, 0.702421, 0.534469, 0.341807, 0.400419, 0.478161, 0.323150, 0.545955, 0.377550, 0.499524, 1.233816, 0.546708, 0.763020, 0.409406, 0.917971, 0.360996, 0.678051, 0.394834, 0.376906, 0.396658, 0.601350, 0.760094, 0.360868, 0.398421, 0.549156, 2.605765, 0.864226, 0.414051, 0.395359, 3.167905, 0.484985, 0.417052, 0.261636, 0.395488, 0.442192, 0.505313, 0.292481, 0.479514, 0.407777, 0.436982, 0.655175, 0.322807, 0.442513, 0.447698, 0.627075, 0.745191, 0.382949, 0.614852, 0.346790, 0.739982, 0.545819, 0.438744, 0.937204, 0.547981, 0.446521, \n",
      "*************** \n",
      "\n",
      "Step 8 | Training Loss: 0.446521 | Test Loss: 1.682739 | Test Accuracy: 0.760823\n",
      "*************** \n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 9 | Training Loss: 0.410772, 1.367199, 0.323332, 0.901875, 0.320048, 0.356600, 0.579638, 0.349522, 0.620798, 0.300907, 0.261979, 0.475548, 0.341922, 0.645831, 0.453497, 0.341138, 0.326531, 0.340459, 0.345459, 0.338066, 0.556152, 0.317153, 0.492468, 0.635856, 0.461838, 0.816562, 0.305428, 0.410815, 0.447127, 0.345446, 0.506097, 0.808923, 0.336949, 1.056345, 0.362320, 0.397829, 0.684248, 0.538260, 0.324100, 0.531252, 0.380577, 0.393976, 0.488858, 0.264470, 0.437909, 0.366119, 0.372647, 0.480933, 0.417664, 0.349706, 0.329923, 0.548334, 0.576809, 0.428409, 0.498841, 0.476949, 0.413239, 0.750555, 0.676764, 0.360095, 0.366732, 0.661987, 0.295437, 0.358333, 0.413464, 0.622541, 0.541478, 0.266286, 0.414202, 0.362219, 0.821312, 0.579511, 0.516133, 0.456386, 0.522253, 0.435707, 0.440386, 0.410377, 0.435154, 0.504981, 0.413256, 0.614060, 0.624517, 0.349253, 0.287337, 1.199201, 0.344524, 0.491004, 0.455175, 0.421413, 0.386376, 0.330121, 0.364903, 0.468511, 0.358866, 0.385290, 0.402815, 0.753113, 1.826580, 0.343421, 0.302391, 0.454942, 2.069772, 0.318377, 0.405691, 0.403715, 0.760350, 1.102658, 0.437966, 0.503130, 0.453169, 0.883338, 0.467716, 0.270360, 0.662455, 0.345003, 0.558902, 0.411247, 0.362639, 0.499890, 0.588578, 0.501943, 0.334434, 0.498724, 0.360397, 0.322164, 0.456582, 1.186736, 0.569431, 0.384203, 0.458739, 0.485664, 0.368451, 0.341096, 0.447341, 1.240590, 0.461883, 0.627047, 0.640287, 0.565006, 0.332506, 0.317934, 0.435663, 0.368836, 0.363733, 0.389510, 0.418864, 0.460628, 0.335228, 0.650139, 0.379574, 0.545093, 1.348752, 0.356901, 0.255165, 0.413911, 0.432244, 0.342013, 0.311608, 0.360296, 0.343049, 0.330834, 0.613339, 0.873793, 1.169812, 0.277229, 0.519767, 0.642405, 0.336822, 0.307914, 0.297917, 0.433768, 0.352106, 0.484569, 0.317524, 0.366967, 0.441193, 0.378502, 0.452126, 0.351026, 0.596946, 1.103889, 0.467164, 0.694914, 0.628988, 0.679670, 0.340832, 0.559830, 0.311288, 0.367030, 0.665583, 0.442800, 0.426814, 0.454089, 0.622069, 1.194989, 3.148867, 0.584275, 0.532547, 0.305712, \n",
      "*************** \n",
      "\n",
      "Step 9 | Training Loss: 0.305712 | Test Loss: 1.662695 | Test Accuracy: 0.773199\n",
      "*************** \n",
      "\n",
      "Step 10 | Training Loss: 0.303746, 0.463928, 0.341033, 0.445367, 0.576973, 0.295863, 0.451609, 0.383776, 0.377848, 0.494200, 0.336216, 0.477252, 0.275188, 0.297193, 0.351132, 0.678013, 0.523794, 0.433752, 0.333153, 0.473674, 0.390034, 0.360729, 0.364799, 0.515366, 0.430347, 0.641192, 0.417407, 0.375572, 1.000914, 0.687676, 0.321363, 0.341141, 0.406837, 0.611593, 0.641712, 0.568548, 0.698109, 0.533846, 0.463025, 0.563897, 0.463061, 0.371975, 0.838873, 0.335128, 1.284932, 0.501342, 0.253123, 0.408410, 0.317769, 0.610565, 0.365210, 0.353854, 0.313420, 0.547356, 2.313484, 1.498161, 0.401924, 0.406508, 0.367875, 0.342042, 0.550161, 0.487908, 1.507968, 0.414918, 0.363960, 0.409838, 1.097171, 0.312212, 0.331909, 0.451879, 0.421480, 0.363052, 0.552963, 0.735912, 0.633612, 0.642953, 0.339225, 0.338273, 0.416480, 0.438007, 0.450683, 0.952373, 0.534060, 0.315936, 0.380075, 0.918857, 1.855895, 0.349805, 0.337772, 0.446123, 0.420461, 0.345815, 0.320827, 0.303385, 0.279967, 0.385998, 0.619753, 0.432859, 0.277769, 0.359744, 0.377196, 0.383759, 0.381740, 0.339788, 3.140902, 0.429423, 0.545578, 0.403769, 0.599717, 0.339739, 2.429381, 0.337426, 0.486245, 0.508886, 0.352322, 0.439104, 0.322927, 0.330327, 0.641050, 0.319633, 0.427504, 0.448202, 0.940653, 0.496646, 0.338743, 0.411825, 0.451466, 0.395195, 0.329379, 0.440564, 0.462948, 0.338695, 0.539055, 0.701338, 0.490011, 0.732410, 0.577612, 0.371808, 1.341073, 0.965767, 0.990161, 0.497863, 0.591340, 0.320803, 0.493769, 0.474623, 0.306369, 1.272729, 0.373112, 0.490445, 0.439947, 0.568368, 0.333538, 0.404336, 0.559898, 0.455836, 0.555739, 0.352193, 0.245995, 0.467122, 0.332063, 0.466734, 0.338899, 0.409276, 0.357724, 0.393023, 0.531218, 0.561318, 0.569563, 0.526997, 0.242933, 0.542466, 0.417781, 0.434297, 0.298864, 0.335587, 0.226536, 0.331172, 0.425386, 0.467416, 0.391007, 0.475103, 0.363727, 0.437457, 0.604107, 0.284832, 0.437525, 0.426721, 1.306011, 0.391405, 0.449234, 0.449606, 0.305447, 0.428609, 1.082523, 0.393311, 0.307053, 0.479940, 0.749602, 0.372929, \n",
      "*************** \n",
      "\n",
      "Step 10 | Training Loss: 0.372929 | Test Loss: 1.657781 | Test Accuracy: 0.769739\n",
      "*************** \n",
      "\n",
      "Current Layer Attributes - epochs:10 hidden layers:4 features count:16\n",
      "Step 1 | Training Loss: 0.820175, 0.825248, 1.002770, 0.867367, 0.855962, 0.812642, 0.753371, 0.864730, 1.012246, 0.783180, 0.899241, 0.839672, 0.821287, 0.849927, 0.786547, 1.039259, 2.576083, 0.669780, 1.023086, 0.935537, 1.586954, 1.159682, 0.911251, 0.722144, 0.600044, 1.005004, 0.943864, 0.746446, 0.742508, 0.637607, 0.585174, 0.604632, 0.668870, 0.639078, 0.631993, 0.687768, 0.658052, 0.591117, 0.646211, 0.680581, 0.819248, 0.608791, 0.856036, 0.806725, 0.554494, 0.763887, 0.610298, 0.767520, 0.964793, 0.577562, 0.572408, 0.593680, 0.708038, 0.637084, 0.610194, 0.576127, 0.555514, 0.582858, 0.854438, 0.740329, 0.562407, 0.523584, 0.494305, 0.677664, 0.643842, 0.596982, 0.680792, 0.660734, 0.554831, 0.500602, 0.623943, 0.600954, 0.701102, 1.199177, 0.735981, 1.011954, 0.533024, 0.600128, 0.631477, 0.548221, 0.550200, 0.552059, 0.644452, 0.739697, 0.601630, 0.547937, 0.573017, 0.675967, 0.897773, 0.804422, 0.574162, 1.036326, 0.532971, 0.511135, 0.513839, 0.504666, 0.735010, 0.544349, 0.559249, 0.470425, 1.139931, 1.611046, 0.598580, 0.500208, 0.570454, 0.555520, 0.717601, 0.595170, 0.477569, 0.517714, 0.749222, 0.540836, 0.647304, 0.580741, 0.561850, 0.402957, 0.606280, 0.504837, 3.066106, 0.492556, 0.536465, 0.635028, 0.492887, 0.483839, 0.676288, 0.487312, 1.377372, 0.411639, 0.768136, 0.489655, 1.567581, 1.033693, 0.408846, 0.672348, 0.469335, 0.510267, 0.623338, 1.379988, 0.497282, 1.125773, 0.557660, 0.652334, 0.599022, 0.492000, 0.463223, 0.473706, 0.581184, 0.465817, 0.552622, 0.479645, 0.788362, 0.627173, 0.404112, 1.368953, 0.532992, 0.480638, 0.517534, 0.615663, 0.572864, 0.499288, 0.491005, 0.412219, 0.432045, 0.994351, 0.502996, 0.783934, 0.494284, 0.435286, 0.583568, 0.485166, 0.551996, 0.618020, 0.443543, 0.755373, 0.671030, 0.575759, 0.953831, 0.823714, 0.444408, 0.499868, 0.729830, 0.547583, 0.438315, 1.538176, 0.728397, 0.498357, 0.641936, 0.644118, 0.670186, 0.447228, 0.508661, 0.608689, 0.546031, 0.461915, 1.221467, 0.536308, 0.377115, 0.482817, 0.554517, 0.493571, \n",
      "*************** \n",
      "\n",
      "Step 1 | Training Loss: 0.493571 | Test Loss: 1.609265 | Test Accuracy: 0.787704\n",
      "*************** \n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 2 | Training Loss: 0.402886, 0.975248, 0.420045, 0.538008, 2.302425, 0.494261, 0.495515, 1.925852, 0.549273, 0.600623, 0.912084, 0.480389, 0.474792, 0.536496, 0.414477, 0.505838, 0.789487, 0.539340, 0.596916, 0.477188, 2.161722, 0.434707, 0.571569, 0.483956, 0.395496, 0.364864, 0.578889, 0.373908, 0.506640, 0.422862, 0.524012, 0.527440, 0.372570, 0.712442, 0.484792, 0.485658, 0.456206, 0.574511, 0.470867, 0.468654, 1.284800, 0.588425, 0.441773, 0.481813, 0.482475, 0.521844, 0.333427, 0.872651, 0.352700, 0.405941, 0.394562, 0.462857, 0.348386, 0.449446, 0.697969, 0.397796, 0.421934, 0.499786, 0.395840, 0.624960, 0.562013, 0.475002, 0.344053, 0.411357, 0.373651, 0.401817, 0.537667, 0.390775, 0.408198, 0.572425, 0.504801, 0.582764, 0.810840, 0.586848, 0.430362, 0.607379, 0.466047, 0.565665, 0.498292, 0.547518, 0.737951, 1.084204, 0.377886, 0.619785, 0.759707, 0.433715, 0.407608, 0.600968, 0.463154, 3.128324, 0.363220, 0.475882, 0.355480, 0.408724, 0.447550, 0.694620, 0.500376, 0.411133, 0.392071, 0.729144, 0.373694, 1.403247, 0.687224, 0.414478, 0.403298, 0.368794, 0.427311, 0.501815, 0.407488, 0.728027, 0.535763, 0.387807, 0.531425, 0.637562, 0.421202, 0.388462, 0.408985, 0.353329, 0.651488, 0.561241, 1.017619, 0.465120, 0.389467, 0.636349, 0.442871, 1.283335, 0.419493, 0.378912, 0.572801, 0.902433, 0.372941, 0.436847, 0.362221, 0.403122, 0.757424, 0.368607, 0.743303, 0.689211, 0.465741, 0.344549, 0.286112, 0.380960, 0.328002, 0.317986, 0.467986, 0.298061, 1.420081, 0.409997, 0.384715, 0.490235, 0.476233, 0.374830, 0.677755, 0.459595, 0.302155, 0.669503, 0.376243, 0.514167, 0.706405, 0.669729, 0.738134, 1.344048, 0.656637, 0.373931, 0.663201, 0.506179, 0.628450, 0.375094, 0.424138, 0.629672, 0.418313, 0.614927, 0.412399, 0.322385, 0.473910, 0.340762, 0.615944, 0.289899, 0.418649, 0.439988, 0.518917, 0.408303, 0.491981, 0.485694, 0.465128, 0.368062, 0.478454, 0.300611, 0.373672, 0.381459, 0.493114, 0.438644, 0.318010, 0.529812, 0.486587, 0.472235, 0.444006, 1.550302, 0.494234, 0.910991, \n",
      "*************** \n",
      "\n",
      "Step 2 | Training Loss: 0.910991 | Test Loss: 1.661925 | Test Accuracy: 0.788414\n",
      "*************** \n",
      "\n",
      "Step 3 | Training Loss: 0.406936, 2.233117, 0.465250, 0.541804, 0.341790, 0.486162, 0.391248, 0.391304, 0.477031, 0.337685, 0.756730, 0.318727, 0.650222, 0.455461, 0.409146, 0.413179, 0.456251, 0.498618, 1.002471, 0.339410, 0.373357, 3.154120, 0.566205, 0.330516, 1.469602, 0.325632, 0.340337, 0.628624, 0.337069, 0.273965, 0.362716, 0.436147, 0.316283, 0.576827, 0.527539, 0.355177, 1.348441, 0.530520, 0.364431, 0.375314, 1.385937, 0.498693, 0.301835, 0.550538, 1.255301, 0.460718, 0.343189, 0.294640, 0.343090, 0.332508, 0.366497, 0.335422, 0.311108, 0.294981, 0.333269, 0.562597, 0.444650, 0.360607, 0.405898, 0.386584, 0.528500, 0.595954, 0.562721, 1.128522, 0.301913, 0.285956, 0.717609, 0.334688, 0.335914, 0.569091, 1.178690, 0.402282, 0.399469, 0.288013, 0.561106, 0.431598, 0.242025, 1.231731, 0.308286, 0.248099, 0.581939, 0.482544, 2.078587, 0.347261, 0.601512, 0.509670, 0.281926, 0.253445, 1.039102, 0.209517, 0.288249, 0.309697, 0.349384, 0.381453, 0.254436, 0.301991, 0.515406, 0.405134, 0.453534, 0.395463, 0.298016, 0.256623, 0.358229, 0.275935, 0.339129, 0.454933, 0.386801, 0.746295, 0.336730, 0.386576, 0.404834, 0.247405, 0.567090, 0.285756, 0.305972, 0.378319, 0.314649, 0.623790, 0.269901, 0.233587, 0.247668, 0.413566, 0.328191, 0.255577, 0.289679, 0.325193, 0.392881, 0.334050, 0.532391, 0.244384, 0.438920, 0.395582, 0.316921, 0.291391, 0.632728, 0.366218, 0.304211, 0.296916, 0.222175, 0.292259, 0.591120, 0.340301, 0.314528, 0.345946, 0.428976, 0.384427, 0.313414, 0.249428, 0.340840, 0.985624, 0.250301, 0.346871, 0.312026, 0.461742, 0.432572, 0.457656, 0.365942, 0.258037, 0.351147, 0.248615, 0.272748, 0.207099, 0.494833, 0.344044, 0.286635, 0.372123, 0.253913, 0.839718, 0.391000, 0.428381, 0.303720, 0.379462, 0.224062, 0.262974, 1.276008, 0.530363, 0.354072, 0.197467, 0.305892, 0.377654, 0.271907, 0.365144, 0.276467, 0.318059, 0.206148, 0.334767, 0.750821, 0.448876, 0.598745, 0.278099, 0.492618, 0.379495, 0.358417, 0.536494, 0.271276, 0.326999, 0.501863, 0.231343, 0.270772, 0.475400, \n",
      "*************** \n",
      "\n",
      "Step 3 | Training Loss: 0.475400 | Test Loss: 1.453562 | Test Accuracy: 0.779010\n",
      "*************** \n",
      "\n",
      "Step 4 | Training Loss: 0.692614, 0.371925, 0.533850, 0.307704, 0.199124, 0.209420, 0.389390, 0.478036, 0.281249, 0.235370, 0.290171, 0.591092, 0.296405, 2.245118, 0.354866, 0.267887, 0.244014, 0.248603, 0.502683, 1.889866, 0.275307, 0.201158, 0.237426, 0.234919, 0.368418, 0.302912, 0.280298, 0.274728, 0.202973, 0.259230, 0.845172, 0.229936, 0.288965, 0.625439, 0.554988, 0.678756, 0.459007, 0.462001, 0.275348, 1.089636, 0.497852, 3.273754, 0.334755, 0.315718, 0.326521, 0.332241, 0.272938, 0.430519, 0.371062, 0.336645, 0.299254, 0.307127, 0.603079, 0.442344, 0.352782, 0.241031, 0.364173, 0.299608, 0.366065, 0.313522, 0.293498, 0.360664, 0.271236, 0.988353, 0.390261, 0.268428, 0.464644, 0.301399, 0.283923, 0.317046, 0.326241, 0.275057, 0.348481, 0.236488, 0.272968, 0.225532, 0.220897, 0.329420, 0.265380, 0.290013, 0.781216, 0.245777, 0.573840, 0.339584, 0.229568, 0.262338, 0.339908, 0.226817, 0.402843, 0.354572, 0.420257, 0.388674, 0.215743, 0.268920, 0.297754, 0.475524, 0.280627, 0.413589, 0.207351, 0.264219, 0.247155, 2.122374, 0.294840, 0.305512, 0.383422, 0.441280, 0.246116, 0.337773, 0.251829, 0.560314, 0.373584, 0.341794, 0.245696, 0.141755, 0.631869, 2.061067, 0.185858, 0.191919, 0.268236, 0.372918, 1.269016, 0.155683, 0.153989, 0.275301, 0.237300, 1.004768, 0.251269, 0.243389, 0.147804, 0.210395, 0.271833, 0.263151, 0.221499, 0.357349, 0.252553, 0.235727, 0.150799, 1.116707, 0.358173, 0.596792, 0.280665, 0.339126, 1.109769, 0.225518, 0.311792, 0.231950, 0.192323, 0.303840, 0.232301, 0.326315, 0.280486, 0.461160, 0.197171, 0.429113, 0.166885, 1.425258, 0.185201, 0.278700, 0.205938, 0.345408, 0.460964, 0.325355, 0.373448, 0.259622, 0.307092, 0.301119, 0.241387, 0.274860, 1.000913, 0.292982, 0.287823, 0.198721, 0.274022, 0.241980, 0.231063, 0.327346, 0.320777, 0.697148, 0.333133, 0.619532, 0.205479, 1.269798, 0.377919, 0.396681, 0.250217, 0.378928, 0.655217, 1.781490, 0.494068, 0.294896, 0.641467, 0.316872, 0.552958, 0.414421, 0.845817, 0.716657, 0.403216, 0.388779, 0.343558, 0.541396, \n",
      "*************** \n",
      "\n",
      "Step 4 | Training Loss: 0.541396 | Test Loss: 1.528351 | Test Accuracy: 0.847276\n",
      "*************** \n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 5 | Training Loss: 0.809966, 0.360138, 0.316869, 0.497697, 0.369341, 0.437427, 0.405874, 0.390062, 0.449411, 0.531350, 0.557400, 0.517632, 0.463326, 0.639807, 0.231688, 0.487348, 0.239436, 0.433378, 0.305651, 1.530137, 0.463119, 0.361785, 0.439754, 0.496278, 0.410367, 0.395010, 0.406378, 0.672883, 0.410565, 0.557038, 0.456693, 0.523996, 0.497751, 0.471716, 0.390639, 0.834977, 0.385161, 0.619583, 0.468638, 0.392329, 0.548967, 0.381730, 0.618245, 0.344423, 0.449898, 0.905424, 0.488749, 0.246218, 0.510070, 0.353474, 0.316702, 0.563176, 0.667877, 0.426993, 0.342167, 0.617098, 0.353339, 0.349368, 0.552150, 0.366163, 0.497497, 0.259049, 1.187636, 0.357329, 0.427976, 0.676901, 0.278771, 0.555886, 0.539154, 0.406785, 0.312391, 0.416162, 5.163030, 0.647494, 0.420133, 0.569597, 0.624100, 0.502813, 0.505877, 0.661151, 1.093920, 0.570800, 0.589593, 1.287169, 0.463359, 0.799281, 0.462621, 0.493599, 0.634355, 0.567432, 0.527261, 0.527557, 0.460385, 0.474897, 0.646703, 0.467656, 0.646545, 0.464395, 0.384436, 0.423185, 0.378389, 0.620098, 0.385072, 0.529330, 0.333835, 0.290896, 0.490702, 0.545489, 0.415412, 0.312302, 0.466799, 0.682376, 0.435562, 1.278749, 0.378134, 0.278423, 0.494732, 0.287224, 0.470067, 0.496381, 2.154373, 0.385617, 0.366976, 0.394137, 0.437257, 0.306641, 1.512412, 0.474599, 0.353258, 1.215226, 2.231053, 0.354001, 0.511555, 0.354583, 0.310407, 0.413772, 0.265951, 0.550745, 0.713038, 0.446841, 0.480295, 0.322806, 0.333956, 0.359549, 0.653729, 0.358209, 0.240127, 0.604514, 0.340011, 0.512648, 0.515092, 0.328175, 0.838657, 0.398223, 0.425339, 0.622821, 0.427094, 0.422129, 0.605058, 0.234441, 0.292334, 0.274830, 0.593281, 0.454936, 0.369555, 1.422779, 0.336367, 0.435389, 0.679958, 0.399646, 0.548124, 0.296195, 0.395979, 0.531010, 0.349093, 0.317714, 0.338487, 0.719658, 0.284387, 0.439481, 0.218664, 0.525231, 0.433542, 0.299140, 0.346542, 0.474022, 0.358259, 0.358370, 0.397132, 0.346231, 0.242394, 0.405949, 0.257554, 0.385945, 0.346260, 0.284617, 0.417315, 0.882409, 1.935479, 0.393200, \n",
      "*************** \n",
      "\n",
      "Step 5 | Training Loss: 0.393200 | Test Loss: 1.535582 | Test Accuracy: 0.789744\n",
      "*************** \n",
      "\n",
      "Step 6 | Training Loss: 0.559661, 0.416449, 0.369932, 0.335609, 0.278341, 0.302961, 2.262368, 1.142900, 0.339200, 0.317086, 0.410191, 0.300938, 0.323452, 0.455717, 0.331872, 0.265584, 0.533600, 0.785475, 0.463983, 0.439384, 0.441729, 0.409773, 0.392649, 0.317960, 0.432973, 0.243255, 1.178256, 0.336296, 2.226344, 0.293030, 0.227042, 0.402662, 0.281480, 0.290865, 0.351303, 0.567669, 0.554243, 0.297074, 0.312746, 0.296169, 0.395580, 0.496861, 0.492577, 0.330788, 0.453197, 0.268254, 0.291349, 1.343610, 0.307575, 0.403245, 0.569286, 0.438912, 0.420242, 0.301224, 0.312809, 0.654918, 0.485671, 0.415528, 0.349496, 0.397017, 0.561460, 0.419224, 0.322686, 0.260966, 0.588061, 0.691891, 0.330509, 0.312035, 0.505892, 0.426443, 0.248649, 0.429859, 0.665388, 0.358379, 0.411012, 0.326058, 0.758138, 0.903122, 0.314860, 0.327086, 0.335567, 0.587280, 0.418323, 0.376263, 0.272156, 0.253167, 0.373564, 0.468241, 0.462930, 0.312389, 0.423466, 0.385243, 0.271818, 0.269117, 1.209175, 0.299734, 0.381866, 0.570039, 0.763039, 0.426554, 0.472947, 0.305288, 0.425097, 0.337393, 0.566713, 0.323611, 0.625894, 0.366673, 0.245900, 0.255190, 0.548622, 3.579252, 0.336687, 0.568148, 0.449486, 0.412439, 0.491832, 0.417394, 0.461993, 0.616426, 0.582434, 0.566520, 0.338868, 0.613989, 1.293295, 0.482674, 0.553843, 0.698707, 0.371455, 0.548078, 3.739717, 0.445405, 0.589001, 0.608129, 0.388220, 1.137816, 0.472143, 0.361082, 0.423270, 0.427499, 0.489111, 0.471348, 0.449741, 0.434804, 0.356899, 1.331697, 0.482077, 0.371987, 0.561169, 0.659609, 0.514390, 0.350983, 0.391122, 0.395052, 0.595345, 0.751936, 0.600748, 0.503255, 0.433120, 0.417653, 0.615501, 0.504652, 0.414103, 0.495092, 0.783880, 0.438540, 0.451392, 0.522234, 0.407754, 0.591495, 0.491545, 0.462500, 0.491587, 0.346251, 0.342613, 0.460898, 0.529929, 0.315423, 0.371292, 0.387565, 0.331015, 1.371773, 0.495675, 0.503185, 0.588701, 0.419461, 0.558733, 1.408403, 0.359639, 0.750963, 0.382865, 1.432154, 0.609705, 0.478049, 0.385139, 0.431189, 0.935087, 0.433771, 0.609069, 0.822793, \n",
      "*************** \n",
      "\n",
      "Step 6 | Training Loss: 0.822793 | Test Loss: 1.662294 | Test Accuracy: 0.741794\n",
      "*************** \n",
      "\n",
      "Step 7 | Training Loss: 0.532060, 1.122880, 0.508205, 0.449742, 0.389514, 0.520869, 0.928789, 0.456205, 0.461978, 0.495377, 1.423070, 0.386705, 0.520610, 0.709185, 0.349123, 0.621980, 0.439111, 0.435441, 0.505977, 0.789447, 0.474972, 0.362121, 1.465251, 0.422502, 0.330050, 0.544583, 0.417577, 0.358136, 0.462835, 0.534043, 0.629825, 0.543677, 0.322480, 0.428658, 0.547407, 0.283249, 0.303955, 0.502194, 0.400747, 0.485855, 0.664806, 0.443708, 0.315158, 0.405083, 0.312832, 0.538402, 0.503745, 0.415432, 0.543522, 0.326799, 0.415633, 0.424887, 0.385987, 0.458438, 0.504516, 0.587535, 0.404979, 0.405402, 0.408087, 0.384077, 1.630896, 0.483029, 0.365801, 0.657412, 0.583609, 0.392194, 1.914737, 0.929231, 0.945673, 0.310787, 0.467173, 0.404938, 0.461655, 0.317902, 0.569879, 0.446629, 0.518400, 0.675629, 0.570005, 0.426967, 0.615052, 1.248802, 0.401769, 0.372863, 0.328090, 0.417882, 0.385185, 0.626536, 1.049880, 0.511500, 0.294120, 0.778603, 0.507438, 1.257617, 1.025162, 0.361922, 0.377527, 1.176121, 0.577608, 0.428415, 0.490358, 0.343514, 0.566322, 0.341273, 0.395107, 0.321246, 0.350637, 0.244395, 0.333777, 0.304312, 0.547437, 0.594507, 0.290202, 0.507189, 0.374531, 0.613861, 1.241707, 0.305168, 0.683956, 0.403292, 0.678016, 0.305902, 0.706514, 0.465723, 0.447657, 1.217076, 0.304051, 0.378981, 0.306343, 0.362237, 0.329184, 0.484033, 0.370403, 0.340511, 0.287337, 0.334635, 0.277778, 0.461048, 0.254681, 0.464711, 0.344401, 0.326786, 0.352911, 0.248008, 0.362313, 0.450684, 0.646007, 2.200131, 0.235442, 0.742989, 0.461366, 0.380687, 0.299149, 0.379237, 0.264586, 0.486076, 0.397736, 0.518518, 0.352972, 0.511942, 0.394396, 0.369708, 0.532444, 0.349033, 0.500131, 0.484313, 0.259670, 0.294550, 0.318907, 0.588892, 0.390865, 0.447588, 0.679815, 0.356992, 0.409460, 0.300606, 0.439578, 0.902078, 0.331425, 0.269860, 0.351484, 0.461020, 0.706443, 0.297054, 0.336865, 0.456649, 0.246463, 0.336105, 0.357792, 0.307459, 3.051688, 0.420641, 0.454964, 0.686947, 0.261047, 1.659488, 0.567190, 0.439627, 0.365038, 0.524150, \n",
      "*************** \n",
      "\n",
      "Step 7 | Training Loss: 0.524150 | Test Loss: 1.616064 | Test Accuracy: 0.742681\n",
      "*************** \n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 8 | Training Loss: 0.313387, 0.369292, 0.316891, 0.444941, 0.401543, 0.370301, 0.551082, 0.460531, 0.310568, 0.281237, 0.497335, 0.447667, 0.314692, 0.400460, 0.763992, 0.368275, 0.465546, 0.767869, 3.209454, 0.734301, 0.582828, 0.401817, 0.330567, 0.517643, 0.392048, 0.526324, 0.464855, 0.276697, 0.594282, 0.347221, 0.303080, 0.312798, 1.927690, 0.401206, 0.378478, 0.256407, 0.828013, 0.458359, 0.322291, 0.386560, 0.500117, 0.384966, 0.311025, 0.250126, 0.219678, 0.663573, 0.438609, 0.459145, 0.368795, 0.326882, 0.330125, 0.314108, 0.386702, 0.368969, 0.631455, 0.326939, 0.475361, 0.558862, 1.014912, 0.380577, 1.366403, 0.488567, 0.356489, 0.339970, 0.419172, 0.378786, 0.386787, 0.480082, 0.557727, 0.340228, 0.348515, 0.289092, 0.261778, 0.263606, 0.333967, 0.393476, 0.301479, 0.286323, 0.286501, 0.457545, 0.444532, 0.597281, 0.295234, 0.326284, 0.518962, 0.536155, 0.466872, 1.171396, 0.356079, 0.442129, 0.405210, 0.351185, 0.253262, 0.391567, 0.286481, 0.526335, 0.373302, 0.639206, 0.334512, 0.276548, 0.373697, 0.337557, 0.574383, 0.379533, 2.149279, 0.325230, 0.530322, 0.380465, 0.222425, 0.708049, 0.397915, 0.549875, 0.541310, 1.201197, 0.296915, 0.441277, 0.528533, 0.307565, 0.441144, 0.596221, 1.269349, 0.369279, 0.566669, 0.337289, 0.369826, 0.435298, 0.317792, 2.140140, 0.456421, 0.297666, 0.517181, 0.333651, 0.413435, 0.298280, 0.300988, 0.367781, 0.368139, 0.341036, 0.492578, 0.450453, 0.874584, 0.337952, 0.633708, 0.381327, 0.476205, 0.519615, 0.369230, 0.401994, 0.264305, 0.421161, 0.918754, 0.478794, 0.300623, 0.245722, 0.475260, 0.255439, 0.310164, 0.639818, 0.285339, 0.338938, 0.529808, 0.248677, 0.454318, 0.345449, 0.339171, 0.222826, 0.322412, 0.228905, 0.639652, 0.321236, 0.252233, 0.555952, 0.372917, 0.294883, 0.280675, 0.387263, 0.309671, 0.294203, 0.945798, 0.286634, 0.337178, 0.316695, 0.432362, 0.333813, 0.637167, 0.469237, 0.303007, 0.370876, 0.217259, 0.318869, 0.619302, 0.331434, 1.366901, 0.278101, 0.301927, 0.911519, 0.392054, 1.256741, 0.279410, 0.302560, \n",
      "*************** \n",
      "\n",
      "Step 8 | Training Loss: 0.302560 | Test Loss: 1.628572 | Test Accuracy: 0.717220\n",
      "*************** \n",
      "\n",
      "Step 9 | Training Loss: 0.630009, 0.196016, 1.032686, 0.613710, 0.433416, 0.337894, 0.392188, 0.323535, 0.335659, 0.451141, 0.493908, 0.309888, 1.004890, 2.090223, 0.807430, 0.397202, 0.242172, 0.281462, 0.313898, 0.399829, 0.465576, 0.297438, 0.323495, 0.313107, 0.442632, 0.451517, 0.353819, 0.422210, 0.327597, 0.496028, 0.295359, 0.476942, 0.326401, 0.262434, 0.551629, 0.241078, 0.321422, 0.377491, 0.374825, 0.344665, 0.253800, 2.650979, 0.368846, 0.327675, 0.200341, 0.294769, 0.375702, 0.679264, 0.433961, 0.992273, 0.265290, 0.305120, 0.253286, 0.751171, 0.260150, 0.376892, 0.306593, 0.313535, 0.853072, 0.275721, 0.510837, 0.298589, 0.442028, 0.408638, 0.635530, 0.330013, 0.232868, 0.332777, 0.351567, 0.424434, 1.275727, 0.551547, 0.288579, 0.355372, 1.465917, 2.180649, 0.369657, 0.310056, 0.336571, 0.330195, 0.252498, 0.476986, 0.282291, 0.541184, 0.284450, 0.462420, 0.922827, 0.343186, 0.328512, 0.230705, 0.290015, 0.238411, 0.343481, 0.319228, 0.563859, 0.356019, 0.604267, 0.631615, 0.509498, 0.272549, 0.364274, 0.398302, 0.333568, 0.295915, 0.249203, 0.306325, 0.351234, 0.206790, 0.529928, 1.120112, 0.353556, 0.356496, 2.952195, 0.267801, 0.280310, 0.308881, 0.482262, 0.380142, 0.586406, 0.186363, 1.266038, 0.385340, 0.478228, 0.455865, 0.253488, 0.364872, 0.266989, 0.377832, 0.256076, 0.422610, 0.306255, 0.279610, 0.211113, 0.367832, 0.359156, 0.265949, 0.364845, 0.315000, 0.211102, 0.352197, 0.379482, 0.456261, 0.273492, 1.228317, 0.264705, 1.176355, 0.400848, 0.922334, 0.376005, 0.692891, 0.350272, 0.225886, 0.604451, 0.271463, 0.333083, 0.263246, 0.341069, 0.473959, 0.166495, 0.404121, 0.280699, 0.410339, 0.457652, 0.235753, 0.511423, 0.235586, 0.362207, 0.574839, 0.304765, 0.304409, 0.420624, 0.533846, 0.863090, 0.392909, 0.276569, 0.337444, 0.395172, 0.410710, 0.294092, 0.339990, 0.487081, 0.341467, 0.266535, 0.259226, 0.222484, 0.239708, 0.610581, 0.227997, 0.308061, 0.290382, 0.183459, 0.347928, 0.446732, 0.329404, 0.267063, 0.348861, 0.375266, 0.352195, 0.298040, 0.209195, \n",
      "*************** \n",
      "\n",
      "Step 9 | Training Loss: 0.209195 | Test Loss: 1.533092 | Test Accuracy: 0.772534\n",
      "*************** \n",
      "\n",
      "Step 10 | Training Loss: 0.504457, 0.333574, 0.485377, 0.310522, 0.321615, 0.336513, 0.307900, 0.525475, 0.340540, 0.226734, 0.332444, 0.328027, 0.331612, 0.293695, 0.511521, 0.274248, 0.210883, 0.360013, 0.257234, 0.471253, 0.313959, 0.304979, 0.346607, 0.185633, 0.282749, 0.341594, 0.323543, 0.378990, 0.208516, 0.318401, 0.493159, 0.306070, 0.253857, 0.429303, 0.246119, 0.270043, 0.293384, 0.305110, 0.362239, 0.242976, 0.342116, 0.406596, 0.278455, 0.383289, 0.410839, 0.575940, 0.325302, 0.253376, 1.170160, 0.303236, 0.549452, 0.837626, 0.318324, 0.709569, 0.353129, 0.265237, 3.079892, 0.356160, 0.331331, 1.182878, 0.362257, 1.123791, 0.240486, 0.564980, 0.208678, 0.244947, 0.389391, 0.309400, 0.313463, 0.263243, 0.302881, 0.367483, 0.368794, 0.330708, 0.462772, 0.287251, 0.286916, 0.224759, 0.194943, 0.350286, 0.325893, 0.351559, 0.324138, 2.987858, 0.378486, 0.232376, 0.454356, 0.431227, 0.215453, 0.356688, 0.304649, 0.237851, 0.247438, 0.339272, 0.247164, 0.709865, 0.228632, 2.774741, 0.350564, 0.349381, 0.266819, 0.472454, 0.403930, 0.945038, 0.351634, 0.446842, 0.364693, 0.364888, 0.199505, 0.632329, 0.326649, 0.446929, 0.286915, 0.289690, 0.349049, 0.458247, 1.009142, 0.280796, 0.277849, 0.932580, 0.242165, 0.192737, 0.356952, 0.510065, 0.305084, 0.276457, 0.263737, 0.252885, 0.353188, 0.250556, 0.311820, 0.299365, 0.163439, 0.456426, 0.311687, 0.717793, 0.552707, 0.572693, 0.262208, 0.287734, 0.241516, 0.195726, 0.254370, 0.385485, 0.337523, 0.217834, 0.274775, 0.850533, 0.395930, 0.244887, 0.425064, 0.283391, 0.536829, 0.307231, 0.473260, 0.622590, 0.316326, 0.445983, 0.453714, 0.287648, 0.286128, 0.248913, 0.366108, 2.321769, 0.696563, 0.600692, 0.434304, 0.375943, 0.340577, 1.096769, 0.344043, 0.270135, 0.370304, 0.524164, 0.365677, 0.651402, 0.487093, 0.261532, 0.416358, 0.255724, 0.408894, 0.429785, 0.248345, 0.298054, 0.343780, 0.420829, 1.210115, 0.342289, 0.258906, 0.422813, 0.383199, 0.278691, 0.520490, 0.315080, 0.880246, 0.371047, 0.491418, 0.354992, 0.505121, 0.439170, \n",
      "*************** \n",
      "\n",
      "Step 10 | Training Loss: 0.439170 | Test Loss: 1.753875 | Test Accuracy: 0.839469\n",
      "*************** \n",
      "\n",
      "Current Layer Attributes - epochs:10 hidden layers:4 features count:32\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 1 | Training Loss: 0.903183, 0.786761, 1.037285, 0.735378, 0.770248, 4.187818, 1.031164, 0.828462, 0.954487, 0.758738, 1.623254, 1.701246, 1.136253, 0.878385, 0.738636, 0.824601, 0.828447, 0.983785, 0.808081, 0.995275, 0.848099, 0.837081, 0.846488, 0.624719, 0.663153, 0.871296, 0.777110, 0.729604, 2.224874, 0.664879, 0.807169, 0.775805, 0.704947, 0.752185, 0.814644, 0.968777, 0.752416, 0.816308, 0.628423, 0.717592, 1.069137, 0.838317, 0.761214, 0.932092, 1.032774, 1.564557, 0.688969, 0.824416, 0.593936, 0.594289, 0.820447, 0.914490, 1.116049, 0.701959, 1.117843, 0.613412, 0.826143, 0.619142, 0.810047, 0.888098, 0.650844, 1.080411, 0.633569, 0.958261, 1.423971, 0.836392, 0.693081, 0.766321, 0.592552, 0.696914, 0.657019, 0.804416, 0.806448, 0.745992, 0.577049, 0.749529, 0.710553, 0.644751, 0.732646, 0.552740, 0.593514, 0.544113, 0.789736, 0.552428, 0.599306, 1.116099, 0.660911, 0.842922, 0.724566, 0.535011, 0.750488, 0.813540, 0.699827, 0.656423, 0.638419, 0.604455, 0.632687, 0.566749, 0.620571, 1.007804, 0.565359, 0.656193, 0.652095, 0.632311, 0.539591, 0.470656, 0.504073, 0.698117, 0.727929, 0.624720, 0.813631, 1.120489, 0.447577, 0.620064, 0.536550, 0.528002, 0.506175, 0.634438, 0.672867, 0.758426, 0.684379, 0.600112, 0.758086, 1.503286, 0.646155, 0.695586, 0.451392, 1.047155, 0.627023, 0.655673, 0.614707, 0.762715, 0.786698, 1.488579, 0.780741, 0.584782, 0.626618, 0.545341, 0.635644, 0.625247, 0.909928, 0.585490, 0.631564, 0.533278, 0.560899, 0.572057, 0.657174, 0.640979, 0.684915, 0.608473, 0.599302, 0.642224, 0.542834, 0.540566, 0.634209, 0.586754, 0.582924, 0.566717, 0.503154, 0.831265, 0.527849, 0.685878, 0.549979, 0.587959, 2.316968, 0.687547, 1.349103, 0.548455, 0.910735, 0.511272, 0.567538, 0.486468, 0.509478, 0.531216, 0.563094, 0.537658, 0.466481, 0.644292, 0.563849, 0.630195, 0.584464, 0.509692, 0.617449, 1.154764, 0.519957, 0.490834, 0.439991, 0.548943, 0.600036, 0.576403, 0.618699, 0.532980, 0.907724, 0.746079, 0.563546, 0.514433, 0.749345, 0.527393, 0.640997, 0.728686, \n",
      "*************** \n",
      "\n",
      "Step 1 | Training Loss: 0.728686 | Test Loss: 1.720905 | Test Accuracy: 0.793870\n",
      "*************** \n",
      "\n",
      "Step 2 | Training Loss: 0.451908, 1.257341, 0.567239, 0.578186, 0.633245, 0.525455, 0.568018, 0.735885, 0.521898, 0.509782, 0.600451, 0.479567, 0.446862, 0.521953, 0.548747, 0.474439, 0.471524, 0.711632, 0.556830, 0.770626, 0.515653, 0.807285, 0.583496, 0.578568, 0.502182, 0.701676, 0.508966, 0.489372, 0.446145, 0.507845, 1.028763, 0.738681, 0.501307, 0.517613, 0.440525, 0.569842, 1.581521, 0.474627, 0.481037, 2.055190, 0.513731, 0.452017, 0.429335, 0.541388, 0.617887, 0.515700, 0.880347, 0.604257, 0.543569, 0.490441, 0.662423, 0.490334, 0.509179, 0.583405, 0.490969, 0.529801, 0.449800, 0.425164, 0.533916, 1.729295, 0.662749, 0.550776, 0.507299, 0.545721, 0.583091, 0.624754, 0.497931, 0.513154, 0.451831, 0.586967, 0.438882, 0.531867, 0.487012, 0.510351, 0.495338, 0.406196, 1.587072, 0.788800, 0.534835, 0.524305, 0.462507, 0.905789, 0.834591, 0.483664, 0.601357, 0.863143, 0.512526, 0.543820, 0.487878, 0.466211, 1.356090, 0.420292, 0.533248, 0.563257, 0.452317, 0.757775, 1.478048, 0.472646, 1.342200, 0.434415, 0.756572, 0.627430, 0.650124, 0.427140, 0.488171, 0.572087, 0.621304, 0.697314, 0.512813, 0.520662, 3.176786, 0.428422, 0.523333, 0.436267, 0.560337, 0.560528, 0.494236, 0.530979, 0.554254, 0.461535, 0.482673, 0.525515, 0.468881, 0.564821, 0.566088, 0.625957, 0.558021, 0.536229, 0.769654, 0.490501, 0.560692, 0.839536, 0.987583, 0.512340, 0.559829, 0.521355, 1.006657, 0.475695, 0.939395, 0.555957, 0.379831, 0.484038, 0.500974, 0.502112, 2.367689, 1.056793, 0.420879, 0.650562, 0.536310, 0.451729, 0.365424, 0.638146, 0.460466, 0.470140, 0.456633, 0.696459, 0.711460, 0.493416, 0.367556, 0.701719, 0.380934, 0.477409, 0.519727, 0.471451, 0.481243, 0.430306, 1.317072, 0.404315, 0.484104, 0.480345, 0.639582, 0.563624, 0.391369, 2.317232, 0.534515, 0.396468, 0.552117, 0.619173, 0.449455, 0.494925, 0.558338, 0.471838, 0.599471, 0.577804, 0.401287, 0.455566, 0.636818, 0.582333, 0.547331, 0.612281, 0.429535, 0.430459, 0.424086, 0.424345, 0.453462, 0.454727, 0.484284, 0.540552, 0.490111, 0.431141, \n",
      "*************** \n",
      "\n",
      "Step 2 | Training Loss: 0.431141 | Test Loss: 1.684311 | Test Accuracy: 0.775550\n",
      "*************** \n",
      "\n",
      "Step 3 | Training Loss: 0.404844, 0.503229, 0.650600, 0.399249, 2.092924, 0.461087, 0.333402, 0.328377, 0.697773, 0.339834, 0.382997, 2.309853, 0.422728, 0.361091, 0.395397, 1.486051, 0.399954, 0.370825, 0.912331, 0.411345, 3.176541, 1.319319, 0.554123, 0.514642, 0.545298, 0.572009, 0.759656, 1.076800, 0.525132, 0.521301, 0.613431, 0.556242, 0.525493, 0.419360, 0.771211, 0.688650, 0.589890, 0.719366, 0.527619, 0.347961, 0.579001, 0.453873, 0.467022, 0.834376, 0.743592, 0.604946, 0.414674, 0.439289, 0.529419, 0.429810, 0.385976, 0.493271, 0.430129, 0.463343, 0.481772, 0.950604, 0.427092, 0.501250, 0.502691, 0.871254, 0.464754, 0.961377, 0.365833, 0.353216, 0.395514, 0.406904, 0.491979, 0.416383, 0.531584, 0.419371, 0.391791, 0.526499, 0.411301, 0.677156, 0.472059, 0.498003, 0.441367, 0.410172, 0.347911, 0.312052, 0.646566, 0.472876, 0.408867, 1.355287, 0.466285, 0.857586, 0.572188, 0.449822, 0.458934, 0.550921, 0.436696, 0.344114, 0.360770, 0.524355, 0.532245, 0.368693, 0.394421, 0.947527, 0.708835, 0.853426, 0.520589, 0.467560, 0.368012, 0.493173, 0.763967, 0.376023, 0.381787, 0.442706, 1.089306, 0.653717, 0.368369, 0.882660, 0.357004, 1.266061, 0.374369, 0.386077, 0.397334, 0.748552, 0.491442, 0.427850, 0.434709, 0.506007, 0.392937, 2.248516, 0.719715, 0.526721, 0.394129, 0.488260, 0.459571, 0.414819, 1.214273, 0.318683, 0.497806, 0.503332, 0.615160, 0.443016, 0.347897, 0.434463, 0.333170, 0.376470, 0.419018, 0.448707, 0.835081, 0.298701, 0.532040, 0.422181, 0.350685, 0.671201, 0.434793, 0.637248, 0.539498, 0.448327, 0.527262, 0.417391, 0.565177, 0.431280, 0.521308, 0.480094, 0.455895, 0.559999, 0.638202, 0.468543, 0.389440, 0.408087, 0.397941, 0.365635, 0.548075, 0.405221, 0.368790, 0.551776, 0.395345, 0.537387, 0.421109, 0.515231, 0.359917, 0.320967, 0.373524, 0.331215, 0.512110, 0.418634, 0.461367, 0.351396, 0.533070, 0.323869, 1.347861, 0.410161, 0.345620, 0.359425, 0.402931, 0.690687, 0.403549, 0.555393, 0.458335, 0.489231, 0.763866, 0.576650, 0.544890, 0.476854, 0.544684, 0.609973, \n",
      "*************** \n",
      "\n",
      "Step 3 | Training Loss: 0.609973 | Test Loss: 1.621499 | Test Accuracy: 0.812101\n",
      "*************** \n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 4 | Training Loss: 0.544561, 0.557070, 2.895801, 0.393129, 2.178460, 0.319510, 0.382530, 0.335877, 0.696253, 0.389558, 0.460700, 0.452024, 0.293900, 3.318252, 0.437133, 0.535576, 0.442195, 0.487128, 0.661142, 0.413512, 0.418947, 0.599508, 0.603113, 0.437176, 0.685286, 0.643349, 0.348111, 0.699664, 1.459856, 0.492756, 0.707126, 0.468905, 0.460375, 0.471011, 0.403054, 0.456855, 0.624108, 0.539216, 0.386195, 0.454893, 0.434717, 0.319705, 0.551122, 0.776016, 0.332568, 0.525415, 0.490020, 0.515477, 0.609498, 0.468847, 0.572941, 0.639245, 0.482408, 0.949967, 0.482101, 0.428406, 0.478470, 0.450920, 0.456973, 0.477098, 0.538017, 0.493732, 0.529845, 0.367082, 0.648129, 0.478543, 0.500964, 0.650224, 0.543782, 1.174892, 0.861282, 0.415794, 0.415056, 0.384234, 0.730778, 0.505852, 0.425767, 0.407080, 0.462706, 0.505953, 0.598769, 0.781586, 0.778582, 0.528543, 1.205656, 0.417199, 0.523034, 0.401974, 0.487633, 0.451136, 0.427954, 0.474092, 0.384783, 0.565120, 0.476767, 0.570057, 0.530617, 0.386857, 0.684390, 0.863251, 0.496378, 0.506676, 0.465501, 0.404102, 0.498804, 0.390064, 0.376481, 0.334979, 1.046302, 0.496828, 0.514236, 0.340560, 0.442358, 1.197123, 0.853240, 0.392654, 0.374195, 0.548387, 0.508665, 0.508854, 0.808571, 1.392005, 0.458797, 0.727645, 0.392665, 1.603466, 0.568682, 0.728139, 0.423796, 0.543623, 0.488420, 0.663174, 0.679670, 0.380070, 0.431354, 0.490938, 0.532808, 0.472600, 0.561124, 2.400213, 0.453047, 0.384377, 0.613482, 0.398483, 0.819830, 0.601660, 0.475804, 0.818026, 0.397678, 0.370328, 0.369711, 0.475856, 0.656308, 0.566907, 0.461626, 0.327111, 0.473327, 1.360818, 0.597362, 0.349687, 0.584087, 0.471343, 0.604015, 0.373635, 0.433843, 0.717269, 0.475255, 0.438988, 0.391904, 0.339676, 0.420175, 0.538350, 0.410819, 0.616564, 0.435167, 0.986181, 0.436532, 0.461530, 0.579058, 0.461064, 0.456701, 0.329591, 0.391351, 0.595991, 0.394277, 0.363629, 0.434420, 0.359222, 0.487909, 0.388006, 0.425388, 0.555877, 0.322371, 0.433325, 0.566387, 0.318527, 0.461899, 0.363983, 0.667346, 0.340541, \n",
      "*************** \n",
      "\n",
      "Step 4 | Training Loss: 0.340541 | Test Loss: 4.619186 | Test Accuracy: 0.786595\n",
      "*************** \n",
      "\n",
      "Step 5 | Training Loss: 0.405334, 0.769812, 0.379104, 0.654024, 0.561814, 1.357113, 0.649195, 0.396806, 0.549713, 0.504746, 0.458347, 0.539250, 0.298723, 0.355453, 0.390061, 0.411949, 0.960781, 0.346647, 0.422606, 0.338203, 0.845392, 0.480238, 0.361537, 0.454414, 1.405716, 0.353412, 0.415309, 2.307556, 0.385641, 0.408558, 0.510161, 0.340348, 0.450708, 0.737313, 0.563869, 0.356945, 0.387289, 0.399566, 0.324592, 0.419035, 0.413897, 0.380420, 0.530095, 0.410450, 0.398038, 0.411590, 0.338695, 0.436833, 0.454054, 0.361406, 0.811497, 1.259237, 0.710033, 0.475449, 0.559132, 0.478865, 0.294757, 0.397263, 0.377313, 0.374662, 0.511356, 0.481987, 0.362775, 0.545967, 0.360370, 0.448077, 0.364015, 0.558266, 0.375932, 0.304194, 0.383115, 3.099208, 0.487472, 0.391564, 0.381498, 0.489864, 0.351086, 0.606341, 0.461842, 0.497256, 0.410484, 0.323004, 0.389527, 0.696661, 0.304003, 0.585038, 0.515196, 0.595789, 0.404291, 0.389054, 0.491472, 0.544918, 0.394646, 0.443389, 1.153986, 0.320520, 0.347124, 0.401288, 1.319696, 0.506211, 0.346366, 0.399601, 0.420493, 0.317561, 0.480900, 0.530548, 0.880131, 0.484209, 0.364612, 0.420675, 0.364077, 0.911235, 2.367546, 0.526952, 0.413332, 0.559932, 1.069317, 1.627784, 0.373359, 0.444805, 0.521446, 0.616806, 0.515136, 0.594858, 0.491494, 0.510716, 0.451760, 0.479429, 0.539655, 0.473654, 0.521019, 0.603382, 0.492560, 0.774954, 0.461028, 0.482498, 0.450459, 0.410380, 0.368799, 0.393276, 0.350534, 0.467184, 0.405423, 1.040995, 0.446194, 0.700888, 326652.343750, 1.402683, 0.498057, 0.725065, 1.209215, 0.383672, 0.553844, 0.483118, 0.738224, 0.515802, 0.604591, 0.416887, 1.462785, 1.596692, 0.530324, 0.458433, 0.573728, 0.433744, 0.489276, 0.456696, 0.526324, 0.525045, 0.472563, 0.466874, 0.692181, 0.454750, 0.590537, 0.498031, 0.518917, 1.586825, 0.470474, 0.637702, 0.745782, 0.515343, 0.434436, 0.464594, 0.488807, 0.607952, 1.977901, 0.877227, 0.391600, 0.414369, 0.416015, 0.363745, 0.413525, 0.688659, 0.454142, 0.428575, 0.503075, 0.878355, 0.574700, 0.563777, 0.681442, 0.478277, \n",
      "*************** \n",
      "\n",
      "Step 5 | Training Loss: 0.478277 | Test Loss: 34008861014753280.000000 | Test Accuracy: 0.816049\n",
      "*************** \n",
      "\n",
      "Step 6 | Training Loss: 0.459502, 0.455642, 0.736308, 0.483082, 0.593442, 0.419636, 0.413008, 0.406946, 0.637041, 0.413509, 0.640310, 0.518152, 0.425443, 0.546845, 1.317758, 1.025453, 0.658762, 0.500607, 0.555184, 1.231031, 0.477616, 0.574225, 0.537476, 2.299418, 0.716907, 0.502594, 0.574315, 0.380508, 0.416885, 0.518330, 0.406377, 0.766277, 0.687969, 0.500200, 0.400138, 1.395075, 0.512129, 0.392087, 1.508629, 0.457015, 0.421094, 0.772028, 0.659765, 0.658079, 0.548474, 0.490862, 0.765519, 0.547045, 0.510717, 0.698453, 0.401310, 0.467078, 0.530152, 0.412964, 0.407188, 0.795121, 0.503630, 0.890204, 0.582307, 0.542436, 0.556375, 0.702768, 0.654530, 1.433968, 0.498845, 0.885619, 0.475126, 0.524728, 0.492821, 0.837242, 0.526198, 0.531850, 0.471973, 1.148232, 0.456726, 0.421152, 0.588924, 0.466653, 0.326930, 1.035445, 0.529803, 1.557724, 0.467429, 0.468083, 0.441486, 0.389682, 0.447695, 0.448321, 0.551297, 1.014591, 0.455237, 0.493500, 0.439864, 0.515934, 0.646523, 0.460729, 0.569091, 0.730103, 0.382812, 0.424913, 0.571953, 0.458948, 0.334905, 1.250590, 0.397832, 0.393278, 0.464875, 2.076332, 0.523150, 0.477782, 0.742678, 0.531072, 0.437617, 0.474079, 0.510317, 0.504853, 0.610721, 0.521867, 0.565632, 0.674388, 0.409408, 0.718773, 0.404189, 0.328462, 0.422390, 0.539248, 0.520865, 0.750605, 1.470835, 0.736814, 0.371309, 0.416826, 0.441688, 0.573569, 0.416272, 0.391479, 0.438185, 0.448612, 0.387009, 0.578583, 0.388077, 0.530234, 0.362095, 0.979552, 0.342149, 2.613294, 0.620564, 0.501208, 0.462383, 0.567989, 0.462382, 0.547147, 0.521718, 0.501697, 0.425527, 0.444423, 0.487352, 0.351944, 0.460258, 0.511885, 0.428359, 0.403038, 0.468981, 0.367833, 0.573780, 0.411830, 3.578283, 0.620183, 0.398290, 0.547639, 0.406637, 0.390007, 0.643589, 0.375250, 0.476034, 0.454172, 0.527312, 1.468844, 0.584216, 0.459675, 0.922912, 0.381737, 0.730502, 0.470945, 0.437254, 0.539346, 0.475728, 0.541672, 0.402103, 0.506944, 0.477337, 0.803385, 0.411450, 0.519859, 0.413238, 0.363423, 0.606843, 0.417078, 0.544980, 0.533466, \n",
      "*************** \n",
      "\n",
      "Step 6 | Training Loss: 0.533466 | Test Loss: 1.727838 | Test Accuracy: 0.788857\n",
      "*************** \n",
      "\n",
      "Step 7 | Training Loss: 0.456260, 0.561556, 2394567737344.000000, 0.494819, 0.453796, 0.445278, 0.617282, 0.556358, 0.741267, 0.442824, 0.530020, 0.806466, 0.495521, 0.535998, 0.742960, 0.648384, 1.395542, 0.601455, 0.918093, 0.548648, 2.028876, 0.633133, 0.677471, 0.510680, 0.460614, 0.586435, 0.770181, 0.608142, 0.540618, 2.457593, 0.580222, 0.574687, 0.819738, 0.465547, 0.404868, 0.855412, 0.703287, 1.554256, 0.561479, 0.471324, 0.797447, 0.593663, 0.531583, 0.604889, 0.632434, 0.492543, 0.560738, 0.677204, 0.448696, 0.555134, 0.515460, 0.538591, 0.806032, 0.445205, 0.609916, 0.449688, 0.833933, 0.547110, 0.671704, 0.598123, 0.528047, 0.502313, 0.468150, 0.452966, 0.716979, 0.587570, 0.822475, 0.583860, 0.433706, 0.712743, 0.523314, 0.649102, 0.491224, 0.403631, 0.811493, 0.591874, 0.585571, 0.542250, 0.962036, 0.520848, "
     ]
    }
   ],
   "source": [
    "import itertools\n",
    "class Hyperparameters:\n",
    "#    features_arr = [2, 4, 8, 16, 32, 64, 128, 256]\n",
    "#    hidden_layers_arr = [2, 4, 6, 10]\n",
    "    features_arr = [4, 8, 16, 32]\n",
    "    hidden_layers_arr = [2, 4]\n",
    "\n",
    "    epochs = [10]\n",
    "    \n",
    "    for e, h, f in itertools.product(epochs, hidden_layers_arr, features_arr):\n",
    "        print(\"Current Layer Attributes - epochs:{} hidden layers:{} features count:{}\".format(e,h,f))\n",
    "        n = network(2,h,f)\n",
    "        n.build_layers()\n",
    "        Train.train(e, n, h,f)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2017-05-14T14:40:01.657Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_results = pd.DataFrame(Train.results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2017-05-14T14:40:01.663Z"
    }
   },
   "outputs": [],
   "source": [
    "df_results.sort_values(by = 'test_score', ascending = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2017-05-14T14:40:01.668Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pd.Panel(Train.predictions).to_pickle(\"dataset/tf_vae_only_nsl_kdd_predictions.pkl\")\n",
    "df_results.to_pickle(\"dataset/tf_vae_only_nsl_kdd_scores.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2017-05-14T14:40:01.678Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import itertools\n",
    "\n",
    "def plot_confusion_matrix(cm, classes,\n",
    "                          normalize=False,\n",
    "                          title='Confusion matrix',\n",
    "                          cmap=plt.cm.Blues):\n",
    "    \"\"\"\n",
    "    This function prints and plots the confusion matrix.\n",
    "    Normalization can be applied by setting `normalize=True`.\n",
    "    \"\"\"\n",
    "    np.set_printoptions(precision=4)\n",
    "\n",
    "    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n",
    "    plt.title(title)\n",
    "    plt.colorbar()\n",
    "    tick_marks = np.arange(len(classes))\n",
    "    plt.xticks(tick_marks, classes, rotation=45)\n",
    "    plt.yticks(tick_marks, classes)\n",
    "\n",
    "    if normalize:\n",
    "        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "        print(\"Normalized confusion matrix\")\n",
    "    else:\n",
    "        print('Confusion matrix, without normalization')\n",
    "\n",
    "    print(cm)\n",
    "\n",
    "    thresh = cm.max() / 2.\n",
    "    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
    "        plt.text(j, i, cm[i, j].round(4),\n",
    "                 horizontalalignment=\"center\",\n",
    "                 color=\"white\" if cm[i, j] > thresh else \"black\")\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.ylabel('True label')\n",
    "    plt.xlabel('Predicted label')\n",
    "\n",
    "def plot(actual_value, pred_value):\n",
    "    from sklearn.metrics import confusion_matrix\n",
    "    cm_2labels = confusion_matrix(y_pred = pred_value, y_true = actual_value)\n",
    "    plt.figure(figsize=[6,6])\n",
    "    plot_confusion_matrix(cm_2labels, preprocess.output_columns_2labels, normalize = True,\n",
    "                         title = Train.best_parameters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2017-05-14T14:40:01.684Z"
    }
   },
   "outputs": [],
   "source": [
    "plot(actual_value = Train.actual_value, pred_value = Train.pred_value)"
   ]
  }
 ],
 "metadata": {
  "_draft": {
   "nbviewer_url": "https://gist.github.com/7d1ace18a82178e15ece8fc5252fce88"
  },
  "anaconda-cloud": {},
  "gist": {
   "data": {
    "description": "Hyper parameter tuning",
    "public": false
   },
   "id": "7d1ace18a82178e15ece8fc5252fce88"
  },
  "kernelspec": {
   "display_name": "Python [conda env:p3]",
   "language": "python",
   "name": "conda-env-p3-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
