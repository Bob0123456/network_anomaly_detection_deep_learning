{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Deep Learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.layers import Input, Dense, Lambda, Layer\n",
    "from keras.models import Model\n",
    "from keras import regularizers\n",
    "import keras\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from keras import backend as K\n",
    "from keras import metrics\n",
    "from collections import namedtuple\n",
    "pd.set_option(\"display.max_rows\",35)\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "kdd_train_2labels = pd.read_pickle(\"dataset/kdd_train_2labels.pkl\")\n",
    "kdd_test_2labels = pd.read_pickle(\"dataset/kdd_test_2labels.pkl\")\n",
    "\n",
    "#y_train_labels = pd.read_pickle(\"dataset/kdd_train_2labels_y.pkl\")\n",
    "#y_train_labels = pd.read_pickle(\"dataset/kdd_train_2labels.pkl\")\n",
    "#y_test_labels = pd.read_pickle(\"dataset/kdd_test_2labels_y.pkl\")\n",
    "\n",
    "output_columns_2labels = ['is_Attack','is_Normal']\n",
    "\n",
    "from sklearn import model_selection as ms\n",
    "from sklearn import preprocessing as pp\n",
    "\n",
    "x_input = kdd_train_2labels.drop(output_columns_2labels, axis = 1)\n",
    "y_output = kdd_train_2labels.loc[:,output_columns_2labels]\n",
    "\n",
    "ss = pp.StandardScaler()\n",
    "x_input = ss.fit_transform(x_input)\n",
    "\n",
    "#le = pp.LabelEncoder()\n",
    "#y_train = le.fit_transform(y_train_labels).reshape(-1, 1)\n",
    "#y_test = le.transform(y_test_labels).reshape(-1, 1)\n",
    "\n",
    "y_train = kdd_train_2labels.loc[:,output_columns_2labels]\n",
    "\n",
    "x_train, x_valid, y_train, y_valid = ms.train_test_split(x_input, \n",
    "                              y_train, \n",
    "                              test_size=0.1)\n",
    "#x_valid, x_test, y_valid, y_test = ms.train_test_split(x_valid, y_valid, test_size = 0.4)\n",
    "\n",
    "x_test = kdd_test_2labels.drop(output_columns_2labels, axis = 1)\n",
    "y_test = kdd_test_2labels.loc[:,output_columns_2labels]\n",
    "\n",
    "x_test = ss.transform(x_test)\n",
    "\n",
    "x_train = np.hstack((x_train, y_train))\n",
    "x_valid = np.hstack((x_valid, y_valid))\n",
    "\n",
    "x_test = np.hstack((x_test, np.random.normal(loc = 0, scale = 0.01, size = y_test.shape)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "input_dim = 124\n",
    "intermediate_dim = 124\n",
    "latent_dim = 32\n",
    "batch_size = 1409\n",
    "epochs = 5\n",
    "hidden_layers = 8\n",
    "\n",
    "class Train:\n",
    "    def train():\n",
    "        Train.x = Input(shape=(input_dim,))\n",
    "        \n",
    "        hidden_encoder = Train.x\n",
    "        for i in range(hidden_layers):\n",
    "            hidden_encoder = Dense(intermediate_dim, activation='relu')(hidden_encoder)\n",
    "\n",
    "        mean_encoder = Dense(latent_dim, activation=None)(hidden_encoder)\n",
    "\n",
    "        logvar_encoder = Dense(latent_dim, activation=None)(hidden_encoder)\n",
    "\n",
    "        def get_distrib(args):\n",
    "\n",
    "            Train.mean_encoder, Train.logvar_encoder = args\n",
    "\n",
    "            # Sample epsilon\n",
    "            epsilon = np.random.normal(loc=0.0, scale=0.05, size = (batch_size, latent_dim))\n",
    "\n",
    "            # Sample latent variable\n",
    "            z = mean_encoder + K.exp(logvar_encoder / 2) * epsilon\n",
    "            return z\n",
    "\n",
    "        z = Lambda(get_distrib)([mean_encoder, logvar_encoder])\n",
    "\n",
    "        hidden_decoder = z\n",
    "        for i in range(hidden_layers):\n",
    "            hidden_decoder = Dense(intermediate_dim, activation=\"relu\")(hidden_decoder)\n",
    "\n",
    "        Train.x_ = Dense(input_dim, activation=None)(hidden_decoder)\n",
    "\n",
    "def get_loss(args):\n",
    "    x, x_ = args\n",
    "    xent_loss = metrics.binary_crossentropy(x, x_) #input_dim *\n",
    "    kl_loss = - 0.5 * K.sum(1 + Train.logvar_encoder - K.square(Train.mean_encoder) - K.exp(Train.logvar_encoder), axis=-1)\n",
    "    label_loss = K.mean(K.argmax(Train.x[:,-2:], axis = 1) - K.argmax(Train.x_[:,-2:], axis = 1))\n",
    "    \n",
    "    ls = xent_loss + kl_loss\n",
    "    #ls += label_loss\n",
    "    \n",
    "    return ls\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " \n",
      " Current Layer Attributes - epochs:10 hidden layers:2 features count:4\n",
      "Train on 112720 samples, validate on 22544 samples\n",
      "Epoch 1/10\n",
      "112720/112720 [==============================] - 1s - loss: 0.8175 - acc: 0.1252 - label_accuracy: 0.1252 - val_loss: 1.7242 - val_acc: 0.4015 - val_label_accuracy: 0.4015\n",
      "Epoch 2/10\n",
      "112720/112720 [==============================] - 0s - loss: 0.6541 - acc: 0.4719 - label_accuracy: 0.4719 - val_loss: 1.6214 - val_acc: 0.5904 - val_label_accuracy: 0.5904\n",
      "Epoch 3/10\n",
      "112720/112720 [==============================] - 0s - loss: 0.5642 - acc: 0.6349 - label_accuracy: 0.6349 - val_loss: 1.4840 - val_acc: 0.7407 - val_label_accuracy: 0.7407\n",
      "Epoch 4/10\n",
      "112720/112720 [==============================] - 0s - loss: 0.4982 - acc: 0.7340 - label_accuracy: 0.7340 - val_loss: 1.3213 - val_acc: 0.7960 - val_label_accuracy: 0.7960\n",
      "Epoch 5/10\n",
      "112720/112720 [==============================] - 0s - loss: 0.4419 - acc: 0.8191 - label_accuracy: 0.8191 - val_loss: 1.2061 - val_acc: 0.8072 - val_label_accuracy: 0.8072\n",
      "Epoch 6/10\n",
      "112720/112720 [==============================] - 0s - loss: 0.4032 - acc: 0.8360 - label_accuracy: 0.8360 - val_loss: 1.1671 - val_acc: 0.8285 - val_label_accuracy: 0.8285\n",
      "Epoch 7/10\n",
      "112720/112720 [==============================] - 0s - loss: 0.3759 - acc: 0.8454 - label_accuracy: 0.8454 - val_loss: 1.0451 - val_acc: 0.8339 - val_label_accuracy: 0.8339\n",
      "Epoch 8/10\n",
      "112720/112720 [==============================] - 0s - loss: 0.3463 - acc: 0.8534 - label_accuracy: 0.8534 - val_loss: 0.9974 - val_acc: 0.8318 - val_label_accuracy: 0.8318\n",
      "Epoch 9/10\n",
      "112720/112720 [==============================] - 0s - loss: 0.3271 - acc: 0.8583 - label_accuracy: 0.8583 - val_loss: 0.9677 - val_acc: 0.8352 - val_label_accuracy: 0.8352\n",
      "Epoch 10/10\n",
      "112720/112720 [==============================] - 0s - loss: 0.3057 - acc: 0.8601 - label_accuracy: 0.8601 - val_loss: 0.9274 - val_acc: 0.8408 - val_label_accuracy: 0.8408\n",
      "19726/22544 [=========================>....] - ETA: 0s\n",
      " Train Acc: 0.8545954525470734, Test Acc: 0.8408002182841301, Label Acc: 0.7944907735982967\n",
      " \n",
      " Current Layer Attributes - epochs:10 hidden layers:2 features count:16\n",
      "Train on 112720 samples, validate on 22544 samples\n",
      "Epoch 1/10\n",
      "112720/112720 [==============================] - 1s - loss: 782.4108 - acc: 0.1255 - label_accuracy: 0.1255 - val_loss: 74711.9356 - val_acc: 0.4362 - val_label_accuracy: 0.4362\n",
      "Epoch 2/10\n",
      "112720/112720 [==============================] - 0s - loss: 0.7626 - acc: 0.3933 - label_accuracy: 0.3933 - val_loss: 1434.4213 - val_acc: 0.4890 - val_label_accuracy: 0.4890\n",
      "Epoch 3/10\n",
      "112720/112720 [==============================] - 0s - loss: 10.6900 - acc: 0.4960 - label_accuracy: 0.4960 - val_loss: 1.6816 - val_acc: 0.5764 - val_label_accuracy: 0.5764\n",
      "Epoch 4/10\n",
      "112720/112720 [==============================] - 0s - loss: 2.4055 - acc: 0.5707 - label_accuracy: 0.5707 - val_loss: 1.6391 - val_acc: 0.6543 - val_label_accuracy: 0.6543\n",
      "Epoch 5/10\n",
      "112720/112720 [==============================] - 0s - loss: 0.6378 - acc: 0.5726 - label_accuracy: 0.5726 - val_loss: 1.6134 - val_acc: 0.6588 - val_label_accuracy: 0.6588\n",
      "Epoch 6/10\n",
      "112720/112720 [==============================] - 0s - loss: 0.6212 - acc: 0.5876 - label_accuracy: 0.5876 - val_loss: 1.5894 - val_acc: 0.6743 - val_label_accuracy: 0.6743\n",
      "Epoch 7/10\n",
      "112720/112720 [==============================] - 0s - loss: 0.6086 - acc: 0.6014 - label_accuracy: 0.6014 - val_loss: 1.5677 - val_acc: 0.6758 - val_label_accuracy: 0.6758\n",
      "Epoch 8/10\n",
      "112720/112720 [==============================] - 0s - loss: 0.5979 - acc: 0.6171 - label_accuracy: 0.6171 - val_loss: 1.5492 - val_acc: 0.6808 - val_label_accuracy: 0.6808\n",
      "Epoch 9/10\n",
      "112720/112720 [==============================] - 0s - loss: 0.5884 - acc: 0.6281 - label_accuracy: 0.6281 - val_loss: 1.5332 - val_acc: 0.6839 - val_label_accuracy: 0.6839\n",
      "Epoch 10/10\n",
      "112720/112720 [==============================] - 0s - loss: 0.5793 - acc: 0.6416 - label_accuracy: 0.6416 - val_loss: 1.5189 - val_acc: 0.7032 - val_label_accuracy: 0.7032\n",
      "18317/22544 [=======================>......] - ETA: 0s\n",
      " Train Acc: 0.6480660066008568, Test Acc: 0.7032469809055328, Label Acc: 0.7665897799858056\n",
      " \n",
      " Current Layer Attributes - epochs:10 hidden layers:2 features count:32\n",
      "Train on 112720 samples, validate on 22544 samples\n",
      "Epoch 1/10\n",
      "112720/112720 [==============================] - 1s - loss: 679.9799 - acc: 0.1097 - label_accuracy: 0.1097 - val_loss: 6263868.9458 - val_acc: 0.0850 - val_label_accuracy: 0.0850\n",
      "Epoch 2/10\n",
      "112720/112720 [==============================] - 0s - loss: 1650313.3919 - acc: 0.1430 - label_accuracy: 0.1430 - val_loss: 2046.9448 - val_acc: 0.0855 - val_label_accuracy: 0.0855\n",
      "Epoch 3/10\n",
      "112720/112720 [==============================] - 0s - loss: 93.6239 - acc: 0.0802 - label_accuracy: 0.0802 - val_loss: 1.9651 - val_acc: 0.0733 - val_label_accuracy: 0.0733\n",
      "Epoch 4/10\n",
      "112720/112720 [==============================] - 0s - loss: 2763.6181 - acc: 0.1009 - label_accuracy: 0.1009 - val_loss: 1.9277 - val_acc: 0.0828 - val_label_accuracy: 0.0828\n",
      "Epoch 5/10\n",
      "112720/112720 [==============================] - 0s - loss: 0.8527 - acc: 0.1280 - label_accuracy: 0.1280 - val_loss: 1.8961 - val_acc: 0.1026 - val_label_accuracy: 0.1026\n",
      "Epoch 6/10\n",
      "112720/112720 [==============================] - 0s - loss: 0.8377 - acc: 0.1448 - label_accuracy: 0.1448 - val_loss: 1.8839 - val_acc: 0.1533 - val_label_accuracy: 0.1533\n",
      "Epoch 7/10\n",
      "112720/112720 [==============================] - 0s - loss: 0.8284 - acc: 0.1515 - label_accuracy: 0.1515 - val_loss: 1.8742 - val_acc: 0.1578 - val_label_accuracy: 0.1578\n",
      "Epoch 8/10\n",
      "112720/112720 [==============================] - 0s - loss: 0.8208 - acc: 0.1579 - label_accuracy: 0.1579 - val_loss: 1.8612 - val_acc: 0.1639 - val_label_accuracy: 0.1639\n",
      "Epoch 9/10\n",
      "112720/112720 [==============================] - 0s - loss: 0.8131 - acc: 0.1616 - label_accuracy: 0.1616 - val_loss: 1.8535 - val_acc: 0.1730 - val_label_accuracy: 0.1730\n",
      "Epoch 10/10\n",
      "112720/112720 [==============================] - 0s - loss: 0.7989 - acc: 0.1541 - label_accuracy: 0.1541 - val_loss: 1.8153 - val_acc: 0.1504 - val_label_accuracy: 0.1504\n",
      "15499/22544 [===================>..........] - ETA: 0s\n",
      " Train Acc: 0.14992902614176273, Test Acc: 0.15041696559637785, Label Acc: 0.7997249822569198\n",
      " \n",
      " Current Layer Attributes - epochs:10 hidden layers:2 features count:122\n",
      "Train on 112720 samples, validate on 22544 samples\n",
      "Epoch 1/10\n",
      "112720/112720 [==============================] - 1s - loss: 334.4145 - acc: 0.1946 - label_accuracy: 0.1946 - val_loss: 93.1923 - val_acc: 0.1791 - val_label_accuracy: 0.1791\n",
      "Epoch 2/10\n",
      "112720/112720 [==============================] - 0s - loss: 192379.8473 - acc: 0.2068 - label_accuracy: 0.2068 - val_loss: 142.0783 - val_acc: 0.2439 - val_label_accuracy: 0.2439\n",
      "Epoch 3/10\n",
      "112720/112720 [==============================] - 0s - loss: 37892351.3720 - acc: 0.2319 - label_accuracy: 0.2319 - val_loss: 4.2413 - val_acc: 0.2343 - val_label_accuracy: 0.2343\n",
      "Epoch 4/10\n",
      "112720/112720 [==============================] - 0s - loss: 17.7308 - acc: 0.1886 - label_accuracy: 0.1886 - val_loss: 1.9766 - val_acc: 0.2414 - val_label_accuracy: 0.2414\n",
      "Epoch 5/10\n",
      "112720/112720 [==============================] - 0s - loss: 186084.3161 - acc: 0.1405 - label_accuracy: 0.1405 - val_loss: 48.8595 - val_acc: 0.0816 - val_label_accuracy: 0.0816\n",
      "Epoch 6/10\n",
      "112720/112720 [==============================] - 0s - loss: 81543.4455 - acc: 0.1190 - label_accuracy: 0.1190 - val_loss: 2.6243 - val_acc: 0.1843 - val_label_accuracy: 0.1843\n",
      "Epoch 7/10\n",
      "112720/112720 [==============================] - 0s - loss: 326665644.0746 - acc: 0.0867 - label_accuracy: 0.0867 - val_loss: 55019135336448.7031 - val_acc: 0.1483 - val_label_accuracy: 0.1483\n",
      "Epoch 8/10\n",
      "112720/112720 [==============================] - 0s - loss: 767390178957.9261 - acc: 0.0279 - label_accuracy: 0.0279 - val_loss: 18665254.7523 - val_acc: 0.0072 - val_label_accuracy: 0.0072\n",
      "Epoch 9/10\n",
      "112720/112720 [==============================] - 0s - loss: 50.9734 - acc: 0.0290 - label_accuracy: 0.0290 - val_loss: 13175113.5300 - val_acc: 0.0940 - val_label_accuracy: 0.0940\n",
      "Epoch 10/10\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "112720/112720 [==============================] - 0s - loss: 11629.1658 - acc: 0.0356 - label_accuracy: 0.0356 - val_loss: 52802004.2823 - val_acc: 0.0939 - val_label_accuracy: 0.0939\n",
      "15499/22544 [===================>..........] - ETA: 0s\n",
      " Train Acc: 0.03805890679359436, Test Acc: 0.09394960990175605, Label Acc: 0.5689318665720369\n",
      " \n",
      " Current Layer Attributes - epochs:10 hidden layers:6 features count:4\n",
      "Train on 112720 samples, validate on 22544 samples\n",
      "Epoch 1/10\n",
      "112720/112720 [==============================] - 2s - loss: 0.8511 - acc: 0.0199 - label_accuracy: 0.0199 - val_loss: 1.7417 - val_acc: 0.0240 - val_label_accuracy: 0.0240\n",
      "Epoch 2/10\n",
      "112720/112720 [==============================] - 1s - loss: 0.6716 - acc: 0.3737 - label_accuracy: 0.3737 - val_loss: 1.6515 - val_acc: 0.6869 - val_label_accuracy: 0.6869\n",
      "Epoch 3/10\n",
      "112720/112720 [==============================] - 1s - loss: 0.5614 - acc: 0.6777 - label_accuracy: 0.6777 - val_loss: 1.5255 - val_acc: 0.6729 - val_label_accuracy: 0.6729\n",
      "Epoch 4/10\n",
      "112720/112720 [==============================] - 1s - loss: 0.4875 - acc: 0.7417 - label_accuracy: 0.7417 - val_loss: 1.2299 - val_acc: 0.7697 - val_label_accuracy: 0.7697\n",
      "Epoch 5/10\n",
      "112720/112720 [==============================] - 1s - loss: 0.4022 - acc: 0.8054 - label_accuracy: 0.8054 - val_loss: 1.1577 - val_acc: 0.8021 - val_label_accuracy: 0.8021\n",
      "Epoch 6/10\n",
      "112720/112720 [==============================] - 1s - loss: 0.3424 - acc: 0.8323 - label_accuracy: 0.8323 - val_loss: 1.0834 - val_acc: 0.8137 - val_label_accuracy: 0.8137\n",
      "Epoch 7/10\n",
      "112720/112720 [==============================] - 1s - loss: 0.2981 - acc: 0.8528 - label_accuracy: 0.8528 - val_loss: 1.0413 - val_acc: 0.8193 - val_label_accuracy: 0.8193\n",
      "Epoch 8/10\n",
      "112720/112720 [==============================] - 1s - loss: 0.2818 - acc: 0.8524 - label_accuracy: 0.8524 - val_loss: 1.0233 - val_acc: 0.8205 - val_label_accuracy: 0.8205\n",
      "Epoch 9/10\n",
      "112720/112720 [==============================] - 1s - loss: 0.2713 - acc: 0.8579 - label_accuracy: 0.8579 - val_loss: 1.0189 - val_acc: 0.8292 - val_label_accuracy: 0.8292\n",
      "Epoch 10/10\n",
      "112720/112720 [==============================] - 1s - loss: 0.2406 - acc: 0.8694 - label_accuracy: 0.8694 - val_loss: 0.9736 - val_acc: 0.8321 - val_label_accuracy: 0.8321\n",
      "11272/11272 [==============================] - 0s     \n",
      "21135/22544 [===========================>..] - ETA: 0s\n",
      " Train Acc: 0.8783711865544319, Test Acc: 0.8320617415010929, Label Acc: 0.7854418026969482\n",
      " \n",
      " Current Layer Attributes - epochs:10 hidden layers:6 features count:16\n",
      "Train on 112720 samples, validate on 22544 samples\n",
      "Epoch 1/10\n",
      "112720/112720 [==============================] - 2s - loss: 0.8088 - acc: 0.1702 - label_accuracy: 0.1702 - val_loss: 1.6865 - val_acc: 0.4916 - val_label_accuracy: 0.4916\n",
      "Epoch 2/10\n",
      "112720/112720 [==============================] - 1s - loss: 0.5908 - acc: 0.6433 - label_accuracy: 0.6433 - val_loss: 1.5677 - val_acc: 0.6032 - val_label_accuracy: 0.6032\n",
      "Epoch 3/10\n",
      "112720/112720 [==============================] - 1s - loss: 0.4490 - acc: 0.8381 - label_accuracy: 0.8381 - val_loss: 1.3035 - val_acc: 0.7870 - val_label_accuracy: 0.7870\n",
      "Epoch 4/10\n",
      "112720/112720 [==============================] - 1s - loss: 0.3336 - acc: 0.8632 - label_accuracy: 0.8632 - val_loss: 1.1181 - val_acc: 0.8509 - val_label_accuracy: 0.8509\n",
      "Epoch 5/10\n",
      "112720/112720 [==============================] - 1s - loss: 0.2619 - acc: 0.8798 - label_accuracy: 0.8798 - val_loss: 0.9943 - val_acc: 0.8564 - val_label_accuracy: 0.8564\n",
      "Epoch 6/10\n",
      "112720/112720 [==============================] - 1s - loss: 0.2131 - acc: 0.8806 - label_accuracy: 0.8806 - val_loss: 0.9161 - val_acc: 0.8551 - val_label_accuracy: 0.8551\n",
      "Epoch 7/10\n",
      "112720/112720 [==============================] - 1s - loss: 0.1909 - acc: 0.8874 - label_accuracy: 0.8874 - val_loss: 0.8700 - val_acc: 0.8446 - val_label_accuracy: 0.8446\n",
      "Epoch 8/10\n",
      "112720/112720 [==============================] - 1s - loss: 0.1750 - acc: 0.8960 - label_accuracy: 0.8960 - val_loss: 0.8195 - val_acc: 0.8423 - val_label_accuracy: 0.8423\n",
      "Epoch 9/10\n",
      "112720/112720 [==============================] - 1s - loss: 0.1532 - acc: 0.9057 - label_accuracy: 0.9057 - val_loss: 0.8147 - val_acc: 0.8978 - val_label_accuracy: 0.8978\n",
      "Epoch 10/10\n",
      "112720/112720 [==============================] - 1s - loss: 0.1446 - acc: 0.9139 - label_accuracy: 0.9139 - val_loss: 0.7482 - val_acc: 0.8680 - val_label_accuracy: 0.8680\n",
      "21135/22544 [===========================>..] - ETA: 0s\n",
      " Train Acc: 0.9220191612839699, Test Acc: 0.8680358417332172, Label Acc: 0.7764815471965933\n",
      " \n",
      " Current Layer Attributes - epochs:10 hidden layers:6 features count:32\n",
      "Train on 112720 samples, validate on 22544 samples\n",
      "Epoch 1/10\n",
      "112720/112720 [==============================] - 2s - loss: 2381.8750 - acc: 0.0864 - label_accuracy: 0.0864 - val_loss: 1.7993 - val_acc: 0.1988 - val_label_accuracy: 0.1988\n",
      "Epoch 2/10\n",
      "112720/112720 [==============================] - 1s - loss: 0.8103 - acc: 0.2800 - label_accuracy: 0.2800 - val_loss: 1.7127 - val_acc: 0.4740 - val_label_accuracy: 0.4740\n",
      "Epoch 3/10\n",
      "112720/112720 [==============================] - 1s - loss: 2811901.6818 - acc: 0.4403 - label_accuracy: 0.4403 - val_loss: 1.7264 - val_acc: 0.4279 - val_label_accuracy: 0.4279\n",
      "Epoch 4/10\n",
      "112720/112720 [==============================] - 1s - loss: 0.6479 - acc: 0.6249 - label_accuracy: 0.6249 - val_loss: 1.6259 - val_acc: 0.7175 - val_label_accuracy: 0.7175\n",
      "Epoch 5/10\n",
      "112720/112720 [==============================] - 1s - loss: 0.5837 - acc: 0.8025 - label_accuracy: 0.8025 - val_loss: 1.5744 - val_acc: 0.7468 - val_label_accuracy: 0.7468\n",
      "Epoch 6/10\n",
      "112720/112720 [==============================] - 1s - loss: 0.5444 - acc: 0.8332 - label_accuracy: 0.8332 - val_loss: 1.4945 - val_acc: 0.8123 - val_label_accuracy: 0.8123\n",
      "Epoch 7/10\n",
      "112720/112720 [==============================] - 1s - loss: 0.5024 - acc: 0.8553 - label_accuracy: 0.8553 - val_loss: 1.4155 - val_acc: 0.8206 - val_label_accuracy: 0.8206\n",
      "Epoch 8/10\n",
      "112720/112720 [==============================] - 1s - loss: 0.4667 - acc: 0.8538 - label_accuracy: 0.8538 - val_loss: 1.3801 - val_acc: 0.8281 - val_label_accuracy: 0.8281\n",
      "Epoch 9/10\n",
      "112720/112720 [==============================] - 1s - loss: 0.4397 - acc: 0.8596 - label_accuracy: 0.8596 - val_loss: 1.3118 - val_acc: 0.8088 - val_label_accuracy: 0.8088\n",
      "Epoch 10/10\n",
      "112720/112720 [==============================] - 1s - loss: 0.4202 - acc: 0.8401 - label_accuracy: 0.8401 - val_loss: 1.2662 - val_acc: 0.8391 - val_label_accuracy: 0.8391\n",
      "11272/11272 [==============================] - 0s     \n",
      "21135/22544 [===========================>..] - ETA: 0s\n",
      " Train Acc: 0.8681689128279686, Test Acc: 0.8390702605247498, Label Acc: 0.7818931866572036\n",
      " \n",
      " Current Layer Attributes - epochs:10 hidden layers:6 features count:122\n",
      "Train on 112720 samples, validate on 22544 samples\n",
      "Epoch 1/10\n",
      "112720/112720 [==============================] - 2s - loss: 4.2826 - acc: 0.0481 - label_accuracy: 0.0481 - val_loss: 1.7798 - val_acc: 0.4242 - val_label_accuracy: 0.4242\n",
      "Epoch 2/10\n",
      "112720/112720 [==============================] - 1s - loss: 0.6826 - acc: 0.4049 - label_accuracy: 0.4049 - val_loss: 1.6810 - val_acc: 0.5063 - val_label_accuracy: 0.5063\n",
      "Epoch 3/10\n",
      "112720/112720 [==============================] - 1s - loss: 0.5624 - acc: 0.6034 - label_accuracy: 0.6034 - val_loss: 1.5630 - val_acc: 0.6822 - val_label_accuracy: 0.6822\n",
      "Epoch 4/10\n",
      "112720/112720 [==============================] - 1s - loss: 1078.8248 - acc: 0.6814 - label_accuracy: 0.6814 - val_loss: 2.1075 - val_acc: 0.1614 - val_label_accuracy: 0.1614\n",
      "Epoch 5/10\n",
      "112720/112720 [==============================] - 1s - loss: 217691.6709 - acc: 0.0353 - label_accuracy: 0.0353 - val_loss: 1.8280 - val_acc: 0.0203 - val_label_accuracy: 0.0203\n",
      "Epoch 6/10\n",
      "112720/112720 [==============================] - 1s - loss: 0.7509 - acc: 0.1600 - label_accuracy: 0.1600 - val_loss: 1.7108 - val_acc: 0.5222 - val_label_accuracy: 0.5222\n",
      "Epoch 7/10\n",
      "112720/112720 [==============================] - 1s - loss: 0.6465 - acc: 0.5579 - label_accuracy: 0.5579 - val_loss: 1.6186 - val_acc: 0.6321 - val_label_accuracy: 0.6321\n",
      "Epoch 8/10\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "112720/112720 [==============================] - 1s - loss: 0.5815 - acc: 0.6971 - label_accuracy: 0.6971 - val_loss: 1.5750 - val_acc: 0.6642 - val_label_accuracy: 0.6642\n",
      "Epoch 9/10\n",
      "112720/112720 [==============================] - 1s - loss: 0.5432 - acc: 0.7329 - label_accuracy: 0.7329 - val_loss: 1.5105 - val_acc: 0.7378 - val_label_accuracy: 0.7378\n",
      "Epoch 10/10\n",
      "112720/112720 [==============================] - 1s - loss: 0.5162 - acc: 0.7674 - label_accuracy: 0.7674 - val_loss: 1.4736 - val_acc: 0.6987 - val_label_accuracy: 0.6987\n",
      "18317/22544 [=======================>......] - ETA: 0s\n",
      " Train Acc: 0.7398864403367043, Test Acc: 0.6986781395971775, Label Acc: 0.7694730305180979\n",
      " \n",
      " Current Layer Attributes - epochs:10 hidden layers:10 features count:4\n",
      "Train on 112720 samples, validate on 22544 samples\n",
      "Epoch 1/10\n",
      "112720/112720 [==============================] - 3s - loss: 0.9084 - acc: 0.0084 - label_accuracy: 0.0084 - val_loss: 1.8473 - val_acc: 0.0480 - val_label_accuracy: 0.0480\n",
      "Epoch 2/10\n",
      "112720/112720 [==============================] - 2s - loss: 0.7783 - acc: 0.1132 - label_accuracy: 0.1132 - val_loss: 1.7657 - val_acc: 0.1076 - val_label_accuracy: 0.1076\n",
      "Epoch 3/10\n",
      "112720/112720 [==============================] - 2s - loss: 0.7231 - acc: 0.3869 - label_accuracy: 0.3869 - val_loss: 1.7556 - val_acc: 0.4670 - val_label_accuracy: 0.4670\n",
      "Epoch 4/10\n",
      "112720/112720 [==============================] - 2s - loss: 0.6858 - acc: 0.5000 - label_accuracy: 0.5000 - val_loss: 1.7253 - val_acc: 0.5060 - val_label_accuracy: 0.5060\n",
      "Epoch 5/10\n",
      "112720/112720 [==============================] - 2s - loss: 0.6519 - acc: 0.5351 - label_accuracy: 0.5351 - val_loss: 1.6915 - val_acc: 0.4375 - val_label_accuracy: 0.4375\n",
      "Epoch 6/10\n",
      "112720/112720 [==============================] - 2s - loss: 0.6321 - acc: 0.5255 - label_accuracy: 0.5255 - val_loss: 1.6728 - val_acc: 0.5349 - val_label_accuracy: 0.5349\n",
      "Epoch 7/10\n",
      "112720/112720 [==============================] - 2s - loss: 0.6098 - acc: 0.5534 - label_accuracy: 0.5534 - val_loss: 1.6168 - val_acc: 0.5033 - val_label_accuracy: 0.5033\n",
      "Epoch 8/10\n",
      "112720/112720 [==============================] - 2s - loss: 0.6541 - acc: 0.5257 - label_accuracy: 0.5257 - val_loss: 1.6260 - val_acc: 0.5779 - val_label_accuracy: 0.5779\n",
      "Epoch 9/10\n",
      "112720/112720 [==============================] - 2s - loss: 0.6232 - acc: 0.5771 - label_accuracy: 0.5771 - val_loss: 1.6024 - val_acc: 0.6657 - val_label_accuracy: 0.6657\n",
      "Epoch 10/10\n",
      "112720/112720 [==============================] - 2s - loss: 0.5868 - acc: 0.6191 - label_accuracy: 0.6191 - val_loss: 1.5630 - val_acc: 0.5900 - val_label_accuracy: 0.5900\n",
      "22544/22544 [==============================] - 0s     \n",
      "\n",
      " Train Acc: 0.6304116472601891, Test Acc: 0.5899574086070061, Label Acc: 0.7806068133427964\n",
      " \n",
      " Current Layer Attributes - epochs:10 hidden layers:10 features count:16\n",
      "Train on 112720 samples, validate on 22544 samples\n",
      "Epoch 1/10\n",
      "112720/112720 [==============================] - 3s - loss: 0.9191 - acc: 0.0047 - label_accuracy: 0.0047 - val_loss: 1.8911 - val_acc: 0.2822 - val_label_accuracy: 0.2822\n",
      "Epoch 2/10\n",
      "112720/112720 [==============================] - 2s - loss: 0.8278 - acc: 0.2850 - label_accuracy: 0.2850 - val_loss: 1.8201 - val_acc: 0.3204 - val_label_accuracy: 0.3204\n",
      "Epoch 3/10\n",
      "112720/112720 [==============================] - 2s - loss: 0.7676 - acc: 0.4079 - label_accuracy: 0.4079 - val_loss: 1.8734 - val_acc: 0.2251 - val_label_accuracy: 0.2251\n",
      "Epoch 4/10\n",
      "112720/112720 [==============================] - 2s - loss: 0.7209 - acc: 0.4987 - label_accuracy: 0.4987 - val_loss: 1.6655 - val_acc: 0.5415 - val_label_accuracy: 0.5415\n",
      "Epoch 5/10\n",
      "112720/112720 [==============================] - 2s - loss: 0.6763 - acc: 0.5437 - label_accuracy: 0.5437 - val_loss: 1.5628 - val_acc: 0.6661 - val_label_accuracy: 0.6661\n",
      "Epoch 6/10\n",
      "112720/112720 [==============================] - 2s - loss: 0.6382 - acc: 0.6017 - label_accuracy: 0.6017 - val_loss: 1.5431 - val_acc: 0.6850 - val_label_accuracy: 0.6850\n",
      "Epoch 7/10\n",
      "112720/112720 [==============================] - 2s - loss: 0.6189 - acc: 0.6616 - label_accuracy: 0.6616 - val_loss: 1.4711 - val_acc: 0.7006 - val_label_accuracy: 0.7006\n",
      "Epoch 8/10\n",
      "112720/112720 [==============================] - 2s - loss: 0.5845 - acc: 0.6826 - label_accuracy: 0.6826 - val_loss: 1.4097 - val_acc: 0.7235 - val_label_accuracy: 0.7235\n",
      "Epoch 9/10\n",
      "112720/112720 [==============================] - 2s - loss: 0.5494 - acc: 0.7396 - label_accuracy: 0.7396 - val_loss: 1.3573 - val_acc: 0.7504 - val_label_accuracy: 0.7504\n",
      "Epoch 10/10\n",
      "112720/112720 [==============================] - 2s - loss: 0.5120 - acc: 0.7871 - label_accuracy: 0.7871 - val_loss: 1.3330 - val_acc: 0.7899 - val_label_accuracy: 0.7899\n",
      "22544/22544 [==============================] - 0s     \n",
      "\n",
      " Train Acc: 0.8234563618898392, Test Acc: 0.7898775711655617, Label Acc: 0.7919180269694819\n",
      " \n",
      " Current Layer Attributes - epochs:10 hidden layers:10 features count:32\n",
      "Train on 112720 samples, validate on 22544 samples\n",
      "Epoch 1/10\n",
      "112720/112720 [==============================] - 3s - loss: 0.9068 - acc: 5.2342e-04 - label_accuracy: 5.2342e-04 - val_loss: 1.8528 - val_acc: 9.7587e-04 - val_label_accuracy: 9.7587e-04\n",
      "Epoch 2/10\n",
      "112720/112720 [==============================] - 2s - loss: 0.7917 - acc: 0.2425 - label_accuracy: 0.2425 - val_loss: 1.7807 - val_acc: 0.3167 - val_label_accuracy: 0.3167\n",
      "Epoch 3/10\n",
      "112720/112720 [==============================] - 2s - loss: 0.7321 - acc: 0.4449 - label_accuracy: 0.4449 - val_loss: 1.7302 - val_acc: 0.5162 - val_label_accuracy: 0.5162\n",
      "Epoch 4/10\n",
      "112720/112720 [==============================] - 2s - loss: 0.6836 - acc: 0.5449 - label_accuracy: 0.5449 - val_loss: 1.6836 - val_acc: 0.6264 - val_label_accuracy: 0.6264\n",
      "Epoch 5/10\n",
      "112720/112720 [==============================] - 2s - loss: 0.6587 - acc: 0.5661 - label_accuracy: 0.5661 - val_loss: 1.5681 - val_acc: 0.6611 - val_label_accuracy: 0.6611\n",
      "Epoch 6/10\n",
      "112720/112720 [==============================] - 2s - loss: 0.6412 - acc: 0.5845 - label_accuracy: 0.5845 - val_loss: 1.4272 - val_acc: 0.6844 - val_label_accuracy: 0.6844\n",
      "Epoch 7/10\n",
      "112720/112720 [==============================] - 2s - loss: 0.6250 - acc: 0.5886 - label_accuracy: 0.5886 - val_loss: 1.4778 - val_acc: 0.6727 - val_label_accuracy: 0.6727\n",
      "Epoch 8/10\n",
      "112720/112720 [==============================] - 2s - loss: 0.5911 - acc: 0.6269 - label_accuracy: 0.6269 - val_loss: 1.3041 - val_acc: 0.7358 - val_label_accuracy: 0.7358\n",
      "Epoch 9/10\n",
      "112720/112720 [==============================] - 2s - loss: 0.5667 - acc: 0.6590 - label_accuracy: 0.6590 - val_loss: 1.2871 - val_acc: 0.7423 - val_label_accuracy: 0.7423\n",
      "Epoch 10/10\n",
      "112720/112720 [==============================] - 2s - loss: 0.5678 - acc: 0.6781 - label_accuracy: 0.6781 - val_loss: 1.4673 - val_acc: 0.7362 - val_label_accuracy: 0.7362\n",
      "19726/22544 [=========================>....] - ETA: 0s\n",
      " Train Acc: 0.6703335717320442, Test Acc: 0.7362491115927696, Label Acc: 0.7684528034066714\n",
      " \n",
      " Current Layer Attributes - epochs:10 hidden layers:10 features count:122\n",
      "Train on 112720 samples, validate on 22544 samples\n",
      "Epoch 1/10\n",
      "112720/112720 [==============================] - 4s - loss: 0.9036 - acc: 0.0014 - label_accuracy: 0.0014 - val_loss: 1.8366 - val_acc: 0.0073 - val_label_accuracy: 0.0073\n",
      "Epoch 2/10\n",
      "112720/112720 [==============================] - 2s - loss: 4.1561 - acc: 0.2016 - label_accuracy: 0.2016 - val_loss: 1.7869 - val_acc: 0.3270 - val_label_accuracy: 0.3270\n",
      "Epoch 3/10\n",
      "112720/112720 [==============================] - 2s - loss: 0.7334 - acc: 0.4249 - label_accuracy: 0.4249 - val_loss: 1.7283 - val_acc: 0.3878 - val_label_accuracy: 0.3878\n",
      "Epoch 4/10\n",
      "112720/112720 [==============================] - 2s - loss: 0.6878 - acc: 0.4905 - label_accuracy: 0.4905 - val_loss: 1.7074 - val_acc: 0.6045 - val_label_accuracy: 0.6045\n",
      "Epoch 5/10\n",
      "112720/112720 [==============================] - 2s - loss: 0.6617 - acc: 0.5587 - label_accuracy: 0.5587 - val_loss: 1.7007 - val_acc: 0.5969 - val_label_accuracy: 0.5969\n",
      "Epoch 6/10\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "112720/112720 [==============================] - 2s - loss: 0.6536 - acc: 0.5437 - label_accuracy: 0.5437 - val_loss: 1.6854 - val_acc: 0.6610 - val_label_accuracy: 0.6610\n",
      "Epoch 7/10\n",
      "112720/112720 [==============================] - 2s - loss: 0.6239 - acc: 0.6187 - label_accuracy: 0.6187 - val_loss: 1.6739 - val_acc: 0.6331 - val_label_accuracy: 0.6331\n",
      "Epoch 8/10\n",
      "112720/112720 [==============================] - 2s - loss: 0.6062 - acc: 0.6409 - label_accuracy: 0.6409 - val_loss: 1.6627 - val_acc: 0.6361 - val_label_accuracy: 0.6361\n",
      "Epoch 9/10\n",
      "112720/112720 [==============================] - 2s - loss: 0.6025 - acc: 0.6223 - label_accuracy: 0.6223 - val_loss: 1.6546 - val_acc: 0.6757 - val_label_accuracy: 0.6757\n",
      "Epoch 10/10\n",
      "112720/112720 [==============================] - 2s - loss: 0.5764 - acc: 0.6778 - label_accuracy: 0.6778 - val_loss: 1.6219 - val_acc: 0.6964 - val_label_accuracy: 0.6964\n",
      "18317/22544 [=======================>......] - ETA: 0s\n",
      " Train Acc: 0.6501951888203621, Test Acc: 0.696371540427208, Label Acc: 0.7638839602555003\n"
     ]
    }
   ],
   "source": [
    "import itertools\n",
    "#features_arr = [4, 16, 32, 256, 1024]\n",
    "#hidden_layers_arr = [2, 6, 10, 100]\n",
    "\n",
    "features_arr = [4, 16, 32, 122]\n",
    "hidden_layers_arr = [2, 6, 10]\n",
    "\n",
    "epoch_arr = [10]\n",
    "\n",
    "def label_accuracy(y_true, y_pred):\n",
    "    return K.mean(K.equal(K.argmax(y_true, axis = 1), K.argmax(y_pred, axis = 1)))\n",
    "\n",
    "score = namedtuple(\"score\", ['epoch', 'no_of_features','hidden_layers','train_score', 'test_score'])\n",
    "scores = []\n",
    "predictions = pd.DataFrame()\n",
    "\n",
    "for e, h, f in itertools.product(epoch_arr, hidden_layers_arr, features_arr):\n",
    "    \n",
    "    print(\" \\n Current Layer Attributes - epochs:{} hidden layers:{} features count:{}\".format(e,h,f))\n",
    "    latent_dim = f\n",
    "    epochs = e\n",
    "    hidden_layers = h\n",
    "\n",
    "    Train.train()\n",
    "\n",
    "    vae_model = Model(inputs = Train.x, outputs = Train.x_ )\n",
    "    vae_model.compile(optimizer = \"adam\", loss = \"mean_squared_error\", metrics = ['accuracy', label_accuracy] )\n",
    "    #vae_model.compile(optimizer = \"adam\", loss = Lambda(get_loss)([Train.x, Train.x_]), metrics = ['accuracy', label_accuracy] )\n",
    "\n",
    "    train_size = x_train.shape[0] - x_train.shape[0]%batch_size\n",
    "    valid_size = x_valid.shape[0] - x_valid.shape[0]%batch_size\n",
    "\n",
    "    vae_model.fit(x = x_train[:train_size,:], y = x_train[:train_size,:], \n",
    "                  shuffle=True, epochs=epochs, \n",
    "                  batch_size = batch_size, \n",
    "                  #validation_data = (x_valid[:valid_size,:], x_valid[:valid_size,:]),\n",
    "                  validation_data = (x_test, x_test),\n",
    "                  verbose = 1)\n",
    "    \n",
    "    score_train = vae_model.evaluate(x_valid[:valid_size,:], y = x_valid[:valid_size,:],\n",
    "                               batch_size = batch_size,\n",
    "                               verbose = 1)\n",
    "    \n",
    "    score_test = vae_model.evaluate(x_test, y = x_test,\n",
    "                           batch_size = batch_size,\n",
    "                           verbose = 1)\n",
    "    y_test_pred = vae_model.predict(x_test, batch_size=batch_size)\n",
    "    \n",
    "    y_pred = np.argmax(y_test_pred[:,-2:], axis = 1)\n",
    "    y_test_1d = np.argmax(y_test.values, axis = 1)\n",
    "    \n",
    "    #y_pred[y_pred >= y_test_pred[:,-1].mean()] = 1\n",
    "    #y_pred[y_pred < y_test_pred[:,-1].mean()] = 0\n",
    "    \n",
    "    label_acc = np.mean(np.equal(y_test_1d, y_pred))\n",
    "    \n",
    "    scores.append(score(e,f,h,score_train[-1], label_acc)) #score_test[-1]))\n",
    "    \n",
    "    curr_pred = pd.DataFrame({\"{}_{}_{}\".format(e,f,h):y_pred},)\n",
    "    predictions = pd.concat([predictions, curr_pred], axis = 1)\n",
    "    \n",
    "    print(\"\\n Train Acc: {}, Test Acc: {}, Label Acc: {}\".format(score_train[-1], \n",
    "                                                                 score_test[-1], \n",
    "                                                                 label_acc)  )\n",
    "    \n",
    "scores = pd.DataFrame(scores)\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>epoch</th>\n",
       "      <th>no_of_features</th>\n",
       "      <th>hidden_layers</th>\n",
       "      <th>train_score</th>\n",
       "      <th>test_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>10</td>\n",
       "      <td>32</td>\n",
       "      <td>2</td>\n",
       "      <td>0.149929</td>\n",
       "      <td>0.799725</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>0.854595</td>\n",
       "      <td>0.794491</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>10</td>\n",
       "      <td>16</td>\n",
       "      <td>10</td>\n",
       "      <td>0.823456</td>\n",
       "      <td>0.791918</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>10</td>\n",
       "      <td>4</td>\n",
       "      <td>6</td>\n",
       "      <td>0.878371</td>\n",
       "      <td>0.785442</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>10</td>\n",
       "      <td>32</td>\n",
       "      <td>6</td>\n",
       "      <td>0.868169</td>\n",
       "      <td>0.781893</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>10</td>\n",
       "      <td>4</td>\n",
       "      <td>10</td>\n",
       "      <td>0.630412</td>\n",
       "      <td>0.780607</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>10</td>\n",
       "      <td>16</td>\n",
       "      <td>6</td>\n",
       "      <td>0.922019</td>\n",
       "      <td>0.776482</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>10</td>\n",
       "      <td>122</td>\n",
       "      <td>6</td>\n",
       "      <td>0.739886</td>\n",
       "      <td>0.769473</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>10</td>\n",
       "      <td>32</td>\n",
       "      <td>10</td>\n",
       "      <td>0.670334</td>\n",
       "      <td>0.768453</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10</td>\n",
       "      <td>16</td>\n",
       "      <td>2</td>\n",
       "      <td>0.648066</td>\n",
       "      <td>0.766590</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>10</td>\n",
       "      <td>122</td>\n",
       "      <td>10</td>\n",
       "      <td>0.650195</td>\n",
       "      <td>0.763884</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>10</td>\n",
       "      <td>122</td>\n",
       "      <td>2</td>\n",
       "      <td>0.038059</td>\n",
       "      <td>0.568932</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    epoch  no_of_features  hidden_layers  train_score  test_score\n",
       "2      10              32              2     0.149929    0.799725\n",
       "0      10               4              2     0.854595    0.794491\n",
       "9      10              16             10     0.823456    0.791918\n",
       "4      10               4              6     0.878371    0.785442\n",
       "6      10              32              6     0.868169    0.781893\n",
       "8      10               4             10     0.630412    0.780607\n",
       "5      10              16              6     0.922019    0.776482\n",
       "7      10             122              6     0.739886    0.769473\n",
       "10     10              32             10     0.670334    0.768453\n",
       "1      10              16              2     0.648066    0.766590\n",
       "11     10             122             10     0.650195    0.763884\n",
       "3      10             122              2     0.038059    0.568932"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scores.sort_values(\"test_score\", ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "predictions.to_pickle(\"dataset/vae_only_predictions.pkl\")\n",
    "scores.to_pickle(\"dataset/vae_only_scores.pkl\")"
   ]
  }
 ],
 "metadata": {
  "_draft": {
   "nbviewer_url": "https://gist.github.com/33dcb1bcf3ca4a3461c4405a003a7591"
  },
  "anaconda-cloud": {},
  "gist": {
   "data": {
    "description": "Final Hyper parameter tuning",
    "public": false
   },
   "id": "33dcb1bcf3ca4a3461c4405a003a7591"
  },
  "kernelspec": {
   "display_name": "Python [conda env:p3]",
   "language": "python",
   "name": "conda-env-p3-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
