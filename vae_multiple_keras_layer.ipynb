{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Deep Learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.layers import Input, Dense, Lambda, Layer\n",
    "from keras.models import Model\n",
    "from keras import regularizers\n",
    "import keras\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from keras import backend as K\n",
    "from keras import metrics\n",
    "pd.set_option(\"display.max_rows\",15)\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "kdd_train_2labels = pd.read_pickle(\"dataset/kdd_train_2labels.pkl\")\n",
    "kdd_test_2labels = pd.read_pickle(\"dataset/kdd_test_2labels.pkl\")\n",
    "y_train_labels = pd.read_pickle(\"dataset/kdd_train_2labels_y.pkl\")\n",
    "y_test_labels = pd.read_pickle(\"dataset/kdd_test_2labels_y.pkl\")\n",
    "\n",
    "output_columns_2labels = ['is_Attack','is_Normal']\n",
    "\n",
    "from sklearn import model_selection as ms\n",
    "from sklearn import preprocessing as pp\n",
    "\n",
    "x_input = kdd_train_2labels.drop(output_columns_2labels, axis = 1)\n",
    "#y_output = kdd_train_2labels.loc[:,output_columns_2labels]\n",
    "\n",
    "ss = pp.StandardScaler()\n",
    "x_input = ss.fit_transform(x_input)\n",
    "\n",
    "le = pp.LabelEncoder()\n",
    "y_train = le.fit_transform(y_train_labels).reshape(-1, 1)\n",
    "y_test = le.transform(y_test_labels).reshape(-1, 1)\n",
    "\n",
    "\n",
    "x_train, x_valid, y_train, y_valid = ms.train_test_split(x_input, \n",
    "                              y_train, \n",
    "                              test_size=0.2)\n",
    "#x_valid, x_test, y_valid, y_test = ms.train_test_split(x_valid, y_valid, test_size = 0.4)\n",
    "\n",
    "x_test = kdd_test_2labels.drop(output_columns_2labels, axis = 1)\n",
    "#y_test = kdd_test_2labels.loc[:,output_columns_2labels]\n",
    "\n",
    "x_test = ss.transform(x_test)\n",
    "\n",
    "x_train = np.hstack((x_train, y_train))\n",
    "x_valid = np.hstack((x_valid, y_valid))\n",
    "\n",
    "x_test = np.hstack((x_test, np.random.normal(loc = 0, scale = 0.05, size = y_test.shape)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_dim = 123\n",
    "intermediate_dim = 80\n",
    "latent_dim = 32\n",
    "batch_size = 64\n",
    "epochs = 5\n",
    "hidden_layers = 8\n",
    "\n",
    "class Train:\n",
    "    def train():\n",
    "        Train.x = Input(shape=(input_dim,))\n",
    "        \n",
    "        hidden_encoder = Train.x\n",
    "        for i in range(hidden_layers):\n",
    "            hidden_encoder = Dense(intermediate_dim, activation='relu')(hidden_encoder)\n",
    "\n",
    "        mean_encoder = Dense(latent_dim, activation=None)(hidden_encoder)\n",
    "\n",
    "        logvar_encoder = Dense(latent_dim, activation=None)(hidden_encoder)\n",
    "\n",
    "        def get_distrib(args):\n",
    "\n",
    "            mean_encoder, logvar_encoder = args\n",
    "\n",
    "            # Sample epsilon\n",
    "            epsilon = np.random.normal(loc=0.0, scale=0.05, size = (batch_size, latent_dim))\n",
    "\n",
    "            # Sample latent variable\n",
    "            z = mean_encoder + K.exp(logvar_encoder / 2) * epsilon\n",
    "            return z\n",
    "\n",
    "        z = Lambda(get_distrib)([mean_encoder, logvar_encoder])\n",
    "\n",
    "        hidden_decoder = z\n",
    "        for i in range(hidden_layers):\n",
    "            hidden_decoder = Dense(intermediate_dim, activation=\"relu\")(hidden_decoder)\n",
    "\n",
    "        Train.x_ = Dense(input_dim, activation=None)(hidden_decoder)\n",
    "\n",
    "def get_loss(x, x_):\n",
    "    xent_loss = input_dim * metrics.binary_crossentropy(x, x_) \n",
    "    kl_loss = - 0.5 * K.sum(1 + logvar_encoder - K.square(mean_encoder) - K.exp(logvar_encoder), axis=-1)\n",
    "    return K.abs(K.mean(xent_loss + kl_loss))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current Layer Attributes - epochs:1 hidden layers:2 features count:2\n",
      "Train on 100736 samples, validate on 25152 samples\n",
      "Epoch 1/1\n",
      "100736/100736 [==============================] - 4s - loss: 0.7381 - val_loss: 0.6536\n",
      "Current Layer Attributes - epochs:1 hidden layers:2 features count:4\n",
      "Train on 100736 samples, validate on 25152 samples\n",
      "Epoch 1/1\n",
      "100736/100736 [==============================] - 4s - loss: 584.2402 - val_loss: 0.6017\n",
      "Current Layer Attributes - epochs:1 hidden layers:2 features count:8\n",
      "Train on 100736 samples, validate on 25152 samples\n",
      "Epoch 1/1\n",
      "100736/100736 [==============================] - 4s - loss: 0.5119 - val_loss: 0.3181\n",
      "Current Layer Attributes - epochs:1 hidden layers:2 features count:16\n",
      "Train on 100736 samples, validate on 25152 samples\n",
      "Epoch 1/1\n",
      "100736/100736 [==============================] - 4s - loss: 1.1940 - val_loss: 0.4649\n",
      "Current Layer Attributes - epochs:1 hidden layers:2 features count:32\n",
      "Train on 100736 samples, validate on 25152 samples\n",
      "Epoch 1/1\n",
      "100736/100736 [==============================] - 4s - loss: 9688694.7080 - val_loss: 0.5807\n",
      "Current Layer Attributes - epochs:1 hidden layers:2 features count:64\n",
      "Train on 100736 samples, validate on 25152 samples\n",
      "Epoch 1/1\n",
      "100736/100736 [==============================] - 4s - loss: 5012.2774 - val_loss: 0.6842\n",
      "Current Layer Attributes - epochs:1 hidden layers:2 features count:128\n",
      "Train on 100736 samples, validate on 25152 samples\n",
      "Epoch 1/1\n",
      "100736/100736 [==============================] - 4s - loss: 770.1966 - val_loss: 0.5727\n",
      "Current Layer Attributes - epochs:1 hidden layers:2 features count:256\n",
      "Train on 100736 samples, validate on 25152 samples\n",
      "Epoch 1/1\n",
      "100736/100736 [==============================] - 5s - loss: 185759474996.7596 - val_loss: 19.3821\n",
      "Current Layer Attributes - epochs:1 hidden layers:4 features count:2\n",
      "Train on 100736 samples, validate on 25152 samples\n",
      "Epoch 1/1\n",
      "100736/100736 [==============================] - 5s - loss: 0.7004 - val_loss: 0.5793\n",
      "Current Layer Attributes - epochs:1 hidden layers:4 features count:4\n",
      "Train on 100736 samples, validate on 25152 samples\n",
      "Epoch 1/1\n",
      "100736/100736 [==============================] - 5s - loss: 733315577850649.6250 - val_loss: 0.9610\n",
      "Current Layer Attributes - epochs:1 hidden layers:4 features count:8\n",
      "Train on 100736 samples, validate on 25152 samples\n",
      "Epoch 1/1\n",
      "100736/100736 [==============================] - 6s - loss: 0.5236 - val_loss: 0.3175\n",
      "Current Layer Attributes - epochs:1 hidden layers:4 features count:16\n",
      "Train on 100736 samples, validate on 25152 samples\n",
      "Epoch 1/1\n",
      "100736/100736 [==============================] - 6s - loss: nan - val_loss: nan\n",
      "Current Layer Attributes - epochs:1 hidden layers:4 features count:32\n",
      "Train on 100736 samples, validate on 25152 samples\n",
      "Epoch 1/1\n",
      "100736/100736 [==============================] - 7s - loss: 223375813.4928 - val_loss: 0.5005\n",
      "Current Layer Attributes - epochs:1 hidden layers:4 features count:64\n",
      "Train on 100736 samples, validate on 25152 samples\n",
      "Epoch 1/1\n",
      "100736/100736 [==============================] - 6s - loss: 0.5301 - val_loss: 0.3410\n",
      "Current Layer Attributes - epochs:1 hidden layers:4 features count:128\n",
      "Train on 100736 samples, validate on 25152 samples\n",
      "Epoch 1/1\n",
      "100736/100736 [==============================] - 6s - loss: 0.5013 - val_loss: 0.2860\n",
      "Current Layer Attributes - epochs:1 hidden layers:4 features count:256\n",
      "Train on 100736 samples, validate on 25152 samples\n",
      "Epoch 1/1\n",
      "100736/100736 [==============================] - 8s - loss: 607939.0336 - val_loss: 0.6093\n",
      "Current Layer Attributes - epochs:1 hidden layers:6 features count:2\n",
      "Train on 100736 samples, validate on 25152 samples\n",
      "Epoch 1/1\n",
      "100736/100736 [==============================] - 7s - loss: 0.7251 - val_loss: 0.6274\n",
      "Current Layer Attributes - epochs:1 hidden layers:6 features count:4\n",
      "Train on 100736 samples, validate on 25152 samples\n",
      "Epoch 1/1\n",
      "100736/100736 [==============================] - 7s - loss: 0.6787 - val_loss: 0.5438\n",
      "Current Layer Attributes - epochs:1 hidden layers:6 features count:8\n",
      "Train on 100736 samples, validate on 25152 samples\n",
      "Epoch 1/1\n",
      "100736/100736 [==============================] - 7s - loss: 112.7546 - val_loss: 0.5123\n",
      "Current Layer Attributes - epochs:1 hidden layers:6 features count:16\n",
      "Train on 100736 samples, validate on 25152 samples\n",
      "Epoch 1/1\n",
      "100736/100736 [==============================] - 8s - loss: 0.6010 - val_loss: 0.4570\n",
      "Current Layer Attributes - epochs:1 hidden layers:6 features count:32\n",
      "Train on 100736 samples, validate on 25152 samples\n",
      "Epoch 1/1\n",
      "100736/100736 [==============================] - 9s - loss: 9040313950.2679 - val_loss: 1995.8075\n",
      "Current Layer Attributes - epochs:1 hidden layers:6 features count:64\n",
      "Train on 100736 samples, validate on 25152 samples\n",
      "Epoch 1/1\n",
      "100736/100736 [==============================] - 10s - loss: 1043.4253 - val_loss: 0.6111\n",
      "Current Layer Attributes - epochs:1 hidden layers:6 features count:128\n",
      "Train on 100736 samples, validate on 25152 samples\n",
      "Epoch 1/1\n",
      "100736/100736 [==============================] - 10s - loss: nan - val_loss: nan\n",
      "Current Layer Attributes - epochs:1 hidden layers:6 features count:256\n",
      "Train on 100736 samples, validate on 25152 samples\n",
      "Epoch 1/1\n",
      "100736/100736 [==============================] - 11s - loss: 1620.9559 - val_loss: 0.4759\n",
      "Current Layer Attributes - epochs:1 hidden layers:10 features count:2\n",
      "Train on 100736 samples, validate on 25152 samples\n",
      "Epoch 1/1\n",
      "100736/100736 [==============================] - 11s - loss: 0.7606 - val_loss: 0.6508\n",
      "Current Layer Attributes - epochs:1 hidden layers:10 features count:4\n",
      "Train on 100736 samples, validate on 25152 samples\n",
      "Epoch 1/1\n",
      "100736/100736 [==============================] - 11s - loss: 0.7804 - val_loss: 0.6496\n",
      "Current Layer Attributes - epochs:1 hidden layers:10 features count:8\n",
      "Train on 100736 samples, validate on 25152 samples\n",
      "Epoch 1/1\n",
      "100736/100736 [==============================] - 11s - loss: 0.7752 - val_loss: 0.6757\n",
      "Current Layer Attributes - epochs:1 hidden layers:10 features count:16\n",
      "Train on 100736 samples, validate on 25152 samples\n",
      "Epoch 1/1\n",
      " 88128/100736 [=========================>....] - ETA: 1s - loss: 0.7928"
     ]
    }
   ],
   "source": [
    "import itertools\n",
    "features_arr = [2, 4, 8, 16, 32, 64, 128, 256]\n",
    "hidden_layers_arr = [2, 4, 6, 10]\n",
    "epoch_arr = [1]\n",
    "\n",
    "for e, h, f in itertools.product(epoch_arr, hidden_layers_arr, features_arr):\n",
    "    \n",
    "    print(\"Current Layer Attributes - epochs:{} hidden layers:{} features count:{}\".format(e,h,f))\n",
    "    latent_dim = f\n",
    "    epochs = e\n",
    "    hidden_layers = h\n",
    "\n",
    "    Train.train()\n",
    "\n",
    "    vae_model = Model(inputs = Train.x, outputs = Train.x_ )\n",
    "    vae_model.compile(optimizer = \"adam\", loss = \"mean_squared_error\" )\n",
    "\n",
    "    train_size = x_train.shape[0] - x_train.shape[0]%batch_size\n",
    "    valid_size = x_valid.shape[0] - x_valid.shape[0]%batch_size\n",
    "\n",
    "    vae_model.fit(x = x_train[:train_size,:], y = x_train[:train_size,:], \n",
    "                  shuffle=True, epochs=epochs, \n",
    "                  batch_size = batch_size, \n",
    "                  validation_data = (x_valid[:valid_size,:], x_valid[:valid_size,:]),\n",
    "                  verbose = 1)\n",
    "    #vae_model.evaluate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_pred = vae_model.predict(x_train[:train_size,:], batch_size = batch_size)\n",
    "pred_value = x_pred[:,-1]\n",
    "actual_value = y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import itertools\n",
    "\n",
    "def plot_confusion_matrix(cm, classes,\n",
    "                          normalize=False,\n",
    "                          title='Confusion matrix',\n",
    "                          cmap=plt.cm.Blues):\n",
    "    \"\"\"\n",
    "    This function prints and plots the confusion matrix.\n",
    "    Normalization can be applied by setting `normalize=True`.\n",
    "    \"\"\"\n",
    "    np.set_printoptions(precision=4)\n",
    "\n",
    "    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n",
    "    plt.title(title)\n",
    "    plt.colorbar()\n",
    "    tick_marks = np.arange(len(classes))\n",
    "    plt.xticks(tick_marks, classes, rotation=45)\n",
    "    plt.yticks(tick_marks, classes)\n",
    "\n",
    "    if normalize:\n",
    "        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "        print(\"Normalized confusion matrix\")\n",
    "    else:\n",
    "        print('Confusion matrix, without normalization')\n",
    "\n",
    "    print(cm)\n",
    "\n",
    "    thresh = cm.max() / 2.\n",
    "    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
    "        plt.text(j, i, cm[i, j].round(4),\n",
    "                 horizontalalignment=\"center\",\n",
    "                 color=\"white\" if cm[i, j] > thresh else \"black\")\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.ylabel('True label')\n",
    "    plt.xlabel('Predicted label')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "cm_2labels = confusion_matrix(y_pred = pred_value, y_true = actual_value)\n",
    "plt.figure(figsize=[6,6])\n",
    "plot_confusion_matrix(cm_2labels, output_columns_2labels, normalize = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "kdd_diff_level_train = pd.read_pickle(\"dataset/kdd_diff_level_train.pkl\")\n",
    "kdd_diff_level_test = pd.read_pickle(\"dataset/kdd_diff_level_test.pkl\")\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "_draft": {
   "nbviewer_url": "https://gist.github.com/441dbeee083527e615728d6d3057ba04"
  },
  "anaconda-cloud": {},
  "gist": {
   "data": {
    "description": "With Truth Table: Getting 90% accuracy with KDDTest+",
    "public": false
   },
   "id": "441dbeee083527e615728d6d3057ba04"
  },
  "kernelspec": {
   "display_name": "Python [conda env:p3]",
   "language": "python",
   "name": "conda-env-p3-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
