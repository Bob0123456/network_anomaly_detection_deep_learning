{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Deep Learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.layers import Input, Dense, Lambda, Layer\n",
    "from keras.models import Model\n",
    "from keras import regularizers\n",
    "import keras\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from keras import backend as K\n",
    "from keras import metrics\n",
    "from collections import namedtuple\n",
    "pd.set_option(\"display.max_rows\",15)\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "kdd_train_2labels = pd.read_pickle(\"dataset/kdd_train_2labels.pkl\")\n",
    "kdd_test_2labels = pd.read_pickle(\"dataset/kdd_test_2labels.pkl\")\n",
    "y_train_labels = pd.read_pickle(\"dataset/kdd_train_2labels_y.pkl\")\n",
    "y_test_labels = pd.read_pickle(\"dataset/kdd_test_2labels_y.pkl\")\n",
    "\n",
    "output_columns_2labels = ['is_Attack','is_Normal']\n",
    "\n",
    "from sklearn import model_selection as ms\n",
    "from sklearn import preprocessing as pp\n",
    "\n",
    "x_input = kdd_train_2labels.drop(output_columns_2labels, axis = 1)\n",
    "#y_output = kdd_train_2labels.loc[:,output_columns_2labels]\n",
    "\n",
    "ss = pp.StandardScaler()\n",
    "x_input = ss.fit_transform(x_input)\n",
    "\n",
    "le = pp.LabelEncoder()\n",
    "y_train = le.fit_transform(y_train_labels).reshape(-1, 1)\n",
    "y_test = le.transform(y_test_labels).reshape(-1, 1)\n",
    "\n",
    "\n",
    "x_train, x_valid, y_train, y_valid = ms.train_test_split(x_input, \n",
    "                              y_train, \n",
    "                              test_size=0.2)\n",
    "#x_valid, x_test, y_valid, y_test = ms.train_test_split(x_valid, y_valid, test_size = 0.4)\n",
    "\n",
    "x_test = kdd_test_2labels.drop(output_columns_2labels, axis = 1)\n",
    "#y_test = kdd_test_2labels.loc[:,output_columns_2labels]\n",
    "\n",
    "x_test = ss.transform(x_test)\n",
    "\n",
    "x_train = np.hstack((x_train, y_train))\n",
    "x_valid = np.hstack((x_valid, y_valid))\n",
    "\n",
    "x_test = np.hstack((x_test, np.random.normal(loc = 0, scale = 0.05, size = y_test.shape)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "input_dim = 123\n",
    "intermediate_dim = 80\n",
    "latent_dim = 32\n",
    "batch_size = 1409\n",
    "epochs = 5\n",
    "hidden_layers = 8\n",
    "\n",
    "class Train:\n",
    "    def train():\n",
    "        Train.x = Input(shape=(input_dim,))\n",
    "        \n",
    "        hidden_encoder = Train.x\n",
    "        for i in range(hidden_layers):\n",
    "            hidden_encoder = Dense(intermediate_dim, activation='relu')(hidden_encoder)\n",
    "\n",
    "        mean_encoder = Dense(latent_dim, activation=None)(hidden_encoder)\n",
    "\n",
    "        logvar_encoder = Dense(latent_dim, activation=None)(hidden_encoder)\n",
    "\n",
    "        def get_distrib(args):\n",
    "\n",
    "            mean_encoder, logvar_encoder = args\n",
    "\n",
    "            # Sample epsilon\n",
    "            epsilon = np.random.normal(loc=0.0, scale=0.05, size = (batch_size, latent_dim))\n",
    "\n",
    "            # Sample latent variable\n",
    "            z = mean_encoder + K.exp(logvar_encoder / 2) * epsilon\n",
    "            return z\n",
    "\n",
    "        z = Lambda(get_distrib)([mean_encoder, logvar_encoder])\n",
    "\n",
    "        hidden_decoder = z\n",
    "        for i in range(hidden_layers):\n",
    "            hidden_decoder = Dense(intermediate_dim, activation=\"relu\")(hidden_decoder)\n",
    "\n",
    "        Train.x_ = Dense(input_dim, activation=None)(hidden_decoder)\n",
    "\n",
    "def get_loss(x, x_):\n",
    "    xent_loss = input_dim * metrics.binary_crossentropy(x, x_) \n",
    "    kl_loss = - 0.5 * K.sum(1 + logvar_encoder - K.square(mean_encoder) - K.exp(logvar_encoder), axis=-1)\n",
    "    return K.abs(K.mean(xent_loss + kl_loss))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " \n",
      " Current Layer Attributes - epochs:1 hidden layers:2 features count:2\n",
      "16908/22544 [=====================>........] - ETA: 0s \n",
      " Current Layer Attributes - epochs:1 hidden layers:2 features count:4\n",
      "15499/22544 [===================>..........] - ETA: 0s \n",
      " Current Layer Attributes - epochs:1 hidden layers:2 features count:8\n",
      "16908/22544 [=====================>........] - ETA: 0s \n",
      " Current Layer Attributes - epochs:1 hidden layers:2 features count:16\n",
      "15499/22544 [===================>..........] - ETA: 0s \n",
      " Current Layer Attributes - epochs:1 hidden layers:2 features count:32\n",
      "14090/22544 [=================>............] - ETA: 0s \n",
      " Current Layer Attributes - epochs:1 hidden layers:2 features count:64\n",
      "12681/22544 [===============>..............] - ETA: 0s \n",
      " Current Layer Attributes - epochs:1 hidden layers:2 features count:128\n",
      "23953/23953 [==============================] - 0s     \n",
      "14090/22544 [=================>............] - ETA: 0s \n",
      " Current Layer Attributes - epochs:1 hidden layers:2 features count:256\n",
      "18317/22544 [=======================>......] - ETA: 0s \n",
      " Current Layer Attributes - epochs:1 hidden layers:4 features count:2\n",
      "12681/22544 [===============>..............] - ETA: 0s \n",
      " Current Layer Attributes - epochs:1 hidden layers:4 features count:4\n",
      "23953/23953 [==============================] - 0s     \n",
      "12681/22544 [===============>..............] - ETA: 0s \n",
      " Current Layer Attributes - epochs:1 hidden layers:4 features count:8\n",
      "12681/22544 [===============>..............] - ETA: 0s \n",
      " Current Layer Attributes - epochs:1 hidden layers:4 features count:16\n",
      "23953/23953 [==============================] - 0s     \n",
      "22544/22544 [==============================] - 0s     \n",
      " \n",
      " Current Layer Attributes - epochs:1 hidden layers:4 features count:32\n",
      "23953/23953 [==============================] - 0s     \n",
      "22544/22544 [==============================] - 0s     \n",
      " \n",
      " Current Layer Attributes - epochs:1 hidden layers:4 features count:64\n",
      "23953/23953 [==============================] - 0s     \n",
      "21135/22544 [===========================>..] - ETA: 0s \n",
      " Current Layer Attributes - epochs:1 hidden layers:4 features count:128\n",
      "21135/22544 [===========================>..] - ETA: 0s \n",
      " Current Layer Attributes - epochs:1 hidden layers:4 features count:256\n",
      "22544/22544 [==============================] - 0s     \n",
      " \n",
      " Current Layer Attributes - epochs:1 hidden layers:6 features count:2\n",
      "19726/22544 [=========================>....] - ETA: 0s \n",
      " Current Layer Attributes - epochs:1 hidden layers:6 features count:4\n",
      "19726/22544 [=========================>....] - ETA: 0s \n",
      " Current Layer Attributes - epochs:1 hidden layers:6 features count:8\n",
      "19726/22544 [=========================>....] - ETA: 0s \n",
      " Current Layer Attributes - epochs:1 hidden layers:6 features count:16\n",
      "18317/22544 [=======================>......] - ETA: 0s \n",
      " Current Layer Attributes - epochs:1 hidden layers:6 features count:32\n",
      "18317/22544 [=======================>......] - ETA: 0s \n",
      " Current Layer Attributes - epochs:1 hidden layers:6 features count:64\n",
      "18317/22544 [=======================>......] - ETA: 0s \n",
      " Current Layer Attributes - epochs:1 hidden layers:6 features count:128\n",
      "18317/22544 [=======================>......] - ETA: 0s \n",
      " Current Layer Attributes - epochs:1 hidden layers:6 features count:256\n",
      "22544/22544 [==============================] - 0s     \n",
      " \n",
      " Current Layer Attributes - epochs:1 hidden layers:10 features count:2\n",
      "21135/22544 [===========================>..] - ETA: 0s \n",
      " Current Layer Attributes - epochs:1 hidden layers:10 features count:4\n",
      "22544/22544 [==============================] - 0s     \n",
      " \n",
      " Current Layer Attributes - epochs:1 hidden layers:10 features count:8\n",
      "22544/22544 [==============================] - 0s     \n",
      " \n",
      " Current Layer Attributes - epochs:1 hidden layers:10 features count:16\n",
      "22544/22544 [==============================] - 0s     \n",
      " \n",
      " Current Layer Attributes - epochs:1 hidden layers:10 features count:32\n",
      "22544/22544 [==============================] - 0s     \n",
      " \n",
      " Current Layer Attributes - epochs:1 hidden layers:10 features count:64\n",
      "22544/22544 [==============================] - 0s     \n",
      " \n",
      " Current Layer Attributes - epochs:1 hidden layers:10 features count:128\n",
      "19726/22544 [=========================>....] - ETA: 0s \n",
      " Current Layer Attributes - epochs:1 hidden layers:10 features count:256\n",
      "23953/23953 [==============================] - 0s     \n",
      "18317/22544 [=======================>......] - ETA: 0s"
     ]
    }
   ],
   "source": [
    "import itertools\n",
    "features_arr = [2, 4, 8, 16, 32, 64, 128, 256]\n",
    "hidden_layers_arr = [2, 4, 6, 10]\n",
    "\n",
    "epoch_arr = [1]\n",
    "\n",
    "score = namedtuple(\"score\", ['epoch', 'no_of_features','hidden_layers','train_score', 'test_score'])\n",
    "scores = []\n",
    "predictions = pd.DataFrame()\n",
    "\n",
    "for e, h, f in itertools.product(epoch_arr, hidden_layers_arr, features_arr):\n",
    "    \n",
    "    print(\" \\n Current Layer Attributes - epochs:{} hidden layers:{} features count:{}\".format(e,h,f))\n",
    "    latent_dim = f\n",
    "    epochs = e\n",
    "    hidden_layers = h\n",
    "\n",
    "    Train.train()\n",
    "\n",
    "    vae_model = Model(inputs = Train.x, outputs = Train.x_ )\n",
    "    vae_model.compile(optimizer = \"adam\", loss = \"mean_squared_error\" )\n",
    "\n",
    "    train_size = x_train.shape[0] - x_train.shape[0]%batch_size\n",
    "    valid_size = x_valid.shape[0] - x_valid.shape[0]%batch_size\n",
    "\n",
    "    vae_model.fit(x = x_train[:train_size,:], y = x_train[:train_size,:], \n",
    "                  shuffle=True, epochs=epochs, \n",
    "                  batch_size = batch_size, \n",
    "                  validation_data = (x_valid[:valid_size,:], x_valid[:valid_size,:]),\n",
    "                  verbose = 0)\n",
    "    score_train = vae_model.evaluate(x_valid[:valid_size,:], y = x_valid[:valid_size,:],\n",
    "                               batch_size = batch_size,\n",
    "                               verbose = 1)\n",
    "    score_test = vae_model.evaluate(x_test, y = x_test,\n",
    "                           batch_size = batch_size,\n",
    "                           verbose = 1)\n",
    "    y_test_pred = vae_model.predict(x_test, batch_size=batch_size)\n",
    "    \n",
    "    y_pred = y_test_pred[:,-1]\n",
    "    \n",
    "    y_pred = y_test_pred[:,-1]\n",
    "    y_pred[y_pred >= y_test_pred[:,-1].mean()] = 1\n",
    "    y_pred[y_pred < y_test_pred[:,-1].mean()] = 0\n",
    "    #print (y_pred)\n",
    "    \n",
    "    scores.append(score(e,f,h,score_train, score_test))\n",
    "    curr_pred = pd.DataFrame({\"{}_{}_{}\".format(e,f,h):y_pred},)\n",
    "    predictions = pd.concat([predictions, curr_pred], axis = 1)\n",
    "    \n",
    "scores = pd.DataFrame(scores)\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "predictions.to_pickle(\"dataset/vae_only_predictions.pkl\")\n",
    "scores.to_pickle(\"dataset/vae_only_scores.pkl\")"
   ]
  }
 ],
 "metadata": {
  "_draft": {
   "nbviewer_url": "https://gist.github.com/441dbeee083527e615728d6d3057ba04"
  },
  "anaconda-cloud": {},
  "gist": {
   "data": {
    "description": "With Truth Table: Getting 90% accuracy with KDDTest+",
    "public": false
   },
   "id": "441dbeee083527e615728d6d3057ba04"
  },
  "kernelspec": {
   "display_name": "Python [conda env:p3]",
   "language": "python",
   "name": "conda-env-p3-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
