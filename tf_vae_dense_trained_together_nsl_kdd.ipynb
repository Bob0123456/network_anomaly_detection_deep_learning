{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Read Data Sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-05-15T18:00:29.301523Z",
     "start_time": "2017-05-15T18:00:28.768069Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "from collections import namedtuple\n",
    "pd.set_option(\"display.max_rows\",100)\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-05-15T18:00:29.392806Z",
     "start_time": "2017-05-15T18:00:29.303586Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class dataset:\n",
    "    kdd_train_2labels = pd.read_pickle(\"dataset/kdd_train_2labels.pkl\")\n",
    "    kdd_test_2labels = pd.read_pickle(\"dataset/kdd_test_2labels.pkl\")\n",
    "    \n",
    "    kdd_train_5labels = pd.read_pickle(\"dataset/kdd_train_5labels.pkl\")\n",
    "    kdd_test_5labels = pd.read_pickle(\"dataset/kdd_test_5labels.pkl\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-05-15T18:00:29.400310Z",
     "start_time": "2017-05-15T18:00:29.395261Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(125973, 124)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.kdd_train_2labels.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-05-15T18:00:29.406814Z",
     "start_time": "2017-05-15T18:00:29.401831Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(22544, 124)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.kdd_test_2labels.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-05-15T18:00:30.295010Z",
     "start_time": "2017-05-15T18:00:29.408799Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.99589320646770185"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn import model_selection as ms\n",
    "from sklearn import preprocessing as pp\n",
    "\n",
    "class preprocess:\n",
    "    \n",
    "    output_columns_2labels = ['is_Attack','is_Normal']\n",
    "    \n",
    "    x_input = dataset.kdd_train_2labels.drop(output_columns_2labels, axis = 1)\n",
    "    y_output = dataset.kdd_train_2labels.loc[:,output_columns_2labels]\n",
    "\n",
    "    x_test_input = dataset.kdd_test_2labels.drop(output_columns_2labels, axis = 1)\n",
    "    y_test = dataset.kdd_test_2labels.loc[:,output_columns_2labels]\n",
    "\n",
    "    ss = pp.StandardScaler()\n",
    "\n",
    "    x_train = ss.fit_transform(x_input)\n",
    "    x_test = ss.transform(x_test_input)\n",
    "\n",
    "    y_train = y_output.values\n",
    "    y_test = y_test.values\n",
    "\n",
    "preprocess.x_train.std()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-05-15T18:00:31.707224Z",
     "start_time": "2017-05-15T18:00:30.297018Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-05-15T18:00:32.361061Z",
     "start_time": "2017-05-15T18:00:31.709440Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class network(object):\n",
    "    \n",
    "    input_dim = 122\n",
    "    classes = 2\n",
    "    hidden_encoder_dim = 122\n",
    "    hidden_layers = 1\n",
    "    latent_dim = 10\n",
    "\n",
    "    hidden_decoder_dim = 122\n",
    "    lam = 0.001\n",
    "    \n",
    "    def __init__(self, classes, hidden_layers, num_of_features):\n",
    "        self.classes = classes\n",
    "        self.hidden_layers = hidden_layers\n",
    "        self.latent_dim = num_of_features\n",
    "            \n",
    "    def build_layers(self):\n",
    "        tf.reset_default_graph()\n",
    "        #learning_rate = tf.Variable(initial_value=0.001)\n",
    "\n",
    "        input_dim = self.input_dim\n",
    "        classes = self.classes\n",
    "        hidden_encoder_dim = self.hidden_encoder_dim\n",
    "        hidden_layers = self.hidden_layers\n",
    "        latent_dim = self.latent_dim\n",
    "        hidden_decoder_dim = self.hidden_decoder_dim\n",
    "        lam = self.lam\n",
    "        \n",
    "        with tf.variable_scope(\"Input\"):\n",
    "            self.x = tf.placeholder(\"float\", shape=[None, input_dim])\n",
    "            self.y_ = tf.placeholder(\"float\", shape=[None, classes])\n",
    "            self.keep_prob = tf.placeholder(\"float\")\n",
    "        \n",
    "        with tf.variable_scope(\"Layer_Encoder\"):\n",
    "\n",
    "            hidden_encoder = tf.layers.dense(self.x, hidden_encoder_dim, activation = tf.nn.relu, kernel_regularizer=tf.nn.l2_loss)\n",
    "            hidden_encoder = tf.nn.dropout(hidden_encoder, self.keep_prob)\n",
    "            for h in range(hidden_layers - 1):\n",
    "                hidden_encoder = tf.layers.dense(hidden_encoder, hidden_encoder_dim, activation = tf.nn.relu, kernel_regularizer=tf.nn.l2_loss)\n",
    "                hidden_encoder = tf.nn.dropout(hidden_encoder, self.keep_prob)\n",
    "                \n",
    "        with tf.variable_scope(\"Layer_Mean\"):\n",
    "            mu_encoder = tf.layers.dense(hidden_encoder, latent_dim, activation = None, kernel_regularizer=tf.nn.l2_loss)\n",
    "\n",
    "        with tf.variable_scope(\"Layer_Variance\"):\n",
    "            logvar_encoder = tf.layers.dense(hidden_encoder, latent_dim, activation = None, kernel_regularizer=tf.nn.l2_loss)\n",
    "\n",
    "        with tf.variable_scope(\"Sampling_Distribution\"):\n",
    "            # Sample epsilon\n",
    "            epsilon = tf.random_normal(tf.shape(logvar_encoder), mean=0, stddev=1, name='epsilon')\n",
    "\n",
    "            # Sample latent variable\n",
    "            std_encoder = tf.exp(0.5 * logvar_encoder)\n",
    "            z = mu_encoder + tf.multiply(std_encoder, epsilon)\n",
    "            \n",
    "            #tf.summary.histogram(\"Sample_Distribution\", z)\n",
    "\n",
    "        with tf.variable_scope(\"Layer_Decoder\"):\n",
    "            hidden_decoder = tf.layers.dense(z, hidden_decoder_dim, activation = tf.nn.relu, kernel_regularizer=tf.nn.l2_loss)\n",
    "            hidden_decoder = tf.nn.dropout(hidden_decoder, self.keep_prob)\n",
    "            for h in range(hidden_layers - 1):\n",
    "                hidden_decoder = tf.layers.dense(hidden_decoder, hidden_decoder_dim, activation = tf.nn.relu, kernel_regularizer=tf.nn.l2_loss)\n",
    "                hidden_decoder = tf.nn.dropout(hidden_decoder, self.keep_prob)\n",
    "                \n",
    "        with tf.variable_scope(\"Layer_Reconstruction\"):\n",
    "            x_hat = tf.layers.dense(hidden_decoder, input_dim, activation = None)\n",
    "            \n",
    "        with tf.variable_scope(\"Layer_Dense_Hidden\"):\n",
    "            hidden_output = tf.layers.dense(z,latent_dim, activation=tf.nn.relu)\n",
    "\n",
    "        with tf.variable_scope(\"Layer_Dense_Softmax\"):\n",
    "            self.y = tf.layers.dense(z, classes, activation=tf.nn.softmax)\n",
    "\n",
    "        with tf.variable_scope(\"Loss\"):\n",
    "            \n",
    "            BCE = tf.reduce_mean(tf.nn.sigmoid_cross_entropy_with_logits(logits=x_hat, labels=self.x), reduction_indices=1)\n",
    "            KLD = -0.5 * tf.reduce_mean(1 + logvar_encoder - tf.pow(mu_encoder, 2) - tf.exp(logvar_encoder), reduction_indices=1)\n",
    "            softmax_loss = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(labels = self.y_, logits = self.y))\n",
    "\n",
    "            loss = tf.reduce_mean((BCE + KLD + softmax_loss) * lam)\n",
    "\n",
    "            #loss = tf.clip_by_value(loss, -1e-2, 1e-2)\n",
    "            #loss = tf.where(tf.is_nan(loss), 1e-2, loss)\n",
    "            #loss = tf.where(tf.equal(loss, -1e-2), tf.random_normal(loss.shape), loss)\n",
    "            #loss = tf.where(tf.equal(loss, 1e-2), tf.random_normal(loss.shape), loss)\n",
    "            \n",
    "            self.regularized_loss = tf.abs(loss, name = \"Regularized_loss\")\n",
    "            correct_prediction = tf.equal(tf.argmax(self.y_, 1), tf.argmax(self.y, 1))\n",
    "            self.tf_accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32), name = \"Accuracy\")\n",
    "\n",
    "        with tf.variable_scope(\"Optimizer\"):\n",
    "            learning_rate=1e-2\n",
    "            optimizer = tf.train.AdamOptimizer(learning_rate)\n",
    "            gradients, variables = zip(*optimizer.compute_gradients(self.regularized_loss))\n",
    "            gradients = [\n",
    "                None if gradient is None else tf.clip_by_value(gradient, -1, 1)\n",
    "                for gradient in gradients]\n",
    "            self.train_op = optimizer.apply_gradients(zip(gradients, variables))\n",
    "            #self.train_op = optimizer.minimize(self.regularized_loss)\n",
    "            \n",
    "        # add op for merging summary\n",
    "        #self.summary_op = tf.summary.merge_all()\n",
    "        self.pred = tf.argmax(self.y, axis = 1)\n",
    "        self.actual = tf.argmax(self.y_, axis = 1)\n",
    "\n",
    "        # add Saver ops\n",
    "        self.saver = tf.train.Saver()\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-05-15T18:00:32.579994Z",
     "start_time": "2017-05-15T18:00:32.363203Z"
    },
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import collections\n",
    "\n",
    "class Train:    \n",
    "    \n",
    "    result = namedtuple(\"score\", ['epoch', 'no_of_features','hidden_layers','train_score', 'test_score'])\n",
    "\n",
    "    predictions = {}\n",
    "\n",
    "    results = []\n",
    "    best_acc = 0\n",
    "    \n",
    "    def train(epochs, net, h,f):\n",
    "        batch_iterations = 200\n",
    "        train_loss = None\n",
    "        Train.best_acc = 0\n",
    "        os.makedirs(\"dataset/tf_vae_dense_trained_together_nsl_kdd/hidden layers_{}_features count_{}\".format(epochs,h,f),\n",
    "                    exist_ok = True)\n",
    "\n",
    "        with tf.Session() as sess:\n",
    "            #summary_writer_train = tf.summary.FileWriter('./logs/kdd/VAE/training', graph=sess.graph)\n",
    "            #summary_writer_valid = tf.summary.FileWriter('./logs/kdd/VAE/validation')\n",
    "\n",
    "            sess.run(tf.global_variables_initializer())\n",
    "            Train.best_acc = 0\n",
    "            for epoch in range(1, (epochs+1)):\n",
    "                x_train, x_valid, y_train, y_valid, = ms.train_test_split(preprocess.x_train, \n",
    "                                                                          preprocess.y_train, \n",
    "                                                                          test_size=0.2)\n",
    "                batch_indices = np.array_split(np.arange(x_train.shape[0]), \n",
    "                                           batch_iterations)\n",
    "                                                                          \n",
    "                for i in batch_indices:\n",
    "                    \n",
    "                    def train_batch():\n",
    "                        nonlocal train_loss\n",
    "                        _, train_loss = sess.run([net.train_op, \n",
    "                                                               net.regularized_loss, \n",
    "                                                               ], #net.summary_op\n",
    "                                                              feed_dict={net.x: x_train[i,:], \n",
    "                                                                         net.y_: y_train[i,:], \n",
    "                                                                         net.keep_prob:1})\n",
    "                    \n",
    "                    train_batch()\n",
    "                    count = 10\n",
    "                    while((train_loss > 1e4 or np.isnan(train_loss)) and epoch > 1 and count < 1):\n",
    "                        print(\"Step {} | High Training Loss: {:.6f} ... Restoring Net\".format(epoch, train_loss))\n",
    "                        net.saver.restore(sess, \n",
    "                                          tf.train.latest_checkpoint('dataset/tf_vae_dense_trained_together_nsl_kdd/hidden layers_{}_features count_{}'\n",
    "                                                                     .format(epochs,h,f)))\n",
    "                        train_batch()\n",
    "                        count -= 1\n",
    "                    \n",
    "                valid_loss, valid_accuracy = sess.run([net.regularized_loss, net.tf_accuracy], #net.summary_op\n",
    "                                                          feed_dict={net.x: x_valid, \n",
    "                                                                     net.y_: y_valid, \n",
    "                                                                     net.keep_prob:1})\n",
    "                \n",
    "                test_accuracy, test_loss, pred_value, actual_value, y_pred = sess.run([net.tf_accuracy, net.regularized_loss, net.pred, \n",
    "                                                                                  net.actual, net.y], #net.summary_op \n",
    "                                                                                  feed_dict={net.x: preprocess.x_test, \n",
    "                                                                                 net.y_: preprocess.y_test, \n",
    "                                                                                 net.keep_prob:1})\n",
    "                #summary_writer_valid.add_summary(summary_str, epoch)\n",
    "\n",
    "                if epoch % 1 == 0:\n",
    "                    print(\"Step {} | Training Loss: {:.6f} | Test Loss: {:.6f} | Test Accuracy: {:.6f}\"\n",
    "                          .format(epoch, train_loss, test_loss, test_accuracy))\n",
    "\n",
    "                if test_accuracy > Train.best_acc:\n",
    "                    Train.best_acc = test_accuracy\n",
    "                    Train.pred_value = pred_value\n",
    "                    Train.actual_value = actual_value\n",
    "                    Train.best_parameters = \"Hidden Layers:{}, Features Count:{}\".format(h, f)\n",
    "                    if not (np.isnan(train_loss)):\n",
    "                        net.saver.save(sess, \n",
    "                                   \"dataset/tf_vae_dense_trained_together_nsl_kdd/hidden layers_{}_features count_{}/model\"\n",
    "                                   .format(epochs,h,f), \n",
    "                                   global_step = epoch, \n",
    "                                   write_meta_graph=False)\n",
    "                    \n",
    "                    curr_pred = pd.DataFrame({\"Attack_prob\":y_pred[:,-2], \"Normal_prob\":y_pred[:, -1], \"Prediction\":pred_value})\n",
    "                    Train.predictions.update({\"{}_{}_{}\".format(epochs,f,h):\n",
    "                                              (curr_pred, \n",
    "                                               Train.result(epochs, f, h,valid_accuracy, test_accuracy))})\n",
    "                    #Train.results.append(Train.result(epochs, f, h,valid_accuracy, test_accuracy))\n",
    "            print(\"Best Accuracy on Test data: {}\".format(Train.best_acc))\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-05-15T19:22:55.623797Z",
     "start_time": "2017-05-15T18:00:32.581788Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current Layer Attributes - epochs:100 hidden layers:2 features count:4\n",
      "Step 1 | Training Loss: 0.000222 | Test Loss: 0.000432 | Test Accuracy: 0.764860\n",
      "Step 2 | Training Loss: 0.000095 | Test Loss: 0.000330 | Test Accuracy: 0.787527\n",
      "Step 3 | Training Loss: 0.000123 | Test Loss: 0.000588 | Test Accuracy: 0.823989\n",
      "Step 4 | Training Loss: 0.000082 | Test Loss: 0.000165 | Test Accuracy: 0.855749\n",
      "Step 5 | Training Loss: 0.000110 | Test Loss: 0.000620 | Test Accuracy: 0.677342\n",
      "Step 6 | Training Loss: 0.000082 | Test Loss: 0.000291 | Test Accuracy: 0.775284\n",
      "Step 7 | Training Loss: 0.000031 | Test Loss: 0.000264 | Test Accuracy: 0.804249\n",
      "Step 8 | Training Loss: 0.000001 | Test Loss: 0.000266 | Test Accuracy: 0.812012\n",
      "Step 9 | Training Loss: 0.000041 | Test Loss: 0.000285 | Test Accuracy: 0.813919\n",
      "Step 10 | Training Loss: 0.000086 | Test Loss: 0.000292 | Test Accuracy: 0.822480\n",
      "Step 11 | Training Loss: 0.000066 | Test Loss: 0.000254 | Test Accuracy: 0.842264\n",
      "Step 12 | Training Loss: 0.000025 | Test Loss: 0.000291 | Test Accuracy: 0.846966\n",
      "Step 13 | Training Loss: 0.000049 | Test Loss: 0.000253 | Test Accuracy: 0.829134\n",
      "Step 14 | Training Loss: 0.000032 | Test Loss: 0.000279 | Test Accuracy: 0.810282\n",
      "Step 15 | Training Loss: 0.000027 | Test Loss: 0.000292 | Test Accuracy: 0.822480\n",
      "Step 16 | Training Loss: 0.000027 | Test Loss: 0.000320 | Test Accuracy: 0.823767\n",
      "Step 17 | Training Loss: 0.000019 | Test Loss: 0.000306 | Test Accuracy: 0.841599\n",
      "Step 18 | Training Loss: 0.000073 | Test Loss: 0.000305 | Test Accuracy: 0.826029\n",
      "Step 19 | Training Loss: 0.000037 | Test Loss: 0.000263 | Test Accuracy: 0.826694\n",
      "Step 20 | Training Loss: 0.000154 | Test Loss: 0.000283 | Test Accuracy: 0.829711\n",
      "Step 21 | Training Loss: 0.000089 | Test Loss: 0.000318 | Test Accuracy: 0.817867\n",
      "Step 22 | Training Loss: 0.000010 | Test Loss: 0.000283 | Test Accuracy: 0.818932\n",
      "Step 23 | Training Loss: 0.000071 | Test Loss: 0.000242 | Test Accuracy: 0.836498\n",
      "Step 24 | Training Loss: 0.000062 | Test Loss: 0.000143 | Test Accuracy: 0.851801\n",
      "Step 25 | Training Loss: 0.000078 | Test Loss: 0.000247 | Test Accuracy: 0.829844\n",
      "Step 26 | Training Loss: 0.000060 | Test Loss: 0.000206 | Test Accuracy: 0.849583\n",
      "Step 27 | Training Loss: 0.000015 | Test Loss: 0.000201 | Test Accuracy: 0.848518\n",
      "Step 28 | Training Loss: 0.000004 | Test Loss: 0.000215 | Test Accuracy: 0.831263\n",
      "Step 29 | Training Loss: 0.000002 | Test Loss: 0.000229 | Test Accuracy: 0.837252\n",
      "Step 30 | Training Loss: 0.000072 | Test Loss: 0.000245 | Test Accuracy: 0.852200\n",
      "Step 31 | Training Loss: 0.000022 | Test Loss: 0.000218 | Test Accuracy: 0.843062\n",
      "Step 32 | Training Loss: 0.000044 | Test Loss: 0.000237 | Test Accuracy: 0.849627\n",
      "Step 33 | Training Loss: 0.000076 | Test Loss: 0.000125 | Test Accuracy: 0.850869\n",
      "Step 34 | Training Loss: 0.000031 | Test Loss: 0.000133 | Test Accuracy: 0.855216\n",
      "Step 35 | Training Loss: 0.000007 | Test Loss: 0.000149 | Test Accuracy: 0.857301\n",
      "Step 36 | Training Loss: 0.000047 | Test Loss: 0.000106 | Test Accuracy: 0.858943\n",
      "Step 37 | Training Loss: 0.000007 | Test Loss: 0.000120 | Test Accuracy: 0.866661\n",
      "Step 38 | Training Loss: 0.000091 | Test Loss: 0.000086 | Test Accuracy: 0.860761\n",
      "Step 39 | Training Loss: 0.000004 | Test Loss: 0.000159 | Test Accuracy: 0.865241\n",
      "Step 40 | Training Loss: 0.000011 | Test Loss: 0.000196 | Test Accuracy: 0.871097\n",
      "Step 41 | Training Loss: 0.000047 | Test Loss: 0.000170 | Test Accuracy: 0.871230\n",
      "Step 42 | Training Loss: 0.000023 | Test Loss: 0.000186 | Test Accuracy: 0.869012\n",
      "Step 43 | Training Loss: 0.000006 | Test Loss: 0.000256 | Test Accuracy: 0.855261\n",
      "Step 44 | Training Loss: 0.000006 | Test Loss: 0.000183 | Test Accuracy: 0.848829\n",
      "Step 45 | Training Loss: 0.000007 | Test Loss: 0.000192 | Test Accuracy: 0.860495\n",
      "Step 46 | Training Loss: 0.000097 | Test Loss: 0.000100 | Test Accuracy: 0.864265\n",
      "Step 47 | Training Loss: 0.000005 | Test Loss: 0.000117 | Test Accuracy: 0.859076\n",
      "Step 48 | Training Loss: 0.000047 | Test Loss: 0.000035 | Test Accuracy: 0.871185\n",
      "Step 49 | Training Loss: 0.000024 | Test Loss: 0.000111 | Test Accuracy: 0.860672\n",
      "Step 50 | Training Loss: 0.000041 | Test Loss: 0.000080 | Test Accuracy: 0.848652\n",
      "Step 51 | Training Loss: 0.000061 | Test Loss: 0.000191 | Test Accuracy: 0.838139\n",
      "Step 52 | Training Loss: 0.000014 | Test Loss: 0.000120 | Test Accuracy: 0.839203\n",
      "Step 53 | Training Loss: 0.000016 | Test Loss: 0.000132 | Test Accuracy: 0.833348\n",
      "Step 54 | Training Loss: 0.000019 | Test Loss: 0.000052 | Test Accuracy: 0.835566\n",
      "Step 55 | Training Loss: 0.000035 | Test Loss: 0.000043 | Test Accuracy: 0.841066\n",
      "Step 56 | Training Loss: 0.000017 | Test Loss: 0.000102 | Test Accuracy: 0.834457\n",
      "Step 57 | Training Loss: 0.000001 | Test Loss: 0.000073 | Test Accuracy: 0.837784\n",
      "Step 58 | Training Loss: 0.000036 | Test Loss: 0.000061 | Test Accuracy: 0.843683\n",
      "Step 59 | Training Loss: 0.000016 | Test Loss: 0.000114 | Test Accuracy: 0.844748\n",
      "Step 60 | Training Loss: 0.000004 | Test Loss: 0.000152 | Test Accuracy: 0.847232\n",
      "Step 61 | Training Loss: 0.000051 | Test Loss: 0.000160 | Test Accuracy: 0.845502\n",
      "Step 62 | Training Loss: 0.000039 | Test Loss: 0.000129 | Test Accuracy: 0.851357\n",
      "Step 63 | Training Loss: 0.000049 | Test Loss: 0.000086 | Test Accuracy: 0.849184\n",
      "Step 64 | Training Loss: 0.000027 | Test Loss: 0.000127 | Test Accuracy: 0.862003\n",
      "Step 65 | Training Loss: 0.000062 | Test Loss: 0.000171 | Test Accuracy: 0.852954\n",
      "Step 66 | Training Loss: 0.000003 | Test Loss: 0.000122 | Test Accuracy: 0.861914\n",
      "Step 67 | Training Loss: 0.000001 | Test Loss: 0.000136 | Test Accuracy: 0.862003\n",
      "Step 68 | Training Loss: 0.000048 | Test Loss: 0.000137 | Test Accuracy: 0.868479\n",
      "Step 69 | Training Loss: 0.000020 | Test Loss: 0.000179 | Test Accuracy: 0.865241\n",
      "Step 70 | Training Loss: 0.000041 | Test Loss: 0.000100 | Test Accuracy: 0.842441\n",
      "Step 71 | Training Loss: 0.000038 | Test Loss: 0.000177 | Test Accuracy: 0.855483\n",
      "Step 72 | Training Loss: 0.000047 | Test Loss: 0.000179 | Test Accuracy: 0.866040\n",
      "Step 73 | Training Loss: 0.000026 | Test Loss: 0.000185 | Test Accuracy: 0.855749\n",
      "Step 74 | Training Loss: 0.000029 | Test Loss: 0.000174 | Test Accuracy: 0.853487\n",
      "Step 75 | Training Loss: 0.000021 | Test Loss: 0.000144 | Test Accuracy: 0.859386\n",
      "Step 76 | Training Loss: 0.000049 | Test Loss: 0.000189 | Test Accuracy: 0.854152\n",
      "Step 77 | Training Loss: 0.000045 | Test Loss: 0.000152 | Test Accuracy: 0.850958\n",
      "Step 78 | Training Loss: 0.000049 | Test Loss: 0.000131 | Test Accuracy: 0.850914\n",
      "Step 79 | Training Loss: 0.000047 | Test Loss: 0.000188 | Test Accuracy: 0.858366\n",
      "Step 80 | Training Loss: 0.000072 | Test Loss: 0.000156 | Test Accuracy: 0.864354\n",
      "Step 81 | Training Loss: 0.000035 | Test Loss: 0.000114 | Test Accuracy: 0.850869\n",
      "Step 82 | Training Loss: 0.000004 | Test Loss: 0.000113 | Test Accuracy: 0.860983\n",
      "Step 83 | Training Loss: 0.000043 | Test Loss: 0.000102 | Test Accuracy: 0.860140\n",
      "Step 84 | Training Loss: 0.000084 | Test Loss: 0.000169 | Test Accuracy: 0.872072\n",
      "Step 85 | Training Loss: 0.000026 | Test Loss: 0.000141 | Test Accuracy: 0.864443\n",
      "Step 86 | Training Loss: 0.000032 | Test Loss: 0.000155 | Test Accuracy: 0.866971\n",
      "Step 87 | Training Loss: 0.000014 | Test Loss: 0.000196 | Test Accuracy: 0.877040\n",
      "Step 88 | Training Loss: 0.000007 | Test Loss: 0.000136 | Test Accuracy: 0.864532\n",
      "Step 89 | Training Loss: 0.000012 | Test Loss: 0.000173 | Test Accuracy: 0.862269\n",
      "Step 90 | Training Loss: 0.000015 | Test Loss: 0.000124 | Test Accuracy: 0.874113\n",
      "Step 91 | Training Loss: 0.000030 | Test Loss: 0.000136 | Test Accuracy: 0.862358\n",
      "Step 92 | Training Loss: 0.000069 | Test Loss: 0.000062 | Test Accuracy: 0.862003\n",
      "Step 93 | Training Loss: 0.000046 | Test Loss: 0.000123 | Test Accuracy: 0.868435\n",
      "Step 94 | Training Loss: 0.000049 | Test Loss: 0.000107 | Test Accuracy: 0.885646\n",
      "Step 95 | Training Loss: 0.000033 | Test Loss: 0.000138 | Test Accuracy: 0.867016\n",
      "Step 96 | Training Loss: 0.000036 | Test Loss: 0.000128 | Test Accuracy: 0.874068\n",
      "Step 97 | Training Loss: 0.000021 | Test Loss: 0.000116 | Test Accuracy: 0.870254\n",
      "Step 98 | Training Loss: 0.000055 | Test Loss: 0.000101 | Test Accuracy: 0.859164\n",
      "Step 99 | Training Loss: 0.000053 | Test Loss: 0.000121 | Test Accuracy: 0.873891\n",
      "Step 100 | Training Loss: 0.000006 | Test Loss: 0.000141 | Test Accuracy: 0.877839\n",
      "Best Accuracy on Test data: 0.885645866394043\n",
      "Current Layer Attributes - epochs:100 hidden layers:2 features count:8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 1 | Training Loss: 0.000103 | Test Loss: 0.000073 | Test Accuracy: 0.783135\n",
      "Step 2 | Training Loss: 0.000124 | Test Loss: 0.000482 | Test Accuracy: 0.783978\n",
      "Step 3 | Training Loss: 0.000036 | Test Loss: 0.000253 | Test Accuracy: 0.786196\n",
      "Step 4 | Training Loss: 0.000238 | Test Loss: 164265967616.000000 | Test Accuracy: 0.792539\n",
      "Step 5 | Training Loss: 0.000080 | Test Loss: 0.000307 | Test Accuracy: 0.782958\n",
      "Step 6 | Training Loss: 0.000183 | Test Loss: 0.000252 | Test Accuracy: 0.807709\n",
      "Step 7 | Training Loss: 0.000007 | Test Loss: 0.000282 | Test Accuracy: 0.804161\n",
      "Step 8 | Training Loss: 0.000103 | Test Loss: 0.000251 | Test Accuracy: 0.825586\n",
      "Step 9 | Training Loss: 0.000004 | Test Loss: 0.000201 | Test Accuracy: 0.823456\n",
      "Step 10 | Training Loss: 0.000469 | Test Loss: 0.000285 | Test Accuracy: 0.814363\n",
      "Step 11 | Training Loss: 0.000008 | Test Loss: 0.000226 | Test Accuracy: 0.843196\n",
      "Step 12 | Training Loss: 0.000034 | Test Loss: 0.000163 | Test Accuracy: 0.844304\n",
      "Step 13 | Training Loss: 0.000003 | Test Loss: 0.000103 | Test Accuracy: 0.846345\n",
      "Step 14 | Training Loss: 0.000010 | Test Loss: 0.000141 | Test Accuracy: 0.840135\n",
      "Step 15 | Training Loss: 0.000009 | Test Loss: 0.000095 | Test Accuracy: 0.846434\n",
      "Step 16 | Training Loss: 0.000002 | Test Loss: 0.000141 | Test Accuracy: 0.850781\n",
      "Step 17 | Training Loss: 0.000001 | Test Loss: 0.000131 | Test Accuracy: 0.842308\n",
      "Step 18 | Training Loss: 0.000008 | Test Loss: 0.000089 | Test Accuracy: 0.842220\n",
      "Step 19 | Training Loss: 0.000032 | Test Loss: 0.000134 | Test Accuracy: 0.823989\n",
      "Step 20 | Training Loss: 0.000086 | Test Loss: 0.000125 | Test Accuracy: 0.838449\n",
      "Step 21 | Training Loss: 0.000011 | Test Loss: 0.000131 | Test Accuracy: 0.823722\n",
      "Step 22 | Training Loss: 0.000035 | Test Loss: 0.000146 | Test Accuracy: 0.828424\n",
      "Step 23 | Training Loss: 0.000041 | Test Loss: 0.000149 | Test Accuracy: 0.823412\n",
      "Step 24 | Training Loss: 0.000019 | Test Loss: 0.000175 | Test Accuracy: 0.828735\n",
      "Step 25 | Training Loss: 0.000000 | Test Loss: 0.000112 | Test Accuracy: 0.825807\n",
      "Step 26 | Training Loss: 0.000028 | Test Loss: 0.000091 | Test Accuracy: 0.831130\n",
      "Step 27 | Training Loss: 0.000012 | Test Loss: 0.000104 | Test Accuracy: 0.829578\n",
      "Step 28 | Training Loss: 0.000045 | Test Loss: 0.000123 | Test Accuracy: 0.829179\n",
      "Step 29 | Training Loss: 0.000049 | Test Loss: 0.000085 | Test Accuracy: 0.833526\n",
      "Step 30 | Training Loss: 0.000027 | Test Loss: 0.000114 | Test Accuracy: 0.827182\n",
      "Step 31 | Training Loss: 0.000040 | Test Loss: 0.000113 | Test Accuracy: 0.828912\n",
      "Step 32 | Training Loss: 0.000003 | Test Loss: 0.000130 | Test Accuracy: 0.826961\n",
      "Step 33 | Training Loss: 0.000016 | Test Loss: 0.000114 | Test Accuracy: 0.824477\n",
      "Step 34 | Training Loss: 0.000004 | Test Loss: 0.000132 | Test Accuracy: 0.825985\n",
      "Step 35 | Training Loss: 0.000067 | Test Loss: 0.000075 | Test Accuracy: 0.821283\n",
      "Step 36 | Training Loss: 0.000038 | Test Loss: 0.000123 | Test Accuracy: 0.817335\n",
      "Step 37 | Training Loss: 0.000055 | Test Loss: 0.000215 | Test Accuracy: 0.821771\n",
      "Step 38 | Training Loss: 0.000016 | Test Loss: 0.000127 | Test Accuracy: 0.827449\n",
      "Step 39 | Training Loss: 0.000045 | Test Loss: 0.000176 | Test Accuracy: 0.825364\n",
      "Step 40 | Training Loss: 0.000073 | Test Loss: 0.000224 | Test Accuracy: 0.824876\n",
      "Step 41 | Training Loss: 0.000005 | Test Loss: 0.000185 | Test Accuracy: 0.826428\n",
      "Step 42 | Training Loss: 0.000018 | Test Loss: 0.000129 | Test Accuracy: 0.842087\n",
      "Step 43 | Training Loss: 0.000033 | Test Loss: 0.000095 | Test Accuracy: 0.840179\n",
      "Step 44 | Training Loss: 0.000065 | Test Loss: 0.000115 | Test Accuracy: 0.842397\n",
      "Step 45 | Training Loss: 0.000061 | Test Loss: 0.000105 | Test Accuracy: 0.846700\n",
      "Step 46 | Training Loss: 0.000022 | Test Loss: 0.000093 | Test Accuracy: 0.846833\n",
      "Step 47 | Training Loss: 0.000032 | Test Loss: 0.000098 | Test Accuracy: 0.845369\n",
      "Step 48 | Training Loss: 0.000051 | Test Loss: 0.000198 | Test Accuracy: 0.843462\n",
      "Step 49 | Training Loss: 0.000027 | Test Loss: 0.000101 | Test Accuracy: 0.844127\n",
      "Step 50 | Training Loss: 0.000035 | Test Loss: 0.000122 | Test Accuracy: 0.843994\n",
      "Step 51 | Training Loss: 0.000033 | Test Loss: 0.000168 | Test Accuracy: 0.827892\n",
      "Step 52 | Training Loss: 0.000010 | Test Loss: 0.000133 | Test Accuracy: 0.829445\n",
      "Step 53 | Training Loss: 0.000014 | Test Loss: 0.000119 | Test Accuracy: 0.823767\n",
      "Step 54 | Training Loss: 0.000001 | Test Loss: 0.000129 | Test Accuracy: 0.834590\n",
      "Step 55 | Training Loss: 0.000002 | Test Loss: 0.000171 | Test Accuracy: 0.845768\n",
      "Step 56 | Training Loss: 0.000044 | Test Loss: 0.000148 | Test Accuracy: 0.833259\n",
      "Step 57 | Training Loss: 0.000011 | Test Loss: 0.000175 | Test Accuracy: 0.831884\n",
      "Step 58 | Training Loss: 0.000011 | Test Loss: 0.000150 | Test Accuracy: 0.822569\n",
      "Step 59 | Training Loss: 0.000005 | Test Loss: 0.000195 | Test Accuracy: 0.811036\n",
      "Step 60 | Training Loss: 0.000031 | Test Loss: 0.000206 | Test Accuracy: 0.810016\n",
      "Step 61 | Training Loss: 0.000031 | Test Loss: 0.000159 | Test Accuracy: 0.813077\n",
      "Step 62 | Training Loss: 0.000005 | Test Loss: 0.000131 | Test Accuracy: 0.820130\n",
      "Step 63 | Training Loss: 0.000027 | Test Loss: 0.000120 | Test Accuracy: 0.814851\n",
      "Step 64 | Training Loss: 0.000043 | Test Loss: 0.000143 | Test Accuracy: 0.822525\n",
      "Step 65 | Training Loss: 0.000061 | Test Loss: 0.000146 | Test Accuracy: 0.826828\n",
      "Step 66 | Training Loss: 0.000057 | Test Loss: 0.000197 | Test Accuracy: 0.824033\n",
      "Step 67 | Training Loss: 0.000050 | Test Loss: 0.000126 | Test Accuracy: 0.852244\n",
      "Step 68 | Training Loss: 0.000030 | Test Loss: 0.000145 | Test Accuracy: 0.847897\n",
      "Step 69 | Training Loss: 0.000075 | Test Loss: 0.000111 | Test Accuracy: 0.847809\n",
      "Step 70 | Training Loss: 0.000004 | Test Loss: 0.000181 | Test Accuracy: 0.846123\n",
      "Step 71 | Training Loss: 0.000050 | Test Loss: 0.000117 | Test Accuracy: 0.842308\n",
      "Step 72 | Training Loss: 0.000006 | Test Loss: 0.000145 | Test Accuracy: 0.836409\n",
      "Step 73 | Training Loss: 0.000030 | Test Loss: 0.000123 | Test Accuracy: 0.844171\n",
      "Step 74 | Training Loss: 0.000007 | Test Loss: 0.000125 | Test Accuracy: 0.849627\n",
      "Step 75 | Training Loss: 0.000019 | Test Loss: 0.000117 | Test Accuracy: 0.843595\n",
      "Step 76 | Training Loss: 0.000006 | Test Loss: 0.000152 | Test Accuracy: 0.836054\n",
      "Step 77 | Training Loss: 0.000022 | Test Loss: 0.000149 | Test Accuracy: 0.844393\n",
      "Step 78 | Training Loss: 0.000003 | Test Loss: 0.000142 | Test Accuracy: 0.849494\n",
      "Step 79 | Training Loss: 0.000027 | Test Loss: 0.000125 | Test Accuracy: 0.841066\n",
      "Step 80 | Training Loss: 0.000050 | Test Loss: 0.000088 | Test Accuracy: 0.849095\n",
      "Step 81 | Training Loss: 0.000030 | Test Loss: 0.000118 | Test Accuracy: 0.830997\n",
      "Step 82 | Training Loss: 0.000006 | Test Loss: 0.000118 | Test Accuracy: 0.845724\n",
      "Step 83 | Training Loss: 0.000021 | Test Loss: 0.000120 | Test Accuracy: 0.842308\n",
      "Step 84 | Training Loss: 0.000025 | Test Loss: 0.000106 | Test Accuracy: 0.843240\n",
      "Step 85 | Training Loss: 0.000014 | Test Loss: 0.000093 | Test Accuracy: 0.846877\n",
      "Step 86 | Training Loss: 0.000008 | Test Loss: 0.000090 | Test Accuracy: 0.839780\n",
      "Step 87 | Training Loss: 0.000003 | Test Loss: 0.000126 | Test Accuracy: 0.847942\n",
      "Step 88 | Training Loss: 0.000015 | Test Loss: 0.000131 | Test Accuracy: 0.850648\n",
      "Step 89 | Training Loss: 0.000037 | Test Loss: 0.000148 | Test Accuracy: 0.843683\n",
      "Step 90 | Training Loss: 0.000029 | Test Loss: 0.000119 | Test Accuracy: 0.842353\n",
      "Step 91 | Training Loss: 0.000056 | Test Loss: 0.000105 | Test Accuracy: 0.841332\n",
      "Step 92 | Training Loss: 0.000037 | Test Loss: 0.000135 | Test Accuracy: 0.827892\n",
      "Step 93 | Training Loss: 0.000035 | Test Loss: 0.000135 | Test Accuracy: 0.818355\n",
      "Step 94 | Training Loss: 0.000032 | Test Loss: 0.000106 | Test Accuracy: 0.828513\n",
      "Step 95 | Training Loss: 0.000035 | Test Loss: 0.000122 | Test Accuracy: 0.834368\n",
      "Step 96 | Training Loss: 0.000020 | Test Loss: 0.000110 | Test Accuracy: 0.832993\n",
      "Step 97 | Training Loss: 0.000013 | Test Loss: 0.000175 | Test Accuracy: 0.822880\n",
      "Step 98 | Training Loss: 0.000010 | Test Loss: 0.000125 | Test Accuracy: 0.827582\n",
      "Step 99 | Training Loss: 0.000024 | Test Loss: 0.000084 | Test Accuracy: 0.827892\n",
      "Step 100 | Training Loss: 0.000019 | Test Loss: 0.000131 | Test Accuracy: 0.825674\n",
      "Best Accuracy on Test data: 0.85224449634552\n",
      "Current Layer Attributes - epochs:100 hidden layers:2 features count:16\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 1 | Training Loss: 0.000026 | Test Loss: 0.000221 | Test Accuracy: 0.781627\n",
      "Step 2 | Training Loss: 0.000120 | Test Loss: 0.000183 | Test Accuracy: 0.804959\n",
      "Step 3 | Training Loss: 0.000125 | Test Loss: 0.000358 | Test Accuracy: 0.823944\n",
      "Step 4 | Training Loss: 0.000001 | Test Loss: 0.000244 | Test Accuracy: 0.837606\n",
      "Step 5 | Training Loss: 0.000092 | Test Loss: 0.000234 | Test Accuracy: 0.853841\n",
      "Step 6 | Training Loss: 0.000017 | Test Loss: 0.000170 | Test Accuracy: 0.862757\n",
      "Step 7 | Training Loss: 0.000070 | Test Loss: 0.000172 | Test Accuracy: 0.856680\n",
      "Step 8 | Training Loss: 0.000000 | Test Loss: 0.000156 | Test Accuracy: 0.868125\n",
      "Step 9 | Training Loss: 0.000013 | Test Loss: 0.000104 | Test Accuracy: 0.876464\n",
      "Step 10 | Training Loss: 0.000004 | Test Loss: 0.000115 | Test Accuracy: 0.870830\n",
      "Step 11 | Training Loss: 0.000049 | Test Loss: 0.000186 | Test Accuracy: 0.872339\n",
      "Step 12 | Training Loss: 0.000039 | Test Loss: 0.000166 | Test Accuracy: 0.874068\n",
      "Step 13 | Training Loss: 0.000091 | Test Loss: 0.000195 | Test Accuracy: 0.872383\n",
      "Step 14 | Training Loss: 0.000004 | Test Loss: 0.000153 | Test Accuracy: 0.872339\n",
      "Step 15 | Training Loss: 0.000029 | Test Loss: 0.000177 | Test Accuracy: 0.875310\n",
      "Step 16 | Training Loss: 0.000025 | Test Loss: 0.000176 | Test Accuracy: 0.876641\n",
      "Step 17 | Training Loss: 0.000013 | Test Loss: 0.000166 | Test Accuracy: 0.878504\n",
      "Step 18 | Training Loss: 0.000005 | Test Loss: 0.000147 | Test Accuracy: 0.877040\n",
      "Step 19 | Training Loss: 0.000042 | Test Loss: 0.000178 | Test Accuracy: 0.874379\n",
      "Step 20 | Training Loss: 0.000004 | Test Loss: 0.000173 | Test Accuracy: 0.876198\n",
      "Step 21 | Training Loss: 0.000026 | Test Loss: 0.000147 | Test Accuracy: 0.876597\n",
      "Step 22 | Training Loss: 0.000013 | Test Loss: 0.000185 | Test Accuracy: 0.877218\n",
      "Step 23 | Training Loss: 0.000021 | Test Loss: 0.000152 | Test Accuracy: 0.875310\n",
      "Step 24 | Training Loss: 0.000016 | Test Loss: 0.000165 | Test Accuracy: 0.878815\n",
      "Step 25 | Training Loss: 0.000040 | Test Loss: 0.000235 | Test Accuracy: 0.859475\n",
      "Step 26 | Training Loss: 0.000010 | Test Loss: 0.000162 | Test Accuracy: 0.856769\n",
      "Step 27 | Training Loss: 0.000021 | Test Loss: 0.000162 | Test Accuracy: 0.856902\n",
      "Step 28 | Training Loss: 0.000002 | Test Loss: 0.000208 | Test Accuracy: 0.856458\n",
      "Step 29 | Training Loss: 0.000041 | Test Loss: 0.000182 | Test Accuracy: 0.879347\n",
      "Step 30 | Training Loss: 0.000032 | Test Loss: 0.000128 | Test Accuracy: 0.870121\n",
      "Step 31 | Training Loss: 0.000007 | Test Loss: 0.000136 | Test Accuracy: 0.873048\n",
      "Step 32 | Training Loss: 0.000023 | Test Loss: 0.000122 | Test Accuracy: 0.865995\n",
      "Step 33 | Training Loss: 0.000027 | Test Loss: 0.000150 | Test Accuracy: 0.865552\n",
      "Step 34 | Training Loss: 0.000005 | Test Loss: 0.000154 | Test Accuracy: 0.871363\n",
      "Step 35 | Training Loss: 0.000007 | Test Loss: 0.000182 | Test Accuracy: 0.878061\n",
      "Step 36 | Training Loss: 0.000077 | Test Loss: 0.000165 | Test Accuracy: 0.875000\n",
      "Step 37 | Training Loss: 0.000001 | Test Loss: 0.000122 | Test Accuracy: 0.874823\n",
      "Step 38 | Training Loss: 0.000008 | Test Loss: 0.000111 | Test Accuracy: 0.878815\n",
      "Step 39 | Training Loss: 0.000007 | Test Loss: 0.000107 | Test Accuracy: 0.876774\n",
      "Step 40 | Training Loss: 0.000029 | Test Loss: 0.000103 | Test Accuracy: 0.877928\n",
      "Step 41 | Training Loss: 0.000003 | Test Loss: 0.000110 | Test Accuracy: 0.877307\n",
      "Step 42 | Training Loss: 0.000032 | Test Loss: 0.000094 | Test Accuracy: 0.877129\n",
      "Step 43 | Training Loss: 0.000004 | Test Loss: 0.000115 | Test Accuracy: 0.862048\n",
      "Step 44 | Training Loss: 0.000028 | Test Loss: 0.000154 | Test Accuracy: 0.853797\n",
      "Step 45 | Training Loss: 0.000001 | Test Loss: 0.000153 | Test Accuracy: 0.854107\n",
      "Step 46 | Training Loss: 0.000016 | Test Loss: 0.000149 | Test Accuracy: 0.853620\n",
      "Step 47 | Training Loss: 0.000006 | Test Loss: 0.000154 | Test Accuracy: 0.854196\n",
      "Step 48 | Training Loss: 0.000015 | Test Loss: 0.000142 | Test Accuracy: 0.855083\n",
      "Step 49 | Training Loss: 0.000065 | Test Loss: 0.000161 | Test Accuracy: 0.856059\n",
      "Step 50 | Training Loss: 0.000029 | Test Loss: 0.000141 | Test Accuracy: 0.858321\n",
      "Step 51 | Training Loss: 0.000010 | Test Loss: 0.000132 | Test Accuracy: 0.858410\n",
      "Step 52 | Training Loss: 0.000068 | Test Loss: 0.000201 | Test Accuracy: 0.858765\n",
      "Step 53 | Training Loss: 0.000046 | Test Loss: 0.000111 | Test Accuracy: 0.890703\n",
      "Step 54 | Training Loss: 0.000014 | Test Loss: 0.000118 | Test Accuracy: 0.882807\n",
      "Step 55 | Training Loss: 0.000021 | Test Loss: 0.000105 | Test Accuracy: 0.887376\n",
      "Step 56 | Training Loss: 0.000011 | Test Loss: 0.000147 | Test Accuracy: 0.876730\n",
      "Step 57 | Training Loss: 0.000014 | Test Loss: 0.000147 | Test Accuracy: 0.871540\n",
      "Step 58 | Training Loss: 0.000027 | Test Loss: 0.000202 | Test Accuracy: 0.873847\n",
      "Step 59 | Training Loss: 0.000016 | Test Loss: 0.000197 | Test Accuracy: 0.874956\n",
      "Step 60 | Training Loss: 0.000007 | Test Loss: 0.000180 | Test Accuracy: 0.877440\n",
      "Step 61 | Training Loss: 0.000010 | Test Loss: 0.000149 | Test Accuracy: 0.875887\n",
      "Step 62 | Training Loss: 0.000012 | Test Loss: 0.000142 | Test Accuracy: 0.874778\n",
      "Step 63 | Training Loss: 0.000036 | Test Loss: 0.000187 | Test Accuracy: 0.875355\n",
      "Step 64 | Training Loss: 0.000054 | Test Loss: 0.000184 | Test Accuracy: 0.877351\n",
      "Step 65 | Training Loss: 0.000052 | Test Loss: 0.000154 | Test Accuracy: 0.877573\n",
      "Step 66 | Training Loss: 0.000001 | Test Loss: 0.000127 | Test Accuracy: 0.879391\n",
      "Step 67 | Training Loss: 0.000002 | Test Loss: 0.000143 | Test Accuracy: 0.877040\n",
      "Step 68 | Training Loss: 0.000018 | Test Loss: 0.000105 | Test Accuracy: 0.881476\n",
      "Step 69 | Training Loss: 0.000009 | Test Loss: 0.000119 | Test Accuracy: 0.878948\n",
      "Step 70 | Training Loss: 0.000027 | Test Loss: 0.000112 | Test Accuracy: 0.881077\n",
      "Step 71 | Training Loss: 0.000004 | Test Loss: 0.000177 | Test Accuracy: 0.885114\n",
      "Step 72 | Training Loss: 0.000037 | Test Loss: 0.000150 | Test Accuracy: 0.883029\n",
      "Step 73 | Training Loss: 0.000002 | Test Loss: 0.000127 | Test Accuracy: 0.883694\n",
      "Step 74 | Training Loss: 0.000009 | Test Loss: 0.000140 | Test Accuracy: 0.886666\n",
      "Step 75 | Training Loss: 0.000029 | Test Loss: 0.000140 | Test Accuracy: 0.883738\n",
      "Step 76 | Training Loss: 0.000029 | Test Loss: 0.000132 | Test Accuracy: 0.881964\n",
      "Step 77 | Training Loss: 0.000033 | Test Loss: 0.000141 | Test Accuracy: 0.880944\n",
      "Step 78 | Training Loss: 0.000002 | Test Loss: 0.000109 | Test Accuracy: 0.881077\n",
      "Step 79 | Training Loss: 0.000020 | Test Loss: 0.000104 | Test Accuracy: 0.876819\n",
      "Step 80 | Training Loss: 0.000006 | Test Loss: 0.000160 | Test Accuracy: 0.881698\n",
      "Step 81 | Training Loss: 0.000012 | Test Loss: 0.000128 | Test Accuracy: 0.882674\n",
      "Step 82 | Training Loss: 0.000008 | Test Loss: 0.000079 | Test Accuracy: 0.880012\n",
      "Step 83 | Training Loss: 0.000050 | Test Loss: 0.000145 | Test Accuracy: 0.880900\n",
      "Step 84 | Training Loss: 0.000021 | Test Loss: 0.000149 | Test Accuracy: 0.896469\n",
      "Step 85 | Training Loss: 0.000012 | Test Loss: 0.000143 | Test Accuracy: 0.895360\n",
      "Step 86 | Training Loss: 0.000032 | Test Loss: 0.000142 | Test Accuracy: 0.895138\n",
      "Step 87 | Training Loss: 0.000027 | Test Loss: 0.000108 | Test Accuracy: 0.895405\n",
      "Step 88 | Training Loss: 0.000046 | Test Loss: 0.000105 | Test Accuracy: 0.894784\n",
      "Step 89 | Training Loss: 0.000037 | Test Loss: 0.000118 | Test Accuracy: 0.892743\n",
      "Step 90 | Training Loss: 0.000019 | Test Loss: 0.000141 | Test Accuracy: 0.892388\n",
      "Step 91 | Training Loss: 0.000011 | Test Loss: 0.000130 | Test Accuracy: 0.890348\n",
      "Step 92 | Training Loss: 0.000023 | Test Loss: 0.000103 | Test Accuracy: 0.893320\n",
      "Step 93 | Training Loss: 0.000041 | Test Loss: 0.000109 | Test Accuracy: 0.896336\n",
      "Step 94 | Training Loss: 0.000013 | Test Loss: 0.000132 | Test Accuracy: 0.892211\n",
      "Step 95 | Training Loss: 0.000043 | Test Loss: 0.000171 | Test Accuracy: 0.898510\n",
      "Step 96 | Training Loss: 0.000032 | Test Loss: 0.000134 | Test Accuracy: 0.906317\n",
      "Step 97 | Training Loss: 0.000010 | Test Loss: 0.000145 | Test Accuracy: 0.895715\n",
      "Step 98 | Training Loss: 0.000029 | Test Loss: 0.000148 | Test Accuracy: 0.893231\n",
      "Step 99 | Training Loss: 0.000014 | Test Loss: 0.000116 | Test Accuracy: 0.882363\n",
      "Step 100 | Training Loss: 0.000034 | Test Loss: 0.000126 | Test Accuracy: 0.882807\n",
      "Best Accuracy on Test data: 0.9063165187835693\n",
      "Current Layer Attributes - epochs:100 hidden layers:2 features count:32\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 1 | Training Loss: 0.000252 | Test Loss: 0.000490 | Test Accuracy: 0.778478\n",
      "Step 2 | Training Loss: 0.000090 | Test Loss: 0.000284 | Test Accuracy: 0.755500\n",
      "Step 3 | Training Loss: 0.000017 | Test Loss: 0.000241 | Test Accuracy: 0.795200\n",
      "Step 4 | Training Loss: 0.000034 | Test Loss: 0.000169 | Test Accuracy: 0.808552\n",
      "Step 5 | Training Loss: 0.000043 | Test Loss: 0.000186 | Test Accuracy: 0.797862\n",
      "Step 6 | Training Loss: 0.000062 | Test Loss: 0.000270 | Test Accuracy: 0.803895\n",
      "Step 7 | Training Loss: 0.000082 | Test Loss: 0.000209 | Test Accuracy: 0.813254\n",
      "Step 8 | Training Loss: 0.000023 | Test Loss: 0.000214 | Test Accuracy: 0.807133\n",
      "Step 9 | Training Loss: 0.000037 | Test Loss: 0.000193 | Test Accuracy: 0.800878\n",
      "Step 10 | Training Loss: 0.000039 | Test Loss: 0.000228 | Test Accuracy: 0.786817\n",
      "Step 11 | Training Loss: 0.000027 | Test Loss: 0.000230 | Test Accuracy: 0.801278\n",
      "Step 12 | Training Loss: 0.000002 | Test Loss: 0.000187 | Test Accuracy: 0.801278\n",
      "Step 13 | Training Loss: 0.000024 | Test Loss: 0.000217 | Test Accuracy: 0.797463\n",
      "Step 14 | Training Loss: 0.000001 | Test Loss: 0.000251 | Test Accuracy: 0.774219\n",
      "Step 15 | Training Loss: 0.000010 | Test Loss: 0.000191 | Test Accuracy: 0.791253\n",
      "Step 16 | Training Loss: 0.000017 | Test Loss: 0.000245 | Test Accuracy: 0.790853\n",
      "Step 17 | Training Loss: 0.000005 | Test Loss: 0.000289 | Test Accuracy: 0.791741\n",
      "Step 18 | Training Loss: 0.000036 | Test Loss: 0.000251 | Test Accuracy: 0.813919\n",
      "Step 19 | Training Loss: 0.000035 | Test Loss: 0.000248 | Test Accuracy: 0.829134\n",
      "Step 20 | Training Loss: 0.000068 | Test Loss: 0.000168 | Test Accuracy: 0.849849\n",
      "Step 21 | Training Loss: 0.000037 | Test Loss: 0.000194 | Test Accuracy: 0.867637\n",
      "Step 22 | Training Loss: 0.000056 | Test Loss: 0.000163 | Test Accuracy: 0.842796\n",
      "Step 23 | Training Loss: 0.000029 | Test Loss: 0.000185 | Test Accuracy: 0.863999\n",
      "Step 24 | Training Loss: 0.000018 | Test Loss: 0.000156 | Test Accuracy: 0.863644\n",
      "Step 25 | Training Loss: 0.000005 | Test Loss: 0.000161 | Test Accuracy: 0.863068\n",
      "Step 26 | Training Loss: 0.000019 | Test Loss: 0.000099 | Test Accuracy: 0.871540\n",
      "Step 27 | Training Loss: 0.000043 | Test Loss: 0.000147 | Test Accuracy: 0.854684\n",
      "Step 28 | Training Loss: 0.000018 | Test Loss: 0.000168 | Test Accuracy: 0.855350\n",
      "Step 29 | Training Loss: 0.000013 | Test Loss: 0.000196 | Test Accuracy: 0.856725\n",
      "Step 30 | Training Loss: 0.000004 | Test Loss: 0.000125 | Test Accuracy: 0.878504\n",
      "Step 31 | Training Loss: 0.000079 | Test Loss: 0.000170 | Test Accuracy: 0.876286\n",
      "Step 32 | Training Loss: 0.000005 | Test Loss: 0.000150 | Test Accuracy: 0.873935\n",
      "Step 33 | Training Loss: 0.000029 | Test Loss: 0.000178 | Test Accuracy: 0.873093\n",
      "Step 34 | Training Loss: 0.000003 | Test Loss: 0.000132 | Test Accuracy: 0.878815\n",
      "Step 35 | Training Loss: 0.000012 | Test Loss: 0.000170 | Test Accuracy: 0.876286\n",
      "Step 36 | Training Loss: 0.000016 | Test Loss: 0.000136 | Test Accuracy: 0.861737\n",
      "Step 37 | Training Loss: 0.000005 | Test Loss: 0.000126 | Test Accuracy: 0.882452\n",
      "Step 38 | Training Loss: 0.000029 | Test Loss: 0.000195 | Test Accuracy: 0.866705\n",
      "Step 39 | Training Loss: 0.000039 | Test Loss: 0.000148 | Test Accuracy: 0.878859\n",
      "Step 40 | Training Loss: 0.000023 | Test Loss: 0.000142 | Test Accuracy: 0.883251\n",
      "Step 41 | Training Loss: 0.000003 | Test Loss: 0.000142 | Test Accuracy: 0.880767\n",
      "Step 42 | Training Loss: 0.000067 | Test Loss: 0.000185 | Test Accuracy: 0.894517\n",
      "Step 43 | Training Loss: 0.000046 | Test Loss: 0.000137 | Test Accuracy: 0.894517\n",
      "Step 44 | Training Loss: 0.000012 | Test Loss: 0.000136 | Test Accuracy: 0.895493\n",
      "Step 45 | Training Loss: 0.000017 | Test Loss: 0.000146 | Test Accuracy: 0.894650\n",
      "Step 46 | Training Loss: 0.000017 | Test Loss: 0.000142 | Test Accuracy: 0.892078\n",
      "Step 47 | Training Loss: 0.000015 | Test Loss: 0.000110 | Test Accuracy: 0.894828\n",
      "Step 48 | Training Loss: 0.000000 | Test Loss: 0.000115 | Test Accuracy: 0.893719\n",
      "Step 49 | Training Loss: 0.000002 | Test Loss: 0.000103 | Test Accuracy: 0.894517\n",
      "Step 50 | Training Loss: 0.000002 | Test Loss: 0.000116 | Test Accuracy: 0.894118\n",
      "Step 51 | Training Loss: 0.000043 | Test Loss: 0.000121 | Test Accuracy: 0.893808\n",
      "Step 52 | Training Loss: 0.000001 | Test Loss: 0.000130 | Test Accuracy: 0.894296\n",
      "Step 53 | Training Loss: 0.000032 | Test Loss: 0.000088 | Test Accuracy: 0.884803\n",
      "Step 54 | Training Loss: 0.000004 | Test Loss: 0.000110 | Test Accuracy: 0.897489\n",
      "Step 55 | Training Loss: 0.000038 | Test Loss: 0.000119 | Test Accuracy: 0.893941\n",
      "Step 56 | Training Loss: 0.000020 | Test Loss: 0.000105 | Test Accuracy: 0.893408\n",
      "Step 57 | Training Loss: 0.000057 | Test Loss: 0.000110 | Test Accuracy: 0.895271\n",
      "Step 58 | Training Loss: 0.000004 | Test Loss: 0.000091 | Test Accuracy: 0.898243\n",
      "Step 59 | Training Loss: 0.000024 | Test Loss: 0.000097 | Test Accuracy: 0.898510\n",
      "Step 60 | Training Loss: 0.000002 | Test Loss: 0.000048 | Test Accuracy: 0.902546\n",
      "Step 61 | Training Loss: 0.000044 | Test Loss: 0.000075 | Test Accuracy: 0.894296\n",
      "Step 62 | Training Loss: 0.000021 | Test Loss: 0.000114 | Test Accuracy: 0.896336\n",
      "Step 63 | Training Loss: 0.000029 | Test Loss: 0.000098 | Test Accuracy: 0.894296\n",
      "Step 64 | Training Loss: 0.000032 | Test Loss: 0.000107 | Test Accuracy: 0.894695\n",
      "Step 65 | Training Loss: 0.000034 | Test Loss: 0.000078 | Test Accuracy: 0.893941\n",
      "Step 66 | Training Loss: 0.000014 | Test Loss: 0.000063 | Test Accuracy: 0.894251\n",
      "Step 67 | Training Loss: 0.000027 | Test Loss: 0.000098 | Test Accuracy: 0.894606\n",
      "Step 68 | Training Loss: 0.000011 | Test Loss: 0.000127 | Test Accuracy: 0.891856\n",
      "Step 69 | Training Loss: 0.000080 | Test Loss: 0.000091 | Test Accuracy: 0.891457\n",
      "Step 70 | Training Loss: 0.000030 | Test Loss: 0.000062 | Test Accuracy: 0.893719\n",
      "Step 71 | Training Loss: 0.000021 | Test Loss: 0.000082 | Test Accuracy: 0.894828\n",
      "Step 72 | Training Loss: 0.000048 | Test Loss: 0.000075 | Test Accuracy: 0.896070\n",
      "Step 73 | Training Loss: 0.000030 | Test Loss: 0.000069 | Test Accuracy: 0.895138\n",
      "Step 74 | Training Loss: 0.000011 | Test Loss: 0.000090 | Test Accuracy: 0.894473\n",
      "Step 75 | Training Loss: 0.000016 | Test Loss: 0.000112 | Test Accuracy: 0.894517\n",
      "Step 76 | Training Loss: 0.000013 | Test Loss: 0.000090 | Test Accuracy: 0.894739\n",
      "Step 77 | Training Loss: 0.000020 | Test Loss: 0.000097 | Test Accuracy: 0.892832\n",
      "Step 78 | Training Loss: 0.000027 | Test Loss: 0.000096 | Test Accuracy: 0.893808\n",
      "Step 79 | Training Loss: 0.000002 | Test Loss: 0.000087 | Test Accuracy: 0.892211\n",
      "Step 80 | Training Loss: 0.000048 | Test Loss: 0.000090 | Test Accuracy: 0.894118\n",
      "Step 81 | Training Loss: 0.000028 | Test Loss: 0.000082 | Test Accuracy: 0.894872\n",
      "Step 82 | Training Loss: 0.000006 | Test Loss: 0.000092 | Test Accuracy: 0.894650\n",
      "Step 83 | Training Loss: 0.000011 | Test Loss: 0.000068 | Test Accuracy: 0.894251\n",
      "Step 84 | Training Loss: 0.000033 | Test Loss: 0.000060 | Test Accuracy: 0.879924\n",
      "Step 85 | Training Loss: 0.000030 | Test Loss: 0.000071 | Test Accuracy: 0.891945\n",
      "Step 86 | Training Loss: 0.000013 | Test Loss: 0.000091 | Test Accuracy: 0.895405\n",
      "Step 87 | Training Loss: 0.000016 | Test Loss: 0.000091 | Test Accuracy: 0.895493\n",
      "Step 88 | Training Loss: 0.000008 | Test Loss: 0.000080 | Test Accuracy: 0.898066\n",
      "Step 89 | Training Loss: 0.000010 | Test Loss: 0.000076 | Test Accuracy: 0.895138\n",
      "Step 90 | Training Loss: 0.000000 | Test Loss: 0.000051 | Test Accuracy: 0.888618\n",
      "Step 91 | Training Loss: 0.000015 | Test Loss: 0.000086 | Test Accuracy: 0.884847\n",
      "Step 92 | Training Loss: 0.000022 | Test Loss: 0.000081 | Test Accuracy: 0.893408\n",
      "Step 93 | Training Loss: 0.000024 | Test Loss: 0.000076 | Test Accuracy: 0.897445\n",
      "Step 94 | Training Loss: 0.000002 | Test Loss: 0.000082 | Test Accuracy: 0.890791\n",
      "Step 95 | Training Loss: 0.000042 | Test Loss: 0.000058 | Test Accuracy: 0.893231\n",
      "Step 96 | Training Loss: 0.000015 | Test Loss: 0.000056 | Test Accuracy: 0.893675\n",
      "Step 97 | Training Loss: 0.000023 | Test Loss: 0.000078 | Test Accuracy: 0.899352\n",
      "Step 98 | Training Loss: 0.000000 | Test Loss: 0.000108 | Test Accuracy: 0.904498\n",
      "Step 99 | Training Loss: 0.000048 | Test Loss: 0.000068 | Test Accuracy: 0.909022\n",
      "Step 100 | Training Loss: 0.000020 | Test Loss: 0.000065 | Test Accuracy: 0.903522\n",
      "Best Accuracy on Test data: 0.909022331237793\n",
      "Current Layer Attributes - epochs:100 hidden layers:4 features count:4\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 1 | Training Loss: 0.000033 | Test Loss: 0.000561 | Test Accuracy: 0.640747\n",
      "Step 2 | Training Loss: 0.000227 | Test Loss: 0.000511 | Test Accuracy: 0.718329\n",
      "Step 3 | Training Loss: 0.000199 | Test Loss: 0.000344 | Test Accuracy: 0.697569\n",
      "Step 4 | Training Loss: 0.000020 | Test Loss: 0.000342 | Test Accuracy: 0.690161\n",
      "Step 5 | Training Loss: 0.000301 | Test Loss: 0.000200 | Test Accuracy: 0.715046\n",
      "Step 6 | Training Loss: 0.000126 | Test Loss: 0.000133 | Test Accuracy: 0.780518\n",
      "Step 7 | Training Loss: 0.000046 | Test Loss: 0.000169 | Test Accuracy: 0.760069\n",
      "Step 8 | Training Loss: 0.000048 | Test Loss: 0.000259 | Test Accuracy: 0.805758\n",
      "Step 9 | Training Loss: 0.000051 | Test Loss: 0.000297 | Test Accuracy: 0.818799\n",
      "Step 10 | Training Loss: 0.000142 | Test Loss: 0.000376 | Test Accuracy: 0.764283\n",
      "Step 11 | Training Loss: 0.000009 | Test Loss: 0.000254 | Test Accuracy: 0.842885\n",
      "Step 12 | Training Loss: 0.000022 | Test Loss: 0.000207 | Test Accuracy: 0.821948\n",
      "Step 13 | Training Loss: 0.000027 | Test Loss: 0.000176 | Test Accuracy: 0.829578\n",
      "Step 14 | Training Loss: 0.000020 | Test Loss: 0.000153 | Test Accuracy: 0.859164\n",
      "Step 15 | Training Loss: 0.000006 | Test Loss: 0.000248 | Test Accuracy: 0.857301\n",
      "Step 16 | Training Loss: 0.000029 | Test Loss: 0.000178 | Test Accuracy: 0.861870\n",
      "Step 17 | Training Loss: 0.000017 | Test Loss: 0.000153 | Test Accuracy: 0.837695\n",
      "Step 18 | Training Loss: 0.000005 | Test Loss: 0.000110 | Test Accuracy: 0.829800\n",
      "Step 19 | Training Loss: 0.000053 | Test Loss: 0.000213 | Test Accuracy: 0.810016\n",
      "Step 20 | Training Loss: 0.000004 | Test Loss: 0.000180 | Test Accuracy: 0.828424\n",
      "Step 21 | Training Loss: 0.000017 | Test Loss: 0.000155 | Test Accuracy: 0.820573\n",
      "Step 22 | Training Loss: 0.000067 | Test Loss: 0.000355 | Test Accuracy: 0.764283\n",
      "Step 23 | Training Loss: 0.000049 | Test Loss: 0.000142 | Test Accuracy: 0.793559\n",
      "Step 24 | Training Loss: 0.000070 | Test Loss: 0.000123 | Test Accuracy: 0.824521\n",
      "Step 25 | Training Loss: 0.000015 | Test Loss: 0.000176 | Test Accuracy: 0.825452\n",
      "Step 26 | Training Loss: 0.000018 | Test Loss: 0.000216 | Test Accuracy: 0.769695\n",
      "Step 27 | Training Loss: 0.000087 | Test Loss: 0.000158 | Test Accuracy: 0.817069\n",
      "Step 28 | Training Loss: 0.000007 | Test Loss: 0.000183 | Test Accuracy: 0.806024\n",
      "Step 29 | Training Loss: 0.000000 | Test Loss: 0.000172 | Test Accuracy: 0.830376\n",
      "Step 30 | Training Loss: 0.000052 | Test Loss: 0.000113 | Test Accuracy: 0.836187\n",
      "Step 31 | Training Loss: 0.000032 | Test Loss: 0.000156 | Test Accuracy: 0.824920\n",
      "Step 32 | Training Loss: 0.000030 | Test Loss: 0.000204 | Test Accuracy: 0.844659\n",
      "Step 33 | Training Loss: 0.000047 | Test Loss: 0.000189 | Test Accuracy: 0.833570\n",
      "Step 34 | Training Loss: 0.000041 | Test Loss: 0.000188 | Test Accuracy: 0.811480\n",
      "Step 35 | Training Loss: 0.000010 | Test Loss: 0.000164 | Test Accuracy: 0.811302\n",
      "Step 36 | Training Loss: 0.000014 | Test Loss: 0.000187 | Test Accuracy: 0.816492\n",
      "Step 37 | Training Loss: 0.000021 | Test Loss: 0.000141 | Test Accuracy: 0.809705\n",
      "Step 38 | Training Loss: 0.000043 | Test Loss: 0.000154 | Test Accuracy: 0.821593\n",
      "Step 39 | Training Loss: 0.000058 | Test Loss: 0.000098 | Test Accuracy: 0.826029\n",
      "Step 40 | Training Loss: 0.000027 | Test Loss: 0.000217 | Test Accuracy: 0.818267\n",
      "Step 41 | Training Loss: 0.000010 | Test Loss: 0.000176 | Test Accuracy: 0.820884\n",
      "Step 42 | Training Loss: 0.000000 | Test Loss: 0.000163 | Test Accuracy: 0.827715\n",
      "Step 43 | Training Loss: 0.000007 | Test Loss: 0.000152 | Test Accuracy: 0.815250\n",
      "Step 44 | Training Loss: 0.000038 | Test Loss: 0.000116 | Test Accuracy: 0.836941\n",
      "Step 45 | Training Loss: 0.000048 | Test Loss: 0.000128 | Test Accuracy: 0.815960\n",
      "Step 46 | Training Loss: 0.000030 | Test Loss: 0.000149 | Test Accuracy: 0.833171\n",
      "Step 47 | Training Loss: 0.000049 | Test Loss: 0.000218 | Test Accuracy: 0.827981\n",
      "Step 48 | Training Loss: 0.000004 | Test Loss: 0.000149 | Test Accuracy: 0.822880\n",
      "Step 49 | Training Loss: 0.000055 | Test Loss: 0.000157 | Test Accuracy: 0.838050\n",
      "Step 50 | Training Loss: 0.000026 | Test Loss: 0.000174 | Test Accuracy: 0.827626\n",
      "Step 51 | Training Loss: 0.000023 | Test Loss: 0.000188 | Test Accuracy: 0.799548\n",
      "Step 52 | Training Loss: 0.000032 | Test Loss: 0.000175 | Test Accuracy: 0.809395\n",
      "Step 53 | Training Loss: 0.000039 | Test Loss: 0.000112 | Test Accuracy: 0.792894\n",
      "Step 54 | Training Loss: 0.000026 | Test Loss: 0.000142 | Test Accuracy: 0.836631\n",
      "Step 55 | Training Loss: 0.000030 | Test Loss: 0.000144 | Test Accuracy: 0.834013\n",
      "Step 56 | Training Loss: 0.000009 | Test Loss: 0.000136 | Test Accuracy: 0.819908\n",
      "Step 57 | Training Loss: 0.000026 | Test Loss: 0.000162 | Test Accuracy: 0.783490\n",
      "Step 58 | Training Loss: 0.000002 | Test Loss: 0.000143 | Test Accuracy: 0.808375\n",
      "Step 59 | Training Loss: 0.000058 | Test Loss: 0.000192 | Test Accuracy: 0.823323\n",
      "Step 60 | Training Loss: 0.000006 | Test Loss: 0.000150 | Test Accuracy: 0.836054\n",
      "Step 61 | Training Loss: 0.000001 | Test Loss: 0.000206 | Test Accuracy: 0.845946\n",
      "Step 62 | Training Loss: 0.000014 | Test Loss: 0.000204 | Test Accuracy: 0.820928\n",
      "Step 63 | Training Loss: 0.000002 | Test Loss: 0.000174 | Test Accuracy: 0.837473\n",
      "Step 64 | Training Loss: 0.000015 | Test Loss: 0.000152 | Test Accuracy: 0.836941\n",
      "Step 65 | Training Loss: 0.000007 | Test Loss: 0.000120 | Test Accuracy: 0.841599\n",
      "Step 66 | Training Loss: 0.000046 | Test Loss: 0.000170 | Test Accuracy: 0.798616\n",
      "Step 67 | Training Loss: 0.000024 | Test Loss: 0.000153 | Test Accuracy: 0.829223\n",
      "Step 68 | Training Loss: 0.000001 | Test Loss: 0.000124 | Test Accuracy: 0.843062\n",
      "Step 69 | Training Loss: 0.000034 | Test Loss: 0.000215 | Test Accuracy: 0.816492\n",
      "Step 70 | Training Loss: 0.000006 | Test Loss: 0.000145 | Test Accuracy: 0.834634\n",
      "Step 71 | Training Loss: 0.000005 | Test Loss: 0.000150 | Test Accuracy: 0.833393\n",
      "Step 72 | Training Loss: 0.000021 | Test Loss: 0.000149 | Test Accuracy: 0.832860\n",
      "Step 73 | Training Loss: 0.000021 | Test Loss: 0.000156 | Test Accuracy: 0.804649\n",
      "Step 74 | Training Loss: 0.000006 | Test Loss: 0.000151 | Test Accuracy: 0.774840\n",
      "Step 75 | Training Loss: 0.000019 | Test Loss: 0.000143 | Test Accuracy: 0.803229\n",
      "Step 76 | Training Loss: 0.000032 | Test Loss: 0.000129 | Test Accuracy: 0.816492\n",
      "Step 77 | Training Loss: 0.000001 | Test Loss: 0.000130 | Test Accuracy: 0.835211\n",
      "Step 78 | Training Loss: 0.000030 | Test Loss: 0.000132 | Test Accuracy: 0.835477\n",
      "Step 79 | Training Loss: 0.000006 | Test Loss: 0.000158 | Test Accuracy: 0.820484\n",
      "Step 80 | Training Loss: 0.000004 | Test Loss: 0.000159 | Test Accuracy: 0.807532\n",
      "Step 81 | Training Loss: 0.000002 | Test Loss: 0.000096 | Test Accuracy: 0.788325\n",
      "Step 82 | Training Loss: 0.000002 | Test Loss: 0.000085 | Test Accuracy: 0.833614\n",
      "Step 83 | Training Loss: 0.000034 | Test Loss: 0.000178 | Test Accuracy: 0.831042\n",
      "Step 84 | Training Loss: 0.000005 | Test Loss: 0.000128 | Test Accuracy: 0.823678\n",
      "Step 85 | Training Loss: 0.000011 | Test Loss: 0.000103 | Test Accuracy: 0.841066\n",
      "Step 86 | Training Loss: 0.000005 | Test Loss: 0.000116 | Test Accuracy: 0.833348\n",
      "Step 87 | Training Loss: 0.000033 | Test Loss: 0.000125 | Test Accuracy: 0.825807\n",
      "Step 88 | Training Loss: 0.000021 | Test Loss: 0.000119 | Test Accuracy: 0.813298\n",
      "Step 89 | Training Loss: 0.000078 | Test Loss: 0.000186 | Test Accuracy: 0.818799\n",
      "Step 90 | Training Loss: 0.000013 | Test Loss: 0.000169 | Test Accuracy: 0.830066\n",
      "Step 91 | Training Loss: 0.000058 | Test Loss: 0.000135 | Test Accuracy: 0.815694\n",
      "Step 92 | Training Loss: 0.000044 | Test Loss: 0.000169 | Test Accuracy: 0.816492\n",
      "Step 93 | Training Loss: 0.000021 | Test Loss: 0.000128 | Test Accuracy: 0.832372\n",
      "Step 94 | Training Loss: 0.000043 | Test Loss: 0.000157 | Test Accuracy: 0.832638\n",
      "Step 95 | Training Loss: 0.000010 | Test Loss: 0.000111 | Test Accuracy: 0.828114\n",
      "Step 96 | Training Loss: 0.000009 | Test Loss: 0.000093 | Test Accuracy: 0.778877\n",
      "Step 97 | Training Loss: 0.000069 | Test Loss: 0.000177 | Test Accuracy: 0.720502\n",
      "Step 98 | Training Loss: 0.000023 | Test Loss: 0.000192 | Test Accuracy: 0.826872\n",
      "Step 99 | Training Loss: 0.000002 | Test Loss: 0.000144 | Test Accuracy: 0.843018\n",
      "Step 100 | Training Loss: 0.000004 | Test Loss: 0.000131 | Test Accuracy: 0.788015\n",
      "Best Accuracy on Test data: 0.8618701100349426\n",
      "Current Layer Attributes - epochs:100 hidden layers:4 features count:8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 1 | Training Loss: 0.000145 | Test Loss: 0.001140 | Test Accuracy: 0.765259\n",
      "Step 2 | Training Loss: 0.000225 | Test Loss: 0.022636 | Test Accuracy: 0.800346\n",
      "Step 3 | Training Loss: 0.000002 | Test Loss: 0.000098 | Test Accuracy: 0.757585\n",
      "Step 4 | Training Loss: 0.000062 | Test Loss: 0.000192 | Test Accuracy: 0.793692\n",
      "Step 5 | Training Loss: 0.000060 | Test Loss: 0.000075 | Test Accuracy: 0.800346\n",
      "Step 6 | Training Loss: 0.000013 | Test Loss: 0.000283 | Test Accuracy: 0.745742\n",
      "Step 7 | Training Loss: 0.000046 | Test Loss: 0.000592 | Test Accuracy: 0.694508\n",
      "Step 8 | Training Loss: 0.000090 | Test Loss: 0.000461 | Test Accuracy: 0.717663\n",
      "Step 9 | Training Loss: 0.000035 | Test Loss: 0.000438 | Test Accuracy: 0.706618\n",
      "Step 10 | Training Loss: 0.000016 | Test Loss: 0.000344 | Test Accuracy: 0.744766\n",
      "Step 11 | Training Loss: 0.000024 | Test Loss: 0.000313 | Test Accuracy: 0.734031\n",
      "Step 12 | Training Loss: 0.000055 | Test Loss: 0.000219 | Test Accuracy: 0.744233\n",
      "Step 13 | Training Loss: 0.000031 | Test Loss: 0.000328 | Test Accuracy: 0.706396\n",
      "Step 14 | Training Loss: 0.000040 | Test Loss: 0.000210 | Test Accuracy: 0.825940\n",
      "Step 15 | Training Loss: 0.000021 | Test Loss: 0.000191 | Test Accuracy: 0.801056\n",
      "Step 16 | Training Loss: 0.000039 | Test Loss: 0.000276 | Test Accuracy: 0.774752\n",
      "Step 17 | Training Loss: 0.000001 | Test Loss: 0.000312 | Test Accuracy: 0.758694\n",
      "Step 18 | Training Loss: 0.000047 | Test Loss: 0.000353 | Test Accuracy: 0.711409\n",
      "Step 19 | Training Loss: 0.000009 | Test Loss: 0.000314 | Test Accuracy: 0.747427\n",
      "Step 20 | Training Loss: 0.000013 | Test Loss: 0.000347 | Test Accuracy: 0.712296\n",
      "Step 21 | Training Loss: 0.000021 | Test Loss: 0.000340 | Test Accuracy: 0.724672\n",
      "Step 22 | Training Loss: 0.000015 | Test Loss: 0.000360 | Test Accuracy: 0.723829\n",
      "Step 23 | Training Loss: 0.000003 | Test Loss: 0.000322 | Test Accuracy: 0.734741\n",
      "Step 24 | Training Loss: 0.000033 | Test Loss: 0.000239 | Test Accuracy: 0.843639\n",
      "Step 25 | Training Loss: 0.000002 | Test Loss: 0.000164 | Test Accuracy: 0.857213\n",
      "Step 26 | Training Loss: 0.000018 | Test Loss: 0.000192 | Test Accuracy: 0.856503\n",
      "Step 27 | Training Loss: 0.000030 | Test Loss: 0.000219 | Test Accuracy: 0.854862\n",
      "Step 28 | Training Loss: 0.000040 | Test Loss: 0.000228 | Test Accuracy: 0.849006\n",
      "Step 29 | Training Loss: 0.000028 | Test Loss: 0.000303 | Test Accuracy: 0.779986\n",
      "Step 30 | Training Loss: 0.000037 | Test Loss: 0.000330 | Test Accuracy: 0.750000\n",
      "Step 31 | Training Loss: 0.000050 | Test Loss: 0.000433 | Test Accuracy: 0.752573\n",
      "Step 32 | Training Loss: 0.000007 | Test Loss: 0.000320 | Test Accuracy: 0.761178\n",
      "Step 33 | Training Loss: 0.000048 | Test Loss: 0.000342 | Test Accuracy: 0.729950\n",
      "Step 34 | Training Loss: 0.000018 | Test Loss: 0.000298 | Test Accuracy: 0.765570\n",
      "Step 35 | Training Loss: 0.000031 | Test Loss: 0.000366 | Test Accuracy: 0.720413\n",
      "Step 36 | Training Loss: 0.000005 | Test Loss: 0.000331 | Test Accuracy: 0.768009\n",
      "Step 37 | Training Loss: 0.000014 | Test Loss: 0.000304 | Test Accuracy: 0.769429\n",
      "Step 38 | Training Loss: 0.000010 | Test Loss: 0.000307 | Test Accuracy: 0.756521\n",
      "Step 39 | Training Loss: 0.000052 | Test Loss: 0.000417 | Test Accuracy: 0.737846\n",
      "Step 40 | Training Loss: 0.000032 | Test Loss: 0.000306 | Test Accuracy: 0.780385\n",
      "Step 41 | Training Loss: 0.000015 | Test Loss: 0.000315 | Test Accuracy: 0.760513\n",
      "Step 42 | Training Loss: 0.000068 | Test Loss: 0.000299 | Test Accuracy: 0.779365\n",
      "Step 43 | Training Loss: 0.000011 | Test Loss: 0.000324 | Test Accuracy: 0.740862\n",
      "Step 44 | Training Loss: 0.000003 | Test Loss: 0.000352 | Test Accuracy: 0.719571\n",
      "Step 45 | Training Loss: 0.000022 | Test Loss: 0.000318 | Test Accuracy: 0.741705\n",
      "Step 46 | Training Loss: 0.000002 | Test Loss: 0.000282 | Test Accuracy: 0.756077\n",
      "Step 47 | Training Loss: 0.000033 | Test Loss: 0.000337 | Test Accuracy: 0.739576\n",
      "Step 48 | Training Loss: 0.000041 | Test Loss: 0.000296 | Test Accuracy: 0.743923\n",
      "Step 49 | Training Loss: 0.000024 | Test Loss: 0.000307 | Test Accuracy: 0.772622\n",
      "Step 50 | Training Loss: 0.000001 | Test Loss: 0.000207 | Test Accuracy: 0.822747\n",
      "Step 51 | Training Loss: 0.000009 | Test Loss: 0.000225 | Test Accuracy: 0.820484\n",
      "Step 52 | Training Loss: 0.000028 | Test Loss: 0.000198 | Test Accuracy: 0.854551\n",
      "Step 53 | Training Loss: 0.000034 | Test Loss: 0.000296 | Test Accuracy: 0.829223\n",
      "Step 54 | Training Loss: 0.000002 | Test Loss: 0.000231 | Test Accuracy: 0.823146\n",
      "Step 55 | Training Loss: 0.000036 | Test Loss: 0.000206 | Test Accuracy: 0.827759\n",
      "Step 56 | Training Loss: 0.000013 | Test Loss: 0.000206 | Test Accuracy: 0.850027\n",
      "Step 57 | Training Loss: 0.000004 | Test Loss: 0.000194 | Test Accuracy: 0.859253\n",
      "Step 58 | Training Loss: 0.000030 | Test Loss: 0.000185 | Test Accuracy: 0.869500\n",
      "Step 59 | Training Loss: 0.000003 | Test Loss: 0.000226 | Test Accuracy: 0.864177\n",
      "Step 60 | Training Loss: 0.000011 | Test Loss: 0.000225 | Test Accuracy: 0.868923\n",
      "Step 61 | Training Loss: 0.000021 | Test Loss: 0.000230 | Test Accuracy: 0.862491\n",
      "Step 62 | Training Loss: 0.000002 | Test Loss: 0.000183 | Test Accuracy: 0.869189\n",
      "Step 63 | Training Loss: 0.000007 | Test Loss: 0.000203 | Test Accuracy: 0.856725\n",
      "Step 64 | Training Loss: 0.000006 | Test Loss: 0.000197 | Test Accuracy: 0.858543\n",
      "Step 65 | Training Loss: 0.000023 | Test Loss: 0.000201 | Test Accuracy: 0.865020\n",
      "Step 66 | Training Loss: 0.000004 | Test Loss: 0.000220 | Test Accuracy: 0.864798\n",
      "Step 67 | Training Loss: 0.000010 | Test Loss: 0.000183 | Test Accuracy: 0.866883\n",
      "Step 68 | Training Loss: 0.000019 | Test Loss: 0.000202 | Test Accuracy: 0.856458\n",
      "Step 69 | Training Loss: 0.000005 | Test Loss: 0.000226 | Test Accuracy: 0.869411\n",
      "Step 70 | Training Loss: 0.000025 | Test Loss: 0.000184 | Test Accuracy: 0.868568\n",
      "Step 71 | Training Loss: 0.000004 | Test Loss: 0.000218 | Test Accuracy: 0.868169\n",
      "Step 72 | Training Loss: 0.000020 | Test Loss: 0.000197 | Test Accuracy: 0.867725\n",
      "Step 73 | Training Loss: 0.000013 | Test Loss: 0.000213 | Test Accuracy: 0.870165\n",
      "Step 74 | Training Loss: 0.000007 | Test Loss: 0.000218 | Test Accuracy: 0.869056\n",
      "Step 75 | Training Loss: 0.000007 | Test Loss: 0.000214 | Test Accuracy: 0.870032\n",
      "Step 76 | Training Loss: 0.000047 | Test Loss: 0.000195 | Test Accuracy: 0.871984\n",
      "Step 77 | Training Loss: 0.000012 | Test Loss: 0.000190 | Test Accuracy: 0.869233\n",
      "Step 78 | Training Loss: 0.000024 | Test Loss: 0.000183 | Test Accuracy: 0.867681\n",
      "Step 79 | Training Loss: 0.000024 | Test Loss: 0.000197 | Test Accuracy: 0.868790\n",
      "Step 80 | Training Loss: 0.000034 | Test Loss: 0.000191 | Test Accuracy: 0.864177\n",
      "Step 81 | Training Loss: 0.000019 | Test Loss: 0.000185 | Test Accuracy: 0.857789\n",
      "Step 82 | Training Loss: 0.000009 | Test Loss: 0.000234 | Test Accuracy: 0.764239\n",
      "Step 83 | Training Loss: 0.000038 | Test Loss: 0.000247 | Test Accuracy: 0.752617\n",
      "Step 84 | Training Loss: 0.000090 | Test Loss: 0.000194 | Test Accuracy: 0.781760\n",
      "Step 85 | Training Loss: 0.000035 | Test Loss: 0.000209 | Test Accuracy: 0.784599\n",
      "Step 86 | Training Loss: 0.000101 | Test Loss: 0.000091 | Test Accuracy: 0.786240\n",
      "Step 87 | Training Loss: 0.000029 | Test Loss: 0.000068 | Test Accuracy: 0.749734\n",
      "Step 88 | Training Loss: 0.000029 | Test Loss: 0.000229 | Test Accuracy: 0.834413\n",
      "Step 89 | Training Loss: 0.000005 | Test Loss: 0.000200 | Test Accuracy: 0.844304\n",
      "Step 90 | Training Loss: 0.000009 | Test Loss: 0.000195 | Test Accuracy: 0.853220\n",
      "Step 91 | Training Loss: 0.000019 | Test Loss: 0.000200 | Test Accuracy: 0.849494\n",
      "Step 92 | Training Loss: 0.000004 | Test Loss: 0.000143 | Test Accuracy: 0.848962\n",
      "Step 93 | Training Loss: 0.000001 | Test Loss: 0.000156 | Test Accuracy: 0.858277\n",
      "Step 94 | Training Loss: 0.000004 | Test Loss: 0.000213 | Test Accuracy: 0.861027\n",
      "Step 95 | Training Loss: 0.000014 | Test Loss: 0.000185 | Test Accuracy: 0.859342\n",
      "Step 96 | Training Loss: 0.000024 | Test Loss: 0.000187 | Test Accuracy: 0.857124\n",
      "Step 97 | Training Loss: 0.000029 | Test Loss: 0.000213 | Test Accuracy: 0.847809\n",
      "Step 98 | Training Loss: 0.000016 | Test Loss: 0.000177 | Test Accuracy: 0.858233\n",
      "Step 99 | Training Loss: 0.000035 | Test Loss: 0.000206 | Test Accuracy: 0.855926\n",
      "Step 100 | Training Loss: 0.000030 | Test Loss: 0.000220 | Test Accuracy: 0.854063\n",
      "Best Accuracy on Test data: 0.8719836473464966\n",
      "Current Layer Attributes - epochs:100 hidden layers:4 features count:16\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 1 | Training Loss: 0.000044 | Test Loss: 0.000096 | Test Accuracy: 0.749690\n",
      "Step 2 | Training Loss: 0.000027 | Test Loss: 0.000083 | Test Accuracy: 0.752617\n",
      "Step 3 | Training Loss: 0.000095 | Test Loss: 0.000232 | Test Accuracy: 0.766679\n",
      "Step 4 | Training Loss: 0.000023 | Test Loss: 0.000291 | Test Accuracy: 0.703735\n",
      "Step 5 | Training Loss: 0.000020 | Test Loss: 0.000275 | Test Accuracy: 0.810992\n",
      "Step 6 | Training Loss: 0.000069 | Test Loss: 0.000335 | Test Accuracy: 0.766324\n",
      "Step 7 | Training Loss: 0.000037 | Test Loss: 0.000257 | Test Accuracy: 0.803451\n",
      "Step 8 | Training Loss: 0.000063 | Test Loss: 0.000255 | Test Accuracy: 0.829445\n",
      "Step 9 | Training Loss: 0.000030 | Test Loss: 0.000342 | Test Accuracy: 0.816581\n",
      "Step 10 | Training Loss: 0.000008 | Test Loss: 0.000308 | Test Accuracy: 0.790055\n",
      "Step 11 | Training Loss: 0.000051 | Test Loss: 0.000313 | Test Accuracy: 0.804205\n",
      "Step 12 | Training Loss: 0.000962 | Test Loss: 0.000315 | Test Accuracy: 0.819242\n",
      "Step 13 | Training Loss: 0.000103 | Test Loss: 0.000358 | Test Accuracy: 0.801499\n",
      "Step 14 | Training Loss: 0.000025 | Test Loss: 0.000200 | Test Accuracy: 0.788813\n",
      "Step 15 | Training Loss: 0.000040 | Test Loss: 0.000209 | Test Accuracy: 0.838582\n",
      "Step 16 | Training Loss: 0.000019 | Test Loss: 0.000201 | Test Accuracy: 0.844171\n",
      "Step 17 | Training Loss: 0.000029 | Test Loss: 0.000176 | Test Accuracy: 0.851712\n",
      "Step 18 | Training Loss: 0.000009 | Test Loss: 0.000170 | Test Accuracy: 0.846478\n",
      "Step 19 | Training Loss: 0.000030 | Test Loss: 0.000180 | Test Accuracy: 0.849894\n",
      "Step 20 | Training Loss: 0.000054 | Test Loss: 0.000202 | Test Accuracy: 0.852732\n",
      "Step 21 | Training Loss: 0.000016 | Test Loss: 0.000223 | Test Accuracy: 0.853043\n",
      "Step 22 | Training Loss: 0.000002 | Test Loss: 0.000190 | Test Accuracy: 0.851402\n",
      "Step 23 | Training Loss: 0.000026 | Test Loss: 0.000190 | Test Accuracy: 0.847276\n",
      "Step 24 | Training Loss: 0.000038 | Test Loss: 0.000222 | Test Accuracy: 0.854595\n",
      "Step 25 | Training Loss: 0.000022 | Test Loss: 0.000152 | Test Accuracy: 0.854196\n",
      "Step 26 | Training Loss: 0.000015 | Test Loss: 0.000098 | Test Accuracy: 0.854507\n",
      "Step 27 | Training Loss: 0.000024 | Test Loss: 0.000133 | Test Accuracy: 0.853886\n",
      "Step 28 | Training Loss: 0.000023 | Test Loss: 0.000205 | Test Accuracy: 0.854152\n",
      "Step 29 | Training Loss: 0.000026 | Test Loss: 0.000164 | Test Accuracy: 0.853841\n",
      "Step 30 | Training Loss: 0.000009 | Test Loss: 0.000179 | Test Accuracy: 0.850470\n",
      "Step 31 | Training Loss: 0.000005 | Test Loss: 0.000161 | Test Accuracy: 0.877883\n",
      "Step 32 | Training Loss: 0.000008 | Test Loss: 0.000209 | Test Accuracy: 0.853087\n",
      "Step 33 | Training Loss: 0.000018 | Test Loss: 0.000241 | Test Accuracy: 0.830598\n",
      "Step 34 | Training Loss: 0.000022 | Test Loss: 0.000182 | Test Accuracy: 0.802741\n",
      "Step 35 | Training Loss: 0.000013 | Test Loss: 0.000205 | Test Accuracy: 0.832905\n",
      "Step 36 | Training Loss: 0.000003 | Test Loss: 0.000139 | Test Accuracy: 0.842175\n",
      "Step 37 | Training Loss: 0.000035 | Test Loss: 0.000168 | Test Accuracy: 0.794225\n",
      "Step 38 | Training Loss: 0.000023 | Test Loss: 0.000165 | Test Accuracy: 0.825719\n",
      "Step 39 | Training Loss: 0.000038 | Test Loss: 0.000229 | Test Accuracy: 0.833969\n",
      "Step 40 | Training Loss: 0.000022 | Test Loss: 0.000229 | Test Accuracy: 0.803451\n",
      "Step 41 | Training Loss: 0.000010 | Test Loss: 0.000212 | Test Accuracy: 0.803540\n",
      "Step 42 | Training Loss: 0.000014 | Test Loss: 0.000226 | Test Accuracy: 0.795334\n",
      "Step 43 | Training Loss: 0.000060 | Test Loss: 0.000169 | Test Accuracy: 0.828158\n",
      "Step 44 | Training Loss: 0.000003 | Test Loss: 0.000140 | Test Accuracy: 0.827138\n",
      "Step 45 | Training Loss: 0.000018 | Test Loss: 0.000204 | Test Accuracy: 0.833969\n",
      "Step 46 | Training Loss: 0.000065 | Test Loss: 0.000166 | Test Accuracy: 0.832949\n",
      "Step 47 | Training Loss: 0.000012 | Test Loss: 0.000174 | Test Accuracy: 0.833304\n",
      "Step 48 | Training Loss: 0.000011 | Test Loss: 0.000166 | Test Accuracy: 0.829755\n",
      "Step 49 | Training Loss: 0.000031 | Test Loss: 0.000166 | Test Accuracy: 0.831529\n",
      "Step 50 | Training Loss: 0.000007 | Test Loss: 0.000206 | Test Accuracy: 0.833703\n",
      "Step 51 | Training Loss: 0.000003 | Test Loss: 0.000163 | Test Accuracy: 0.833969\n",
      "Step 52 | Training Loss: 0.000028 | Test Loss: 0.000124 | Test Accuracy: 0.832372\n",
      "Step 53 | Training Loss: 0.000057 | Test Loss: 0.000205 | Test Accuracy: 0.828557\n",
      "Step 54 | Training Loss: 0.000036 | Test Loss: 0.000219 | Test Accuracy: 0.829489\n",
      "Step 55 | Training Loss: 0.000021 | Test Loss: 0.000207 | Test Accuracy: 0.834413\n",
      "Step 56 | Training Loss: 0.000030 | Test Loss: 0.000163 | Test Accuracy: 0.824787\n",
      "Step 57 | Training Loss: 0.000023 | Test Loss: 0.000182 | Test Accuracy: 0.834634\n",
      "Step 58 | Training Loss: 0.000009 | Test Loss: 0.000147 | Test Accuracy: 0.837429\n",
      "Step 59 | Training Loss: 0.000031 | Test Loss: 0.000199 | Test Accuracy: 0.826916\n",
      "Step 60 | Training Loss: 0.000034 | Test Loss: 0.000159 | Test Accuracy: 0.832150\n",
      "Step 61 | Training Loss: 0.000008 | Test Loss: 0.000166 | Test Accuracy: 0.836764\n",
      "Step 62 | Training Loss: 0.000023 | Test Loss: 0.000136 | Test Accuracy: 0.836364\n",
      "Step 63 | Training Loss: 0.000168 | Test Loss: 0.000125 | Test Accuracy: 0.819021\n",
      "Step 64 | Training Loss: 0.000029 | Test Loss: 0.000158 | Test Accuracy: 0.834546\n",
      "Step 65 | Training Loss: 0.000004 | Test Loss: 0.000177 | Test Accuracy: 0.833481\n",
      "Step 66 | Training Loss: 0.000023 | Test Loss: 0.000181 | Test Accuracy: 0.835034\n",
      "Step 67 | Training Loss: 0.000035 | Test Loss: 0.000179 | Test Accuracy: 0.835300\n",
      "Step 68 | Training Loss: 0.000004 | Test Loss: 0.000166 | Test Accuracy: 0.828824\n",
      "Step 69 | Training Loss: 0.000049 | Test Loss: 0.000300 | Test Accuracy: 0.567912\n",
      "Step 70 | Training Loss: 0.000005 | Test Loss: 0.000167 | Test Accuracy: 0.821948\n",
      "Step 71 | Training Loss: 0.000074 | Test Loss: 0.000170 | Test Accuracy: 0.831574\n",
      "Step 72 | Training Loss: 0.000066 | Test Loss: 0.000186 | Test Accuracy: 0.705243\n",
      "Step 73 | Training Loss: 0.000046 | Test Loss: 0.000185 | Test Accuracy: 0.734963\n",
      "Step 74 | Training Loss: 0.000020 | Test Loss: 0.000188 | Test Accuracy: 0.807576\n",
      "Step 75 | Training Loss: 0.000036 | Test Loss: 0.000090 | Test Accuracy: 0.817645\n",
      "Step 76 | Training Loss: 0.000008 | Test Loss: 0.000131 | Test Accuracy: 0.557532\n",
      "Step 77 | Training Loss: 0.000170 | Test Loss: 0.000022 | Test Accuracy: 0.518453\n",
      "Step 78 | Training Loss: 0.000019 | Test Loss: 0.000166 | Test Accuracy: 0.572303\n",
      "Step 79 | Training Loss: 0.000071 | Test Loss: 0.000146 | Test Accuracy: 0.573545\n",
      "Step 80 | Training Loss: 0.000088 | Test Loss: 0.000180 | Test Accuracy: 0.555314\n",
      "Step 81 | Training Loss: 0.000079 | Test Loss: 0.000169 | Test Accuracy: 0.555137\n",
      "Step 82 | Training Loss: 0.000029 | Test Loss: 0.000169 | Test Accuracy: 0.532780\n",
      "Step 83 | Training Loss: 0.000010 | Test Loss: 0.000170 | Test Accuracy: 0.531050\n",
      "Step 84 | Training Loss: 0.000078 | Test Loss: 0.000137 | Test Accuracy: 0.548527\n",
      "Step 85 | Training Loss: 0.000137 | Test Loss: 0.000182 | Test Accuracy: 0.546620\n",
      "Step 86 | Training Loss: 0.000106 | Test Loss: 0.000174 | Test Accuracy: 0.509493\n",
      "Step 87 | Training Loss: 0.000034 | Test Loss: 0.000145 | Test Accuracy: 0.539922\n",
      "Step 88 | Training Loss: 0.000059 | Test Loss: 0.000126 | Test Accuracy: 0.563254\n",
      "Step 89 | Training Loss: 0.000102 | Test Loss: 0.000108 | Test Accuracy: 0.553451\n",
      "Step 90 | Training Loss: 0.000043 | Test Loss: 0.000129 | Test Accuracy: 0.553052\n",
      "Step 91 | Training Loss: 0.000010 | Test Loss: 0.000126 | Test Accuracy: 0.550035\n",
      "Step 92 | Training Loss: 0.000012 | Test Loss: 0.000079 | Test Accuracy: 0.555092\n",
      "Step 93 | Training Loss: 0.000016 | Test Loss: 0.000060 | Test Accuracy: 0.553052\n",
      "Step 94 | Training Loss: 0.000016 | Test Loss: 0.000053 | Test Accuracy: 0.555492\n",
      "Step 95 | Training Loss: 0.000001 | Test Loss: 0.000120 | Test Accuracy: 0.556246\n",
      "Step 96 | Training Loss: 0.000098 | Test Loss: 0.000071 | Test Accuracy: 0.550124\n",
      "Step 97 | Training Loss: 0.000007 | Test Loss: 0.000046 | Test Accuracy: 0.559351\n",
      "Step 98 | Training Loss: 0.000025 | Test Loss: 0.000015 | Test Accuracy: 0.559839\n",
      "Step 99 | Training Loss: 0.000027 | Test Loss: 0.000006 | Test Accuracy: 0.561746\n",
      "Step 100 | Training Loss: 0.000007 | Test Loss: 0.000011 | Test Accuracy: 0.564851\n",
      "Best Accuracy on Test data: 0.87788325548172\n",
      "Current Layer Attributes - epochs:100 hidden layers:4 features count:32\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 1 | Training Loss: 0.000055 | Test Loss: 0.000317 | Test Accuracy: 0.796620\n",
      "Step 2 | Training Loss: 0.000282 | Test Loss: 0.000448 | Test Accuracy: 0.644606\n",
      "Step 3 | Training Loss: 0.000034 | Test Loss: 0.000314 | Test Accuracy: 0.629436\n",
      "Step 4 | Training Loss: 0.000027 | Test Loss: 0.000276 | Test Accuracy: 0.635868\n",
      "Step 5 | Training Loss: 0.000057 | Test Loss: 0.000307 | Test Accuracy: 0.652679\n",
      "Step 6 | Training Loss: 0.000018 | Test Loss: 0.000342 | Test Accuracy: 0.678983\n",
      "Step 7 | Training Loss: 0.000066 | Test Loss: 0.000280 | Test Accuracy: 0.690694\n",
      "Step 8 | Training Loss: 0.000052 | Test Loss: 0.000379 | Test Accuracy: 0.711098\n",
      "Step 9 | Training Loss: 0.000002 | Test Loss: 0.000269 | Test Accuracy: 0.657337\n",
      "Step 10 | Training Loss: 0.000070 | Test Loss: 0.000287 | Test Accuracy: 0.723341\n",
      "Step 11 | Training Loss: 0.000001 | Test Loss: 0.000273 | Test Accuracy: 0.704844\n",
      "Step 12 | Training Loss: 0.000022 | Test Loss: 0.000247 | Test Accuracy: 0.701650\n",
      "Step 13 | Training Loss: 0.000075 | Test Loss: 0.000362 | Test Accuracy: 0.709679\n",
      "Step 14 | Training Loss: 0.000026 | Test Loss: 0.000314 | Test Accuracy: 0.695751\n",
      "Step 15 | Training Loss: 0.000028 | Test Loss: 0.000310 | Test Accuracy: 0.693888\n",
      "Step 16 | Training Loss: 0.000004 | Test Loss: 0.000317 | Test Accuracy: 0.704489\n",
      "Step 17 | Training Loss: 0.000026 | Test Loss: 0.000316 | Test Accuracy: 0.706751\n",
      "Step 18 | Training Loss: 0.000035 | Test Loss: 0.000316 | Test Accuracy: 0.708526\n",
      "Step 19 | Training Loss: 0.000073 | Test Loss: 0.000296 | Test Accuracy: 0.713715\n",
      "Step 20 | Training Loss: 0.000084 | Test Loss: 0.000296 | Test Accuracy: 0.740951\n",
      "Step 21 | Training Loss: 0.000034 | Test Loss: 0.000323 | Test Accuracy: 0.750399\n",
      "Step 22 | Training Loss: 0.000022 | Test Loss: 0.000256 | Test Accuracy: 0.746407\n",
      "Step 23 | Training Loss: 0.000045 | Test Loss: 0.000258 | Test Accuracy: 0.740108\n",
      "Step 24 | Training Loss: 0.000023 | Test Loss: 0.000239 | Test Accuracy: 0.712207\n",
      "Step 25 | Training Loss: 0.000048 | Test Loss: 0.000328 | Test Accuracy: 0.735761\n",
      "Step 26 | Training Loss: 0.000037 | Test Loss: 0.000295 | Test Accuracy: 0.800967\n",
      "Step 27 | Training Loss: 0.000065 | Test Loss: 0.000204 | Test Accuracy: 0.758650\n",
      "Step 28 | Training Loss: 0.000040 | Test Loss: 0.000207 | Test Accuracy: 0.752040\n",
      "Step 29 | Training Loss: 0.000084 | Test Loss: 0.000210 | Test Accuracy: 0.746806\n",
      "Step 30 | Training Loss: 0.000068 | Test Loss: 0.000228 | Test Accuracy: 0.757763\n",
      "Step 31 | Training Loss: 0.000030 | Test Loss: 0.000240 | Test Accuracy: 0.774175\n",
      "Step 32 | Training Loss: 0.000008 | Test Loss: 0.000426 | Test Accuracy: 0.641368\n",
      "Step 33 | Training Loss: 0.000054 | Test Loss: 0.000365 | Test Accuracy: 0.669535\n",
      "Step 34 | Training Loss: 0.000076 | Test Loss: 0.000395 | Test Accuracy: 0.609475\n",
      "Step 35 | Training Loss: 0.000062 | Test Loss: 0.000264 | Test Accuracy: 0.713582\n",
      "Step 36 | Training Loss: 0.000023 | Test Loss: 0.000309 | Test Accuracy: 0.717619\n",
      "Step 37 | Training Loss: 0.000032 | Test Loss: 0.000230 | Test Accuracy: 0.766634\n",
      "Step 38 | Training Loss: 0.000062 | Test Loss: 0.000300 | Test Accuracy: 0.696505\n",
      "Step 39 | Training Loss: 0.000075 | Test Loss: 0.000261 | Test Accuracy: 0.665720\n",
      "Step 40 | Training Loss: 0.000084 | Test Loss: 0.000223 | Test Accuracy: 0.645893\n",
      "Step 41 | Training Loss: 0.000082 | Test Loss: 0.000273 | Test Accuracy: 0.653123\n",
      "Step 42 | Training Loss: 0.000024 | Test Loss: 0.000284 | Test Accuracy: 0.644251\n",
      "Step 43 | Training Loss: 0.000053 | Test Loss: 0.000286 | Test Accuracy: 0.649973\n",
      "Step 44 | Training Loss: 0.000002 | Test Loss: 0.000280 | Test Accuracy: 0.672818\n",
      "Step 45 | Training Loss: 0.000071 | Test Loss: 0.000245 | Test Accuracy: 0.663458\n",
      "Step 46 | Training Loss: 0.000022 | Test Loss: 0.000330 | Test Accuracy: 0.655829\n",
      "Step 47 | Training Loss: 0.000032 | Test Loss: 0.000486 | Test Accuracy: 0.518808\n",
      "Step 48 | Training Loss: 0.000018 | Test Loss: 0.000348 | Test Accuracy: 0.607213\n",
      "Step 49 | Training Loss: 0.000010 | Test Loss: 0.000259 | Test Accuracy: 0.680713\n",
      "Step 50 | Training Loss: 0.000046 | Test Loss: 0.000169 | Test Accuracy: 0.671886\n",
      "Step 51 | Training Loss: 0.000080 | Test Loss: 0.000431 | Test Accuracy: 0.587961\n",
      "Step 52 | Training Loss: 0.000045 | Test Loss: 0.000436 | Test Accuracy: 0.569819\n",
      "Step 53 | Training Loss: 0.000012 | Test Loss: 0.000361 | Test Accuracy: 0.632230\n",
      "Step 54 | Training Loss: 0.000012 | Test Loss: 0.000175 | Test Accuracy: 0.643941\n",
      "Step 55 | Training Loss: 0.000010 | Test Loss: 0.000256 | Test Accuracy: 0.641767\n",
      "Step 56 | Training Loss: 0.000015 | Test Loss: 0.000281 | Test Accuracy: 0.640303\n",
      "Step 57 | Training Loss: 0.000041 | Test Loss: 0.000239 | Test Accuracy: 0.637154\n",
      "Step 58 | Training Loss: 0.000002 | Test Loss: 0.000246 | Test Accuracy: 0.650683\n",
      "Step 59 | Training Loss: 0.000089 | Test Loss: 0.000234 | Test Accuracy: 0.638884\n",
      "Step 60 | Training Loss: 0.000074 | Test Loss: 0.000156 | Test Accuracy: 0.638041\n",
      "Step 61 | Training Loss: 0.000009 | Test Loss: 0.000236 | Test Accuracy: 0.636444\n",
      "Step 62 | Training Loss: 0.000036 | Test Loss: 0.000327 | Test Accuracy: 0.563121\n",
      "Step 63 | Training Loss: 0.000005 | Test Loss: 0.000400 | Test Accuracy: 0.562589\n",
      "Step 64 | Training Loss: 0.000084 | Test Loss: 0.000292 | Test Accuracy: 0.595591\n",
      "Step 65 | Training Loss: 0.000034 | Test Loss: 0.000249 | Test Accuracy: 0.631742\n",
      "Step 66 | Training Loss: 0.000043 | Test Loss: 0.000196 | Test Accuracy: 0.653611\n",
      "Step 67 | Training Loss: 0.000040 | Test Loss: 0.000160 | Test Accuracy: 0.658579\n",
      "Step 68 | Training Loss: 0.000025 | Test Loss: 0.000299 | Test Accuracy: 0.685548\n",
      "Step 69 | Training Loss: 0.000071 | Test Loss: 0.000170 | Test Accuracy: 0.685016\n",
      "Step 70 | Training Loss: 0.000006 | Test Loss: 0.000177 | Test Accuracy: 0.681379\n",
      "Step 71 | Training Loss: 0.000039 | Test Loss: 0.000275 | Test Accuracy: 0.648776\n",
      "Step 72 | Training Loss: 0.000023 | Test Loss: 0.000263 | Test Accuracy: 0.673483\n",
      "Step 73 | Training Loss: 0.000012 | Test Loss: 0.000267 | Test Accuracy: 0.655962\n",
      "Step 74 | Training Loss: 0.000070 | Test Loss: 0.000354 | Test Accuracy: 0.636356\n",
      "Step 75 | Training Loss: 0.000000 | Test Loss: 0.000636 | Test Accuracy: 0.509359\n",
      "Step 76 | Training Loss: 0.000026 | Test Loss: 0.000448 | Test Accuracy: 0.628327\n",
      "Step 77 | Training Loss: 0.000086 | Test Loss: 0.000572 | Test Accuracy: 0.536418\n",
      "Step 78 | Training Loss: 0.000022 | Test Loss: 0.000402 | Test Accuracy: 0.636888\n",
      "Step 79 | Training Loss: 0.000017 | Test Loss: 0.000312 | Test Accuracy: 0.629081\n",
      "Step 80 | Training Loss: 0.000026 | Test Loss: 0.000417 | Test Accuracy: 0.614132\n",
      "Step 81 | Training Loss: 0.000033 | Test Loss: 0.000692 | Test Accuracy: 0.499734\n",
      "Step 82 | Training Loss: 0.000009 | Test Loss: 0.000608 | Test Accuracy: 0.506388\n",
      "Step 83 | Training Loss: 0.000053 | Test Loss: 0.000524 | Test Accuracy: 0.536994\n",
      "Step 84 | Training Loss: 0.000033 | Test Loss: 0.000323 | Test Accuracy: 0.656583\n",
      "Step 85 | Training Loss: 0.000060 | Test Loss: 0.000224 | Test Accuracy: 0.651748\n",
      "Step 86 | Training Loss: 0.000099 | Test Loss: 0.000331 | Test Accuracy: 0.608144\n",
      "Step 87 | Training Loss: 0.000034 | Test Loss: 0.000335 | Test Accuracy: 0.634759\n",
      "Step 88 | Training Loss: 0.000009 | Test Loss: 0.000276 | Test Accuracy: 0.645671\n",
      "Step 89 | Training Loss: 0.000040 | Test Loss: 0.000255 | Test Accuracy: 0.656450\n",
      "Step 90 | Training Loss: 0.000015 | Test Loss: 0.000403 | Test Accuracy: 0.642477\n",
      "Step 91 | Training Loss: 0.000000 | Test Loss: 0.000425 | Test Accuracy: 0.652280\n",
      "Step 92 | Training Loss: 0.000005 | Test Loss: 0.000387 | Test Accuracy: 0.648243\n",
      "Step 93 | Training Loss: 0.000065 | Test Loss: 0.000330 | Test Accuracy: 0.649219\n",
      "Step 94 | Training Loss: 0.000011 | Test Loss: 0.000310 | Test Accuracy: 0.663680\n",
      "Step 95 | Training Loss: 0.000102 | Test Loss: 0.000300 | Test Accuracy: 0.650373\n",
      "Step 96 | Training Loss: 0.000032 | Test Loss: 0.000303 | Test Accuracy: 0.647401\n",
      "Step 97 | Training Loss: 0.000013 | Test Loss: 0.000348 | Test Accuracy: 0.632674\n",
      "Step 98 | Training Loss: 0.000054 | Test Loss: 0.000199 | Test Accuracy: 0.658268\n",
      "Step 99 | Training Loss: 0.000030 | Test Loss: 0.000416 | Test Accuracy: 0.668337\n",
      "Step 100 | Training Loss: 0.000017 | Test Loss: 0.000460 | Test Accuracy: 0.647844\n",
      "Best Accuracy on Test data: 0.8009669780731201\n",
      "Current Layer Attributes - epochs:100 hidden layers:6 features count:4\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 1 | Training Loss: 0.000379 | Test Loss: 0.000814 | Test Accuracy: 0.605660\n",
      "Step 2 | Training Loss: 0.000106 | Test Loss: 0.000778 | Test Accuracy: 0.620653\n",
      "Step 3 | Training Loss: 0.000102 | Test Loss: 0.000560 | Test Accuracy: 0.657647\n",
      "Step 4 | Training Loss: 0.000017 | Test Loss: 0.000675 | Test Accuracy: 0.563298\n",
      "Step 5 | Training Loss: 0.000013 | Test Loss: 0.001687 | Test Accuracy: 0.604329\n",
      "Step 6 | Training Loss: 0.000042 | Test Loss: 0.000424 | Test Accuracy: 0.527502\n",
      "Step 7 | Training Loss: 0.000001 | Test Loss: 0.000591 | Test Accuracy: 0.587917\n",
      "Step 8 | Training Loss: 0.000031 | Test Loss: 0.000496 | Test Accuracy: 0.582328\n",
      "Step 9 | Training Loss: 0.000016 | Test Loss: 0.000354 | Test Accuracy: 0.610806\n",
      "Step 10 | Training Loss: 0.000036 | Test Loss: 0.000282 | Test Accuracy: 0.622205\n",
      "Step 11 | Training Loss: 0.000031 | Test Loss: 0.000253 | Test Accuracy: 0.638485\n",
      "Step 12 | Training Loss: 0.000041 | Test Loss: 0.000330 | Test Accuracy: 0.622649\n",
      "Step 13 | Training Loss: 0.000072 | Test Loss: 0.000406 | Test Accuracy: 0.584901\n",
      "Step 14 | Training Loss: 0.000034 | Test Loss: 0.000345 | Test Accuracy: 0.613778\n",
      "Step 15 | Training Loss: 0.000044 | Test Loss: 0.000458 | Test Accuracy: 0.555979\n",
      "Step 16 | Training Loss: 0.000091 | Test Loss: 0.000429 | Test Accuracy: 0.582993\n",
      "Step 17 | Training Loss: 0.000078 | Test Loss: 0.000438 | Test Accuracy: 0.646602\n",
      "Step 18 | Training Loss: 0.000042 | Test Loss: 0.000320 | Test Accuracy: 0.654853\n",
      "Step 19 | Training Loss: 0.000035 | Test Loss: 0.000382 | Test Accuracy: 0.642920\n",
      "Step 20 | Training Loss: 0.000003 | Test Loss: 0.000379 | Test Accuracy: 0.641945\n",
      "Step 21 | Training Loss: 0.000012 | Test Loss: 0.000297 | Test Accuracy: 0.634980\n",
      "Step 22 | Training Loss: 0.000046 | Test Loss: 0.000385 | Test Accuracy: 0.610806\n",
      "Step 23 | Training Loss: 0.000085 | Test Loss: 0.000346 | Test Accuracy: 0.817468\n",
      "Step 24 | Training Loss: 0.000033 | Test Loss: 0.000492 | Test Accuracy: 0.802874\n",
      "Step 25 | Training Loss: 0.000072 | Test Loss: 0.000270 | Test Accuracy: 0.833393\n",
      "Step 26 | Training Loss: 0.000038 | Test Loss: 0.000226 | Test Accuracy: 0.716865\n",
      "Step 27 | Training Loss: 0.000047 | Test Loss: 0.000254 | Test Accuracy: 0.777369\n",
      "Step 28 | Training Loss: 0.000071 | Test Loss: 0.000221 | Test Accuracy: 0.804959\n",
      "Step 29 | Training Loss: 0.000034 | Test Loss: 0.000300 | Test Accuracy: 0.803052\n",
      "Step 30 | Training Loss: 0.000036 | Test Loss: 0.000290 | Test Accuracy: 0.798439\n",
      "Step 31 | Training Loss: 0.000076 | Test Loss: 0.000138 | Test Accuracy: 0.807665\n",
      "Step 32 | Training Loss: 0.000064 | Test Loss: 0.000180 | Test Accuracy: 0.790454\n",
      "Step 33 | Training Loss: 0.000008 | Test Loss: 0.000398 | Test Accuracy: 0.694154\n",
      "Step 34 | Training Loss: 0.000059 | Test Loss: 0.000273 | Test Accuracy: 0.798660\n",
      "Step 35 | Training Loss: 0.000014 | Test Loss: 0.000344 | Test Accuracy: 0.800124\n",
      "Step 36 | Training Loss: 0.000127 | Test Loss: 0.000251 | Test Accuracy: 0.797596\n",
      "Step 37 | Training Loss: 0.000022 | Test Loss: 0.000277 | Test Accuracy: 0.777724\n",
      "Step 38 | Training Loss: 0.000004 | Test Loss: 0.000319 | Test Accuracy: 0.785087\n",
      "Step 39 | Training Loss: 0.000008 | Test Loss: 0.000320 | Test Accuracy: 0.793737\n",
      "Step 40 | Training Loss: 0.000070 | Test Loss: 0.000286 | Test Accuracy: 0.678229\n",
      "Step 41 | Training Loss: 0.000026 | Test Loss: 0.000264 | Test Accuracy: 0.720059\n",
      "Step 42 | Training Loss: 0.000023 | Test Loss: 0.000303 | Test Accuracy: 0.757496\n",
      "Step 43 | Training Loss: 0.000135 | Test Loss: 0.000243 | Test Accuracy: 0.688698\n",
      "Step 44 | Training Loss: 0.000048 | Test Loss: 0.000237 | Test Accuracy: 0.750532\n",
      "Step 45 | Training Loss: 0.000062 | Test Loss: 0.000110 | Test Accuracy: 0.723208\n",
      "Step 46 | Training Loss: 0.000074 | Test Loss: 0.000186 | Test Accuracy: 0.769606\n",
      "Step 47 | Training Loss: 0.000277 | Test Loss: 0.000518 | Test Accuracy: 0.544047\n",
      "Step 48 | Training Loss: 0.000120 | Test Loss: 0.000510 | Test Accuracy: 0.531938\n",
      "Step 49 | Training Loss: 0.000096 | Test Loss: 0.000508 | Test Accuracy: 0.576384\n",
      "Step 50 | Training Loss: 0.000017 | Test Loss: 0.000433 | Test Accuracy: 0.579578\n",
      "Step 51 | Training Loss: 0.000036 | Test Loss: 0.000418 | Test Accuracy: 0.523820\n",
      "Step 52 | Training Loss: 0.000293 | Test Loss: 0.000717 | Test Accuracy: 0.523776\n",
      "Step 53 | Training Loss: 0.000000 | Test Loss: 0.000199 | Test Accuracy: 0.526171\n",
      "Step 54 | Training Loss: 0.000149 | Test Loss: 0.000391 | Test Accuracy: 0.525240\n",
      "Step 55 | Training Loss: 0.000216 | Test Loss: 0.000290 | Test Accuracy: 0.526615\n",
      "Step 56 | Training Loss: 0.000027 | Test Loss: 0.000456 | Test Accuracy: 0.508339\n",
      "Step 57 | Training Loss: 0.000007 | Test Loss: 0.000429 | Test Accuracy: 0.510690\n",
      "Step 58 | Training Loss: 0.000148 | Test Loss: 0.000615 | Test Accuracy: 0.509182\n",
      "Step 59 | Training Loss: 0.000187 | Test Loss: 0.000380 | Test Accuracy: 0.509005\n",
      "Step 60 | Training Loss: 0.000288 | Test Loss: 0.000404 | Test Accuracy: 0.506210\n",
      "Step 61 | Training Loss: 0.000215 | Test Loss: 0.000488 | Test Accuracy: 0.505500\n",
      "Step 62 | Training Loss: 0.000285 | Test Loss: 0.000569 | Test Accuracy: 0.511977\n",
      "Step 63 | Training Loss: 0.000152 | Test Loss: 0.000283 | Test Accuracy: 0.501819\n",
      "Step 64 | Training Loss: 0.000271 | Test Loss: 0.000361 | Test Accuracy: 0.507896\n",
      "Step 65 | Training Loss: 0.000399 | Test Loss: 0.000482 | Test Accuracy: 0.478930\n",
      "Step 66 | Training Loss: 0.000529 | Test Loss: 0.000377 | Test Accuracy: 0.522223\n",
      "Step 67 | Training Loss: 0.000096 | Test Loss: 0.000376 | Test Accuracy: 0.486293\n",
      "Step 68 | Training Loss: 0.000088 | Test Loss: 0.000420 | Test Accuracy: 0.530208\n",
      "Step 69 | Training Loss: 0.000023 | Test Loss: 0.000442 | Test Accuracy: 0.526570\n",
      "Step 70 | Training Loss: 0.000126 | Test Loss: 0.000304 | Test Accuracy: 0.523022\n",
      "Step 71 | Training Loss: 0.000075 | Test Loss: 0.000380 | Test Accuracy: 0.523909\n",
      "Step 72 | Training Loss: 0.000076 | Test Loss: 0.000352 | Test Accuracy: 0.523998\n",
      "Step 73 | Training Loss: 0.000060 | Test Loss: 0.000394 | Test Accuracy: 0.523998\n",
      "Step 74 | Training Loss: 0.000022 | Test Loss: 0.000294 | Test Accuracy: 0.523687\n",
      "Step 75 | Training Loss: 0.000034 | Test Loss: 0.000234 | Test Accuracy: 0.526703\n",
      "Step 76 | Training Loss: 0.000025 | Test Loss: 0.000333 | Test Accuracy: 0.519429\n",
      "Step 77 | Training Loss: 0.000070 | Test Loss: 0.000322 | Test Accuracy: 0.525018\n",
      "Step 78 | Training Loss: 0.000025 | Test Loss: 0.000297 | Test Accuracy: 0.522933\n",
      "Step 79 | Training Loss: 0.000054 | Test Loss: 0.000275 | Test Accuracy: 0.520582\n",
      "Step 80 | Training Loss: 0.000015 | Test Loss: 0.000313 | Test Accuracy: 0.521824\n",
      "Step 81 | Training Loss: 0.000013 | Test Loss: 0.000307 | Test Accuracy: 0.521513\n",
      "Step 82 | Training Loss: 0.000013 | Test Loss: 0.000232 | Test Accuracy: 0.521247\n",
      "Step 83 | Training Loss: 0.000079 | Test Loss: 0.000311 | Test Accuracy: 0.522090\n",
      "Step 84 | Training Loss: 0.000001 | Test Loss: 0.000283 | Test Accuracy: 0.521247\n",
      "Step 85 | Training Loss: 0.000019 | Test Loss: 0.000221 | Test Accuracy: 0.519917\n",
      "Step 86 | Training Loss: 0.000016 | Test Loss: 0.000210 | Test Accuracy: 0.525417\n",
      "Step 87 | Training Loss: 0.000084 | Test Loss: 0.000157 | Test Accuracy: 0.522667\n",
      "Step 88 | Training Loss: 0.000036 | Test Loss: 0.000269 | Test Accuracy: 0.526437\n",
      "Step 89 | Training Loss: 0.000001 | Test Loss: 0.000240 | Test Accuracy: 0.524796\n",
      "Step 90 | Training Loss: 0.000060 | Test Loss: 0.000257 | Test Accuracy: 0.521247\n",
      "Step 91 | Training Loss: 0.000014 | Test Loss: 0.000263 | Test Accuracy: 0.523953\n",
      "Step 92 | Training Loss: 0.000039 | Test Loss: 0.000288 | Test Accuracy: 0.518675\n",
      "Step 93 | Training Loss: 0.000013 | Test Loss: 0.000287 | Test Accuracy: 0.522046\n",
      "Step 94 | Training Loss: 0.000062 | Test Loss: 0.000269 | Test Accuracy: 0.517654\n",
      "Step 95 | Training Loss: 0.000061 | Test Loss: 0.000277 | Test Accuracy: 0.521292\n",
      "Step 96 | Training Loss: 0.000018 | Test Loss: 0.000265 | Test Accuracy: 0.520138\n",
      "Step 97 | Training Loss: 0.000031 | Test Loss: 0.000253 | Test Accuracy: 0.524885\n",
      "Step 98 | Training Loss: 0.000062 | Test Loss: 0.000222 | Test Accuracy: 0.522001\n",
      "Step 99 | Training Loss: 0.000032 | Test Loss: 0.000250 | Test Accuracy: 0.521070\n",
      "Step 100 | Training Loss: 0.000040 | Test Loss: 0.000241 | Test Accuracy: 0.526482\n",
      "Best Accuracy on Test data: 0.8333925008773804\n",
      "Current Layer Attributes - epochs:100 hidden layers:6 features count:8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 1 | Training Loss: 0.000694 | Test Loss: 0.000681 | Test Accuracy: 0.621718\n",
      "Step 2 | Training Loss: 0.000053 | Test Loss: 0.000171 | Test Accuracy: 0.788015\n",
      "Step 3 | Training Loss: 0.000011 | Test Loss: 0.000295 | Test Accuracy: 0.802120\n",
      "Step 4 | Training Loss: 0.000078 | Test Loss: 0.000469 | Test Accuracy: 0.857567\n",
      "Step 5 | Training Loss: 0.000036 | Test Loss: 0.000341 | Test Accuracy: 0.792805\n",
      "Step 6 | Training Loss: 0.000026 | Test Loss: 0.000249 | Test Accuracy: 0.801056\n",
      "Step 7 | Training Loss: 0.000000 | Test Loss: 0.000300 | Test Accuracy: 0.775861\n",
      "Step 8 | Training Loss: 0.000033 | Test Loss: 0.000227 | Test Accuracy: 0.804737\n",
      "Step 9 | Training Loss: 0.000073 | Test Loss: 0.000280 | Test Accuracy: 0.811081\n",
      "Step 10 | Training Loss: 0.000040 | Test Loss: 0.000220 | Test Accuracy: 0.813875\n",
      "Step 11 | Training Loss: 0.000072 | Test Loss: 0.000242 | Test Accuracy: 0.814984\n",
      "Step 12 | Training Loss: 0.000032 | Test Loss: 0.000232 | Test Accuracy: 0.832594\n",
      "Step 13 | Training Loss: 0.000014 | Test Loss: 0.000587 | Test Accuracy: 0.823146\n",
      "Step 14 | Training Loss: 0.000009 | Test Loss: 0.000261 | Test Accuracy: 0.769606\n",
      "Step 15 | Training Loss: 0.000066 | Test Loss: 0.000238 | Test Accuracy: 0.758561\n",
      "Step 16 | Training Loss: 0.000086 | Test Loss: 0.000171 | Test Accuracy: 0.756432\n",
      "Step 17 | Training Loss: 0.000086 | Test Loss: 0.000230 | Test Accuracy: 0.747782\n",
      "Step 18 | Training Loss: 0.000024 | Test Loss: 0.000255 | Test Accuracy: 0.765348\n",
      "Step 19 | Training Loss: 0.000132 | Test Loss: 0.000481 | Test Accuracy: 0.709013\n",
      "Step 20 | Training Loss: 0.000050 | Test Loss: 0.000421 | Test Accuracy: 0.695218\n",
      "Step 21 | Training Loss: 0.000028 | Test Loss: 0.000200 | Test Accuracy: 0.708836\n",
      "Step 22 | Training Loss: 0.000061 | Test Loss: 0.000287 | Test Accuracy: 0.724938\n",
      "Step 23 | Training Loss: 0.000117 | Test Loss: 0.000425 | Test Accuracy: 0.727378\n",
      "Step 24 | Training Loss: 0.000202 | Test Loss: 0.000358 | Test Accuracy: 0.750089\n",
      "Step 25 | Training Loss: 0.000062 | Test Loss: 0.000301 | Test Accuracy: 0.769384\n",
      "Step 26 | Training Loss: 0.000055 | Test Loss: 0.000241 | Test Accuracy: 0.805669\n",
      "Step 27 | Training Loss: 0.000033 | Test Loss: 0.000220 | Test Accuracy: 0.820839\n",
      "Step 28 | Training Loss: 0.000045 | Test Loss: 0.000201 | Test Accuracy: 0.827936\n",
      "Step 29 | Training Loss: 0.000051 | Test Loss: 0.000188 | Test Accuracy: 0.823856\n",
      "Step 30 | Training Loss: 0.000016 | Test Loss: 0.000211 | Test Accuracy: 0.822347\n",
      "Step 31 | Training Loss: 0.000014 | Test Loss: 0.000177 | Test Accuracy: 0.812944\n",
      "Step 32 | Training Loss: 0.000129 | Test Loss: 0.000995 | Test Accuracy: 0.482434\n",
      "Step 33 | Training Loss: 0.000081 | Test Loss: 0.000798 | Test Accuracy: 0.502351\n",
      "Step 34 | Training Loss: 0.000024 | Test Loss: 0.000524 | Test Accuracy: 0.461409\n",
      "Step 35 | Training Loss: 0.000088 | Test Loss: 0.000348 | Test Accuracy: 0.472365\n",
      "Step 36 | Training Loss: 0.000128 | Test Loss: 0.000327 | Test Accuracy: 0.442468\n",
      "Step 37 | Training Loss: 0.000110 | Test Loss: 0.000212 | Test Accuracy: 0.503637\n",
      "Step 38 | Training Loss: 0.000159 | Test Loss: 0.000586 | Test Accuracy: 0.502218\n",
      "Step 39 | Training Loss: 0.000368 | Test Loss: 0.000733 | Test Accuracy: 0.468817\n",
      "Step 40 | Training Loss: 0.000233 | Test Loss: 0.000710 | Test Accuracy: 0.482922\n",
      "Step 41 | Training Loss: 0.000159 | Test Loss: 0.000504 | Test Accuracy: 0.514461\n",
      "Step 42 | Training Loss: 0.000033 | Test Loss: 0.000154 | Test Accuracy: 0.495963\n",
      "Step 43 | Training Loss: 0.000130 | Test Loss: 0.000550 | Test Accuracy: 0.499024\n",
      "Step 44 | Training Loss: 0.000052 | Test Loss: 0.000377 | Test Accuracy: 0.499556\n",
      "Step 45 | Training Loss: 0.000272 | Test Loss: 0.000298 | Test Accuracy: 0.485229\n",
      "Step 46 | Training Loss: 0.000192 | Test Loss: 0.000357 | Test Accuracy: 0.446859\n",
      "Step 47 | Training Loss: 0.000030 | Test Loss: 0.000327 | Test Accuracy: 0.462961\n",
      "Step 48 | Training Loss: 0.000006 | Test Loss: 0.000306 | Test Accuracy: 0.518054\n",
      "Step 49 | Training Loss: 0.000075 | Test Loss: 0.000104 | Test Accuracy: 0.472188\n",
      "Step 50 | Training Loss: 0.000029 | Test Loss: 0.000303 | Test Accuracy: 0.503416\n",
      "Step 51 | Training Loss: 0.000015 | Test Loss: 0.000245 | Test Accuracy: 0.506476\n",
      "Step 52 | Training Loss: 0.000007 | Test Loss: 0.000398 | Test Accuracy: 0.522844\n",
      "Step 53 | Training Loss: 0.000008 | Test Loss: 0.000226 | Test Accuracy: 0.488467\n",
      "Step 54 | Training Loss: 0.000033 | Test Loss: 0.000156 | Test Accuracy: 0.474849\n",
      "Step 55 | Training Loss: 0.000075 | Test Loss: 0.000282 | Test Accuracy: 0.501686\n",
      "Step 56 | Training Loss: 0.000004 | Test Loss: 0.000271 | Test Accuracy: 0.485273\n",
      "Step 57 | Training Loss: 0.000134 | Test Loss: 0.000134 | Test Accuracy: 0.467308\n",
      "Step 58 | Training Loss: 0.000086 | Test Loss: 0.000266 | Test Accuracy: 0.474095\n",
      "Step 59 | Training Loss: 0.000017 | Test Loss: 0.000181 | Test Accuracy: 0.483233\n",
      "Step 60 | Training Loss: 0.000085 | Test Loss: 0.000326 | Test Accuracy: 0.506299\n",
      "Step 61 | Training Loss: 0.000046 | Test Loss: 0.000157 | Test Accuracy: 0.518231\n",
      "Step 62 | Training Loss: 0.000071 | Test Loss: 0.000284 | Test Accuracy: 0.488733\n",
      "Step 63 | Training Loss: 0.000171 | Test Loss: 0.000261 | Test Accuracy: 0.495076\n",
      "Step 64 | Training Loss: 0.000137 | Test Loss: 0.000085 | Test Accuracy: 0.496895\n",
      "Step 65 | Training Loss: 0.000100 | Test Loss: 0.000295 | Test Accuracy: 0.507230\n",
      "Step 66 | Training Loss: 0.000006 | Test Loss: 0.000372 | Test Accuracy: 0.502307\n",
      "Step 67 | Training Loss: 0.000071 | Test Loss: 0.000231 | Test Accuracy: 0.484386\n",
      "Step 68 | Training Loss: 0.000040 | Test Loss: 0.000339 | Test Accuracy: 0.483455\n",
      "Step 69 | Training Loss: 0.000036 | Test Loss: 0.000257 | Test Accuracy: 0.524663\n",
      "Step 70 | Training Loss: 0.000072 | Test Loss: 0.000291 | Test Accuracy: 0.487181\n",
      "Step 71 | Training Loss: 0.000096 | Test Loss: 0.000288 | Test Accuracy: 0.486249\n",
      "Step 72 | Training Loss: 0.000000 | Test Loss: 0.000138 | Test Accuracy: 0.489265\n",
      "Step 73 | Training Loss: 0.000005 | Test Loss: 0.000212 | Test Accuracy: 0.536152\n",
      "Step 74 | Training Loss: 0.000011 | Test Loss: 0.000238 | Test Accuracy: 0.502528\n",
      "Step 75 | Training Loss: 0.000049 | Test Loss: 0.000228 | Test Accuracy: 0.516812\n",
      "Step 76 | Training Loss: 0.000056 | Test Loss: 0.000265 | Test Accuracy: 0.518763\n",
      "Step 77 | Training Loss: 0.000057 | Test Loss: 0.000269 | Test Accuracy: 0.495697\n",
      "Step 78 | Training Loss: 0.000003 | Test Loss: 0.000131 | Test Accuracy: 0.470458\n",
      "Step 79 | Training Loss: 0.000028 | Test Loss: 0.000314 | Test Accuracy: 0.467308\n",
      "Step 80 | Training Loss: 0.000117 | Test Loss: 0.000242 | Test Accuracy: 0.509049\n",
      "Step 81 | Training Loss: 0.000072 | Test Loss: 0.000360 | Test Accuracy: 0.515969\n",
      "Step 82 | Training Loss: 0.000004 | Test Loss: 0.000340 | Test Accuracy: 0.460655\n",
      "Step 83 | Training Loss: 0.000015 | Test Loss: 0.000433 | Test Accuracy: 0.449965\n",
      "Step 84 | Training Loss: 0.000004 | Test Loss: 0.000374 | Test Accuracy: 0.521425\n",
      "Step 85 | Training Loss: 0.000048 | Test Loss: 0.000136 | Test Accuracy: 0.470546\n",
      "Step 86 | Training Loss: 0.000002 | Test Loss: 0.000224 | Test Accuracy: 0.512465\n",
      "Step 87 | Training Loss: 0.000001 | Test Loss: 0.000143 | Test Accuracy: 0.491971\n",
      "Step 88 | Training Loss: 0.000064 | Test Loss: 0.000082 | Test Accuracy: 0.469083\n",
      "Step 89 | Training Loss: 0.000033 | Test Loss: 0.000224 | Test Accuracy: 0.483898\n",
      "Step 90 | Training Loss: 0.000065 | Test Loss: 0.000118 | Test Accuracy: 0.466111\n",
      "Step 91 | Training Loss: 0.000007 | Test Loss: 0.000149 | Test Accuracy: 0.468506\n",
      "Step 92 | Training Loss: 0.000055 | Test Loss: 0.000229 | Test Accuracy: 0.471478\n",
      "Step 93 | Training Loss: 0.000001 | Test Loss: 0.000079 | Test Accuracy: 0.488999\n",
      "Step 94 | Training Loss: 0.000002 | Test Loss: 0.000131 | Test Accuracy: 0.514993\n",
      "Step 95 | Training Loss: 0.000089 | Test Loss: 0.000264 | Test Accuracy: 0.483721\n",
      "Step 96 | Training Loss: 0.000066 | Test Loss: 0.000156 | Test Accuracy: 0.475115\n",
      "Step 97 | Training Loss: 0.000004 | Test Loss: 0.000210 | Test Accuracy: 0.488156\n",
      "Step 98 | Training Loss: 0.000018 | Test Loss: 0.000092 | Test Accuracy: 0.477289\n",
      "Step 99 | Training Loss: 0.000045 | Test Loss: 0.000347 | Test Accuracy: 0.512686\n",
      "Step 100 | Training Loss: 0.000006 | Test Loss: 0.000215 | Test Accuracy: 0.491128\n",
      "Best Accuracy on Test data: 0.8575674295425415\n",
      "Current Layer Attributes - epochs:100 hidden layers:6 features count:16\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 1 | Training Loss: 0.000288 | Test Loss: 0.000057 | Test Accuracy: 0.852378\n",
      "Step 2 | Training Loss: 0.000094 | Test Loss: 0.000314 | Test Accuracy: 0.641945\n",
      "Step 3 | Training Loss: 0.000077 | Test Loss: 0.000327 | Test Accuracy: 0.779143\n",
      "Step 4 | Training Loss: 0.000034 | Test Loss: 0.000264 | Test Accuracy: 0.782514\n",
      "Step 5 | Training Loss: 0.000065 | Test Loss: 0.000741 | Test Accuracy: 0.554383\n",
      "Step 6 | Training Loss: 0.000084 | Test Loss: 0.000450 | Test Accuracy: 0.588405\n",
      "Step 7 | Training Loss: 0.000066 | Test Loss: 0.000416 | Test Accuracy: 0.647046\n",
      "Step 8 | Training Loss: 0.000004 | Test Loss: 0.000434 | Test Accuracy: 0.695218\n",
      "Step 9 | Training Loss: 0.000028 | Test Loss: 0.000463 | Test Accuracy: 0.619012\n",
      "Step 10 | Training Loss: 0.000015 | Test Loss: 0.000518 | Test Accuracy: 0.626375\n",
      "Step 11 | Training Loss: 0.000058 | Test Loss: 0.000438 | Test Accuracy: 0.630589\n",
      "Step 12 | Training Loss: 0.000092 | Test Loss: 0.000588 | Test Accuracy: 0.635380\n",
      "Step 13 | Training Loss: 0.000071 | Test Loss: 0.000446 | Test Accuracy: 0.634226\n",
      "Step 14 | Training Loss: 0.000044 | Test Loss: 0.000405 | Test Accuracy: 0.633117\n",
      "Step 15 | Training Loss: 0.000031 | Test Loss: 0.000333 | Test Accuracy: 0.722143\n",
      "Step 16 | Training Loss: 0.000007 | Test Loss: 0.000359 | Test Accuracy: 0.730350\n",
      "Step 17 | Training Loss: 0.000051 | Test Loss: 0.000421 | Test Accuracy: 0.708304\n",
      "Step 18 | Training Loss: 0.000007 | Test Loss: 0.000433 | Test Accuracy: 0.730837\n",
      "Step 19 | Training Loss: 0.000094 | Test Loss: 0.000267 | Test Accuracy: 0.755279\n",
      "Step 20 | Training Loss: 0.000027 | Test Loss: 0.000094 | Test Accuracy: 0.842264\n",
      "Step 21 | Training Loss: 0.000027 | Test Loss: 0.000037 | Test Accuracy: 0.837429\n",
      "Step 22 | Training Loss: 0.000016 | Test Loss: 0.000069 | Test Accuracy: 0.837562\n",
      "Step 23 | Training Loss: 0.000028 | Test Loss: 0.000052 | Test Accuracy: 0.832150\n",
      "Step 24 | Training Loss: 0.000000 | Test Loss: 0.000145 | Test Accuracy: 0.844925\n",
      "Step 25 | Training Loss: 0.000113 | Test Loss: 0.000102 | Test Accuracy: 0.837651\n",
      "Step 26 | Training Loss: 0.000027 | Test Loss: 0.000112 | Test Accuracy: 0.843950\n",
      "Step 27 | Training Loss: 0.000051 | Test Loss: 0.000120 | Test Accuracy: 0.838494\n",
      "Step 28 | Training Loss: 0.000013 | Test Loss: 0.000235 | Test Accuracy: 0.866927\n",
      "Step 29 | Training Loss: 0.000074 | Test Loss: 0.000167 | Test Accuracy: 0.867504\n",
      "Step 30 | Training Loss: 0.000093 | Test Loss: 0.000136 | Test Accuracy: 0.867326\n",
      "Step 31 | Training Loss: 0.000005 | Test Loss: 0.000207 | Test Accuracy: 0.820130\n",
      "Step 32 | Training Loss: 0.000047 | Test Loss: 0.000310 | Test Accuracy: 0.810326\n",
      "Step 33 | Training Loss: 0.000003 | Test Loss: 0.000318 | Test Accuracy: 0.805181\n",
      "Step 34 | Training Loss: 0.000065 | Test Loss: 0.000311 | Test Accuracy: 0.793337\n",
      "Step 35 | Training Loss: 0.000087 | Test Loss: 0.000278 | Test Accuracy: 0.778300\n",
      "Step 36 | Training Loss: 0.000072 | Test Loss: 0.000211 | Test Accuracy: 0.807931\n",
      "Step 37 | Training Loss: 0.000088 | Test Loss: 0.000308 | Test Accuracy: 0.841377\n",
      "Step 38 | Training Loss: 0.000064 | Test Loss: 0.000151 | Test Accuracy: 0.837651\n",
      "Step 39 | Training Loss: 0.000026 | Test Loss: 0.000199 | Test Accuracy: 0.841599\n",
      "Step 40 | Training Loss: 0.000014 | Test Loss: 0.000176 | Test Accuracy: 0.836054\n",
      "Step 41 | Training Loss: 0.000005 | Test Loss: 0.000182 | Test Accuracy: 0.840135\n",
      "Step 42 | Training Loss: 0.000029 | Test Loss: 0.000200 | Test Accuracy: 0.836764\n",
      "Step 43 | Training Loss: 0.000079 | Test Loss: 0.000269 | Test Accuracy: 0.845857\n",
      "Step 44 | Training Loss: 0.000000 | Test Loss: 0.000250 | Test Accuracy: 0.846389\n",
      "Step 45 | Training Loss: 0.000045 | Test Loss: 0.000191 | Test Accuracy: 0.845901\n",
      "Step 46 | Training Loss: 0.000041 | Test Loss: 0.000204 | Test Accuracy: 0.845768\n",
      "Step 47 | Training Loss: 0.000063 | Test Loss: 0.000230 | Test Accuracy: 0.702360\n",
      "Step 48 | Training Loss: 0.000064 | Test Loss: 0.000175 | Test Accuracy: 0.700452\n",
      "Step 49 | Training Loss: 0.000087 | Test Loss: 0.000128 | Test Accuracy: 0.712207\n",
      "Step 50 | Training Loss: 0.000051 | Test Loss: 0.000283 | Test Accuracy: 0.714159\n",
      "Step 51 | Training Loss: 0.000008 | Test Loss: 0.000155 | Test Accuracy: 0.816891\n",
      "Step 52 | Training Loss: 0.000060 | Test Loss: 0.000128 | Test Accuracy: 0.812899\n",
      "Step 53 | Training Loss: 0.000053 | Test Loss: 0.000162 | Test Accuracy: 0.784776\n",
      "Step 54 | Training Loss: 0.000019 | Test Loss: 0.000104 | Test Accuracy: 0.802032\n",
      "Step 55 | Training Loss: 0.000036 | Test Loss: 0.000109 | Test Accuracy: 0.801721\n",
      "Step 56 | Training Loss: 0.000013 | Test Loss: 0.000074 | Test Accuracy: 0.807798\n",
      "Step 57 | Training Loss: 0.000068 | Test Loss: 0.000101 | Test Accuracy: 0.765791\n",
      "Step 58 | Training Loss: 0.000029 | Test Loss: 0.000133 | Test Accuracy: 0.831840\n",
      "Step 59 | Training Loss: 0.000056 | Test Loss: 0.000166 | Test Accuracy: 0.830110\n",
      "Step 60 | Training Loss: 0.000001 | Test Loss: 0.000157 | Test Accuracy: 0.843018\n",
      "Step 61 | Training Loss: 0.000015 | Test Loss: 0.000080 | Test Accuracy: 0.835389\n",
      "Step 62 | Training Loss: 0.000038 | Test Loss: 0.000123 | Test Accuracy: 0.842708\n",
      "Step 63 | Training Loss: 0.000084 | Test Loss: 0.000109 | Test Accuracy: 0.840756\n",
      "Step 64 | Training Loss: 0.000014 | Test Loss: 0.000122 | Test Accuracy: 0.841865\n",
      "Step 65 | Training Loss: 0.000062 | Test Loss: 0.000087 | Test Accuracy: 0.849805\n",
      "Step 66 | Training Loss: 0.000004 | Test Loss: 0.000155 | Test Accuracy: 0.843240\n",
      "Step 67 | Training Loss: 0.000063 | Test Loss: 0.000183 | Test Accuracy: 0.845680\n",
      "Step 68 | Training Loss: 0.000037 | Test Loss: 0.000256 | Test Accuracy: 0.846212\n",
      "Step 69 | Training Loss: 0.000027 | Test Loss: 0.000164 | Test Accuracy: 0.849716\n",
      "Step 70 | Training Loss: 0.000164 | Test Loss: 0.000362 | Test Accuracy: 0.849539\n",
      "Step 71 | Training Loss: 0.000077 | Test Loss: 0.000113 | Test Accuracy: 0.851934\n",
      "Step 72 | Training Loss: 0.000009 | Test Loss: 0.000093 | Test Accuracy: 0.847143\n",
      "Step 73 | Training Loss: 0.000020 | Test Loss: 0.000119 | Test Accuracy: 0.850559\n",
      "Step 74 | Training Loss: 0.000032 | Test Loss: 0.000100 | Test Accuracy: 0.852156\n",
      "Step 75 | Training Loss: 0.000060 | Test Loss: 0.000112 | Test Accuracy: 0.852244\n",
      "Step 76 | Training Loss: 0.000006 | Test Loss: 0.000126 | Test Accuracy: 0.853043\n",
      "Step 77 | Training Loss: 0.000013 | Test Loss: 0.000122 | Test Accuracy: 0.852333\n",
      "Step 78 | Training Loss: 0.000069 | Test Loss: 0.000093 | Test Accuracy: 0.849539\n",
      "Step 79 | Training Loss: 0.000004 | Test Loss: 0.000115 | Test Accuracy: 0.848341\n",
      "Step 80 | Training Loss: 0.000196 | Test Loss: 0.000063 | Test Accuracy: 0.851535\n",
      "Step 81 | Training Loss: 0.000000 | Test Loss: 0.000112 | Test Accuracy: 0.844393\n",
      "Step 82 | Training Loss: 0.000045 | Test Loss: 0.000119 | Test Accuracy: 0.849938\n",
      "Step 83 | Training Loss: 0.000059 | Test Loss: 0.000135 | Test Accuracy: 0.853841\n",
      "Step 84 | Training Loss: 0.000016 | Test Loss: 0.000196 | Test Accuracy: 0.854241\n",
      "Step 85 | Training Loss: 0.000023 | Test Loss: 0.000154 | Test Accuracy: 0.850160\n",
      "Step 86 | Training Loss: 0.000011 | Test Loss: 0.000159 | Test Accuracy: 0.853708\n",
      "Step 87 | Training Loss: 0.000070 | Test Loss: 0.000080 | Test Accuracy: 0.853664\n",
      "Step 88 | Training Loss: 0.000101 | Test Loss: 0.000097 | Test Accuracy: 0.854418\n",
      "Step 89 | Training Loss: 0.000008 | Test Loss: 0.000128 | Test Accuracy: 0.854107\n",
      "Step 90 | Training Loss: 0.000012 | Test Loss: 0.000106 | Test Accuracy: 0.854817\n",
      "Step 91 | Training Loss: 0.000017 | Test Loss: 0.000124 | Test Accuracy: 0.854374\n",
      "Step 92 | Training Loss: 0.000035 | Test Loss: 0.000113 | Test Accuracy: 0.852422\n",
      "Step 93 | Training Loss: 0.000046 | Test Loss: 0.000070 | Test Accuracy: 0.853974\n",
      "Step 94 | Training Loss: 0.000000 | Test Loss: 0.000094 | Test Accuracy: 0.849406\n",
      "Step 95 | Training Loss: 0.000080 | Test Loss: 0.000146 | Test Accuracy: 0.853841\n",
      "Step 96 | Training Loss: 0.000051 | Test Loss: 0.000078 | Test Accuracy: 0.854729\n",
      "Step 97 | Training Loss: 0.000008 | Test Loss: 0.000102 | Test Accuracy: 0.854595\n",
      "Step 98 | Training Loss: 0.000021 | Test Loss: 0.000157 | Test Accuracy: 0.854418\n",
      "Step 99 | Training Loss: 0.000012 | Test Loss: 0.000091 | Test Accuracy: 0.853797\n",
      "Step 100 | Training Loss: 0.000039 | Test Loss: 0.000160 | Test Accuracy: 0.774219\n",
      "Best Accuracy on Test data: 0.8675035238265991\n",
      "Current Layer Attributes - epochs:100 hidden layers:6 features count:32\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 1 | Training Loss: 0.000247 | Test Loss: 0.000362 | Test Accuracy: 0.796309\n",
      "Step 2 | Training Loss: 0.000030 | Test Loss: 0.038385 | Test Accuracy: 0.847853\n",
      "Step 3 | Training Loss: 0.000095 | Test Loss: 0.000212 | Test Accuracy: 0.842530\n",
      "Step 4 | Training Loss: 0.000011 | Test Loss: 0.000298 | Test Accuracy: 0.622427\n",
      "Step 5 | Training Loss: 0.000039 | Test Loss: 0.000304 | Test Accuracy: 0.632496\n",
      "Step 6 | Training Loss: 0.000045 | Test Loss: 0.000252 | Test Accuracy: 0.649752\n",
      "Step 7 | Training Loss: 0.000041 | Test Loss: 0.000302 | Test Accuracy: 0.808463\n",
      "Step 8 | Training Loss: 0.000026 | Test Loss: 0.000166 | Test Accuracy: 0.800612\n",
      "Step 9 | Training Loss: 0.000121 | Test Loss: 0.000135 | Test Accuracy: 0.822924\n",
      "Step 10 | Training Loss: 0.000047 | Test Loss: 0.000057 | Test Accuracy: 0.812367\n",
      "Step 11 | Training Loss: 0.000026 | Test Loss: 0.000131 | Test Accuracy: 0.815073\n",
      "Step 12 | Training Loss: 0.000099 | Test Loss: 0.000123 | Test Accuracy: 0.806334\n",
      "Step 13 | Training Loss: 0.000059 | Test Loss: 0.000124 | Test Accuracy: 0.804870\n",
      "Step 14 | Training Loss: 0.000036 | Test Loss: 0.000091 | Test Accuracy: 0.798084\n",
      "Step 15 | Training Loss: 0.000081 | Test Loss: 0.000116 | Test Accuracy: 0.801899\n",
      "Step 16 | Training Loss: 0.000006 | Test Loss: 0.000616 | Test Accuracy: 0.636533\n",
      "Step 17 | Training Loss: 0.000020 | Test Loss: 0.000096 | Test Accuracy: 0.805181\n",
      "Step 18 | Training Loss: 0.000010 | Test Loss: 0.000202 | Test Accuracy: 0.806733\n",
      "Step 19 | Training Loss: 0.000047 | Test Loss: 0.000061 | Test Accuracy: 0.833126\n",
      "Step 20 | Training Loss: 0.000022 | Test Loss: 0.000562 | Test Accuracy: 0.692158\n",
      "Step 21 | Training Loss: 0.000046 | Test Loss: 0.000424 | Test Accuracy: 0.736781\n",
      "Step 22 | Training Loss: 0.000094 | Test Loss: 0.000273 | Test Accuracy: 0.840002\n",
      "Step 23 | Training Loss: 0.000034 | Test Loss: 0.000217 | Test Accuracy: 0.792007\n",
      "Step 24 | Training Loss: 0.000018 | Test Loss: 0.000183 | Test Accuracy: 0.814984\n",
      "Step 25 | Training Loss: 0.000014 | Test Loss: 0.000225 | Test Accuracy: 0.792140\n",
      "Step 26 | Training Loss: 0.000067 | Test Loss: 0.000213 | Test Accuracy: 0.772046\n",
      "Step 27 | Training Loss: 0.000007 | Test Loss: 0.000207 | Test Accuracy: 0.779720\n",
      "Step 28 | Training Loss: 0.000001 | Test Loss: 0.000236 | Test Accuracy: 0.768009\n",
      "Step 29 | Training Loss: 0.000027 | Test Loss: 0.000292 | Test Accuracy: 0.784732\n",
      "Step 30 | Training Loss: 0.000019 | Test Loss: 0.000225 | Test Accuracy: 0.826384\n",
      "Step 31 | Training Loss: 0.000033 | Test Loss: 0.000243 | Test Accuracy: 0.819819\n",
      "Step 32 | Training Loss: 0.000040 | Test Loss: 0.000185 | Test Accuracy: 0.810149\n",
      "Step 33 | Training Loss: 0.000849 | Test Loss: 0.001131 | Test Accuracy: 0.465135\n",
      "Step 34 | Training Loss: 0.000755 | Test Loss: 0.001051 | Test Accuracy: 0.465135\n",
      "Step 35 | Training Loss: 0.000723 | Test Loss: 0.001052 | Test Accuracy: 0.461897\n",
      "Step 36 | Training Loss: 0.000738 | Test Loss: 0.000920 | Test Accuracy: 0.449299\n",
      "Step 37 | Training Loss: 0.000817 | Test Loss: 0.001099 | Test Accuracy: 0.445174\n",
      "Step 38 | Training Loss: 0.000686 | Test Loss: 0.001028 | Test Accuracy: 0.445751\n",
      "Step 39 | Training Loss: 0.000707 | Test Loss: 0.001080 | Test Accuracy: 0.433907\n",
      "Step 40 | Training Loss: 0.000694 | Test Loss: 0.001260 | Test Accuracy: 0.448811\n",
      "Step 41 | Training Loss: 0.000705 | Test Loss: 0.001323 | Test Accuracy: 0.447037\n",
      "Step 42 | Training Loss: 0.000778 | Test Loss: 0.001278 | Test Accuracy: 0.441803\n",
      "Step 43 | Training Loss: 0.000857 | Test Loss: 0.001112 | Test Accuracy: 0.441891\n",
      "Step 44 | Training Loss: 0.000399 | Test Loss: 0.002352 | Test Accuracy: 0.456352\n",
      "Step 45 | Training Loss: 0.000446 | Test Loss: 0.001978 | Test Accuracy: 0.445174\n",
      "Step 46 | Training Loss: 0.000682 | Test Loss: 0.001165 | Test Accuracy: 0.452626\n",
      "Step 47 | Training Loss: 0.000683 | Test Loss: 0.001133 | Test Accuracy: 0.441226\n",
      "Step 48 | Training Loss: 0.000758 | Test Loss: 0.001207 | Test Accuracy: 0.439940\n",
      "Step 49 | Training Loss: 0.000836 | Test Loss: 0.001214 | Test Accuracy: 0.439940\n",
      "Step 50 | Training Loss: 0.000738 | Test Loss: 0.001122 | Test Accuracy: 0.446505\n",
      "Step 51 | Training Loss: 0.000797 | Test Loss: 0.001071 | Test Accuracy: 0.446017\n",
      "Step 52 | Training Loss: 0.000755 | Test Loss: 0.001053 | Test Accuracy: 0.462651\n",
      "Step 53 | Training Loss: 0.000690 | Test Loss: 0.001060 | Test Accuracy: 0.444198\n",
      "Step 54 | Training Loss: 0.000848 | Test Loss: 0.001382 | Test Accuracy: 0.444553\n",
      "Step 55 | Training Loss: 0.000684 | Test Loss: 0.001025 | Test Accuracy: 0.439363\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-9-77cc9c2cea4f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mitertools\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0;32mclass\u001b[0m \u001b[0mHyperparameters\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;31m#    features_arr = [2, 4, 8, 16, 32, 64, 128, 256]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;31m#    hidden_layers_arr = [2, 4, 6, 10]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mfeatures_arr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m8\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m16\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m32\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-9-77cc9c2cea4f>\u001b[0m in \u001b[0;36mHyperparameters\u001b[0;34m()\u001b[0m\n\u001b[1;32m     12\u001b[0m         \u001b[0mn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnetwork\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mh\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m         \u001b[0mn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuild_layers\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m         \u001b[0mTrain\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mh\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     15\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-8-7912a34d95d8>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(epochs, net, h, f)\u001b[0m\n\u001b[1;32m     41\u001b[0m                                                                          net.keep_prob:1})\n\u001b[1;32m     42\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 43\u001b[0;31m                     \u001b[0mtrain_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     44\u001b[0m                     \u001b[0mcount\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m10\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     45\u001b[0m                     \u001b[0;32mwhile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_loss\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1e4\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0misnan\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_loss\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mepoch\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mcount\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-8-7912a34d95d8>\u001b[0m in \u001b[0;36mtrain_batch\u001b[0;34m()\u001b[0m\n\u001b[1;32m     39\u001b[0m                                                               feed_dict={net.x: x_train[i,:], \n\u001b[1;32m     40\u001b[0m                                                                          \u001b[0mnet\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0my_\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 41\u001b[0;31m                                                                          net.keep_prob:1})\n\u001b[0m\u001b[1;32m     42\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     43\u001b[0m                     \u001b[0mtrain_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/ritesh_malaiya/anaconda3/envs/p3/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    776\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    777\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 778\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    779\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    780\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/ritesh_malaiya/anaconda3/envs/p3/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    980\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    981\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[0;32m--> 982\u001b[0;31m                              feed_dict_string, options, run_metadata)\n\u001b[0m\u001b[1;32m    983\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    984\u001b[0m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/ritesh_malaiya/anaconda3/envs/p3/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1030\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1031\u001b[0m       return self._do_call(_run_fn, self._session, feed_dict, fetch_list,\n\u001b[0;32m-> 1032\u001b[0;31m                            target_list, options, run_metadata)\n\u001b[0m\u001b[1;32m   1033\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1034\u001b[0m       return self._do_call(_prun_fn, self._session, handle, feed_dict,\n",
      "\u001b[0;32m/home/ritesh_malaiya/anaconda3/envs/p3/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1037\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1038\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1039\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1040\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1041\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/ritesh_malaiya/anaconda3/envs/p3/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[0;34m(session, feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[1;32m   1019\u001b[0m         return tf_session.TF_Run(session, options,\n\u001b[1;32m   1020\u001b[0m                                  \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1021\u001b[0;31m                                  status, run_metadata)\n\u001b[0m\u001b[1;32m   1022\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1023\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_prun_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msession\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import itertools\n",
    "class Hyperparameters:\n",
    "#    features_arr = [2, 4, 8, 16, 32, 64, 128, 256]\n",
    "#    hidden_layers_arr = [2, 4, 6, 10]\n",
    "    features_arr = [4, 8, 16, 32]\n",
    "    hidden_layers_arr = [2, 4, 6]\n",
    "\n",
    "    epochs = [100]\n",
    "    \n",
    "    for e, h, f in itertools.product(epochs, hidden_layers_arr, features_arr):\n",
    "        print(\"Current Layer Attributes - epochs:{} hidden layers:{} features count:{}\".format(e,h,f))\n",
    "        n = network(2,h,f)\n",
    "        n.build_layers()\n",
    "        Train.train(e, n, h,f)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-05-15T19:22:58.206669Z",
     "start_time": "2017-05-15T19:22:58.201926Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dict1 = {}\n",
    "dict2 = []\n",
    "for k, (v1, v2) in Train.predictions.items():\n",
    "    dict1.update({k: v1})\n",
    "    dict2.append(v2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-05-15T19:23:00.072336Z",
     "start_time": "2017-05-15T19:23:00.069110Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Train.predictions = dict1\n",
    "Train.results = dict2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-05-15T19:23:02.593816Z",
     "start_time": "2017-05-15T19:23:02.589452Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_results = pd.DataFrame(Train.results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-05-15T19:23:04.801950Z",
     "start_time": "2017-05-15T19:23:04.789472Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>epoch</th>\n",
       "      <th>no_of_features</th>\n",
       "      <th>hidden_layers</th>\n",
       "      <th>train_score</th>\n",
       "      <th>test_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>100</td>\n",
       "      <td>32</td>\n",
       "      <td>2</td>\n",
       "      <td>0.894503</td>\n",
       "      <td>0.909022</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>100</td>\n",
       "      <td>16</td>\n",
       "      <td>2</td>\n",
       "      <td>0.898035</td>\n",
       "      <td>0.906317</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>100</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>0.867156</td>\n",
       "      <td>0.885646</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>100</td>\n",
       "      <td>16</td>\n",
       "      <td>4</td>\n",
       "      <td>0.911649</td>\n",
       "      <td>0.877883</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>100</td>\n",
       "      <td>8</td>\n",
       "      <td>4</td>\n",
       "      <td>0.926057</td>\n",
       "      <td>0.871984</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>100</td>\n",
       "      <td>16</td>\n",
       "      <td>6</td>\n",
       "      <td>0.849097</td>\n",
       "      <td>0.867504</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>100</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>0.829927</td>\n",
       "      <td>0.861870</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>100</td>\n",
       "      <td>8</td>\n",
       "      <td>6</td>\n",
       "      <td>0.909268</td>\n",
       "      <td>0.857567</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>100</td>\n",
       "      <td>8</td>\n",
       "      <td>2</td>\n",
       "      <td>0.826751</td>\n",
       "      <td>0.852244</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>100</td>\n",
       "      <td>32</td>\n",
       "      <td>6</td>\n",
       "      <td>0.945704</td>\n",
       "      <td>0.847853</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>100</td>\n",
       "      <td>4</td>\n",
       "      <td>6</td>\n",
       "      <td>0.764040</td>\n",
       "      <td>0.833393</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>100</td>\n",
       "      <td>32</td>\n",
       "      <td>4</td>\n",
       "      <td>0.922326</td>\n",
       "      <td>0.800967</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    epoch  no_of_features  hidden_layers  train_score  test_score\n",
       "3     100              32              2     0.894503    0.909022\n",
       "2     100              16              2     0.898035    0.906317\n",
       "0     100               4              2     0.867156    0.885646\n",
       "6     100              16              4     0.911649    0.877883\n",
       "5     100               8              4     0.926057    0.871984\n",
       "10    100              16              6     0.849097    0.867504\n",
       "4     100               4              4     0.829927    0.861870\n",
       "9     100               8              6     0.909268    0.857567\n",
       "1     100               8              2     0.826751    0.852244\n",
       "11    100              32              6     0.945704    0.847853\n",
       "8     100               4              6     0.764040    0.833393\n",
       "7     100              32              4     0.922326    0.800967"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_results.sort_values(by = 'test_score', ascending = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-05-15T19:23:08.655221Z",
     "start_time": "2017-05-15T19:23:08.641518Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pd.Panel(Train.predictions).to_pickle(\"dataset/tf_vae_dense_trained_together_nsl_kdd_predictions.pkl\")\n",
    "df_results.to_pickle(\"dataset/tf_vae_dense_trained_together_nsl_kdd_scores.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-05-15T19:23:10.952386Z",
     "start_time": "2017-05-15T19:23:10.888991Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import itertools\n",
    "\n",
    "def plot_confusion_matrix(cm, classes,\n",
    "                          normalize=False,\n",
    "                          title='Confusion matrix',\n",
    "                          cmap=plt.cm.Blues):\n",
    "    \"\"\"\n",
    "    This function prints and plots the confusion matrix.\n",
    "    Normalization can be applied by setting `normalize=True`.\n",
    "    \"\"\"\n",
    "    np.set_printoptions(precision=4)\n",
    "\n",
    "    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n",
    "    plt.title(title)\n",
    "    plt.colorbar()\n",
    "    tick_marks = np.arange(len(classes))\n",
    "    plt.xticks(tick_marks, classes, rotation=45)\n",
    "    plt.yticks(tick_marks, classes)\n",
    "\n",
    "    if normalize:\n",
    "        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "        print(\"Normalized confusion matrix\")\n",
    "    else:\n",
    "        print('Confusion matrix, without normalization')\n",
    "\n",
    "    print(cm)\n",
    "\n",
    "    thresh = cm.max() / 2.\n",
    "    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
    "        plt.text(j, i, cm[i, j].round(4),\n",
    "                 horizontalalignment=\"center\",\n",
    "                 color=\"white\" if cm[i, j] > thresh else \"black\")\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.ylabel('True label')\n",
    "    plt.xlabel('Predicted label')\n",
    "\n",
    "def plot(actual_value, pred_value):\n",
    "    from sklearn.metrics import confusion_matrix\n",
    "    cm_2labels = confusion_matrix(y_pred = pred_value, y_true = actual_value)\n",
    "    plt.figure(figsize=[6,6])\n",
    "    plot_confusion_matrix(cm_2labels, preprocess.output_columns_2labels, normalize = True,\n",
    "                         title = Train.best_parameters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-05-15T19:23:14.484557Z",
     "start_time": "2017-05-15T19:23:14.189489Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Normalized confusion matrix\n",
      "[[ 0.7887  0.2113]\n",
      " [ 0.074   0.926 ]]\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAbcAAAGeCAYAAAAXNE8VAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n4hsDov4AAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7fabb46608d0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot(actual_value = Train.actual_value, pred_value = Train.pred_value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "_draft": {
   "nbviewer_url": "https://gist.github.com/7d1ace18a82178e15ece8fc5252fce88"
  },
  "anaconda-cloud": {},
  "gist": {
   "data": {
    "description": "Hyper parameter tuning",
    "public": false
   },
   "id": "7d1ace18a82178e15ece8fc5252fce88"
  },
  "kernelspec": {
   "display_name": "Python [conda env:p3]",
   "language": "python",
   "name": "conda-env-p3-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
