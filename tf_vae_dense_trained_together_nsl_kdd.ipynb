{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Read Data Sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-05-31T18:11:46.112651Z",
     "start_time": "2017-05-31T18:11:45.704283Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "from collections import namedtuple\n",
    "pd.set_option(\"display.max_rows\",100)\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-05-31T18:11:46.197797Z",
     "start_time": "2017-05-31T18:11:46.114121Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class dataset:\n",
    "    kdd_train_2labels = pd.read_pickle(\"dataset/kdd_train_2labels.pkl\")\n",
    "    kdd_test_2labels = pd.read_pickle(\"dataset/kdd_test_2labels.pkl\")\n",
    "    \n",
    "    kdd_train_5labels = pd.read_pickle(\"dataset/kdd_train_5labels.pkl\")\n",
    "    kdd_test_5labels = pd.read_pickle(\"dataset/kdd_test_5labels.pkl\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-05-31T18:11:46.204978Z",
     "start_time": "2017-05-31T18:11:46.199819Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(125973, 124)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.kdd_train_2labels.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-05-31T18:11:46.214866Z",
     "start_time": "2017-05-31T18:11:46.206872Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(22544, 124)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.kdd_test_2labels.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-05-31T18:11:47.033326Z",
     "start_time": "2017-05-31T18:11:46.216409Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.99589320646770185"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn import model_selection as ms\n",
    "from sklearn import preprocessing as pp\n",
    "\n",
    "class preprocess:\n",
    "    \n",
    "    output_columns_2labels = ['is_Attack','is_Normal']\n",
    "    \n",
    "    x_input = dataset.kdd_train_2labels.drop(output_columns_2labels, axis = 1)\n",
    "    y_output = dataset.kdd_train_2labels.loc[:,output_columns_2labels]\n",
    "\n",
    "    x_test_input = dataset.kdd_test_2labels.drop(output_columns_2labels, axis = 1)\n",
    "    y_test = dataset.kdd_test_2labels.loc[:,output_columns_2labels]\n",
    "\n",
    "    ss = pp.StandardScaler()\n",
    "\n",
    "    x_train = ss.fit_transform(x_input)\n",
    "    x_test = ss.transform(x_test_input)\n",
    "\n",
    "    y_train = y_output.values\n",
    "    y_test = y_test.values\n",
    "\n",
    "preprocess.x_train.std()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-05-31T18:11:48.115477Z",
     "start_time": "2017-05-31T18:11:47.034993Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-05-31T18:11:48.605813Z",
     "start_time": "2017-05-31T18:11:48.117273Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class network(object):\n",
    "    \n",
    "    input_dim = 122\n",
    "    classes = 2\n",
    "    hidden_encoder_dim = 122\n",
    "    hidden_layers = 1\n",
    "    latent_dim = 10\n",
    "\n",
    "    hidden_decoder_dim = 122\n",
    "    lam = 0.001\n",
    "    \n",
    "    def __init__(self, classes, hidden_layers, num_of_features):\n",
    "        self.classes = classes\n",
    "        self.hidden_layers = hidden_layers\n",
    "        self.latent_dim = num_of_features\n",
    "            \n",
    "    def build_layers(self):\n",
    "        tf.reset_default_graph()\n",
    "        #learning_rate = tf.Variable(initial_value=0.001)\n",
    "\n",
    "        input_dim = self.input_dim\n",
    "        classes = self.classes\n",
    "        hidden_encoder_dim = self.hidden_encoder_dim\n",
    "        hidden_layers = self.hidden_layers\n",
    "        latent_dim = self.latent_dim\n",
    "        hidden_decoder_dim = self.hidden_decoder_dim\n",
    "        lam = self.lam\n",
    "        \n",
    "        with tf.variable_scope(\"Input\"):\n",
    "            self.x = tf.placeholder(\"float\", shape=[None, input_dim])\n",
    "            self.y_ = tf.placeholder(\"float\", shape=[None, classes])\n",
    "            self.keep_prob = tf.placeholder(\"float\")\n",
    "            self.lr = tf.placeholder(\"float\")\n",
    "        \n",
    "        with tf.variable_scope(\"Layer_Encoder\"):\n",
    "\n",
    "            hidden_encoder = tf.layers.dense(self.x, hidden_encoder_dim, activation = tf.nn.relu, kernel_regularizer=tf.nn.l2_loss)\n",
    "            hidden_encoder = tf.nn.dropout(hidden_encoder, self.keep_prob)\n",
    "            for h in range(hidden_layers - 1):\n",
    "                hidden_encoder = tf.layers.dense(hidden_encoder, hidden_encoder_dim, activation = tf.nn.relu, kernel_regularizer=tf.nn.l2_loss)\n",
    "                hidden_encoder = tf.nn.dropout(hidden_encoder, self.keep_prob)\n",
    "                \n",
    "        with tf.variable_scope(\"Layer_Mean\"):\n",
    "            mu_encoder = tf.layers.dense(hidden_encoder, latent_dim, activation = None, kernel_regularizer=tf.nn.l2_loss)\n",
    "\n",
    "        with tf.variable_scope(\"Layer_Variance\"):\n",
    "            logvar_encoder = tf.layers.dense(hidden_encoder, latent_dim, activation = None, kernel_regularizer=tf.nn.l2_loss)\n",
    "\n",
    "        with tf.variable_scope(\"Sampling_Distribution\"):\n",
    "            # Sample epsilon\n",
    "            epsilon = tf.random_normal(tf.shape(logvar_encoder), mean=0, stddev=1, name='epsilon')\n",
    "\n",
    "            # Sample latent variable\n",
    "            std_encoder = tf.exp(0.5 * logvar_encoder)\n",
    "            z = mu_encoder + tf.multiply(std_encoder, epsilon)\n",
    "            \n",
    "            #tf.summary.histogram(\"Sample_Distribution\", z)\n",
    "\n",
    "        with tf.variable_scope(\"Layer_Decoder\"):\n",
    "            hidden_decoder = tf.layers.dense(z, hidden_decoder_dim, activation = tf.nn.relu, kernel_regularizer=tf.nn.l2_loss)\n",
    "            hidden_decoder = tf.nn.dropout(hidden_decoder, self.keep_prob)\n",
    "            for h in range(hidden_layers - 1):\n",
    "                hidden_decoder = tf.layers.dense(hidden_decoder, hidden_decoder_dim, activation = tf.nn.relu, kernel_regularizer=tf.nn.l2_loss)\n",
    "                hidden_decoder = tf.nn.dropout(hidden_decoder, self.keep_prob)\n",
    "                \n",
    "        with tf.variable_scope(\"Layer_Reconstruction\"):\n",
    "            x_hat = tf.layers.dense(hidden_decoder, input_dim, activation = None)\n",
    "            \n",
    "        with tf.variable_scope(\"Layer_Dense_Hidden\"):\n",
    "            hidden_output = tf.layers.dense(z,latent_dim, activation=tf.nn.relu)\n",
    "\n",
    "        with tf.variable_scope(\"Layer_Dense_Softmax\"):\n",
    "            self.y = tf.layers.dense(z, classes, activation=tf.nn.softmax)\n",
    "\n",
    "        with tf.variable_scope(\"Loss\"):\n",
    "            \n",
    "            BCE = tf.reduce_mean(tf.nn.sigmoid_cross_entropy_with_logits(logits=x_hat, labels=self.x), reduction_indices=1)\n",
    "            KLD = -0.5 * tf.reduce_mean(1 + logvar_encoder - tf.pow(mu_encoder, 2) - tf.exp(logvar_encoder), reduction_indices=1)\n",
    "            softmax_loss = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(labels = self.y_, logits = self.y))\n",
    "\n",
    "            loss = tf.reduce_mean((BCE + KLD + softmax_loss) * lam)\n",
    "\n",
    "            #loss = tf.clip_by_value(loss, -1e-2, 1e-2)\n",
    "            #loss = tf.where(tf.is_nan(loss), 1e-2, loss)\n",
    "            #loss = tf.where(tf.equal(loss, -1e-2), tf.random_normal(loss.shape), loss)\n",
    "            #loss = tf.where(tf.equal(loss, 1e-2), tf.random_normal(loss.shape), loss)\n",
    "            \n",
    "            self.regularized_loss = tf.abs(loss, name = \"Regularized_loss\")\n",
    "            correct_prediction = tf.equal(tf.argmax(self.y_, 1), tf.argmax(self.y, 1))\n",
    "            self.tf_accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32), name = \"Accuracy\")\n",
    "\n",
    "        with tf.variable_scope(\"Optimizer\"):\n",
    "            learning_rate=self.lr #1e-2\n",
    "            optimizer = tf.train.AdamOptimizer(learning_rate)\n",
    "            gradients, variables = zip(*optimizer.compute_gradients(self.regularized_loss))\n",
    "            gradients = [\n",
    "                None if gradient is None else tf.clip_by_value(gradient, -1, 1)\n",
    "                for gradient in gradients]\n",
    "            self.train_op = optimizer.apply_gradients(zip(gradients, variables))\n",
    "            #self.train_op = optimizer.minimize(self.regularized_loss)\n",
    "            \n",
    "        # add op for merging summary\n",
    "        #self.summary_op = tf.summary.merge_all()\n",
    "        self.pred = tf.argmax(self.y, axis = 1)\n",
    "        self.actual = tf.argmax(self.y_, axis = 1)\n",
    "\n",
    "        # add Saver ops\n",
    "        self.saver = tf.train.Saver()\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-05-31T18:11:48.826964Z",
     "start_time": "2017-05-31T18:11:48.607624Z"
    },
    "collapsed": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import collections\n",
    "import time\n",
    "\n",
    "class Train:    \n",
    "    \n",
    "    result = namedtuple(\"score\", ['epoch', 'no_of_features','hidden_layers','train_score', 'test_score', 'time_taken'])\n",
    "\n",
    "    predictions = {}\n",
    "\n",
    "    results = []\n",
    "    best_acc = 0\n",
    "    best_acc_global = 0\n",
    "\n",
    "    def train(epochs, net, h,f, lrs):\n",
    "        batch_iterations = 200\n",
    "        train_loss = None\n",
    "        Train.best_acc = 0\n",
    "        os.makedirs(\"dataset/tf_vae_dense_trained_together_nsl_kdd/hidden layers_{}_features count_{}\".format(epochs,h,f),\n",
    "                    exist_ok = True)\n",
    "\n",
    "        with tf.Session() as sess:\n",
    "            #summary_writer_train = tf.summary.FileWriter('./logs/kdd/VAE/training', graph=sess.graph)\n",
    "            #summary_writer_valid = tf.summary.FileWriter('./logs/kdd/VAE/validation')\n",
    "\n",
    "            sess.run(tf.global_variables_initializer())\n",
    "            start_time = time.perf_counter()\n",
    "\n",
    "            Train.best_acc = 0\n",
    "            for lr in lrs:\n",
    "                for epoch in range(1, (epochs+1)):\n",
    "                    x_train, x_valid, y_train, y_valid, = ms.train_test_split(preprocess.x_train, \n",
    "                                                                              preprocess.y_train, \n",
    "                                                                              test_size=0.2)\n",
    "                    batch_indices = np.array_split(np.arange(x_train.shape[0]), \n",
    "                                               batch_iterations)\n",
    "\n",
    "                    for i in batch_indices:\n",
    "\n",
    "                        def train_batch():\n",
    "                            nonlocal train_loss\n",
    "                            _, train_loss = sess.run([net.train_op, \n",
    "                                                                   net.regularized_loss, \n",
    "                                                                   ], #net.summary_op\n",
    "                                                                  feed_dict={net.x: x_train[i,:], \n",
    "                                                                             net.y_: y_train[i,:], \n",
    "                                                                             net.keep_prob:1, net.lr:lr})\n",
    "\n",
    "                        train_batch()\n",
    "                        count = 10\n",
    "                        \n",
    "                        while((train_loss > 1e4 or np.isnan(train_loss)) and epoch > 1 and count > 1):\n",
    "                            print(\"Step {} | High Training Loss: {:.6f} ... Restoring Net\".format(epoch, train_loss))\n",
    "                            net.saver.restore(sess, \n",
    "                                              tf.train.latest_checkpoint('dataset/tf_vae_dense_trained_together_nsl_kdd/hidden layers_{}_features count_{}'\n",
    "                                                                         .format(epochs,h,f)))\n",
    "                            train_batch()\n",
    "                            count -= 1\n",
    "\n",
    "                    valid_loss, valid_accuracy = sess.run([net.regularized_loss, net.tf_accuracy], #net.summary_op\n",
    "                                                              feed_dict={net.x: x_valid, \n",
    "                                                                         net.y_: y_valid, \n",
    "                                                                         net.keep_prob:1, net.lr:lr})\n",
    "\n",
    "                    test_accuracy, test_loss, pred_value, actual_value, y_pred = sess.run([net.tf_accuracy, net.regularized_loss, net.pred, \n",
    "                                                                                      net.actual, net.y], #net.summary_op \n",
    "                                                                                      feed_dict={net.x: preprocess.x_test, \n",
    "                                                                                     net.y_: preprocess.y_test, \n",
    "                                                                                     net.keep_prob:1, net.lr:lr})\n",
    "                    #summary_writer_valid.add_summary(summary_str, epoch)\n",
    "\n",
    "                    if epoch % 1 == 0:\n",
    "                        print(\"Step {} | Training Loss: {:.6f} | Test Loss: {:.6f} | Test Accuracy: {:.6f}\"\n",
    "                              .format(epoch, train_loss, test_loss, test_accuracy))\n",
    "\n",
    "                    if test_accuracy > Train.best_acc_global:\n",
    "                        Train.best_acc_global = test_accuracy\n",
    "                        Train.pred_value = pred_value\n",
    "                        Train.actual_value = actual_value\n",
    "                        Train.best_parameters = \"Hidden Layers:{}, Features Count:{}\".format(h, f)\n",
    "\n",
    "                    if test_accuracy > Train.best_acc:\n",
    "                        Train.best_acc = test_accuracy\n",
    "\n",
    "                        if not (np.isnan(train_loss)):\n",
    "                            net.saver.save(sess, \n",
    "                                       \"dataset/tf_vae_dense_trained_together_nsl_kdd/hidden layers_{}_features count_{}/model\"\n",
    "                                       .format(epochs,h,f), \n",
    "                                       global_step = epoch, \n",
    "                                       write_meta_graph=False)\n",
    "\n",
    "                        curr_pred = pd.DataFrame({\"Attack_prob\":y_pred[:,-2], \"Normal_prob\":y_pred[:, -1], \"Prediction\":pred_value})\n",
    "                        Train.predictions.update({\"{}_{}_{}\".format(epochs*len(lrs),f,h):\n",
    "                                                  (curr_pred, \n",
    "                                                   Train.result(epochs*len(lrs), f, h,valid_accuracy, test_accuracy, time.perf_counter() - start_time))})\n",
    "                        #Train.results.append(Train.result(epochs, f, h,valid_accuracy, test_accuracy))\n",
    "            print(\"Best Accuracy on Test data: {}\".format(Train.best_acc))\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-05-31T19:29:21.018437Z",
     "start_time": "2017-05-31T18:11:48.829028Z"
    },
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current Layer Attributes - epochs:30 hidden layers:2 features count:4\n",
      "Step 1 | Training Loss: 0.000214 | Test Loss: 0.000347 | Test Accuracy: 0.707417\n",
      "Step 2 | High Training Loss: 18149.396484 ... Restoring Net\n",
      "INFO:tensorflow:Restoring parameters from dataset/tf_vae_dense_trained_together_nsl_kdd/hidden layers_30_features count_2/model-1\n",
      "Step 2 | Training Loss: 0.000079 | Test Loss: 0.000333 | Test Accuracy: 0.727555\n",
      "Step 3 | Training Loss: 0.000033 | Test Loss: 0.000208 | Test Accuracy: 0.767654\n",
      "Step 4 | Training Loss: 0.000072 | Test Loss: 0.000195 | Test Accuracy: 0.797152\n",
      "Step 5 | Training Loss: 0.000039 | Test Loss: 0.000292 | Test Accuracy: 0.806600\n",
      "Step 6 | Training Loss: 0.000110 | Test Loss: 0.000197 | Test Accuracy: 0.798927\n",
      "Step 7 | Training Loss: 0.000036 | Test Loss: 0.000224 | Test Accuracy: 0.812411\n",
      "Step 8 | Training Loss: 0.000060 | Test Loss: 0.000138 | Test Accuracy: 0.816581\n",
      "Step 9 | Training Loss: 0.000082 | Test Loss: 0.000254 | Test Accuracy: 0.818045\n",
      "Step 10 | Training Loss: 0.000021 | Test Loss: 0.000299 | Test Accuracy: 0.766545\n",
      "Step 11 | Training Loss: 0.000057 | Test Loss: 0.000213 | Test Accuracy: 0.834768\n",
      "Step 12 | Training Loss: 0.000004 | Test Loss: 0.000211 | Test Accuracy: 0.827315\n",
      "Step 13 | Training Loss: 0.000114 | Test Loss: 0.000279 | Test Accuracy: 0.851934\n",
      "Step 14 | Training Loss: 0.000129 | Test Loss: 0.000150 | Test Accuracy: 0.853442\n",
      "Step 15 | Training Loss: 0.000038 | Test Loss: 0.000185 | Test Accuracy: 0.846478\n",
      "Step 16 | Training Loss: 0.000028 | Test Loss: 0.000139 | Test Accuracy: 0.860140\n",
      "Step 17 | Training Loss: 0.000092 | Test Loss: 0.000216 | Test Accuracy: 0.844438\n",
      "Step 18 | Training Loss: 0.000008 | Test Loss: 0.000233 | Test Accuracy: 0.854862\n",
      "Step 19 | Training Loss: 0.000020 | Test Loss: 0.000261 | Test Accuracy: 0.868923\n",
      "Step 20 | Training Loss: 0.000001 | Test Loss: 0.000153 | Test Accuracy: 0.862846\n",
      "Step 21 | Training Loss: 0.000011 | Test Loss: 0.000145 | Test Accuracy: 0.858455\n",
      "Step 22 | Training Loss: 0.000064 | Test Loss: 0.000155 | Test Accuracy: 0.863955\n",
      "Step 23 | Training Loss: 0.000085 | Test Loss: 0.000213 | Test Accuracy: 0.860406\n",
      "Step 24 | Training Loss: 0.000003 | Test Loss: 0.000162 | Test Accuracy: 0.856148\n",
      "Step 25 | Training Loss: 0.000038 | Test Loss: 0.000156 | Test Accuracy: 0.856636\n",
      "Step 26 | Training Loss: 0.000032 | Test Loss: 0.000171 | Test Accuracy: 0.857257\n",
      "Step 27 | Training Loss: 0.000013 | Test Loss: 0.000143 | Test Accuracy: 0.860806\n",
      "Step 28 | Training Loss: 0.000075 | Test Loss: 0.000230 | Test Accuracy: 0.849760\n",
      "Step 29 | Training Loss: 0.000010 | Test Loss: 0.000131 | Test Accuracy: 0.859652\n",
      "Step 30 | Training Loss: 0.000020 | Test Loss: 0.000156 | Test Accuracy: 0.860761\n",
      "Step 1 | Training Loss: 0.000062 | Test Loss: 0.000141 | Test Accuracy: 0.857124\n",
      "Step 2 | Training Loss: 0.000004 | Test Loss: 0.000146 | Test Accuracy: 0.858321\n",
      "Step 3 | Training Loss: 0.000031 | Test Loss: 0.000146 | Test Accuracy: 0.857434\n",
      "Step 4 | Training Loss: 0.000015 | Test Loss: 0.000143 | Test Accuracy: 0.857612\n",
      "Step 5 | Training Loss: 0.000019 | Test Loss: 0.000142 | Test Accuracy: 0.859741\n",
      "Step 6 | Training Loss: 0.000004 | Test Loss: 0.000140 | Test Accuracy: 0.860007\n",
      "Step 7 | Training Loss: 0.000041 | Test Loss: 0.000140 | Test Accuracy: 0.857346\n",
      "Step 8 | Training Loss: 0.000024 | Test Loss: 0.000141 | Test Accuracy: 0.860140\n",
      "Step 9 | Training Loss: 0.000054 | Test Loss: 0.000147 | Test Accuracy: 0.857080\n",
      "Step 10 | Training Loss: 0.000012 | Test Loss: 0.000144 | Test Accuracy: 0.858055\n",
      "Step 11 | Training Loss: 0.000009 | Test Loss: 0.000143 | Test Accuracy: 0.859963\n",
      "Step 12 | Training Loss: 0.000016 | Test Loss: 0.000142 | Test Accuracy: 0.860761\n",
      "Step 13 | Training Loss: 0.000025 | Test Loss: 0.000146 | Test Accuracy: 0.859830\n",
      "Step 14 | Training Loss: 0.000004 | Test Loss: 0.000145 | Test Accuracy: 0.859874\n",
      "Step 15 | Training Loss: 0.000007 | Test Loss: 0.000146 | Test Accuracy: 0.858455\n",
      "Step 16 | Training Loss: 0.000009 | Test Loss: 0.000143 | Test Accuracy: 0.858987\n",
      "Step 17 | Training Loss: 0.000016 | Test Loss: 0.000141 | Test Accuracy: 0.858809\n",
      "Step 18 | Training Loss: 0.000005 | Test Loss: 0.000145 | Test Accuracy: 0.858321\n",
      "Step 19 | Training Loss: 0.000005 | Test Loss: 0.000142 | Test Accuracy: 0.860672\n",
      "Step 20 | Training Loss: 0.000019 | Test Loss: 0.000145 | Test Accuracy: 0.860140\n",
      "Step 21 | Training Loss: 0.000004 | Test Loss: 0.000146 | Test Accuracy: 0.860939\n",
      "Step 22 | Training Loss: 0.000004 | Test Loss: 0.000142 | Test Accuracy: 0.860140\n",
      "Step 23 | Training Loss: 0.000014 | Test Loss: 0.000141 | Test Accuracy: 0.860051\n",
      "Step 24 | Training Loss: 0.000015 | Test Loss: 0.000147 | Test Accuracy: 0.859785\n",
      "Step 25 | Training Loss: 0.000005 | Test Loss: 0.000138 | Test Accuracy: 0.861427\n",
      "Step 26 | Training Loss: 0.000002 | Test Loss: 0.000145 | Test Accuracy: 0.861515\n",
      "Step 27 | Training Loss: 0.000019 | Test Loss: 0.000141 | Test Accuracy: 0.861293\n",
      "Step 28 | Training Loss: 0.000045 | Test Loss: 0.000140 | Test Accuracy: 0.861072\n",
      "Step 29 | Training Loss: 0.000019 | Test Loss: 0.000145 | Test Accuracy: 0.862269\n",
      "Step 30 | Training Loss: 0.000011 | Test Loss: 0.000141 | Test Accuracy: 0.861382\n",
      "Best Accuracy on Test data: 0.868923008441925\n",
      "Current Layer Attributes - epochs:30 hidden layers:2 features count:8\n",
      "Step 1 | Training Loss: 0.000057 | Test Loss: 0.000379 | Test Accuracy: 0.784998\n",
      "Step 2 | High Training Loss: 90110607360.000000 ... Restoring Net\n",
      "INFO:tensorflow:Restoring parameters from dataset/tf_vae_dense_trained_together_nsl_kdd/hidden layers_30_features count_2/model-1\n",
      "Step 2 | Training Loss: 0.000030 | Test Loss: 0.057981 | Test Accuracy: 0.788148\n",
      "Step 3 | Training Loss: 0.000070 | Test Loss: 0.000315 | Test Accuracy: 0.813786\n",
      "Step 4 | Training Loss: 0.000018 | Test Loss: 0.000304 | Test Accuracy: 0.814496\n",
      "Step 5 | Training Loss: 0.000086 | Test Loss: 0.000206 | Test Accuracy: 0.815960\n",
      "Step 6 | Training Loss: 0.000017 | Test Loss: 0.000182 | Test Accuracy: 0.809129\n",
      "Step 7 | Training Loss: 0.000103 | Test Loss: 0.000391 | Test Accuracy: 0.809173\n",
      "Step 8 | Training Loss: 0.000056 | Test Loss: 0.000244 | Test Accuracy: 0.810238\n",
      "Step 9 | Training Loss: 0.000011 | Test Loss: 0.000249 | Test Accuracy: 0.809084\n",
      "Step 10 | Training Loss: 0.000045 | Test Loss: 0.000230 | Test Accuracy: 0.822480\n",
      "Step 11 | Training Loss: 0.000108 | Test Loss: 0.000283 | Test Accuracy: 0.821638\n",
      "Step 12 | Training Loss: 0.000017 | Test Loss: 0.000277 | Test Accuracy: 0.817202\n",
      "Step 13 | Training Loss: 0.000086 | Test Loss: 0.000182 | Test Accuracy: 0.831707\n",
      "Step 14 | Training Loss: 0.000070 | Test Loss: 0.000243 | Test Accuracy: 0.841466\n",
      "Step 15 | Training Loss: 0.000005 | Test Loss: 0.000182 | Test Accuracy: 0.843062\n",
      "Step 16 | High Training Loss: 147517.937500 ... Restoring Net\n",
      "INFO:tensorflow:Restoring parameters from dataset/tf_vae_dense_trained_together_nsl_kdd/hidden layers_30_features count_2/model-15\n",
      "Step 16 | Training Loss: 0.000031 | Test Loss: 0.000181 | Test Accuracy: 0.839780\n",
      "Step 17 | Training Loss: 0.000010 | Test Loss: 0.000198 | Test Accuracy: 0.843107\n",
      "Step 18 | Training Loss: 0.000053 | Test Loss: 0.000182 | Test Accuracy: 0.865951\n",
      "Step 19 | Training Loss: 0.000072 | Test Loss: 0.000042 | Test Accuracy: 0.859386\n",
      "Step 20 | Training Loss: 0.000031 | Test Loss: 0.000182 | Test Accuracy: 0.865064\n",
      "Step 21 | Training Loss: 0.000030 | Test Loss: 0.000165 | Test Accuracy: 0.855128\n",
      "Step 22 | Training Loss: 0.000068 | Test Loss: 0.000129 | Test Accuracy: 0.851890\n",
      "Step 23 | Training Loss: 0.000070 | Test Loss: 0.000202 | Test Accuracy: 0.859741\n",
      "Step 24 | Training Loss: 0.000001 | Test Loss: 0.000136 | Test Accuracy: 0.852821\n",
      "Step 25 | Training Loss: 0.000021 | Test Loss: 0.000119 | Test Accuracy: 0.853930\n",
      "Step 26 | Training Loss: 0.000054 | Test Loss: 0.000132 | Test Accuracy: 0.858144\n",
      "Step 27 | Training Loss: 0.000004 | Test Loss: 0.000212 | Test Accuracy: 0.857346\n",
      "Step 28 | Training Loss: 0.000007 | Test Loss: 0.000180 | Test Accuracy: 0.860051\n",
      "Step 29 | Training Loss: 0.000050 | Test Loss: 0.000114 | Test Accuracy: 0.861515\n",
      "Step 30 | Training Loss: 0.000083 | Test Loss: 0.000144 | Test Accuracy: 0.862314\n",
      "Step 1 | Training Loss: 0.000056 | Test Loss: 0.000117 | Test Accuracy: 0.862003\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 2 | Training Loss: 0.000027 | Test Loss: 0.000120 | Test Accuracy: 0.863068\n",
      "Step 3 | Training Loss: 0.000030 | Test Loss: 0.000121 | Test Accuracy: 0.861604\n",
      "Step 4 | Training Loss: 0.000059 | Test Loss: 0.000119 | Test Accuracy: 0.861205\n",
      "Step 5 | Training Loss: 0.000028 | Test Loss: 0.000126 | Test Accuracy: 0.863201\n",
      "Step 6 | Training Loss: 0.000015 | Test Loss: 0.000122 | Test Accuracy: 0.863644\n",
      "Step 7 | Training Loss: 0.000022 | Test Loss: 0.000120 | Test Accuracy: 0.861959\n",
      "Step 8 | Training Loss: 0.000007 | Test Loss: 0.000118 | Test Accuracy: 0.863733\n",
      "Step 9 | Training Loss: 0.000004 | Test Loss: 0.000120 | Test Accuracy: 0.862979\n",
      "Step 10 | Training Loss: 0.000008 | Test Loss: 0.000124 | Test Accuracy: 0.862136\n",
      "Step 11 | Training Loss: 0.000011 | Test Loss: 0.000121 | Test Accuracy: 0.861205\n",
      "Step 12 | Training Loss: 0.000020 | Test Loss: 0.000120 | Test Accuracy: 0.862491\n",
      "Step 13 | Training Loss: 0.000031 | Test Loss: 0.000126 | Test Accuracy: 0.861737\n",
      "Step 14 | Training Loss: 0.000007 | Test Loss: 0.000125 | Test Accuracy: 0.861737\n",
      "Step 15 | Training Loss: 0.000011 | Test Loss: 0.000124 | Test Accuracy: 0.860983\n",
      "Step 16 | Training Loss: 0.000000 | Test Loss: 0.000123 | Test Accuracy: 0.862402\n",
      "Step 17 | Training Loss: 0.000017 | Test Loss: 0.000124 | Test Accuracy: 0.861515\n",
      "Step 18 | Training Loss: 0.000021 | Test Loss: 0.000133 | Test Accuracy: 0.861427\n",
      "Step 19 | Training Loss: 0.000004 | Test Loss: 0.000131 | Test Accuracy: 0.861471\n",
      "Step 20 | Training Loss: 0.000022 | Test Loss: 0.000133 | Test Accuracy: 0.860717\n",
      "Step 21 | Training Loss: 0.000007 | Test Loss: 0.000126 | Test Accuracy: 0.863378\n",
      "Step 22 | Training Loss: 0.000003 | Test Loss: 0.000127 | Test Accuracy: 0.861914\n",
      "Step 23 | Training Loss: 0.000013 | Test Loss: 0.000127 | Test Accuracy: 0.862447\n",
      "Step 24 | Training Loss: 0.000002 | Test Loss: 0.000126 | Test Accuracy: 0.860761\n",
      "Step 25 | Training Loss: 0.000011 | Test Loss: 0.000131 | Test Accuracy: 0.860939\n",
      "Step 26 | Training Loss: 0.000021 | Test Loss: 0.000132 | Test Accuracy: 0.861116\n",
      "Step 27 | Training Loss: 0.000017 | Test Loss: 0.000133 | Test Accuracy: 0.861648\n",
      "Step 28 | Training Loss: 0.000033 | Test Loss: 0.000129 | Test Accuracy: 0.860983\n",
      "Step 29 | Training Loss: 0.000025 | Test Loss: 0.000131 | Test Accuracy: 0.860451\n",
      "Step 30 | Training Loss: 0.000000 | Test Loss: 0.000128 | Test Accuracy: 0.861338\n",
      "Best Accuracy on Test data: 0.8659510016441345\n",
      "Current Layer Attributes - epochs:30 hidden layers:2 features count:16\n",
      "Step 1 | Training Loss: 0.000083 | Test Loss: 0.000251 | Test Accuracy: 0.799681\n",
      "Step 2 | Training Loss: 0.000058 | Test Loss: 0.000256 | Test Accuracy: 0.818089\n",
      "Step 3 | Training Loss: 0.000007 | Test Loss: 0.000199 | Test Accuracy: 0.832860\n",
      "Step 4 | High Training Loss: 415272664330810687488.000000 ... Restoring Net\n",
      "INFO:tensorflow:Restoring parameters from dataset/tf_vae_dense_trained_together_nsl_kdd/hidden layers_30_features count_2/model-3\n",
      "Step 4 | Training Loss: 0.000014 | Test Loss: 0.000184 | Test Accuracy: 0.847631\n",
      "Step 5 | Training Loss: 0.000021 | Test Loss: 0.000204 | Test Accuracy: 0.855394\n",
      "Step 6 | Training Loss: 0.000009 | Test Loss: 0.000366 | Test Accuracy: 0.840711\n",
      "Step 7 | Training Loss: 0.000003 | Test Loss: 0.000215 | Test Accuracy: 0.858011\n",
      "Step 8 | Training Loss: 0.000032 | Test Loss: 0.000167 | Test Accuracy: 0.859253\n",
      "Step 9 | Training Loss: 0.000082 | Test Loss: 0.000199 | Test Accuracy: 0.860584\n",
      "Step 10 | Training Loss: 0.000022 | Test Loss: 0.000190 | Test Accuracy: 0.861293\n",
      "Step 11 | Training Loss: 0.000020 | Test Loss: 0.000171 | Test Accuracy: 0.869233\n",
      "Step 12 | Training Loss: 0.000003 | Test Loss: 0.000144 | Test Accuracy: 0.856370\n",
      "Step 13 | Training Loss: 0.000003 | Test Loss: 0.000130 | Test Accuracy: 0.867770\n",
      "Step 14 | Training Loss: 0.000015 | Test Loss: 0.000206 | Test Accuracy: 0.862048\n",
      "Step 15 | Training Loss: 0.000048 | Test Loss: 0.000205 | Test Accuracy: 0.858898\n",
      "Step 16 | Training Loss: 0.000027 | Test Loss: 0.000177 | Test Accuracy: 0.858765\n",
      "Step 17 | Training Loss: 0.000007 | Test Loss: 0.000192 | Test Accuracy: 0.862225\n",
      "Step 18 | Training Loss: 0.000087 | Test Loss: 0.000214 | Test Accuracy: 0.867193\n",
      "Step 19 | Training Loss: 0.000024 | Test Loss: 0.000196 | Test Accuracy: 0.862624\n",
      "Step 20 | Training Loss: 0.000013 | Test Loss: 0.000195 | Test Accuracy: 0.854773\n",
      "Step 21 | Training Loss: 0.000074 | Test Loss: 0.000238 | Test Accuracy: 0.875089\n",
      "Step 22 | Training Loss: 0.000009 | Test Loss: 0.000173 | Test Accuracy: 0.877129\n",
      "Step 23 | Training Loss: 0.000013 | Test Loss: 0.000127 | Test Accuracy: 0.879702\n",
      "Step 24 | Training Loss: 0.000017 | Test Loss: 0.000187 | Test Accuracy: 0.884182\n",
      "Step 25 | Training Loss: 0.000037 | Test Loss: 0.000229 | Test Accuracy: 0.879436\n",
      "Step 26 | Training Loss: 0.000027 | Test Loss: 0.000124 | Test Accuracy: 0.880589\n",
      "Step 27 | Training Loss: 0.000007 | Test Loss: 0.000107 | Test Accuracy: 0.873270\n",
      "Step 28 | Training Loss: 0.000020 | Test Loss: 0.000181 | Test Accuracy: 0.876198\n",
      "Step 29 | Training Loss: 0.000022 | Test Loss: 0.000179 | Test Accuracy: 0.879924\n",
      "Step 30 | Training Loss: 0.000004 | Test Loss: 0.000194 | Test Accuracy: 0.870121\n",
      "Step 1 | Training Loss: 0.000002 | Test Loss: 0.000172 | Test Accuracy: 0.869633\n",
      "Step 2 | Training Loss: 0.000021 | Test Loss: 0.000171 | Test Accuracy: 0.870564\n",
      "Step 3 | Training Loss: 0.000021 | Test Loss: 0.000172 | Test Accuracy: 0.871718\n",
      "Step 4 | Training Loss: 0.000004 | Test Loss: 0.000172 | Test Accuracy: 0.870431\n",
      "Step 5 | Training Loss: 0.000014 | Test Loss: 0.000171 | Test Accuracy: 0.871984\n",
      "Step 6 | Training Loss: 0.000028 | Test Loss: 0.000171 | Test Accuracy: 0.872072\n",
      "Step 7 | Training Loss: 0.000016 | Test Loss: 0.000172 | Test Accuracy: 0.871052\n",
      "Step 8 | Training Loss: 0.000014 | Test Loss: 0.000169 | Test Accuracy: 0.871274\n",
      "Step 9 | Training Loss: 0.000009 | Test Loss: 0.000165 | Test Accuracy: 0.871939\n",
      "Step 10 | Training Loss: 0.000007 | Test Loss: 0.000168 | Test Accuracy: 0.871274\n",
      "Step 11 | Training Loss: 0.000016 | Test Loss: 0.000167 | Test Accuracy: 0.872161\n",
      "Step 12 | Training Loss: 0.000034 | Test Loss: 0.000165 | Test Accuracy: 0.871851\n",
      "Step 13 | Training Loss: 0.000007 | Test Loss: 0.000171 | Test Accuracy: 0.870963\n",
      "Step 14 | Training Loss: 0.000013 | Test Loss: 0.000165 | Test Accuracy: 0.871407\n",
      "Step 15 | Training Loss: 0.000021 | Test Loss: 0.000167 | Test Accuracy: 0.871451\n",
      "Step 16 | Training Loss: 0.000032 | Test Loss: 0.000167 | Test Accuracy: 0.871008\n",
      "Step 17 | Training Loss: 0.000047 | Test Loss: 0.000166 | Test Accuracy: 0.871407\n",
      "Step 18 | Training Loss: 0.000039 | Test Loss: 0.000162 | Test Accuracy: 0.872294\n",
      "Step 19 | Training Loss: 0.000001 | Test Loss: 0.000160 | Test Accuracy: 0.873270\n",
      "Step 20 | Training Loss: 0.000016 | Test Loss: 0.000158 | Test Accuracy: 0.871407\n",
      "Step 21 | Training Loss: 0.000021 | Test Loss: 0.000157 | Test Accuracy: 0.872250\n",
      "Step 22 | Training Loss: 0.000002 | Test Loss: 0.000164 | Test Accuracy: 0.872250\n",
      "Step 23 | Training Loss: 0.000031 | Test Loss: 0.000156 | Test Accuracy: 0.873403\n",
      "Step 24 | Training Loss: 0.000001 | Test Loss: 0.000163 | Test Accuracy: 0.872339\n",
      "Step 25 | Training Loss: 0.000001 | Test Loss: 0.000155 | Test Accuracy: 0.873581\n",
      "Step 26 | Training Loss: 0.000002 | Test Loss: 0.000154 | Test Accuracy: 0.873403\n",
      "Step 27 | Training Loss: 0.000019 | Test Loss: 0.000157 | Test Accuracy: 0.872472\n",
      "Step 28 | Training Loss: 0.000014 | Test Loss: 0.000164 | Test Accuracy: 0.872117\n",
      "Step 29 | Training Loss: 0.000004 | Test Loss: 0.000158 | Test Accuracy: 0.872738\n",
      "Step 30 | Training Loss: 0.000022 | Test Loss: 0.000162 | Test Accuracy: 0.873359\n",
      "Best Accuracy on Test data: 0.8841820359230042\n",
      "Current Layer Attributes - epochs:30 hidden layers:2 features count:32\n",
      "Step 1 | Training Loss: 0.000183 | Test Loss: 0.000385 | Test Accuracy: 0.789700\n",
      "Step 2 | Training Loss: 0.000185 | Test Loss: 0.000471 | Test Accuracy: 0.840002\n",
      "Step 3 | Training Loss: 0.000119 | Test Loss: 0.000305 | Test Accuracy: 0.824610\n",
      "Step 4 | High Training Loss: 42078.039062 ... Restoring Net\n",
      "INFO:tensorflow:Restoring parameters from dataset/tf_vae_dense_trained_together_nsl_kdd/hidden layers_30_features count_2/model-2\n",
      "Step 4 | Training Loss: 0.000050 | Test Loss: 565709504512.000000 | Test Accuracy: 0.857878\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 5 | Training Loss: 0.000036 | Test Loss: 0.000413 | Test Accuracy: 0.847897\n",
      "Step 6 | Training Loss: 0.000026 | Test Loss: 0.000342 | Test Accuracy: 0.831929\n",
      "Step 7 | Training Loss: 0.000050 | Test Loss: 0.000272 | Test Accuracy: 0.835433\n",
      "Step 8 | Training Loss: 0.000148 | Test Loss: 0.000615 | Test Accuracy: 0.793914\n",
      "Step 9 | Training Loss: 0.000034 | Test Loss: 0.000324 | Test Accuracy: 0.852821\n",
      "Step 10 | Training Loss: 0.000094 | Test Loss: 0.000212 | Test Accuracy: 0.875089\n",
      "Step 11 | High Training Loss: 1423445697348574904320.000000 ... Restoring Net\n",
      "INFO:tensorflow:Restoring parameters from dataset/tf_vae_dense_trained_together_nsl_kdd/hidden layers_30_features count_2/model-10\n",
      "Step 11 | Training Loss: 0.000034 | Test Loss: 0.000239 | Test Accuracy: 0.864221\n",
      "Step 12 | Training Loss: 0.000076 | Test Loss: 0.000263 | Test Accuracy: 0.847587\n",
      "Step 13 | Training Loss: 0.000050 | Test Loss: 0.000211 | Test Accuracy: 0.870121\n",
      "Step 14 | Training Loss: 0.000040 | Test Loss: 0.000186 | Test Accuracy: 0.864886\n",
      "Step 15 | Training Loss: 0.000077 | Test Loss: 0.000194 | Test Accuracy: 0.867326\n",
      "Step 16 | Training Loss: 0.000033 | Test Loss: 0.000133 | Test Accuracy: 0.868612\n",
      "Step 17 | Training Loss: 0.000094 | Test Loss: 0.000111 | Test Accuracy: 0.876641\n",
      "Step 18 | Training Loss: 0.000028 | Test Loss: 0.000173 | Test Accuracy: 0.873714\n",
      "Step 19 | Training Loss: 0.000053 | Test Loss: 0.000158 | Test Accuracy: 0.870963\n",
      "Step 20 | Training Loss: 0.000018 | Test Loss: 0.000200 | Test Accuracy: 0.874823\n",
      "Step 21 | Training Loss: 0.000026 | Test Loss: 0.000157 | Test Accuracy: 0.861027\n",
      "Step 22 | Training Loss: 0.000044 | Test Loss: 0.000107 | Test Accuracy: 0.857434\n",
      "Step 23 | Training Loss: 0.000041 | Test Loss: 0.000149 | Test Accuracy: 0.864354\n",
      "Step 24 | Training Loss: 0.000014 | Test Loss: 0.000193 | Test Accuracy: 0.866217\n",
      "Step 25 | Training Loss: 0.000008 | Test Loss: 0.000172 | Test Accuracy: 0.856547\n",
      "Step 26 | Training Loss: 0.000028 | Test Loss: 0.000133 | Test Accuracy: 0.880767\n",
      "Step 27 | Training Loss: 0.000012 | Test Loss: 0.000186 | Test Accuracy: 0.837119\n",
      "Step 28 | Training Loss: 0.000035 | Test Loss: 0.000180 | Test Accuracy: 0.867016\n",
      "Step 29 | Training Loss: 0.000031 | Test Loss: 0.000172 | Test Accuracy: 0.871318\n",
      "Step 30 | Training Loss: 0.000024 | Test Loss: 0.000167 | Test Accuracy: 0.874867\n",
      "Step 1 | Training Loss: 0.000016 | Test Loss: 0.000179 | Test Accuracy: 0.873447\n",
      "Step 2 | Training Loss: 0.000010 | Test Loss: 0.000173 | Test Accuracy: 0.872472\n",
      "Step 3 | Training Loss: 0.000008 | Test Loss: 0.000174 | Test Accuracy: 0.874512\n",
      "Step 4 | Training Loss: 0.000026 | Test Loss: 0.000177 | Test Accuracy: 0.872738\n",
      "Step 5 | Training Loss: 0.000016 | Test Loss: 0.000173 | Test Accuracy: 0.874335\n",
      "Step 6 | Training Loss: 0.000004 | Test Loss: 0.000172 | Test Accuracy: 0.875089\n",
      "Step 7 | Training Loss: 0.000005 | Test Loss: 0.000171 | Test Accuracy: 0.873980\n",
      "Step 8 | Training Loss: 0.000005 | Test Loss: 0.000170 | Test Accuracy: 0.874956\n",
      "Step 9 | Training Loss: 0.000022 | Test Loss: 0.000168 | Test Accuracy: 0.874202\n",
      "Step 10 | Training Loss: 0.000009 | Test Loss: 0.000171 | Test Accuracy: 0.873758\n",
      "Step 11 | Training Loss: 0.000007 | Test Loss: 0.000171 | Test Accuracy: 0.873935\n",
      "Step 12 | Training Loss: 0.000013 | Test Loss: 0.000164 | Test Accuracy: 0.874024\n",
      "Step 13 | Training Loss: 0.000009 | Test Loss: 0.000171 | Test Accuracy: 0.874778\n",
      "Step 14 | Training Loss: 0.000009 | Test Loss: 0.000163 | Test Accuracy: 0.874690\n",
      "Step 15 | Training Loss: 0.000030 | Test Loss: 0.000164 | Test Accuracy: 0.876153\n",
      "Step 16 | Training Loss: 0.000005 | Test Loss: 0.000168 | Test Accuracy: 0.874423\n",
      "Step 17 | Training Loss: 0.000045 | Test Loss: 0.000165 | Test Accuracy: 0.875754\n",
      "Step 18 | Training Loss: 0.000012 | Test Loss: 0.000171 | Test Accuracy: 0.874157\n",
      "Step 19 | Training Loss: 0.000036 | Test Loss: 0.000163 | Test Accuracy: 0.874157\n",
      "Step 20 | Training Loss: 0.000002 | Test Loss: 0.000160 | Test Accuracy: 0.874556\n",
      "Step 21 | Training Loss: 0.000037 | Test Loss: 0.000165 | Test Accuracy: 0.874734\n",
      "Step 22 | Training Loss: 0.000002 | Test Loss: 0.000166 | Test Accuracy: 0.874379\n",
      "Step 23 | Training Loss: 0.000034 | Test Loss: 0.000166 | Test Accuracy: 0.874556\n",
      "Step 24 | Training Loss: 0.000047 | Test Loss: 0.000160 | Test Accuracy: 0.875932\n",
      "Step 25 | Training Loss: 0.000015 | Test Loss: 0.000160 | Test Accuracy: 0.876464\n",
      "Step 26 | Training Loss: 0.000021 | Test Loss: 0.000161 | Test Accuracy: 0.874734\n",
      "Step 27 | Training Loss: 0.000022 | Test Loss: 0.000158 | Test Accuracy: 0.876020\n",
      "Step 28 | Training Loss: 0.000026 | Test Loss: 0.000160 | Test Accuracy: 0.875222\n",
      "Step 29 | Training Loss: 0.000044 | Test Loss: 0.000157 | Test Accuracy: 0.875798\n",
      "Step 30 | Training Loss: 0.000042 | Test Loss: 0.000154 | Test Accuracy: 0.875532\n",
      "Best Accuracy on Test data: 0.8807665109634399\n",
      "Current Layer Attributes - epochs:30 hidden layers:4 features count:4\n",
      "Step 1 | Training Loss: 0.000150 | Test Loss: 0.000103 | Test Accuracy: 0.712207\n",
      "Step 2 | Training Loss: 0.000236 | Test Loss: 0.000049 | Test Accuracy: 0.717929\n",
      "Step 3 | Training Loss: 0.000102 | Test Loss: 0.000287 | Test Accuracy: 0.763707\n",
      "Step 4 | Training Loss: 0.000014 | Test Loss: 0.020378 | Test Accuracy: 0.712917\n",
      "Step 5 | Training Loss: 0.000137 | Test Loss: 0.000477 | Test Accuracy: 0.798483\n",
      "Step 6 | Training Loss: 0.000021 | Test Loss: 0.000213 | Test Accuracy: 0.844659\n",
      "Step 7 | Training Loss: 0.000058 | Test Loss: 0.000202 | Test Accuracy: 0.846256\n",
      "Step 8 | Training Loss: 0.000063 | Test Loss: 0.000356 | Test Accuracy: 0.805092\n",
      "Step 9 | Training Loss: 0.000044 | Test Loss: 0.000097 | Test Accuracy: 0.846877\n",
      "Step 10 | Training Loss: 0.000040 | Test Loss: 0.000201 | Test Accuracy: 0.837429\n",
      "Step 11 | Training Loss: 0.000032 | Test Loss: 0.000145 | Test Accuracy: 0.864532\n",
      "Step 12 | Training Loss: 0.000108 | Test Loss: 0.000208 | Test Accuracy: 0.797906\n",
      "Step 13 | Training Loss: 0.000051 | Test Loss: 0.000176 | Test Accuracy: 0.840135\n",
      "Step 14 | Training Loss: 0.000065 | Test Loss: 0.000160 | Test Accuracy: 0.771247\n",
      "Step 15 | Training Loss: 0.000035 | Test Loss: 0.000300 | Test Accuracy: 0.810637\n",
      "Step 16 | Training Loss: 0.000008 | Test Loss: 0.000275 | Test Accuracy: 0.786861\n",
      "Step 17 | Training Loss: 0.000006 | Test Loss: 0.000347 | Test Accuracy: 0.778966\n",
      "Step 18 | Training Loss: 0.000052 | Test Loss: 0.000281 | Test Accuracy: 0.787260\n",
      "Step 19 | Training Loss: 0.000001 | Test Loss: 0.000307 | Test Accuracy: 0.773953\n",
      "Step 20 | Training Loss: 0.000006 | Test Loss: 0.000265 | Test Accuracy: 0.797374\n",
      "Step 21 | Training Loss: 0.000043 | Test Loss: 0.000237 | Test Accuracy: 0.791120\n",
      "Step 22 | Training Loss: 0.000062 | Test Loss: 0.000474 | Test Accuracy: 0.636001\n",
      "Step 23 | Training Loss: 0.000073 | Test Loss: 0.000311 | Test Accuracy: 0.694775\n",
      "Step 24 | Training Loss: 0.000071 | Test Loss: 0.000443 | Test Accuracy: 0.667140\n",
      "Step 25 | Training Loss: 0.000051 | Test Loss: 0.000355 | Test Accuracy: 0.684617\n",
      "Step 26 | Training Loss: 0.000045 | Test Loss: 0.000421 | Test Accuracy: 0.678673\n",
      "Step 27 | Training Loss: 0.000047 | Test Loss: 0.000336 | Test Accuracy: 0.723518\n",
      "Step 28 | Training Loss: 0.000035 | Test Loss: 0.000365 | Test Accuracy: 0.759271\n",
      "Step 29 | Training Loss: 0.000075 | Test Loss: 0.000215 | Test Accuracy: 0.738511\n",
      "Step 30 | Training Loss: 0.000085 | Test Loss: 0.000257 | Test Accuracy: 0.749202\n",
      "Step 1 | Training Loss: 0.000027 | Test Loss: 0.000254 | Test Accuracy: 0.751109\n",
      "Step 2 | Training Loss: 0.000053 | Test Loss: 0.000254 | Test Accuracy: 0.750976\n",
      "Step 3 | Training Loss: 0.000023 | Test Loss: 0.000249 | Test Accuracy: 0.751730\n",
      "Step 4 | Training Loss: 0.000018 | Test Loss: 0.000249 | Test Accuracy: 0.751375\n",
      "Step 5 | Training Loss: 0.000039 | Test Loss: 0.000250 | Test Accuracy: 0.750665\n",
      "Step 6 | Training Loss: 0.000019 | Test Loss: 0.000251 | Test Accuracy: 0.752440\n",
      "Step 7 | Training Loss: 0.000054 | Test Loss: 0.000248 | Test Accuracy: 0.750177\n",
      "Step 8 | Training Loss: 0.000013 | Test Loss: 0.000251 | Test Accuracy: 0.752661\n",
      "Step 9 | Training Loss: 0.000002 | Test Loss: 0.000249 | Test Accuracy: 0.751198\n",
      "Step 10 | Training Loss: 0.000004 | Test Loss: 0.000245 | Test Accuracy: 0.752928\n",
      "Step 11 | Training Loss: 0.000004 | Test Loss: 0.000247 | Test Accuracy: 0.751863\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 12 | Training Loss: 0.000055 | Test Loss: 0.000245 | Test Accuracy: 0.753371\n",
      "Step 13 | Training Loss: 0.000015 | Test Loss: 0.000247 | Test Accuracy: 0.753549\n",
      "Step 14 | Training Loss: 0.000019 | Test Loss: 0.000241 | Test Accuracy: 0.754524\n",
      "Step 15 | Training Loss: 0.000027 | Test Loss: 0.000237 | Test Accuracy: 0.757053\n",
      "Step 16 | Training Loss: 0.000020 | Test Loss: 0.000242 | Test Accuracy: 0.754879\n",
      "Step 17 | Training Loss: 0.000012 | Test Loss: 0.000236 | Test Accuracy: 0.754791\n",
      "Step 18 | Training Loss: 0.000013 | Test Loss: 0.000235 | Test Accuracy: 0.756654\n",
      "Step 19 | Training Loss: 0.000016 | Test Loss: 0.000234 | Test Accuracy: 0.756787\n",
      "Step 20 | Training Loss: 0.000026 | Test Loss: 0.000238 | Test Accuracy: 0.755412\n",
      "Step 21 | Training Loss: 0.000041 | Test Loss: 0.000230 | Test Accuracy: 0.759093\n",
      "Step 22 | Training Loss: 0.000007 | Test Loss: 0.000235 | Test Accuracy: 0.756565\n",
      "Step 23 | Training Loss: 0.000034 | Test Loss: 0.000236 | Test Accuracy: 0.757585\n",
      "Step 24 | Training Loss: 0.000018 | Test Loss: 0.000237 | Test Accuracy: 0.757541\n",
      "Step 25 | Training Loss: 0.000030 | Test Loss: 0.000238 | Test Accuracy: 0.756831\n",
      "Step 26 | Training Loss: 0.000004 | Test Loss: 0.000232 | Test Accuracy: 0.757541\n",
      "Step 27 | Training Loss: 0.000004 | Test Loss: 0.000234 | Test Accuracy: 0.758650\n",
      "Step 28 | Training Loss: 0.000031 | Test Loss: 0.000234 | Test Accuracy: 0.757363\n",
      "Step 29 | Training Loss: 0.000031 | Test Loss: 0.000233 | Test Accuracy: 0.758517\n",
      "Step 30 | Training Loss: 0.000031 | Test Loss: 0.000229 | Test Accuracy: 0.759005\n",
      "Best Accuracy on Test data: 0.8645315766334534\n",
      "Current Layer Attributes - epochs:30 hidden layers:4 features count:8\n",
      "Step 1 | Training Loss: 0.000222 | Test Loss: 0.000017 | Test Accuracy: 0.755545\n",
      "Step 2 | Training Loss: 0.000039 | Test Loss: 0.000234 | Test Accuracy: 0.866084\n",
      "Step 3 | Training Loss: 0.000091 | Test Loss: 0.000134 | Test Accuracy: 0.855394\n",
      "Step 4 | Training Loss: 0.000038 | Test Loss: 0.000268 | Test Accuracy: 0.808907\n",
      "Step 5 | Training Loss: 0.000016 | Test Loss: 0.000251 | Test Accuracy: 0.803362\n",
      "Step 6 | Training Loss: 0.000031 | Test Loss: 0.002498 | Test Accuracy: 0.799193\n",
      "Step 7 | Training Loss: 0.000057 | Test Loss: 0.000324 | Test Accuracy: 0.793027\n",
      "Step 8 | Training Loss: 0.000070 | Test Loss: 0.000280 | Test Accuracy: 0.792938\n",
      "Step 9 | Training Loss: 0.000037 | Test Loss: 0.000319 | Test Accuracy: 0.695174\n",
      "Step 10 | Training Loss: 0.000008 | Test Loss: 0.000369 | Test Accuracy: 0.704711\n",
      "Step 11 | Training Loss: 0.000034 | Test Loss: 0.000416 | Test Accuracy: 0.694553\n",
      "Step 12 | Training Loss: 0.000140 | Test Loss: 0.000312 | Test Accuracy: 0.706796\n",
      "Step 13 | Training Loss: 0.000045 | Test Loss: 0.000339 | Test Accuracy: 0.717486\n",
      "Step 14 | Training Loss: 0.000049 | Test Loss: 0.000386 | Test Accuracy: 0.719482\n",
      "Step 15 | Training Loss: 0.000021 | Test Loss: 0.000339 | Test Accuracy: 0.721655\n",
      "Step 16 | Training Loss: 0.000041 | Test Loss: 0.000423 | Test Accuracy: 0.657204\n",
      "Step 17 | Training Loss: 0.000009 | Test Loss: 0.000490 | Test Accuracy: 0.671043\n",
      "Step 18 | Training Loss: 0.000027 | Test Loss: 0.000342 | Test Accuracy: 0.689097\n",
      "Step 19 | Training Loss: 0.000015 | Test Loss: 0.000346 | Test Accuracy: 0.679427\n",
      "Step 20 | Training Loss: 0.000008 | Test Loss: 0.000400 | Test Accuracy: 0.669934\n",
      "Step 21 | Training Loss: 0.000027 | Test Loss: 0.000370 | Test Accuracy: 0.662172\n",
      "Step 22 | Training Loss: 0.000043 | Test Loss: 0.000338 | Test Accuracy: 0.676189\n",
      "Step 23 | Training Loss: 0.000056 | Test Loss: 0.000382 | Test Accuracy: 0.673749\n",
      "Step 24 | Training Loss: 0.000049 | Test Loss: 0.000267 | Test Accuracy: 0.666607\n",
      "Step 25 | Training Loss: 0.000011 | Test Loss: 0.000336 | Test Accuracy: 0.658357\n",
      "Step 26 | Training Loss: 0.000008 | Test Loss: 0.000325 | Test Accuracy: 0.685504\n",
      "Step 27 | Training Loss: 0.000005 | Test Loss: 0.000279 | Test Accuracy: 0.689186\n",
      "Step 28 | Training Loss: 0.000092 | Test Loss: 0.000279 | Test Accuracy: 0.673616\n",
      "Step 29 | Training Loss: 0.000064 | Test Loss: 0.000278 | Test Accuracy: 0.687855\n",
      "Step 30 | Training Loss: 0.000019 | Test Loss: 0.000303 | Test Accuracy: 0.716199\n",
      "Step 1 | Training Loss: 0.000012 | Test Loss: 0.000309 | Test Accuracy: 0.715623\n",
      "Step 2 | Training Loss: 0.000016 | Test Loss: 0.000303 | Test Accuracy: 0.716199\n",
      "Step 3 | Training Loss: 0.000019 | Test Loss: 0.000307 | Test Accuracy: 0.713848\n",
      "Step 4 | Training Loss: 0.000023 | Test Loss: 0.000304 | Test Accuracy: 0.716066\n",
      "Step 5 | Training Loss: 0.000019 | Test Loss: 0.000303 | Test Accuracy: 0.715179\n",
      "Step 6 | Training Loss: 0.000058 | Test Loss: 0.000306 | Test Accuracy: 0.715091\n",
      "Step 7 | Training Loss: 0.000020 | Test Loss: 0.000302 | Test Accuracy: 0.716022\n",
      "Step 8 | Training Loss: 0.000011 | Test Loss: 0.000296 | Test Accuracy: 0.715445\n",
      "Step 9 | Training Loss: 0.000082 | Test Loss: 0.000301 | Test Accuracy: 0.715756\n",
      "Step 10 | Training Loss: 0.000064 | Test Loss: 0.000305 | Test Accuracy: 0.715268\n",
      "Step 11 | Training Loss: 0.000020 | Test Loss: 0.000302 | Test Accuracy: 0.714824\n",
      "Step 12 | Training Loss: 0.000027 | Test Loss: 0.000301 | Test Accuracy: 0.713449\n",
      "Step 13 | Training Loss: 0.000022 | Test Loss: 0.000299 | Test Accuracy: 0.716510\n",
      "Step 14 | Training Loss: 0.000004 | Test Loss: 0.000302 | Test Accuracy: 0.714514\n",
      "Step 15 | Training Loss: 0.000012 | Test Loss: 0.000300 | Test Accuracy: 0.714514\n",
      "Step 16 | Training Loss: 0.000066 | Test Loss: 0.000301 | Test Accuracy: 0.713982\n",
      "Step 17 | Training Loss: 0.000008 | Test Loss: 0.000298 | Test Accuracy: 0.714026\n",
      "Step 18 | Training Loss: 0.000009 | Test Loss: 0.000295 | Test Accuracy: 0.712961\n",
      "Step 19 | Training Loss: 0.000005 | Test Loss: 0.000290 | Test Accuracy: 0.711941\n",
      "Step 20 | Training Loss: 0.000020 | Test Loss: 0.000293 | Test Accuracy: 0.715490\n",
      "Step 21 | Training Loss: 0.000029 | Test Loss: 0.000293 | Test Accuracy: 0.712828\n",
      "Step 22 | Training Loss: 0.000026 | Test Loss: 0.000292 | Test Accuracy: 0.712163\n",
      "Step 23 | Training Loss: 0.000003 | Test Loss: 0.000292 | Test Accuracy: 0.713405\n",
      "Step 24 | Training Loss: 0.000050 | Test Loss: 0.000292 | Test Accuracy: 0.713316\n",
      "Step 25 | Training Loss: 0.000022 | Test Loss: 0.000294 | Test Accuracy: 0.711941\n",
      "Step 26 | Training Loss: 0.000032 | Test Loss: 0.000285 | Test Accuracy: 0.712340\n",
      "Step 27 | Training Loss: 0.000030 | Test Loss: 0.000288 | Test Accuracy: 0.711010\n",
      "Step 28 | Training Loss: 0.000016 | Test Loss: 0.000289 | Test Accuracy: 0.710078\n",
      "Step 29 | Training Loss: 0.000016 | Test Loss: 0.000291 | Test Accuracy: 0.713094\n",
      "Step 30 | Training Loss: 0.000013 | Test Loss: 0.000291 | Test Accuracy: 0.711231\n",
      "Best Accuracy on Test data: 0.866084098815918\n",
      "Current Layer Attributes - epochs:30 hidden layers:4 features count:16\n",
      "Step 1 | Training Loss: 0.000071 | Test Loss: 0.000202 | Test Accuracy: 0.791607\n",
      "Step 2 | Training Loss: 0.000092 | Test Loss: 0.000444 | Test Accuracy: 0.824210\n",
      "Step 3 | Training Loss: 0.000088 | Test Loss: 0.000239 | Test Accuracy: 0.842175\n",
      "Step 4 | Training Loss: 0.000143 | Test Loss: 0.000324 | Test Accuracy: 0.760513\n",
      "Step 5 | Training Loss: 0.000098 | Test Loss: 0.000219 | Test Accuracy: 0.822480\n",
      "Step 6 | Training Loss: 0.000028 | Test Loss: 0.000318 | Test Accuracy: 0.846877\n",
      "Step 7 | Training Loss: 0.000014 | Test Loss: 0.000256 | Test Accuracy: 0.851801\n",
      "Step 8 | Training Loss: 0.000016 | Test Loss: 0.000266 | Test Accuracy: 0.851002\n",
      "Step 9 | Training Loss: 0.000040 | Test Loss: 0.000289 | Test Accuracy: 0.870609\n",
      "Step 10 | Training Loss: 0.000079 | Test Loss: 0.000187 | Test Accuracy: 0.849805\n",
      "Step 11 | Training Loss: 0.000002 | Test Loss: 0.000218 | Test Accuracy: 0.841998\n",
      "Step 12 | Training Loss: 0.000048 | Test Loss: 0.000120 | Test Accuracy: 0.835743\n",
      "Step 13 | Training Loss: 0.000018 | Test Loss: 0.000163 | Test Accuracy: 0.849273\n",
      "Step 14 | Training Loss: 0.000049 | Test Loss: 0.000131 | Test Accuracy: 0.855749\n",
      "Step 15 | Training Loss: 0.000034 | Test Loss: 0.000141 | Test Accuracy: 0.891900\n",
      "Step 16 | Training Loss: 0.000017 | Test Loss: 0.000145 | Test Accuracy: 0.887198\n",
      "Step 17 | Training Loss: 0.000020 | Test Loss: 0.000154 | Test Accuracy: 0.885025\n",
      "Step 18 | Training Loss: 0.000021 | Test Loss: 0.000129 | Test Accuracy: 0.890747\n",
      "Step 19 | Training Loss: 0.000010 | Test Loss: 0.000121 | Test Accuracy: 0.888352\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 20 | Training Loss: 0.000028 | Test Loss: 0.000084 | Test Accuracy: 0.887243\n",
      "Step 21 | Training Loss: 0.000023 | Test Loss: 0.000203 | Test Accuracy: 0.892920\n",
      "Step 22 | Training Loss: 0.000004 | Test Loss: 0.000182 | Test Accuracy: 0.891767\n",
      "Step 23 | Training Loss: 0.000010 | Test Loss: 0.000161 | Test Accuracy: 0.894429\n",
      "Step 24 | Training Loss: 0.000032 | Test Loss: 0.000193 | Test Accuracy: 0.890037\n",
      "Step 25 | Training Loss: 0.000019 | Test Loss: 0.000190 | Test Accuracy: 0.886222\n",
      "Step 26 | Training Loss: 0.000028 | Test Loss: 0.000182 | Test Accuracy: 0.890126\n",
      "Step 27 | Training Loss: 0.000002 | Test Loss: 0.000152 | Test Accuracy: 0.891989\n",
      "Step 28 | Training Loss: 0.000013 | Test Loss: 0.000139 | Test Accuracy: 0.892122\n",
      "Step 29 | Training Loss: 0.000015 | Test Loss: 0.000130 | Test Accuracy: 0.891545\n",
      "Step 30 | Training Loss: 0.000005 | Test Loss: 0.000156 | Test Accuracy: 0.886311\n",
      "Step 1 | Training Loss: 0.000007 | Test Loss: 0.000168 | Test Accuracy: 0.886267\n",
      "Step 2 | Training Loss: 0.000013 | Test Loss: 0.000168 | Test Accuracy: 0.886444\n",
      "Step 3 | Training Loss: 0.000010 | Test Loss: 0.000165 | Test Accuracy: 0.886844\n",
      "Step 4 | Training Loss: 0.000003 | Test Loss: 0.000164 | Test Accuracy: 0.886844\n",
      "Step 5 | Training Loss: 0.000009 | Test Loss: 0.000169 | Test Accuracy: 0.886622\n",
      "Step 6 | Training Loss: 0.000007 | Test Loss: 0.000165 | Test Accuracy: 0.886444\n",
      "Step 7 | Training Loss: 0.000002 | Test Loss: 0.000166 | Test Accuracy: 0.886799\n",
      "Step 8 | Training Loss: 0.000024 | Test Loss: 0.000163 | Test Accuracy: 0.886755\n",
      "Step 9 | Training Loss: 0.000003 | Test Loss: 0.000162 | Test Accuracy: 0.886799\n",
      "Step 10 | Training Loss: 0.000008 | Test Loss: 0.000165 | Test Accuracy: 0.886622\n",
      "Step 11 | Training Loss: 0.000004 | Test Loss: 0.000160 | Test Accuracy: 0.886666\n",
      "Step 12 | Training Loss: 0.000027 | Test Loss: 0.000163 | Test Accuracy: 0.887198\n",
      "Step 13 | Training Loss: 0.000020 | Test Loss: 0.000162 | Test Accuracy: 0.886932\n",
      "Step 14 | Training Loss: 0.000029 | Test Loss: 0.000163 | Test Accuracy: 0.886888\n",
      "Step 15 | Training Loss: 0.000005 | Test Loss: 0.000162 | Test Accuracy: 0.886799\n",
      "Step 16 | Training Loss: 0.000011 | Test Loss: 0.000161 | Test Accuracy: 0.887198\n",
      "Step 17 | Training Loss: 0.000017 | Test Loss: 0.000162 | Test Accuracy: 0.886888\n",
      "Step 18 | Training Loss: 0.000001 | Test Loss: 0.000160 | Test Accuracy: 0.887198\n",
      "Step 19 | Training Loss: 0.000004 | Test Loss: 0.000158 | Test Accuracy: 0.887198\n",
      "Step 20 | Training Loss: 0.000025 | Test Loss: 0.000163 | Test Accuracy: 0.887376\n",
      "Step 21 | Training Loss: 0.000014 | Test Loss: 0.000159 | Test Accuracy: 0.886755\n",
      "Step 22 | Training Loss: 0.000009 | Test Loss: 0.000157 | Test Accuracy: 0.887331\n",
      "Step 23 | Training Loss: 0.000022 | Test Loss: 0.000154 | Test Accuracy: 0.887598\n",
      "Step 24 | Training Loss: 0.000019 | Test Loss: 0.000161 | Test Accuracy: 0.887065\n",
      "Step 25 | Training Loss: 0.000014 | Test Loss: 0.000155 | Test Accuracy: 0.887420\n",
      "Step 26 | Training Loss: 0.000011 | Test Loss: 0.000150 | Test Accuracy: 0.887376\n",
      "Step 27 | Training Loss: 0.000012 | Test Loss: 0.000151 | Test Accuracy: 0.887154\n",
      "Step 28 | Training Loss: 0.000001 | Test Loss: 0.000154 | Test Accuracy: 0.886844\n",
      "Step 29 | Training Loss: 0.000003 | Test Loss: 0.000152 | Test Accuracy: 0.886666\n",
      "Step 30 | Training Loss: 0.000023 | Test Loss: 0.000158 | Test Accuracy: 0.886134\n",
      "Best Accuracy on Test data: 0.8944286704063416\n",
      "Current Layer Attributes - epochs:30 hidden layers:4 features count:32\n",
      "Step 1 | Training Loss: 0.000022 | Test Loss: 0.000442 | Test Accuracy: 0.716776\n",
      "Step 2 | Training Loss: 0.000169 | Test Loss: 3236.110107 | Test Accuracy: 0.769739\n",
      "Step 3 | Training Loss: 0.000096 | Test Loss: 0.000280 | Test Accuracy: 0.775550\n",
      "Step 4 | Training Loss: 0.000148 | Test Loss: 0.000097 | Test Accuracy: 0.722543\n",
      "Step 5 | Training Loss: 0.000372 | Test Loss: 0.000372 | Test Accuracy: 0.581529\n",
      "Step 6 | Training Loss: 0.000024 | Test Loss: 0.000023 | Test Accuracy: 0.687855\n",
      "Step 7 | Training Loss: 0.000122 | Test Loss: 0.000328 | Test Accuracy: 0.525240\n",
      "Step 8 | Training Loss: 0.000030 | Test Loss: 0.000415 | Test Accuracy: 0.522223\n",
      "Step 9 | Training Loss: 0.000155 | Test Loss: 0.000448 | Test Accuracy: 0.508029\n",
      "Step 10 | Training Loss: 0.000045 | Test Loss: 0.000428 | Test Accuracy: 0.534688\n",
      "Step 11 | Training Loss: 0.000182 | Test Loss: 0.000517 | Test Accuracy: 0.573989\n",
      "Step 12 | Training Loss: 0.000091 | Test Loss: 0.000456 | Test Accuracy: 0.563254\n",
      "Step 13 | Training Loss: 0.000062 | Test Loss: 0.000506 | Test Accuracy: 0.589957\n",
      "Step 14 | Training Loss: 0.000012 | Test Loss: 0.000431 | Test Accuracy: 0.548749\n",
      "Step 15 | Training Loss: 0.000037 | Test Loss: 0.000298 | Test Accuracy: 0.646868\n",
      "Step 16 | Training Loss: 0.000016 | Test Loss: 0.000375 | Test Accuracy: 0.646913\n",
      "Step 17 | Training Loss: 0.000095 | Test Loss: 0.000272 | Test Accuracy: 0.729063\n",
      "Step 18 | Training Loss: 0.000010 | Test Loss: 0.000330 | Test Accuracy: 0.633561\n",
      "Step 19 | Training Loss: 0.000010 | Test Loss: 0.000345 | Test Accuracy: 0.731237\n",
      "Step 20 | Training Loss: 0.000057 | Test Loss: 0.000219 | Test Accuracy: 0.762686\n",
      "Step 21 | Training Loss: 0.000037 | Test Loss: 0.000244 | Test Accuracy: 0.799636\n",
      "Step 22 | Training Loss: 0.000110 | Test Loss: 0.000059 | Test Accuracy: 0.790011\n",
      "Step 23 | Training Loss: 0.000043 | Test Loss: 0.000181 | Test Accuracy: 0.754081\n",
      "Step 24 | Training Loss: 0.000039 | Test Loss: 0.000044 | Test Accuracy: 0.757851\n",
      "Step 25 | Training Loss: 0.000029 | Test Loss: 0.000162 | Test Accuracy: 0.755412\n",
      "Step 26 | Training Loss: 0.000025 | Test Loss: 0.000116 | Test Accuracy: 0.769029\n",
      "Step 27 | Training Loss: 0.000011 | Test Loss: 0.000129 | Test Accuracy: 0.768453\n",
      "Step 28 | Training Loss: 0.000013 | Test Loss: 0.000219 | Test Accuracy: 0.768586\n",
      "Step 29 | Training Loss: 0.000037 | Test Loss: 0.000243 | Test Accuracy: 0.767521\n",
      "Step 30 | Training Loss: 0.000067 | Test Loss: 0.000177 | Test Accuracy: 0.762553\n",
      "Step 1 | Training Loss: 0.000003 | Test Loss: 0.000169 | Test Accuracy: 0.762465\n",
      "Step 2 | Training Loss: 0.000003 | Test Loss: 0.000170 | Test Accuracy: 0.761888\n",
      "Step 3 | Training Loss: 0.000004 | Test Loss: 0.000170 | Test Accuracy: 0.761267\n",
      "Step 4 | Training Loss: 0.000061 | Test Loss: 0.000173 | Test Accuracy: 0.761977\n",
      "Step 5 | Training Loss: 0.000042 | Test Loss: 0.000172 | Test Accuracy: 0.762331\n",
      "Step 6 | Training Loss: 0.000023 | Test Loss: 0.000173 | Test Accuracy: 0.762819\n",
      "Step 7 | Training Loss: 0.000000 | Test Loss: 0.000177 | Test Accuracy: 0.761622\n",
      "Step 8 | Training Loss: 0.000069 | Test Loss: 0.000177 | Test Accuracy: 0.761755\n",
      "Step 9 | Training Loss: 0.000010 | Test Loss: 0.000169 | Test Accuracy: 0.763352\n",
      "Step 10 | Training Loss: 0.000013 | Test Loss: 0.000176 | Test Accuracy: 0.761400\n",
      "Step 11 | Training Loss: 0.000042 | Test Loss: 0.000179 | Test Accuracy: 0.762376\n",
      "Step 12 | Training Loss: 0.000021 | Test Loss: 0.000177 | Test Accuracy: 0.761444\n",
      "Step 13 | Training Loss: 0.000007 | Test Loss: 0.000178 | Test Accuracy: 0.762997\n",
      "Step 14 | Training Loss: 0.000003 | Test Loss: 0.000175 | Test Accuracy: 0.762065\n",
      "Step 15 | Training Loss: 0.000013 | Test Loss: 0.000180 | Test Accuracy: 0.762420\n",
      "Step 16 | Training Loss: 0.000001 | Test Loss: 0.000176 | Test Accuracy: 0.762198\n",
      "Step 17 | Training Loss: 0.000006 | Test Loss: 0.000180 | Test Accuracy: 0.762021\n",
      "Step 18 | Training Loss: 0.000021 | Test Loss: 0.000178 | Test Accuracy: 0.763174\n",
      "Step 19 | Training Loss: 0.000017 | Test Loss: 0.000181 | Test Accuracy: 0.760956\n",
      "Step 20 | Training Loss: 0.000033 | Test Loss: 0.000178 | Test Accuracy: 0.762021\n",
      "Step 21 | Training Loss: 0.000030 | Test Loss: 0.000185 | Test Accuracy: 0.761089\n",
      "Step 22 | Training Loss: 0.000002 | Test Loss: 0.000179 | Test Accuracy: 0.762642\n",
      "Step 23 | Training Loss: 0.000018 | Test Loss: 0.000185 | Test Accuracy: 0.760424\n",
      "Step 24 | Training Loss: 0.000027 | Test Loss: 0.000184 | Test Accuracy: 0.761489\n",
      "Step 25 | Training Loss: 0.000007 | Test Loss: 0.000187 | Test Accuracy: 0.761755\n",
      "Step 26 | Training Loss: 0.000037 | Test Loss: 0.000185 | Test Accuracy: 0.761888\n",
      "Step 27 | Training Loss: 0.000006 | Test Loss: 0.000186 | Test Accuracy: 0.761577\n",
      "Step 28 | Training Loss: 0.000008 | Test Loss: 0.000181 | Test Accuracy: 0.761666\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 29 | Training Loss: 0.000026 | Test Loss: 0.000190 | Test Accuracy: 0.762110\n",
      "Step 30 | Training Loss: 0.000001 | Test Loss: 0.000189 | Test Accuracy: 0.761178\n",
      "Best Accuracy on Test data: 0.7996362447738647\n",
      "Current Layer Attributes - epochs:30 hidden layers:6 features count:4\n",
      "Step 1 | Training Loss: 0.000267 | Test Loss: 0.000436 | Test Accuracy: 0.594127\n",
      "Step 2 | Training Loss: 0.000241 | Test Loss: 0.000311 | Test Accuracy: 0.618479\n",
      "Step 3 | Training Loss: 0.000145 | Test Loss: 0.000258 | Test Accuracy: 0.655962\n",
      "Step 4 | Training Loss: 0.000080 | Test Loss: 0.000136 | Test Accuracy: 0.642965\n",
      "Step 5 | Training Loss: 0.000033 | Test Loss: 0.000242 | Test Accuracy: 0.639860\n",
      "Step 6 | Training Loss: 0.000082 | Test Loss: 0.000209 | Test Accuracy: 0.623669\n",
      "Step 7 | Training Loss: 0.000086 | Test Loss: 0.000448 | Test Accuracy: 0.796531\n",
      "Step 8 | Training Loss: 0.000005 | Test Loss: 0.000254 | Test Accuracy: 0.757275\n",
      "Step 9 | Training Loss: 0.000043 | Test Loss: 0.000304 | Test Accuracy: 0.816936\n",
      "Step 10 | Training Loss: 0.000022 | Test Loss: 0.000211 | Test Accuracy: 0.799548\n",
      "Step 11 | Training Loss: 0.000031 | Test Loss: 0.000215 | Test Accuracy: 0.843595\n",
      "Step 12 | Training Loss: 0.000004 | Test Loss: 0.000260 | Test Accuracy: 0.849760\n",
      "Step 13 | Training Loss: 0.000003 | Test Loss: 0.000222 | Test Accuracy: 0.866883\n",
      "Step 14 | Training Loss: 0.000063 | Test Loss: 0.000238 | Test Accuracy: 0.846256\n",
      "Step 15 | Training Loss: 0.000046 | Test Loss: 0.000209 | Test Accuracy: 0.813520\n",
      "Step 16 | Training Loss: 0.000059 | Test Loss: 0.000188 | Test Accuracy: 0.860451\n",
      "Step 17 | Training Loss: 0.000027 | Test Loss: 0.000182 | Test Accuracy: 0.827227\n",
      "Step 18 | Training Loss: 0.000407 | Test Loss: 0.000127 | Test Accuracy: 0.848918\n",
      "Step 19 | Training Loss: 0.000015 | Test Loss: 0.000202 | Test Accuracy: 0.806556\n",
      "Step 20 | Training Loss: 0.000016 | Test Loss: 0.000244 | Test Accuracy: 0.814851\n",
      "Step 21 | Training Loss: 0.000061 | Test Loss: 0.000133 | Test Accuracy: 0.849539\n",
      "Step 22 | Training Loss: 0.000023 | Test Loss: 0.000198 | Test Accuracy: 0.861959\n",
      "Step 23 | Training Loss: 0.000061 | Test Loss: 0.000180 | Test Accuracy: 0.875532\n",
      "Step 24 | Training Loss: 0.000098 | Test Loss: 0.001292 | Test Accuracy: 0.462961\n",
      "Step 25 | Training Loss: 0.000101 | Test Loss: 0.000370 | Test Accuracy: 0.772223\n",
      "Step 26 | Training Loss: 0.000061 | Test Loss: 0.000246 | Test Accuracy: 0.861427\n",
      "Step 27 | Training Loss: 0.000007 | Test Loss: 0.000272 | Test Accuracy: 0.879258\n",
      "Step 28 | Training Loss: 0.000047 | Test Loss: 0.000325 | Test Accuracy: 0.798439\n",
      "Step 29 | Training Loss: 0.000006 | Test Loss: 0.000275 | Test Accuracy: 0.797374\n",
      "Step 30 | Training Loss: 0.000009 | Test Loss: 0.000478 | Test Accuracy: 0.719571\n",
      "Step 1 | Training Loss: 0.000035 | Test Loss: 0.000448 | Test Accuracy: 0.720768\n",
      "Step 2 | Training Loss: 0.000036 | Test Loss: 0.000445 | Test Accuracy: 0.720502\n",
      "Step 3 | Training Loss: 0.000083 | Test Loss: 0.000433 | Test Accuracy: 0.718151\n",
      "Step 4 | Training Loss: 0.000024 | Test Loss: 0.000435 | Test Accuracy: 0.719526\n",
      "Step 5 | Training Loss: 0.000015 | Test Loss: 0.000419 | Test Accuracy: 0.722676\n",
      "Step 6 | Training Loss: 0.000059 | Test Loss: 0.000433 | Test Accuracy: 0.722365\n",
      "Step 7 | Training Loss: 0.000006 | Test Loss: 0.000430 | Test Accuracy: 0.720236\n",
      "Step 8 | Training Loss: 0.000038 | Test Loss: 0.000428 | Test Accuracy: 0.720591\n",
      "Step 9 | Training Loss: 0.000012 | Test Loss: 0.000425 | Test Accuracy: 0.721789\n",
      "Step 10 | Training Loss: 0.000001 | Test Loss: 0.000416 | Test Accuracy: 0.723031\n",
      "Step 11 | Training Loss: 0.000056 | Test Loss: 0.000422 | Test Accuracy: 0.724273\n",
      "Step 12 | Training Loss: 0.000049 | Test Loss: 0.000398 | Test Accuracy: 0.731104\n",
      "Step 13 | Training Loss: 0.000017 | Test Loss: 0.000403 | Test Accuracy: 0.730128\n",
      "Step 14 | Training Loss: 0.000037 | Test Loss: 0.000408 | Test Accuracy: 0.726535\n",
      "Step 15 | Training Loss: 0.000036 | Test Loss: 0.000401 | Test Accuracy: 0.726535\n",
      "Step 16 | Training Loss: 0.000038 | Test Loss: 0.000391 | Test Accuracy: 0.727200\n",
      "Step 17 | Training Loss: 0.000062 | Test Loss: 0.000384 | Test Accuracy: 0.727688\n",
      "Step 18 | Training Loss: 0.000108 | Test Loss: 0.000386 | Test Accuracy: 0.728531\n",
      "Step 19 | Training Loss: 0.000013 | Test Loss: 0.000375 | Test Accuracy: 0.729817\n",
      "Step 20 | Training Loss: 0.000029 | Test Loss: 0.000381 | Test Accuracy: 0.728043\n",
      "Step 21 | Training Loss: 0.000046 | Test Loss: 0.000375 | Test Accuracy: 0.729640\n",
      "Step 22 | Training Loss: 0.000004 | Test Loss: 0.000381 | Test Accuracy: 0.728220\n",
      "Step 23 | Training Loss: 0.000027 | Test Loss: 0.000383 | Test Accuracy: 0.727067\n",
      "Step 24 | Training Loss: 0.000072 | Test Loss: 0.000376 | Test Accuracy: 0.726579\n",
      "Step 25 | Training Loss: 0.000040 | Test Loss: 0.000370 | Test Accuracy: 0.729507\n",
      "Step 26 | Training Loss: 0.000002 | Test Loss: 0.000372 | Test Accuracy: 0.727866\n",
      "Step 27 | Training Loss: 0.000002 | Test Loss: 0.000366 | Test Accuracy: 0.728220\n",
      "Step 28 | Training Loss: 0.000017 | Test Loss: 0.000364 | Test Accuracy: 0.731281\n",
      "Step 29 | Training Loss: 0.000027 | Test Loss: 0.000364 | Test Accuracy: 0.733011\n",
      "Step 30 | Training Loss: 0.000009 | Test Loss: 0.000357 | Test Accuracy: 0.734785\n",
      "Best Accuracy on Test data: 0.8792583346366882\n",
      "Current Layer Attributes - epochs:30 hidden layers:6 features count:8\n",
      "Step 1 | Training Loss: 0.000294 | Test Loss: 0.000061 | Test Accuracy: 0.630855\n",
      "Step 2 | Training Loss: 0.000287 | Test Loss: 0.000753 | Test Accuracy: 0.574654\n",
      "Step 3 | Training Loss: 0.000047 | Test Loss: 0.000324 | Test Accuracy: 0.640791\n",
      "Step 4 | Training Loss: 0.000054 | Test Loss: 0.003128 | Test Accuracy: 0.596522\n",
      "Step 5 | Training Loss: 0.000086 | Test Loss: 0.000227 | Test Accuracy: 0.709812\n",
      "Step 6 | Training Loss: 0.000208 | Test Loss: 0.000619 | Test Accuracy: 0.665366\n",
      "Step 7 | Training Loss: 0.000021 | Test Loss: 0.000227 | Test Accuracy: 0.811568\n",
      "Step 8 | Training Loss: 0.000114 | Test Loss: 0.000246 | Test Accuracy: 0.825186\n",
      "Step 9 | Training Loss: 0.000076 | Test Loss: 0.000143 | Test Accuracy: 0.845857\n",
      "Step 10 | Training Loss: 0.000058 | Test Loss: 0.000247 | Test Accuracy: 0.855039\n",
      "Step 11 | Training Loss: 0.000062 | Test Loss: 0.000150 | Test Accuracy: 0.839780\n",
      "Step 12 | Training Loss: 0.000018 | Test Loss: 0.000131 | Test Accuracy: 0.863911\n",
      "Step 13 | Training Loss: 0.000018 | Test Loss: 0.000160 | Test Accuracy: 0.831086\n",
      "Step 14 | Training Loss: 0.000100 | Test Loss: 0.000175 | Test Accuracy: 0.842264\n",
      "Step 15 | Training Loss: 0.000012 | Test Loss: 0.000369 | Test Accuracy: 0.752395\n",
      "Step 16 | Training Loss: 0.000052 | Test Loss: 0.000204 | Test Accuracy: 0.808153\n",
      "Step 17 | Training Loss: 0.000019 | Test Loss: 0.000257 | Test Accuracy: 0.819597\n",
      "Step 18 | Training Loss: 0.000016 | Test Loss: 0.000265 | Test Accuracy: 0.804959\n",
      "Step 19 | Training Loss: 0.000051 | Test Loss: 0.000207 | Test Accuracy: 0.816270\n",
      "Step 20 | Training Loss: 0.000165 | Test Loss: 0.000142 | Test Accuracy: 0.814230\n",
      "Step 21 | Training Loss: 0.000042 | Test Loss: 0.000233 | Test Accuracy: 0.808907\n",
      "Step 22 | Training Loss: 0.000037 | Test Loss: 0.000502 | Test Accuracy: 0.701428\n",
      "Step 23 | Training Loss: 0.000045 | Test Loss: 0.000202 | Test Accuracy: 0.834147\n",
      "Step 24 | Training Loss: 0.000003 | Test Loss: 0.000220 | Test Accuracy: 0.830953\n",
      "Step 25 | Training Loss: 0.000001 | Test Loss: 0.000191 | Test Accuracy: 0.834147\n",
      "Step 26 | Training Loss: 0.000036 | Test Loss: 0.000149 | Test Accuracy: 0.835034\n",
      "Step 27 | Training Loss: 0.000017 | Test Loss: 0.000184 | Test Accuracy: 0.865685\n",
      "Step 28 | Training Loss: 0.000000 | Test Loss: 0.000216 | Test Accuracy: 0.814984\n",
      "Step 29 | Training Loss: 0.000025 | Test Loss: 0.000266 | Test Accuracy: 0.783756\n",
      "Step 30 | Training Loss: 0.000036 | Test Loss: 0.000217 | Test Accuracy: 0.801366\n",
      "Step 1 | Training Loss: 0.000001 | Test Loss: 0.000223 | Test Accuracy: 0.801366\n",
      "Step 2 | Training Loss: 0.000027 | Test Loss: 0.000230 | Test Accuracy: 0.800302\n",
      "Step 3 | Training Loss: 0.000032 | Test Loss: 0.000226 | Test Accuracy: 0.802120\n",
      "Step 4 | Training Loss: 0.000005 | Test Loss: 0.000221 | Test Accuracy: 0.801854\n",
      "Step 5 | Training Loss: 0.000051 | Test Loss: 0.000221 | Test Accuracy: 0.802919\n",
      "Step 6 | Training Loss: 0.000009 | Test Loss: 0.000229 | Test Accuracy: 0.803983\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 7 | Training Loss: 0.000037 | Test Loss: 0.000223 | Test Accuracy: 0.802431\n",
      "Step 8 | Training Loss: 0.000026 | Test Loss: 0.000220 | Test Accuracy: 0.801455\n",
      "Step 9 | Training Loss: 0.000033 | Test Loss: 0.000220 | Test Accuracy: 0.803584\n",
      "Step 10 | Training Loss: 0.000037 | Test Loss: 0.000219 | Test Accuracy: 0.801899\n",
      "Step 11 | Training Loss: 0.000004 | Test Loss: 0.000218 | Test Accuracy: 0.803274\n",
      "Step 12 | Training Loss: 0.000042 | Test Loss: 0.000216 | Test Accuracy: 0.802963\n",
      "Step 13 | Training Loss: 0.000026 | Test Loss: 0.000216 | Test Accuracy: 0.803939\n",
      "Step 14 | Training Loss: 0.000002 | Test Loss: 0.000214 | Test Accuracy: 0.804383\n",
      "Step 15 | Training Loss: 0.000013 | Test Loss: 0.000214 | Test Accuracy: 0.803274\n",
      "Step 16 | Training Loss: 0.000069 | Test Loss: 0.000210 | Test Accuracy: 0.803939\n",
      "Step 17 | Training Loss: 0.000022 | Test Loss: 0.000211 | Test Accuracy: 0.804427\n",
      "Step 18 | Training Loss: 0.000004 | Test Loss: 0.000214 | Test Accuracy: 0.803052\n",
      "Step 19 | Training Loss: 0.000000 | Test Loss: 0.000209 | Test Accuracy: 0.803628\n",
      "Step 20 | Training Loss: 0.000017 | Test Loss: 0.000213 | Test Accuracy: 0.805048\n",
      "Step 21 | Training Loss: 0.000045 | Test Loss: 0.000218 | Test Accuracy: 0.804826\n",
      "Step 22 | Training Loss: 0.000022 | Test Loss: 0.000212 | Test Accuracy: 0.803673\n",
      "Step 23 | Training Loss: 0.000035 | Test Loss: 0.000209 | Test Accuracy: 0.804782\n",
      "Step 24 | Training Loss: 0.000028 | Test Loss: 0.000213 | Test Accuracy: 0.804338\n",
      "Step 25 | Training Loss: 0.000017 | Test Loss: 0.000209 | Test Accuracy: 0.804915\n",
      "Step 26 | Training Loss: 0.000018 | Test Loss: 0.000210 | Test Accuracy: 0.803717\n",
      "Step 27 | Training Loss: 0.000008 | Test Loss: 0.000213 | Test Accuracy: 0.803717\n",
      "Step 28 | Training Loss: 0.000032 | Test Loss: 0.000208 | Test Accuracy: 0.804427\n",
      "Step 29 | Training Loss: 0.000019 | Test Loss: 0.000207 | Test Accuracy: 0.803185\n",
      "Step 30 | Training Loss: 0.000019 | Test Loss: 0.000214 | Test Accuracy: 0.804383\n",
      "Best Accuracy on Test data: 0.8656848669052124\n",
      "Current Layer Attributes - epochs:30 hidden layers:6 features count:16\n",
      "Step 1 | Training Loss: 0.000058 | Test Loss: 0.000068 | Test Accuracy: 0.843550\n",
      "Step 2 | Training Loss: 0.000129 | Test Loss: 0.000071 | Test Accuracy: 0.839514\n",
      "Step 3 | Training Loss: 0.000065 | Test Loss: 0.000103 | Test Accuracy: 0.778566\n",
      "Step 4 | Training Loss: 0.000019 | Test Loss: 0.000148 | Test Accuracy: 0.851402\n",
      "Step 5 | Training Loss: 0.000075 | Test Loss: 0.000273 | Test Accuracy: 0.844304\n",
      "Step 6 | Training Loss: 0.000037 | Test Loss: 0.000180 | Test Accuracy: 0.845059\n",
      "Step 7 | Training Loss: 0.000090 | Test Loss: 0.000018 | Test Accuracy: 0.829445\n",
      "Step 8 | Training Loss: 0.000011 | Test Loss: 0.000092 | Test Accuracy: 0.837917\n",
      "Step 9 | High Training Loss: 158408638464.000000 ... Restoring Net\n",
      "INFO:tensorflow:Restoring parameters from dataset/tf_vae_dense_trained_together_nsl_kdd/hidden layers_30_features count_6/model-4\n",
      "Step 9 | Training Loss: 0.000072 | Test Loss: 0.000119 | Test Accuracy: 0.853930\n",
      "Step 10 | Training Loss: 0.000007 | Test Loss: 0.000306 | Test Accuracy: 0.779010\n",
      "Step 11 | Training Loss: 0.000078 | Test Loss: 0.000255 | Test Accuracy: 0.799193\n",
      "Step 12 | Training Loss: 0.000040 | Test Loss: 0.000488 | Test Accuracy: 0.685282\n",
      "Step 13 | Training Loss: 0.000008 | Test Loss: 0.000387 | Test Accuracy: 0.739310\n",
      "Step 14 | Training Loss: 0.000033 | Test Loss: 0.000327 | Test Accuracy: 0.748359\n",
      "Step 15 | Training Loss: 0.000061 | Test Loss: 0.000154 | Test Accuracy: 0.682621\n",
      "Step 16 | High Training Loss: 29850.755859 ... Restoring Net\n",
      "INFO:tensorflow:Restoring parameters from dataset/tf_vae_dense_trained_together_nsl_kdd/hidden layers_30_features count_6/model-9\n",
      "Step 16 | Training Loss: 0.000109 | Test Loss: 0.000276 | Test Accuracy: 0.861914\n",
      "Step 17 | Training Loss: 0.000029 | Test Loss: 0.000170 | Test Accuracy: 0.859253\n",
      "Step 18 | High Training Loss: inf ... Restoring Net\n",
      "INFO:tensorflow:Restoring parameters from dataset/tf_vae_dense_trained_together_nsl_kdd/hidden layers_30_features count_6/model-16\n",
      "Step 18 | Training Loss: 0.000014 | Test Loss: 0.000250 | Test Accuracy: 0.830598\n",
      "Step 19 | Training Loss: 0.000067 | Test Loss: 0.000218 | Test Accuracy: 0.816226\n",
      "Step 20 | Training Loss: 0.000012 | Test Loss: 0.000211 | Test Accuracy: 0.824166\n",
      "Step 21 | Training Loss: 0.000089 | Test Loss: 0.000050 | Test Accuracy: 0.823989\n",
      "Step 22 | Training Loss: 0.000038 | Test Loss: 0.000283 | Test Accuracy: 0.832727\n",
      "Step 23 | Training Loss: 0.000103 | Test Loss: 0.000280 | Test Accuracy: 0.853797\n",
      "Step 24 | Training Loss: 0.000080 | Test Loss: 0.000180 | Test Accuracy: 0.856991\n",
      "Step 25 | Training Loss: 0.000036 | Test Loss: 0.000136 | Test Accuracy: 0.855749\n",
      "Step 26 | Training Loss: 0.000076 | Test Loss: 0.000200 | Test Accuracy: 0.852688\n",
      "Step 27 | Training Loss: 0.000031 | Test Loss: 0.000188 | Test Accuracy: 0.840401\n",
      "Step 28 | Training Loss: 0.000050 | Test Loss: 0.000351 | Test Accuracy: 0.786418\n",
      "Step 29 | High Training Loss: 629383.625000 ... Restoring Net\n",
      "INFO:tensorflow:Restoring parameters from dataset/tf_vae_dense_trained_together_nsl_kdd/hidden layers_30_features count_6/model-16\n",
      "Step 29 | Training Loss: 0.000128 | Test Loss: 0.000214 | Test Accuracy: 0.866395\n",
      "Step 30 | Training Loss: 0.000030 | Test Loss: 0.000141 | Test Accuracy: 0.868967\n",
      "Step 1 | Training Loss: 0.000046 | Test Loss: 0.000193 | Test Accuracy: 0.868213\n",
      "Step 2 | Training Loss: 0.000007 | Test Loss: 0.000186 | Test Accuracy: 0.869588\n",
      "Step 3 | Training Loss: 0.000035 | Test Loss: 0.000184 | Test Accuracy: 0.870165\n",
      "Step 4 | Training Loss: 0.000033 | Test Loss: 0.000182 | Test Accuracy: 0.869588\n",
      "Step 5 | Training Loss: 0.000013 | Test Loss: 0.000188 | Test Accuracy: 0.868524\n",
      "Step 6 | Training Loss: 0.000021 | Test Loss: 0.000184 | Test Accuracy: 0.868169\n",
      "Step 7 | Training Loss: 0.000039 | Test Loss: 0.000178 | Test Accuracy: 0.869677\n",
      "Step 8 | Training Loss: 0.000012 | Test Loss: 0.000178 | Test Accuracy: 0.868967\n",
      "Step 9 | Training Loss: 0.000019 | Test Loss: 0.000174 | Test Accuracy: 0.866883\n",
      "Step 10 | Training Loss: 0.000007 | Test Loss: 0.000177 | Test Accuracy: 0.867415\n",
      "Step 11 | Training Loss: 0.000028 | Test Loss: 0.000171 | Test Accuracy: 0.868967\n",
      "Step 12 | Training Loss: 0.000011 | Test Loss: 0.000170 | Test Accuracy: 0.867548\n",
      "Step 13 | Training Loss: 0.000025 | Test Loss: 0.000175 | Test Accuracy: 0.868790\n",
      "Step 14 | Training Loss: 0.000000 | Test Loss: 0.000173 | Test Accuracy: 0.867770\n",
      "Step 15 | Training Loss: 0.000006 | Test Loss: 0.000163 | Test Accuracy: 0.870076\n",
      "Step 16 | Training Loss: 0.000021 | Test Loss: 0.000172 | Test Accuracy: 0.870431\n",
      "Step 17 | Training Loss: 0.000018 | Test Loss: 0.000171 | Test Accuracy: 0.870165\n",
      "Step 18 | Training Loss: 0.000007 | Test Loss: 0.000164 | Test Accuracy: 0.869810\n",
      "Step 19 | Training Loss: 0.000044 | Test Loss: 0.000171 | Test Accuracy: 0.870609\n",
      "Step 20 | Training Loss: 0.000036 | Test Loss: 0.000171 | Test Accuracy: 0.870209\n",
      "Step 21 | Training Loss: 0.000006 | Test Loss: 0.000163 | Test Accuracy: 0.871274\n",
      "Step 22 | Training Loss: 0.000002 | Test Loss: 0.000161 | Test Accuracy: 0.870919\n",
      "Step 23 | Training Loss: 0.000033 | Test Loss: 0.000165 | Test Accuracy: 0.870786\n",
      "Step 24 | Training Loss: 0.000019 | Test Loss: 0.000158 | Test Accuracy: 0.870742\n",
      "Step 25 | Training Loss: 0.000033 | Test Loss: 0.000159 | Test Accuracy: 0.870520\n",
      "Step 26 | Training Loss: 0.000028 | Test Loss: 0.000163 | Test Accuracy: 0.869367\n",
      "Step 27 | Training Loss: 0.000014 | Test Loss: 0.000165 | Test Accuracy: 0.869677\n",
      "Step 28 | Training Loss: 0.000020 | Test Loss: 0.000154 | Test Accuracy: 0.871629\n",
      "Step 29 | Training Loss: 0.000042 | Test Loss: 0.000152 | Test Accuracy: 0.871939\n",
      "Step 30 | Training Loss: 0.000002 | Test Loss: 0.000162 | Test Accuracy: 0.869855\n",
      "Best Accuracy on Test data: 0.8719393014907837\n",
      "Current Layer Attributes - epochs:30 hidden layers:6 features count:32\n",
      "Step 1 | Training Loss: 0.000041 | Test Loss: 0.000359 | Test Accuracy: 0.826783\n",
      "Step 2 | Training Loss: 0.000013 | Test Loss: 0.000016 | Test Accuracy: 0.887908\n",
      "Step 3 | Training Loss: 0.000062 | Test Loss: 0.000189 | Test Accuracy: 0.861781\n",
      "Step 4 | High Training Loss: 2861693491216384.000000 ... Restoring Net\n",
      "INFO:tensorflow:Restoring parameters from dataset/tf_vae_dense_trained_together_nsl_kdd/hidden layers_30_features count_6/model-2\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 4 | Training Loss: 0.000129 | Test Loss: 0.000131 | Test Accuracy: 0.806157\n",
      "Step 5 | Training Loss: 0.000148 | Test Loss: 0.000371 | Test Accuracy: 0.859386\n",
      "Step 6 | Training Loss: 0.000034 | Test Loss: 0.000229 | Test Accuracy: 0.894074\n",
      "Step 7 | Training Loss: 0.000044 | Test Loss: 0.000122 | Test Accuracy: 0.889727\n",
      "Step 8 | Training Loss: 0.000035 | Test Loss: 0.000192 | Test Accuracy: 0.889860\n",
      "Step 9 | Training Loss: 0.000062 | Test Loss: 0.000121 | Test Accuracy: 0.889416\n",
      "Step 10 | Training Loss: 0.000021 | Test Loss: 0.000447 | Test Accuracy: 0.684839\n",
      "Step 11 | Training Loss: 0.000031 | Test Loss: 0.000296 | Test Accuracy: 0.806733\n",
      "Step 12 | Training Loss: 0.000079 | Test Loss: 0.000258 | Test Accuracy: 0.812677\n",
      "Step 13 | Training Loss: 0.000057 | Test Loss: 0.000232 | Test Accuracy: 0.831219\n",
      "Step 14 | Training Loss: 0.000046 | Test Loss: 0.000216 | Test Accuracy: 0.853043\n",
      "Step 15 | Training Loss: 0.000016 | Test Loss: 0.000205 | Test Accuracy: 0.837873\n",
      "Step 16 | Training Loss: 0.000058 | Test Loss: 0.000256 | Test Accuracy: 0.837828\n",
      "Step 17 | Training Loss: 0.000007 | Test Loss: 0.000184 | Test Accuracy: 0.826650\n",
      "Step 18 | Training Loss: 0.000119 | Test Loss: 0.000103 | Test Accuracy: 0.853886\n",
      "Step 19 | Training Loss: 0.000019 | Test Loss: 0.000150 | Test Accuracy: 0.837429\n",
      "Step 20 | Training Loss: 0.000008 | Test Loss: 0.000217 | Test Accuracy: 0.786551\n",
      "Step 21 | Training Loss: 0.000061 | Test Loss: 0.000237 | Test Accuracy: 0.771913\n",
      "Step 22 | Training Loss: 0.000053 | Test Loss: 0.000194 | Test Accuracy: 0.799193\n",
      "Step 23 | Training Loss: 0.000056 | Test Loss: 0.000235 | Test Accuracy: 0.802298\n",
      "Step 24 | Training Loss: 0.000065 | Test Loss: 0.000181 | Test Accuracy: 0.778832\n",
      "Step 25 | Training Loss: 0.000096 | Test Loss: 0.000152 | Test Accuracy: 0.790454\n",
      "Step 26 | Training Loss: 0.000084 | Test Loss: 0.000300 | Test Accuracy: 0.755234\n",
      "Step 27 | Training Loss: 0.000011 | Test Loss: 0.000243 | Test Accuracy: 0.787305\n",
      "Step 28 | Training Loss: 0.000002 | Test Loss: 0.000229 | Test Accuracy: 0.781183\n",
      "Step 29 | Training Loss: 0.000140 | Test Loss: 0.000241 | Test Accuracy: 0.763795\n",
      "Step 30 | Training Loss: 0.000068 | Test Loss: 0.000025 | Test Accuracy: 0.799148\n",
      "Step 1 | Training Loss: 0.000090 | Test Loss: 0.000003 | Test Accuracy: 0.797640\n",
      "Step 2 | Training Loss: 0.000093 | Test Loss: 0.000011 | Test Accuracy: 0.799414\n",
      "Step 3 | High Training Loss: 1083680.000000 ... Restoring Net\n",
      "INFO:tensorflow:Restoring parameters from dataset/tf_vae_dense_trained_together_nsl_kdd/hidden layers_30_features count_6/model-6\n",
      "Step 3 | Training Loss: 0.000021 | Test Loss: 0.000212 | Test Accuracy: 0.894650\n",
      "Step 4 | Training Loss: 0.000050 | Test Loss: 0.000206 | Test Accuracy: 0.894650\n",
      "Step 5 | Training Loss: 0.000013 | Test Loss: 0.000193 | Test Accuracy: 0.896957\n",
      "Step 6 | Training Loss: 0.000039 | Test Loss: 0.000188 | Test Accuracy: 0.896336\n",
      "Step 7 | Training Loss: 0.000030 | Test Loss: 0.000196 | Test Accuracy: 0.895449\n",
      "Step 8 | Training Loss: 0.000016 | Test Loss: 0.000186 | Test Accuracy: 0.896425\n",
      "Step 9 | Training Loss: 0.000011 | Test Loss: 0.000185 | Test Accuracy: 0.896913\n",
      "Step 10 | Training Loss: 0.000007 | Test Loss: 0.000178 | Test Accuracy: 0.895360\n",
      "Step 11 | Training Loss: 0.000037 | Test Loss: 0.000192 | Test Accuracy: 0.895405\n",
      "Step 12 | Training Loss: 0.000016 | Test Loss: 0.000178 | Test Accuracy: 0.896469\n",
      "Step 13 | Training Loss: 0.000008 | Test Loss: 0.000182 | Test Accuracy: 0.896203\n",
      "Step 14 | Training Loss: 0.000002 | Test Loss: 0.000176 | Test Accuracy: 0.896780\n",
      "Step 15 | Training Loss: 0.000013 | Test Loss: 0.000171 | Test Accuracy: 0.896780\n",
      "Step 16 | Training Loss: 0.000032 | Test Loss: 0.000167 | Test Accuracy: 0.897667\n",
      "Step 17 | Training Loss: 0.000044 | Test Loss: 0.000167 | Test Accuracy: 0.896114\n",
      "Step 18 | Training Loss: 0.000009 | Test Loss: 0.000174 | Test Accuracy: 0.896380\n",
      "Step 19 | Training Loss: 0.000005 | Test Loss: 0.000164 | Test Accuracy: 0.896824\n",
      "Step 20 | Training Loss: 0.000003 | Test Loss: 0.000165 | Test Accuracy: 0.896380\n",
      "Step 21 | Training Loss: 0.000041 | Test Loss: 0.000168 | Test Accuracy: 0.895360\n",
      "Step 22 | Training Loss: 0.000011 | Test Loss: 0.000164 | Test Accuracy: 0.895582\n",
      "Step 23 | Training Loss: 0.000008 | Test Loss: 0.000156 | Test Accuracy: 0.895271\n",
      "Step 24 | Training Loss: 0.000000 | Test Loss: 0.000162 | Test Accuracy: 0.895582\n",
      "Step 25 | Training Loss: 0.000009 | Test Loss: 0.000158 | Test Accuracy: 0.895937\n",
      "Step 26 | Training Loss: 0.000003 | Test Loss: 0.000158 | Test Accuracy: 0.894429\n",
      "Step 27 | Training Loss: 0.000040 | Test Loss: 0.000170 | Test Accuracy: 0.894695\n",
      "Step 28 | Training Loss: 0.000024 | Test Loss: 0.000169 | Test Accuracy: 0.891590\n",
      "Step 29 | Training Loss: 0.000016 | Test Loss: 0.000167 | Test Accuracy: 0.889638\n",
      "Step 30 | Training Loss: 0.000010 | Test Loss: 0.000176 | Test Accuracy: 0.889860\n",
      "Best Accuracy on Test data: 0.8976668119430542\n"
     ]
    }
   ],
   "source": [
    "import itertools\n",
    "class Hyperparameters:\n",
    "#    features_arr = [2, 4, 8, 16, 32, 64, 128, 256]\n",
    "#    hidden_layers_arr = [2, 4, 6, 10]\n",
    "    features_arr = [4, 8, 16, 32]\n",
    "    hidden_layers_arr = [2, 4, 6]\n",
    "\n",
    "    epochs = [30]\n",
    "    lrs = [1e-2, 1e-4]\n",
    "    \n",
    "    for e, h, f in itertools.product(epochs, hidden_layers_arr, features_arr):\n",
    "        print(\"Current Layer Attributes - epochs:{} hidden layers:{} features count:{}\".format(e,h,f))\n",
    "        n = network(2,h,f)\n",
    "        n.build_layers()\n",
    "        Train.train(e, n, h,f, lrs)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-05-31T19:29:21.026386Z",
     "start_time": "2017-05-31T19:29:21.020439Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dict1 = {}\n",
    "dict2 = []\n",
    "for k, (v1, v2) in Train.predictions.items():\n",
    "    dict1.update({k: v1})\n",
    "    dict2.append(v2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-05-31T19:29:21.066753Z",
     "start_time": "2017-05-31T19:29:21.028625Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Train.predictions = dict1\n",
    "Train.results = dict2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-05-31T19:29:21.083662Z",
     "start_time": "2017-05-31T19:29:21.068488Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_results = pd.DataFrame(Train.results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-05-31T19:29:21.105902Z",
     "start_time": "2017-05-31T19:29:21.085420Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>epoch</th>\n",
       "      <th>no_of_features</th>\n",
       "      <th>hidden_layers</th>\n",
       "      <th>train_score</th>\n",
       "      <th>test_score</th>\n",
       "      <th>time_taken</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>60</td>\n",
       "      <td>32</td>\n",
       "      <td>6</td>\n",
       "      <td>0.903195</td>\n",
       "      <td>0.897667</td>\n",
       "      <td>415.066499</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>60</td>\n",
       "      <td>16</td>\n",
       "      <td>4</td>\n",
       "      <td>0.937329</td>\n",
       "      <td>0.894429</td>\n",
       "      <td>154.415640</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>60</td>\n",
       "      <td>16</td>\n",
       "      <td>2</td>\n",
       "      <td>0.911689</td>\n",
       "      <td>0.884182</td>\n",
       "      <td>91.800545</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>60</td>\n",
       "      <td>32</td>\n",
       "      <td>2</td>\n",
       "      <td>0.930740</td>\n",
       "      <td>0.880767</td>\n",
       "      <td>110.905065</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>60</td>\n",
       "      <td>4</td>\n",
       "      <td>6</td>\n",
       "      <td>0.878508</td>\n",
       "      <td>0.879258</td>\n",
       "      <td>230.232700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>60</td>\n",
       "      <td>16</td>\n",
       "      <td>6</td>\n",
       "      <td>0.903076</td>\n",
       "      <td>0.871939</td>\n",
       "      <td>518.508926</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>60</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>0.897599</td>\n",
       "      <td>0.868923</td>\n",
       "      <td>68.806965</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>60</td>\n",
       "      <td>8</td>\n",
       "      <td>4</td>\n",
       "      <td>0.916134</td>\n",
       "      <td>0.866084</td>\n",
       "      <td>12.501491</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>60</td>\n",
       "      <td>8</td>\n",
       "      <td>2</td>\n",
       "      <td>0.884183</td>\n",
       "      <td>0.865951</td>\n",
       "      <td>67.387382</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>60</td>\n",
       "      <td>8</td>\n",
       "      <td>6</td>\n",
       "      <td>0.915499</td>\n",
       "      <td>0.865685</td>\n",
       "      <td>230.881235</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>60</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>0.884382</td>\n",
       "      <td>0.864532</td>\n",
       "      <td>71.878820</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>60</td>\n",
       "      <td>32</td>\n",
       "      <td>4</td>\n",
       "      <td>0.843104</td>\n",
       "      <td>0.799636</td>\n",
       "      <td>141.924597</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    epoch  no_of_features  hidden_layers  train_score  test_score  time_taken\n",
       "11     60              32              6     0.903195    0.897667  415.066499\n",
       "6      60              16              4     0.937329    0.894429  154.415640\n",
       "2      60              16              2     0.911689    0.884182   91.800545\n",
       "3      60              32              2     0.930740    0.880767  110.905065\n",
       "8      60               4              6     0.878508    0.879258  230.232700\n",
       "10     60              16              6     0.903076    0.871939  518.508926\n",
       "0      60               4              2     0.897599    0.868923   68.806965\n",
       "5      60               8              4     0.916134    0.866084   12.501491\n",
       "1      60               8              2     0.884183    0.865951   67.387382\n",
       "9      60               8              6     0.915499    0.865685  230.881235\n",
       "4      60               4              4     0.884382    0.864532   71.878820\n",
       "7      60              32              4     0.843104    0.799636  141.924597"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_results.sort_values(by = 'test_score', ascending = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-05-31T19:29:21.149671Z",
     "start_time": "2017-05-31T19:29:21.108074Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pd.Panel(Train.predictions).to_pickle(\"dataset/tf_vae_dense_trained_together_nsl_kdd_predictions.pkl\")\n",
    "df_results.to_pickle(\"dataset/tf_vae_dense_trained_together_nsl_kdd_scores.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-05-31T19:29:21.217166Z",
     "start_time": "2017-05-31T19:29:21.151222Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import itertools\n",
    "\n",
    "def plot_confusion_matrix(cm, classes,\n",
    "                          normalize=False,\n",
    "                          title='Confusion matrix',\n",
    "                          cmap=plt.cm.Blues):\n",
    "    \"\"\"\n",
    "    This function prints and plots the confusion matrix.\n",
    "    Normalization can be applied by setting `normalize=True`.\n",
    "    \"\"\"\n",
    "    np.set_printoptions(precision=4)\n",
    "\n",
    "    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n",
    "    plt.title(title)\n",
    "    plt.colorbar()\n",
    "    tick_marks = np.arange(len(classes))\n",
    "    plt.xticks(tick_marks, classes, rotation=45)\n",
    "    plt.yticks(tick_marks, classes)\n",
    "\n",
    "    if normalize:\n",
    "        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "        print(\"Normalized confusion matrix\")\n",
    "    else:\n",
    "        print('Confusion matrix, without normalization')\n",
    "\n",
    "    print(cm)\n",
    "\n",
    "    thresh = cm.max() / 2.\n",
    "    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
    "        plt.text(j, i, cm[i, j].round(4),\n",
    "                 horizontalalignment=\"center\",\n",
    "                 color=\"white\" if cm[i, j] > thresh else \"black\")\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.ylabel('True label')\n",
    "    plt.xlabel('Predicted label')\n",
    "\n",
    "def plot(actual_value, pred_value):\n",
    "    from sklearn.metrics import confusion_matrix\n",
    "    cm_2labels = confusion_matrix(y_pred = pred_value, y_true = actual_value)\n",
    "    plt.figure(figsize=[6,6])\n",
    "    plot_confusion_matrix(cm_2labels, preprocess.output_columns_2labels, normalize = True,\n",
    "                         title = Train.best_parameters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-05-31T19:29:21.632723Z",
     "start_time": "2017-05-31T19:29:21.219029Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Normalized confusion matrix\n",
      "[[ 0.8931  0.1069]\n",
      " [ 0.0963  0.9037]]\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAbcAAAGeCAYAAAAXNE8VAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nMzOz3HFwMzOz3Pl/sEz0aPIxOIIAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f4446d914a8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot(actual_value = Train.actual_value, pred_value = Train.pred_value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "_draft": {
   "nbviewer_url": "https://gist.github.com/7d1ace18a82178e15ece8fc5252fce88"
  },
  "anaconda-cloud": {},
  "gist": {
   "data": {
    "description": "Hyper parameter tuning",
    "public": false
   },
   "id": "7d1ace18a82178e15ece8fc5252fce88"
  },
  "kernelspec": {
   "display_name": "Python [conda env:p3]",
   "language": "python",
   "name": "conda-env-p3-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
