{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Read Data Sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-05-07T22:03:25.191736Z",
     "start_time": "2017-05-07T22:03:24.776990Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from collections import namedtuple\n",
    "pd.set_option(\"display.max_rows\",35)\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-05-07T22:03:25.287105Z",
     "start_time": "2017-05-07T22:03:25.193806Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class dataset:\n",
    "    kdd_train_2labels = pd.read_pickle(\"dataset/kdd_train_2labels.pkl\")\n",
    "    kdd_test_2labels = pd.read_pickle(\"dataset/kdd_test_2labels.pkl\")\n",
    "    \n",
    "    kdd_train_5labels = pd.read_pickle(\"dataset/kdd_train_5labels.pkl\")\n",
    "    kdd_test_5labels = pd.read_pickle(\"dataset/kdd_test_5labels.pkl\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-05-07T22:03:25.293311Z",
     "start_time": "2017-05-07T22:03:25.288728Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(125973, 124)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.kdd_train_2labels.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-05-07T22:03:25.299071Z",
     "start_time": "2017-05-07T22:03:25.294645Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(22544, 124)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.kdd_test_2labels.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-05-07T22:03:25.993500Z",
     "start_time": "2017-05-07T22:03:25.300398Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn import model_selection as ms\n",
    "from sklearn import preprocessing as pp\n",
    "\n",
    "class preprocess:\n",
    "    \n",
    "    output_columns_2labels = ['is_Attack','is_Normal']\n",
    "    \n",
    "    x_input = dataset.kdd_train_2labels.drop(output_columns_2labels, axis = 1)\n",
    "    y_output = dataset.kdd_train_2labels.loc[:,output_columns_2labels]\n",
    "\n",
    "    x_test_input = dataset.kdd_test_2labels.drop(output_columns_2labels, axis = 1)\n",
    "    y_test = dataset.kdd_test_2labels.loc[:,output_columns_2labels]\n",
    "\n",
    "    ss = pp.StandardScaler()\n",
    "\n",
    "    x_train = ss.fit_transform(x_input)\n",
    "    x_test = ss.transform(x_test_input)\n",
    "\n",
    "    y_train = y_output.values\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-05-07T22:03:27.039084Z",
     "start_time": "2017-05-07T22:03:25.995143Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.python import debug as tf_debug\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-05-07T22:03:27.482034Z",
     "start_time": "2017-05-07T22:03:27.040675Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class network(object):\n",
    "    \n",
    "    input_dim = 122\n",
    "    classes = 2\n",
    "    hidden_encoder_dim = 40\n",
    "    hidden_layers = 1\n",
    "    latent_dim = 10\n",
    "\n",
    "    hidden_decoder_dim = 40\n",
    "    lam = 0.001\n",
    "    \n",
    "    def __init__(self, classes, hidden_layers, num_of_features):\n",
    "        self.classes = classes\n",
    "        self.hidden_layers = hidden_layers\n",
    "        self.latent_dim = num_of_features\n",
    "            \n",
    "    def build_layers(self):\n",
    "        tf.reset_default_graph()\n",
    "        #learning_rate = tf.Variable(initial_value=0.001)\n",
    "\n",
    "        input_dim = self.input_dim\n",
    "        classes = self.classes\n",
    "        hidden_encoder_dim = self.hidden_encoder_dim\n",
    "        hidden_layers = self.hidden_layers\n",
    "        latent_dim = self.latent_dim\n",
    "        hidden_decoder_dim = self.hidden_decoder_dim\n",
    "        lam = self.lam\n",
    "        \n",
    "        with tf.variable_scope(\"Input\"):\n",
    "            self.x = tf.placeholder(\"float\", shape=[None, input_dim])\n",
    "            self.y_ = tf.placeholder(\"float\", shape=[None, classes])\n",
    "            self.keep_prob = tf.placeholder(\"float\")\n",
    "        \n",
    "        with tf.variable_scope(\"Layer_Encoder\"):\n",
    "\n",
    "            hidden_encoder = tf.layers.dense(self.x, hidden_encoder_dim, activation = tf.nn.relu, kernel_regularizer=tf.nn.l2_loss)\n",
    "            hidden_encoder = tf.nn.dropout(hidden_encoder, self.keep_prob)\n",
    "            for h in range(hidden_layers - 1):\n",
    "                hidden_encoder = tf.layers.dense(hidden_encoder, hidden_encoder_dim, activation = tf.nn.relu, kernel_regularizer=tf.nn.l2_loss)\n",
    "                hidden_encoder = tf.nn.dropout(hidden_encoder, self.keep_prob)\n",
    "                \n",
    "        with tf.variable_scope(\"Layer_Mean\"):\n",
    "            mu_encoder = tf.layers.dense(hidden_encoder, latent_dim, activation = None, kernel_regularizer=tf.nn.l2_loss)\n",
    "\n",
    "        with tf.variable_scope(\"Layer_Variance\"):\n",
    "            logvar_encoder = tf.layers.dense(hidden_encoder, latent_dim, activation = None, kernel_regularizer=tf.nn.l2_loss)\n",
    "\n",
    "        with tf.variable_scope(\"Sampling_Distribution\"):\n",
    "            # Sample epsilon\n",
    "            epsilon = tf.random_normal(tf.shape(logvar_encoder), mean=0.01, stddev=0.05, name='epsilon')\n",
    "\n",
    "            # Sample latent variable\n",
    "            std_encoder = tf.exp(0.5 * logvar_encoder)\n",
    "            z = mu_encoder + tf.multiply(std_encoder, epsilon)\n",
    "            \n",
    "            #tf.summary.histogram(\"Sample_Distribution\", z)\n",
    "\n",
    "        with tf.variable_scope(\"Layer_Decoder\"):\n",
    "            hidden_decoder = tf.layers.dense(z, hidden_decoder_dim, activation = tf.nn.relu, kernel_regularizer=tf.nn.l2_loss)\n",
    "            hidden_decoder = tf.nn.dropout(hidden_decoder, self.keep_prob)\n",
    "            for h in range(hidden_layers - 1):\n",
    "                hidden_decoder = tf.layers.dense(hidden_decoder, hidden_decoder_dim, activation = tf.nn.relu, kernel_regularizer=tf.nn.l2_loss)\n",
    "                hidden_decoder = tf.nn.dropout(hidden_decoder, self.keep_prob)\n",
    "                \n",
    "        with tf.variable_scope(\"Layer_Reconstruction\"):\n",
    "            x_hat = tf.layers.dense(hidden_decoder, input_dim, activation = None)\n",
    "            \n",
    "        with tf.variable_scope(\"Layer_Dense_Hidden\"):\n",
    "            hidden_output = tf.layers.dense(z,latent_dim, activation=tf.nn.relu)\n",
    "\n",
    "        with tf.variable_scope(\"Layer_Dense_Softmax\"):\n",
    "            self.y = tf.layers.dense(z, classes, activation=tf.nn.softmax)\n",
    "\n",
    "        with tf.variable_scope(\"Loss\"):\n",
    "            KLD = -0.5 * tf.reduce_sum(1 + logvar_encoder - tf.pow(mu_encoder, 2) - tf.exp(logvar_encoder), reduction_indices=1)\n",
    "            \n",
    "            BCE = tf.losses.mean_squared_error(x_hat, self.x)\n",
    "            #softmax_loss = tf.losses.softmax_cross_entropy(onehot_labels = self.y_, logits = self.y)\n",
    "            \n",
    "            loss = tf.reduce_mean((BCE + KLD ) * lam)\n",
    "\n",
    "            self.regularized_loss = tf.abs(loss, name = \"Regularized_loss\")\n",
    "            correct_prediction = tf.equal(tf.argmax(self.y_, 1), tf.argmax(self.y, 1))\n",
    "            self.tf_accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32), name = \"Accuracy\")\n",
    "\n",
    "        with tf.variable_scope(\"Optimizer\"):\n",
    "            learning_rate=1e-2\n",
    "            optimizer = tf.train.AdamOptimizer(learning_rate)\n",
    "            gradients, variables = zip(*optimizer.compute_gradients(self.regularized_loss))\n",
    "            gradients = [\n",
    "                None if gradient is None else tf.clip_by_value(gradient, -1, 1)\n",
    "                for gradient in gradients]\n",
    "            self.train_op = optimizer.apply_gradients(zip(gradients, variables))\n",
    "            #self.train_op = optimizer.minimize(self.regularized_loss)\n",
    "            \n",
    "        # add op for merging summary\n",
    "        #self.summary_op = tf.summary.merge_all()\n",
    "        self.pred = tf.argmax(self.y, 1)\n",
    "        self.actual = tf.argmax(self.y_, 1)\n",
    "\n",
    "        # add Saver ops\n",
    "        self.saver = tf.train.Saver()\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-05-07T22:03:27.606681Z",
     "start_time": "2017-05-07T22:03:27.483752Z"
    },
    "collapsed": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import collections\n",
    "\n",
    "class Train:    \n",
    "    \n",
    "    result = namedtuple(\"score\", ['epoch', 'no_of_features','hidden_layers','train_score', 'test_score'])\n",
    "\n",
    "    predictions = {}\n",
    "\n",
    "    results = []\n",
    "    best_acc = 0\n",
    "    \n",
    "    def train(epochs, net, h,f):\n",
    "        batch_iterations = 200\n",
    "    \n",
    "        with tf.Session() as sess:\n",
    "            #summary_writer_train = tf.summary.FileWriter('./logs/kdd/VAE/training', graph=sess.graph)\n",
    "            #summary_writer_valid = tf.summary.FileWriter('./logs/kdd/VAE/validation')\n",
    "\n",
    "            sess.run(tf.global_variables_initializer())\n",
    "\n",
    "            for epoch in range(1, (epochs+1)):\n",
    "                x_train, x_valid, y_train, y_valid, = ms.train_test_split(preprocess.x_train, \n",
    "                                                                          preprocess.y_train, \n",
    "                                                                          test_size=0.1)\n",
    "                batch_indices = np.array_split(np.arange(x_train.shape[0]), \n",
    "                                           batch_iterations)\n",
    "                                                                          \n",
    "                for i in batch_indices:\n",
    "                    _, train_loss = sess.run([net.train_op, \n",
    "                                                           net.regularized_loss, \n",
    "                                                           ], #net.summary_op\n",
    "                                                          feed_dict={net.x: x_train[i,:], \n",
    "                                                                     net.y_: y_train[i,:], \n",
    "                                                                     net.keep_prob:0.9})\n",
    "                    \n",
    "                    #summary_writer_train.add_summary(summary_str, epoch)\n",
    "                    if(train_loss > 1e9):\n",
    "                        print(\"Step {} | Training Loss: {:.6f}\".format(epoch, train_loss))\n",
    "                    \n",
    "\n",
    "                valid_accuracy = sess.run(net.tf_accuracy, #net.summary_op \n",
    "                                                      feed_dict={net.x: preprocess.x_test, \n",
    "                                                                 net.y_: preprocess.y_test, \n",
    "                                                                 net.keep_prob:1})\n",
    "                #summary_writer_valid.add_summary(summary_str, epoch)\n",
    "\n",
    "                if epoch % 1 == 0:\n",
    "                    print(\"Step {} | Training Loss: {:.6f} | Validation Accuracy: {:.6f}\".format(epoch, train_loss, valid_accuracy))\n",
    "\n",
    "            accuracy, pred_value, actual_value, y_pred = sess.run([net.tf_accuracy, \n",
    "                                                           net.pred, \n",
    "                                                           net.actual, net.y], \n",
    "                                                          feed_dict={net.x: preprocess.x_test, \n",
    "                                                                     net.y_: preprocess.y_test, \n",
    "                                                                     net.keep_prob:1})\n",
    "\n",
    "\n",
    "            print(\"Accuracy on Test data: {}\".format(accuracy))\n",
    "            \n",
    "            curr_pred = pd.DataFrame({\"Attack_prob\":y_pred[:,-2], \"Normal_prob\":y_pred[:, -1]})\n",
    "            Train.predictions.update({\"{}_{}_{}\".format(epochs,f,h):curr_pred})\n",
    "            \n",
    "            if accuracy > Train.best_acc:\n",
    "                Train.best_acc = accuracy\n",
    "                Train.pred_value = pred_value\n",
    "                Train.actual_value = actual_value\n",
    "                Train.best_parameters = \"Hidden Layers:{}, Features Count:{}\".format(h, f)\n",
    "                #net.saver.save(sess, \"dataset/epochs_{}_hidden layers_{}_features count_{}\".format(epochs,h,f))\n",
    "            Train.results.append(Train.result(epochs, f, h,valid_accuracy, accuracy))\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-05-07T22:06:10.123645Z",
     "start_time": "2017-05-07T22:03:27.608093Z"
    },
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current Layer Attributes - epochs:5 hidden layers:2 features count:4\n",
      "Step 1 | Training Loss: 0.000765 | Validation Accuracy: 0.768630\n",
      "Step 2 | Training Loss: 0.000730 | Validation Accuracy: 0.796398\n",
      "Step 3 | Training Loss: 0.000698 | Validation Accuracy: 0.794092\n",
      "Step 4 | Training Loss: 18515750041944064.000000\n",
      "Step 4 | Training Loss: 0.000777 | Validation Accuracy: 0.773066\n",
      "Step 5 | Training Loss: 0.000866 | Validation Accuracy: 0.804737\n",
      "Accuracy on Test data: 0.8073988556861877\n",
      "Current Layer Attributes - epochs:5 hidden layers:2 features count:8\n",
      "Step 1 | Training Loss: 0.001211 | Validation Accuracy: 0.372205\n",
      "Step 2 | Training Loss: 0.000982 | Validation Accuracy: 0.377528\n",
      "Step 3 | Training Loss: 0.001138 | Validation Accuracy: 0.302032\n",
      "Step 4 | Training Loss: 0.000955 | Validation Accuracy: 0.290853\n",
      "Step 5 | Training Loss: 0.002077 | Validation Accuracy: 0.321194\n",
      "Accuracy on Test data: 0.324299156665802\n",
      "Current Layer Attributes - epochs:5 hidden layers:2 features count:16\n",
      "Step 1 | Training Loss: 0.001016 | Validation Accuracy: 0.465667\n",
      "Step 2 | Training Loss: 0.000813 | Validation Accuracy: 0.435415\n",
      "Step 3 | Training Loss: 0.000717 | Validation Accuracy: 0.425745\n",
      "Step 4 | Training Loss: 0.000999 | Validation Accuracy: 0.412571\n",
      "Step 5 | Training Loss: 0.000851 | Validation Accuracy: 0.433330\n",
      "Accuracy on Test data: 0.43643540143966675\n",
      "Current Layer Attributes - epochs:5 hidden layers:2 features count:32\n",
      "Step 1 | Training Loss: 0.001249 | Validation Accuracy: 0.529320\n",
      "Step 2 | Training Loss: 0.001133 | Validation Accuracy: 0.509493\n",
      "Step 3 | Training Loss: 0.001851 | Validation Accuracy: 0.506964\n",
      "Step 4 | Training Loss: 0.001371 | Validation Accuracy: 0.511977\n",
      "Step 5 | Training Loss: 0.001188 | Validation Accuracy: 0.597631\n",
      "Accuracy on Test data: 0.598518431186676\n",
      "Current Layer Attributes - epochs:5 hidden layers:4 features count:4\n",
      "Step 1 | Training Loss: 0.001218 | Validation Accuracy: 0.488689\n",
      "Step 2 | Training Loss: 0.000886 | Validation Accuracy: 0.495209\n",
      "Step 3 | Training Loss: 0.000899 | Validation Accuracy: 0.492814\n",
      "Step 4 | Training Loss: 0.000771 | Validation Accuracy: 0.489798\n",
      "Step 5 | Training Loss: 0.000812 | Validation Accuracy: 0.493302\n",
      "Accuracy on Test data: 0.49764904379844666\n",
      "Current Layer Attributes - epochs:5 hidden layers:4 features count:8\n",
      "Step 1 | Training Loss: 0.000891 | Validation Accuracy: 0.502706\n",
      "Step 2 | Training Loss: 0.000748 | Validation Accuracy: 0.501686\n",
      "Step 3 | Training Loss: 0.001063 | Validation Accuracy: 0.498536\n",
      "Step 4 | Training Loss: 0.000910 | Validation Accuracy: 0.495786\n",
      "Step 5 | Training Loss: 0.000912 | Validation Accuracy: 0.506388\n",
      "Accuracy on Test data: 0.49458837509155273\n",
      "Current Layer Attributes - epochs:5 hidden layers:4 features count:16\n",
      "Step 1 | Training Loss: 0.001326 | Validation Accuracy: 0.492060\n",
      "Step 2 | Training Loss: 0.000809 | Validation Accuracy: 0.490685\n",
      "Step 3 | Training Loss: 0.000743 | Validation Accuracy: 0.493524\n",
      "Step 4 | Training Loss: 0.001778 | Validation Accuracy: 0.491528\n",
      "Step 5 | Training Loss: 0.000975 | Validation Accuracy: 0.489265\n",
      "Accuracy on Test data: 0.479107528924942\n",
      "Current Layer Attributes - epochs:5 hidden layers:4 features count:32\n",
      "Step 1 | Training Loss: 0.001026 | Validation Accuracy: 0.491439\n",
      "Step 2 | Training Loss: 0.000901 | Validation Accuracy: 0.492548\n",
      "Step 3 | Training Loss: 0.000952 | Validation Accuracy: 0.491128\n",
      "Step 4 | Training Loss: 0.000950 | Validation Accuracy: 0.490330\n",
      "Step 5 | Training Loss: 0.000891 | Validation Accuracy: 0.487669\n",
      "Accuracy on Test data: 0.49361249804496765\n",
      "Current Layer Attributes - epochs:5 hidden layers:6 features count:4\n",
      "Step 1 | Training Loss: 0.000804 | Validation Accuracy: 0.507186\n",
      "Step 2 | Training Loss: 0.000912 | Validation Accuracy: 0.503770\n",
      "Step 3 | Training Loss: 0.000750 | Validation Accuracy: 0.501907\n",
      "Step 4 | Training Loss: 0.001317 | Validation Accuracy: 0.505545\n",
      "Step 5 | Training Loss: 0.003595 | Validation Accuracy: 0.503371\n",
      "Accuracy on Test data: 0.505189836025238\n",
      "Current Layer Attributes - epochs:5 hidden layers:6 features count:8\n",
      "Step 1 | Training Loss: 0.000895 | Validation Accuracy: 0.488955\n",
      "Step 2 | Training Loss: 0.001029 | Validation Accuracy: 0.476801\n",
      "Step 3 | Training Loss: 0.000919 | Validation Accuracy: 0.482656\n",
      "Step 4 | Training Loss: 0.000794 | Validation Accuracy: 0.484785\n",
      "Step 5 | Training Loss: 0.000931 | Validation Accuracy: 0.485495\n",
      "Accuracy on Test data: 0.48522889614105225\n",
      "Current Layer Attributes - epochs:5 hidden layers:6 features count:16\n",
      "Step 1 | Training Loss: 0.000807 | Validation Accuracy: 0.514682\n",
      "Step 2 | Training Loss: 0.000882 | Validation Accuracy: 0.519384\n",
      "Step 3 | Training Loss: 0.000943 | Validation Accuracy: 0.518187\n",
      "Step 4 | Training Loss: 0.000845 | Validation Accuracy: 0.522489\n",
      "Step 5 | Training Loss: 0.000946 | Validation Accuracy: 0.521336\n",
      "Accuracy on Test data: 0.5141057372093201\n",
      "Current Layer Attributes - epochs:5 hidden layers:6 features count:32\n",
      "Step 1 | Training Loss: 0.000829 | Validation Accuracy: 0.489177\n",
      "Step 2 | Training Loss: 0.000831 | Validation Accuracy: 0.487802\n",
      "Step 3 | Training Loss: 0.001052 | Validation Accuracy: 0.484741\n",
      "Step 4 | Training Loss: 0.000830 | Validation Accuracy: 0.493169\n",
      "Step 5 | Training Loss: 0.001019 | Validation Accuracy: 0.485406\n",
      "Accuracy on Test data: 0.4909953773021698\n"
     ]
    }
   ],
   "source": [
    "import itertools\n",
    "class Hyperparameters:\n",
    "#    features_arr = [2, 4, 8, 16, 32, 64, 128, 256]\n",
    "#    hidden_layers_arr = [2, 4, 6, 10]\n",
    "    features_arr = [4, 8, 16, 32]\n",
    "    hidden_layers_arr = [2, 4, 6]\n",
    "\n",
    "    epochs = [5]\n",
    "    \n",
    "    for e, h, f in itertools.product(epochs, hidden_layers_arr, features_arr):\n",
    "        print(\"Current Layer Attributes - epochs:{} hidden layers:{} features count:{}\".format(e,h,f))\n",
    "        n = network(2,h,f)\n",
    "        n.build_layers()\n",
    "        Train.train(e, n, h,f)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-05-07T22:06:10.129398Z",
     "start_time": "2017-05-07T22:06:10.125519Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_results = pd.DataFrame(Train.results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-05-07T22:06:10.186601Z",
     "start_time": "2017-05-07T22:06:10.130893Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ritesh_malaiya/anaconda3/envs/p3/lib/python3.6/site-packages/ipykernel/__main__.py:1: FutureWarning: sort(columns=....) is deprecated, use sort_values(by=.....)\n",
      "  if __name__ == '__main__':\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>epoch</th>\n",
       "      <th>no_of_features</th>\n",
       "      <th>hidden_layers</th>\n",
       "      <th>train_score</th>\n",
       "      <th>test_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>0.804737</td>\n",
       "      <td>0.807399</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5</td>\n",
       "      <td>32</td>\n",
       "      <td>2</td>\n",
       "      <td>0.597631</td>\n",
       "      <td>0.598518</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>5</td>\n",
       "      <td>16</td>\n",
       "      <td>6</td>\n",
       "      <td>0.521336</td>\n",
       "      <td>0.514106</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>6</td>\n",
       "      <td>0.503371</td>\n",
       "      <td>0.505190</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>0.493302</td>\n",
       "      <td>0.497649</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5</td>\n",
       "      <td>8</td>\n",
       "      <td>4</td>\n",
       "      <td>0.506388</td>\n",
       "      <td>0.494588</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>5</td>\n",
       "      <td>32</td>\n",
       "      <td>4</td>\n",
       "      <td>0.487669</td>\n",
       "      <td>0.493612</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>5</td>\n",
       "      <td>32</td>\n",
       "      <td>6</td>\n",
       "      <td>0.485406</td>\n",
       "      <td>0.490995</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>5</td>\n",
       "      <td>8</td>\n",
       "      <td>6</td>\n",
       "      <td>0.485495</td>\n",
       "      <td>0.485229</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>5</td>\n",
       "      <td>16</td>\n",
       "      <td>4</td>\n",
       "      <td>0.489265</td>\n",
       "      <td>0.479108</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5</td>\n",
       "      <td>16</td>\n",
       "      <td>2</td>\n",
       "      <td>0.433330</td>\n",
       "      <td>0.436435</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5</td>\n",
       "      <td>8</td>\n",
       "      <td>2</td>\n",
       "      <td>0.321194</td>\n",
       "      <td>0.324299</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    epoch  no_of_features  hidden_layers  train_score  test_score\n",
       "0       5               4              2     0.804737    0.807399\n",
       "3       5              32              2     0.597631    0.598518\n",
       "10      5              16              6     0.521336    0.514106\n",
       "8       5               4              6     0.503371    0.505190\n",
       "4       5               4              4     0.493302    0.497649\n",
       "5       5               8              4     0.506388    0.494588\n",
       "7       5              32              4     0.487669    0.493612\n",
       "11      5              32              6     0.485406    0.490995\n",
       "9       5               8              6     0.485495    0.485229\n",
       "6       5              16              4     0.489265    0.479108\n",
       "2       5              16              2     0.433330    0.436435\n",
       "1       5               8              2     0.321194    0.324299"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_results.sort('test_score', ascending = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-05-07T22:06:10.197807Z",
     "start_time": "2017-05-07T22:06:10.188015Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pd.Panel(Train.predictions).to_pickle(\"dataset/tf_vae_dense_trained_together_nsl_kdd_predictions.pkl\")\n",
    "df_results.to_pickle(\"dataset/tf_vae_dense_trained_together_nsl_kdd_scores.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-05-07T22:06:10.263372Z",
     "start_time": "2017-05-07T22:06:10.199300Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import itertools\n",
    "\n",
    "def plot_confusion_matrix(cm, classes,\n",
    "                          normalize=False,\n",
    "                          title='Confusion matrix',\n",
    "                          cmap=plt.cm.Blues):\n",
    "    \"\"\"\n",
    "    This function prints and plots the confusion matrix.\n",
    "    Normalization can be applied by setting `normalize=True`.\n",
    "    \"\"\"\n",
    "    np.set_printoptions(precision=4)\n",
    "\n",
    "    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n",
    "    plt.title(title)\n",
    "    plt.colorbar()\n",
    "    tick_marks = np.arange(len(classes))\n",
    "    plt.xticks(tick_marks, classes, rotation=45)\n",
    "    plt.yticks(tick_marks, classes)\n",
    "\n",
    "    if normalize:\n",
    "        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "        print(\"Normalized confusion matrix\")\n",
    "    else:\n",
    "        print('Confusion matrix, without normalization')\n",
    "\n",
    "    print(cm)\n",
    "\n",
    "    thresh = cm.max() / 2.\n",
    "    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
    "        plt.text(j, i, cm[i, j].round(4),\n",
    "                 horizontalalignment=\"center\",\n",
    "                 color=\"white\" if cm[i, j] > thresh else \"black\")\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.ylabel('True label')\n",
    "    plt.xlabel('Predicted label')\n",
    "\n",
    "def plot(actual_value, pred_value):\n",
    "    from sklearn.metrics import confusion_matrix\n",
    "    cm_2labels = confusion_matrix(y_pred = pred_value, y_true = actual_value)\n",
    "    plt.figure(figsize=[6,6])\n",
    "    plot_confusion_matrix(cm_2labels, preprocess.output_columns_2labels, normalize = True,\n",
    "                         title = Train.best_parameters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-05-07T22:06:11.598466Z",
     "start_time": "2017-05-07T22:06:10.264780Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Normalized confusion matrix\n",
      "[[ 0.8041  0.1959]\n",
      " [ 0.1882  0.8118]]\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAbcAAAGeCAYAAAAXNE8VAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f526ed3b048>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot(actual_value = Train.actual_value, pred_value = Train.pred_value)"
   ]
  }
 ],
 "metadata": {
  "_draft": {
   "nbviewer_url": "https://gist.github.com/7d1ace18a82178e15ece8fc5252fce88"
  },
  "anaconda-cloud": {},
  "gist": {
   "data": {
    "description": "Hyper parameter tuning",
    "public": false
   },
   "id": "7d1ace18a82178e15ece8fc5252fce88"
  },
  "kernelspec": {
   "display_name": "Python [conda env:p3]",
   "language": "python",
   "name": "conda-env-p3-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
