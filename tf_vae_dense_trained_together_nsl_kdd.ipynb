{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Read Data Sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-05-13T00:27:48.000051Z",
     "start_time": "2017-05-13T00:27:47.496170Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from collections import namedtuple\n",
    "pd.set_option(\"display.max_rows\",35)\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-05-13T00:27:48.084428Z",
     "start_time": "2017-05-13T00:27:48.001596Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class dataset:\n",
    "    kdd_train_2labels = pd.read_pickle(\"dataset/kdd_train_2labels.pkl\")\n",
    "    kdd_test_2labels = pd.read_pickle(\"dataset/kdd_test_2labels.pkl\")\n",
    "    \n",
    "    kdd_train_5labels = pd.read_pickle(\"dataset/kdd_train_5labels.pkl\")\n",
    "    kdd_test_5labels = pd.read_pickle(\"dataset/kdd_test_5labels.pkl\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-05-13T00:27:48.090438Z",
     "start_time": "2017-05-13T00:27:48.085952Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(125973, 124)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.kdd_train_2labels.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-05-13T00:27:48.104882Z",
     "start_time": "2017-05-13T00:27:48.091877Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(22544, 124)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.kdd_test_2labels.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-05-13T00:27:48.942816Z",
     "start_time": "2017-05-13T00:27:48.106229Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.99589320646770185"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn import model_selection as ms\n",
    "from sklearn import preprocessing as pp\n",
    "\n",
    "class preprocess:\n",
    "    \n",
    "    output_columns_2labels = ['is_Attack','is_Normal']\n",
    "    \n",
    "    x_input = dataset.kdd_train_2labels.drop(output_columns_2labels, axis = 1)\n",
    "    y_output = dataset.kdd_train_2labels.loc[:,output_columns_2labels]\n",
    "\n",
    "    x_test_input = dataset.kdd_test_2labels.drop(output_columns_2labels, axis = 1)\n",
    "    y_test = dataset.kdd_test_2labels.loc[:,output_columns_2labels]\n",
    "\n",
    "    ss = pp.StandardScaler()\n",
    "\n",
    "    x_train = ss.fit_transform(x_input)\n",
    "    x_test = ss.transform(x_test_input)\n",
    "\n",
    "    y_train = y_output.values\n",
    "    y_test = y_test.values\n",
    "\n",
    "preprocess.x_train.std()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-05-13T00:27:50.253367Z",
     "start_time": "2017-05-13T00:27:48.944495Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-05-13T00:27:50.846988Z",
     "start_time": "2017-05-13T00:27:50.255111Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class network(object):\n",
    "    \n",
    "    input_dim = 122\n",
    "    classes = 2\n",
    "    hidden_encoder_dim = 122\n",
    "    hidden_layers = 1\n",
    "    latent_dim = 10\n",
    "\n",
    "    hidden_decoder_dim = 122\n",
    "    lam = 0.01\n",
    "    \n",
    "    def __init__(self, classes, hidden_layers, num_of_features):\n",
    "        self.classes = classes\n",
    "        self.hidden_layers = hidden_layers\n",
    "        self.latent_dim = num_of_features\n",
    "            \n",
    "    def build_layers(self):\n",
    "        tf.reset_default_graph()\n",
    "        #learning_rate = tf.Variable(initial_value=0.001)\n",
    "\n",
    "        input_dim = self.input_dim\n",
    "        classes = self.classes\n",
    "        hidden_encoder_dim = self.hidden_encoder_dim\n",
    "        hidden_layers = self.hidden_layers\n",
    "        latent_dim = self.latent_dim\n",
    "        hidden_decoder_dim = self.hidden_decoder_dim\n",
    "        lam = self.lam\n",
    "        \n",
    "        with tf.variable_scope(\"Input\"):\n",
    "            self.x = tf.placeholder(\"float\", shape=[None, input_dim])\n",
    "            self.y_ = tf.placeholder(\"float\", shape=[None, classes])\n",
    "            self.keep_prob = tf.placeholder(\"float\")\n",
    "        \n",
    "        with tf.variable_scope(\"Layer_Encoder\"):\n",
    "\n",
    "            hidden_encoder = tf.layers.dense(self.x, hidden_encoder_dim, activation = tf.nn.relu, kernel_regularizer=tf.nn.l2_loss)\n",
    "            hidden_encoder = tf.nn.dropout(hidden_encoder, self.keep_prob)\n",
    "            for h in range(hidden_layers - 1):\n",
    "                hidden_encoder = tf.layers.dense(hidden_encoder, hidden_encoder_dim, activation = tf.nn.relu, kernel_regularizer=tf.nn.l2_loss)\n",
    "                hidden_encoder = tf.nn.dropout(hidden_encoder, self.keep_prob)\n",
    "                \n",
    "        with tf.variable_scope(\"Layer_Mean\"):\n",
    "            mu_encoder = tf.layers.dense(hidden_encoder, latent_dim, activation = None, kernel_regularizer=tf.nn.l2_loss)\n",
    "\n",
    "        with tf.variable_scope(\"Layer_Variance\"):\n",
    "            logvar_encoder = tf.layers.dense(hidden_encoder, latent_dim, activation = None, kernel_regularizer=tf.nn.l2_loss)\n",
    "\n",
    "        with tf.variable_scope(\"Sampling_Distribution\"):\n",
    "            # Sample epsilon\n",
    "            epsilon = tf.random_normal(tf.shape(logvar_encoder), mean=0, stddev=1, name='epsilon')\n",
    "\n",
    "            # Sample latent variable\n",
    "            std_encoder = tf.exp(0.5 * logvar_encoder)\n",
    "            z = mu_encoder + tf.multiply(std_encoder, epsilon)\n",
    "            \n",
    "            #tf.summary.histogram(\"Sample_Distribution\", z)\n",
    "\n",
    "        with tf.variable_scope(\"Layer_Decoder\"):\n",
    "            hidden_decoder = tf.layers.dense(z, hidden_decoder_dim, activation = tf.nn.relu, kernel_regularizer=tf.nn.l2_loss)\n",
    "            hidden_decoder = tf.nn.dropout(hidden_decoder, self.keep_prob)\n",
    "            for h in range(hidden_layers - 1):\n",
    "                hidden_decoder = tf.layers.dense(hidden_decoder, hidden_decoder_dim, activation = tf.nn.relu, kernel_regularizer=tf.nn.l2_loss)\n",
    "                hidden_decoder = tf.nn.dropout(hidden_decoder, self.keep_prob)\n",
    "                \n",
    "        with tf.variable_scope(\"Layer_Reconstruction\"):\n",
    "            x_hat = tf.layers.dense(hidden_decoder, input_dim, activation = None)\n",
    "            \n",
    "        with tf.variable_scope(\"Layer_Dense_Hidden\"):\n",
    "            hidden_output = tf.layers.dense(z,latent_dim, activation=tf.nn.relu)\n",
    "\n",
    "        with tf.variable_scope(\"Layer_Dense_Softmax\"):\n",
    "            self.y = tf.layers.dense(z, classes, activation=tf.nn.softmax)\n",
    "\n",
    "        with tf.variable_scope(\"Loss\"):\n",
    "            \n",
    "            BCE = tf.reduce_mean(tf.nn.sigmoid_cross_entropy_with_logits(logits=x_hat, labels=self.x), reduction_indices=1)\n",
    "            KLD = -0.5 * tf.reduce_mean(1 + logvar_encoder - tf.pow(mu_encoder, 2) - tf.exp(logvar_encoder), reduction_indices=1)\n",
    "            softmax_loss = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(labels = self.y_, logits = self.y))\n",
    "\n",
    "            loss = tf.reduce_mean((BCE + KLD + softmax_loss) * lam)\n",
    "\n",
    "            loss = tf.clip_by_value(loss, -1e-1, 1e-1)\n",
    "            loss = tf.where(tf.is_nan(loss), 1e-1, loss)\n",
    "            loss = tf.where(tf.equal(loss, -1e-1), tf.random_normal(loss.shape), loss)\n",
    "            loss = tf.where(tf.equal(loss, 1e-1), tf.random_normal(loss.shape), loss)\n",
    "            \n",
    "            self.regularized_loss = tf.abs(loss, name = \"Regularized_loss\")\n",
    "            correct_prediction = tf.equal(tf.argmax(self.y_, 1), tf.argmax(self.y, 1))\n",
    "            self.tf_accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32), name = \"Accuracy\")\n",
    "\n",
    "        with tf.variable_scope(\"Optimizer\"):\n",
    "            learning_rate=1e-2\n",
    "            optimizer = tf.train.AdamOptimizer(learning_rate)\n",
    "            gradients, variables = zip(*optimizer.compute_gradients(self.regularized_loss))\n",
    "            gradients = [\n",
    "                None if gradient is None else tf.clip_by_value(gradient, -1, 1)\n",
    "                for gradient in gradients]\n",
    "            self.train_op = optimizer.apply_gradients(zip(gradients, variables))\n",
    "            #self.train_op = optimizer.minimize(self.regularized_loss)\n",
    "            \n",
    "        # add op for merging summary\n",
    "        #self.summary_op = tf.summary.merge_all()\n",
    "        self.pred = tf.argmax(self.y, axis = 1)\n",
    "        self.actual = tf.argmax(self.y_, axis = 1)\n",
    "\n",
    "        # add Saver ops\n",
    "        self.saver = tf.train.Saver()\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-05-13T00:27:50.993121Z",
     "start_time": "2017-05-13T00:27:50.848867Z"
    },
    "collapsed": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import collections\n",
    "\n",
    "class Train:    \n",
    "    \n",
    "    result = namedtuple(\"score\", ['epoch', 'no_of_features','hidden_layers','train_score', 'test_score'])\n",
    "\n",
    "    predictions = {}\n",
    "\n",
    "    results = []\n",
    "    best_acc = 0\n",
    "    \n",
    "    def train(epochs, net, h,f):\n",
    "        batch_iterations = 200\n",
    "    \n",
    "        with tf.Session() as sess:\n",
    "            #summary_writer_train = tf.summary.FileWriter('./logs/kdd/VAE/training', graph=sess.graph)\n",
    "            #summary_writer_valid = tf.summary.FileWriter('./logs/kdd/VAE/validation')\n",
    "\n",
    "            sess.run(tf.global_variables_initializer())\n",
    "\n",
    "            for epoch in range(1, (epochs+1)):\n",
    "                x_train, x_valid, y_train, y_valid, = ms.train_test_split(preprocess.x_train, \n",
    "                                                                          preprocess.y_train, \n",
    "                                                                          test_size=0.1)\n",
    "                batch_indices = np.array_split(np.arange(x_train.shape[0]), \n",
    "                                           batch_iterations)\n",
    "                                                                          \n",
    "                for i in batch_indices:\n",
    "                    _, train_loss = sess.run([net.train_op, \n",
    "                                                           net.regularized_loss, \n",
    "                                                           ], #net.summary_op\n",
    "                                                          feed_dict={net.x: x_train[i,:], \n",
    "                                                                     net.y_: y_train[i,:], \n",
    "                                                                     net.keep_prob:1})\n",
    "                    \n",
    "                    #summary_writer_train.add_summary(summary_str, epoch)\n",
    "                    if(train_loss > 1e9):\n",
    "                        print(\"Step {} | Training Loss: {:.6f}\".format(epoch, train_loss))\n",
    "                    \n",
    "\n",
    "                valid_accuracy = sess.run(net.tf_accuracy, #net.summary_op \n",
    "                                                      feed_dict={net.x: preprocess.x_test, \n",
    "                                                                 net.y_: preprocess.y_test, \n",
    "                                                                 net.keep_prob:1})\n",
    "                #summary_writer_valid.add_summary(summary_str, epoch)\n",
    "\n",
    "                if epoch % 1 == 0:\n",
    "                    print(\"Step {} | Training Loss: {:.6f} | Validation Accuracy: {:.6f}\".format(epoch, train_loss, valid_accuracy))\n",
    "\n",
    "            accuracy, pred_value, actual_value, y_pred = sess.run([net.tf_accuracy, \n",
    "                                                           net.pred, \n",
    "                                                           net.actual, net.y], \n",
    "                                                          feed_dict={net.x: preprocess.x_test, \n",
    "                                                                     net.y_: preprocess.y_test, \n",
    "                                                                     net.keep_prob:1})\n",
    "\n",
    "\n",
    "            print(\"Accuracy on Test data: {}\".format(accuracy))\n",
    "            \n",
    "            curr_pred = pd.DataFrame({\"Attack_prob\":y_pred[:,-2], \"Normal_prob\":y_pred[:, -1]})\n",
    "            Train.predictions.update({\"{}_{}_{}\".format(epochs,f,h):curr_pred})\n",
    "            \n",
    "            if accuracy > Train.best_acc:\n",
    "                Train.best_acc = accuracy\n",
    "                Train.pred_value = pred_value\n",
    "                Train.actual_value = actual_value\n",
    "                Train.best_parameters = \"Hidden Layers:{}, Features Count:{}\".format(h, f)\n",
    "                #net.saver.save(sess, \"dataset/epochs_{}_hidden layers_{}_features count_{}\".format(epochs,h,f))\n",
    "            Train.results.append(Train.result(epochs, f, h,valid_accuracy, accuracy))\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-05-13T00:44:33.696660Z",
     "start_time": "2017-05-13T00:27:50.995106Z"
    },
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current Layer Attributes - epochs:20 hidden layers:2 features count:4\n",
      "Step 1 | Training Loss: 0.000036 | Validation Accuracy: 0.779498\n",
      "Step 2 | Training Loss: 0.000676 | Validation Accuracy: 0.778123\n",
      "Step 3 | Training Loss: 0.002117 | Validation Accuracy: 0.814629\n",
      "Step 4 | Training Loss: 0.000388 | Validation Accuracy: 0.796132\n",
      "Step 5 | Training Loss: 0.000348 | Validation Accuracy: 0.786595\n",
      "Step 6 | Training Loss: 0.000132 | Validation Accuracy: 0.811347\n",
      "Step 7 | Training Loss: 0.000091 | Validation Accuracy: 0.806689\n",
      "Step 8 | Training Loss: 0.000076 | Validation Accuracy: 0.825364\n",
      "Step 9 | Training Loss: 0.000197 | Validation Accuracy: 0.842087\n",
      "Step 10 | Training Loss: 0.000654 | Validation Accuracy: 0.835610\n",
      "Step 11 | Training Loss: 0.000445 | Validation Accuracy: 0.836941\n",
      "Step 12 | Training Loss: 0.000100 | Validation Accuracy: 0.837651\n",
      "Step 13 | Training Loss: 0.000035 | Validation Accuracy: 0.838582\n",
      "Step 14 | Training Loss: 0.000488 | Validation Accuracy: 0.838405\n",
      "Step 15 | Training Loss: 0.000204 | Validation Accuracy: 0.847809\n",
      "Step 16 | Training Loss: 0.000070 | Validation Accuracy: 0.844083\n",
      "Step 17 | Training Loss: 0.000550 | Validation Accuracy: 0.849716\n",
      "Step 18 | Training Loss: 0.001172 | Validation Accuracy: 0.848164\n",
      "Step 19 | Training Loss: 0.000390 | Validation Accuracy: 0.852777\n",
      "Step 20 | Training Loss: 0.000351 | Validation Accuracy: 0.858898\n",
      "Accuracy on Test data: 0.8578335642814636\n",
      "Current Layer Attributes - epochs:20 hidden layers:2 features count:8\n",
      "Step 1 | Training Loss: 0.001230 | Validation Accuracy: 0.744633\n",
      "Step 2 | Training Loss: 0.000494 | Validation Accuracy: 0.798172\n",
      "Step 3 | Training Loss: 0.000175 | Validation Accuracy: 0.811480\n",
      "Step 4 | Training Loss: 0.000172 | Validation Accuracy: 0.799902\n",
      "Step 5 | Training Loss: 0.000341 | Validation Accuracy: 0.812899\n",
      "Step 6 | Training Loss: 0.001029 | Validation Accuracy: 0.818444\n",
      "Step 7 | Training Loss: 0.000515 | Validation Accuracy: 0.837429\n",
      "Step 8 | Training Loss: 0.000388 | Validation Accuracy: 0.844748\n",
      "Step 9 | Training Loss: 0.000405 | Validation Accuracy: 0.847498\n",
      "Step 10 | Training Loss: 0.001214 | Validation Accuracy: 0.853531\n",
      "Step 11 | Training Loss: 0.000164 | Validation Accuracy: 0.851357\n",
      "Step 12 | Training Loss: 0.000387 | Validation Accuracy: 0.861781\n",
      "Step 13 | Training Loss: 0.000054 | Validation Accuracy: 0.860539\n",
      "Step 14 | Training Loss: 0.000130 | Validation Accuracy: 0.853265\n",
      "Step 15 | Training Loss: 0.000255 | Validation Accuracy: 0.851047\n",
      "Step 16 | Training Loss: 0.000210 | Validation Accuracy: 0.854906\n",
      "Step 17 | Training Loss: 0.000047 | Validation Accuracy: 0.841599\n",
      "Step 18 | Training Loss: 0.000168 | Validation Accuracy: 0.880589\n",
      "Step 19 | Training Loss: 0.000012 | Validation Accuracy: 0.874867\n",
      "Step 20 | Training Loss: 0.000098 | Validation Accuracy: 0.879303\n",
      "Accuracy on Test data: 0.8785486221313477\n",
      "Current Layer Attributes - epochs:20 hidden layers:2 features count:16\n",
      "Step 1 | Training Loss: 0.001439 | Validation Accuracy: 0.718639\n",
      "Step 2 | Training Loss: 0.000803 | Validation Accuracy: 0.761710\n",
      "Step 3 | Training Loss: 0.000216 | Validation Accuracy: 0.779720\n",
      "Step 4 | Training Loss: 0.153896 | Validation Accuracy: 0.569242\n",
      "Step 5 | Training Loss: 0.872653 | Validation Accuracy: 0.569242\n",
      "Step 6 | Training Loss: 0.675953 | Validation Accuracy: 0.569242\n",
      "Step 7 | Training Loss: 0.923759 | Validation Accuracy: 0.569242\n",
      "Step 8 | Training Loss: 0.438907 | Validation Accuracy: 0.569242\n",
      "Step 9 | Training Loss: 0.595013 | Validation Accuracy: 0.569242\n",
      "Step 10 | Training Loss: 0.504916 | Validation Accuracy: 0.569242\n",
      "Step 11 | Training Loss: 0.031811 | Validation Accuracy: 0.569242\n",
      "Step 12 | Training Loss: 0.742256 | Validation Accuracy: 0.569242\n",
      "Step 13 | Training Loss: 0.427729 | Validation Accuracy: 0.569242\n",
      "Step 14 | Training Loss: 1.569003 | Validation Accuracy: 0.569242\n",
      "Step 15 | Training Loss: 0.397802 | Validation Accuracy: 0.569242\n",
      "Step 16 | Training Loss: 0.449594 | Validation Accuracy: 0.569242\n",
      "Step 17 | Training Loss: 1.506654 | Validation Accuracy: 0.569242\n",
      "Step 18 | Training Loss: 0.190761 | Validation Accuracy: 0.569242\n",
      "Step 19 | Training Loss: 1.015995 | Validation Accuracy: 0.569242\n",
      "Step 20 | Training Loss: 0.787763 | Validation Accuracy: 0.569242\n",
      "Accuracy on Test data: 0.5692423582077026\n",
      "Current Layer Attributes - epochs:20 hidden layers:2 features count:32\n",
      "Step 1 | Training Loss: 0.001847 | Validation Accuracy: 0.779099\n",
      "Step 2 | Training Loss: 1.400651 | Validation Accuracy: 0.569242\n",
      "Step 3 | Training Loss: 0.601854 | Validation Accuracy: 0.569242\n",
      "Step 4 | Training Loss: 0.738774 | Validation Accuracy: 0.569242\n",
      "Step 5 | Training Loss: 0.988270 | Validation Accuracy: 0.569242\n",
      "Step 6 | Training Loss: 0.998850 | Validation Accuracy: 0.569242\n",
      "Step 7 | Training Loss: 2.099568 | Validation Accuracy: 0.569242\n",
      "Step 8 | Training Loss: 0.451570 | Validation Accuracy: 0.569242\n",
      "Step 9 | Training Loss: 0.110504 | Validation Accuracy: 0.569242\n",
      "Step 10 | Training Loss: 1.117090 | Validation Accuracy: 0.569242\n",
      "Step 11 | Training Loss: 1.414563 | Validation Accuracy: 0.569242\n",
      "Step 12 | Training Loss: 0.463409 | Validation Accuracy: 0.569242\n",
      "Step 13 | Training Loss: 0.649304 | Validation Accuracy: 0.569242\n",
      "Step 14 | Training Loss: 1.392920 | Validation Accuracy: 0.569242\n",
      "Step 15 | Training Loss: 0.044942 | Validation Accuracy: 0.569242\n",
      "Step 16 | Training Loss: 0.252849 | Validation Accuracy: 0.569242\n",
      "Step 17 | Training Loss: 1.535793 | Validation Accuracy: 0.569242\n",
      "Step 18 | Training Loss: 1.591254 | Validation Accuracy: 0.569242\n",
      "Step 19 | Training Loss: 0.604998 | Validation Accuracy: 0.569242\n",
      "Step 20 | Training Loss: 1.432218 | Validation Accuracy: 0.569242\n",
      "Accuracy on Test data: 0.5692423582077026\n",
      "Current Layer Attributes - epochs:20 hidden layers:4 features count:4\n",
      "Step 1 | Training Loss: 0.001098 | Validation Accuracy: 0.668204\n",
      "Step 2 | Training Loss: 0.001871 | Validation Accuracy: 0.677431\n",
      "Step 3 | Training Loss: 0.001671 | Validation Accuracy: 0.607434\n",
      "Step 4 | Training Loss: 0.000352 | Validation Accuracy: 0.673705\n",
      "Step 5 | Training Loss: 0.000142 | Validation Accuracy: 0.684750\n",
      "Step 6 | Training Loss: 0.000905 | Validation Accuracy: 0.773864\n",
      "Step 7 | Training Loss: 0.000253 | Validation Accuracy: 0.762243\n",
      "Step 8 | Training Loss: 0.000844 | Validation Accuracy: 0.775018\n",
      "Step 9 | Training Loss: 0.001027 | Validation Accuracy: 0.721256\n",
      "Step 10 | Training Loss: 0.000503 | Validation Accuracy: 0.764860\n",
      "Step 11 | Training Loss: 0.000337 | Validation Accuracy: 0.794313\n",
      "Step 12 | Training Loss: 0.000905 | Validation Accuracy: 0.709901\n",
      "Step 13 | Training Loss: 0.000193 | Validation Accuracy: 0.728265\n",
      "Step 14 | Training Loss: 0.000084 | Validation Accuracy: 0.700719\n",
      "Step 15 | Training Loss: 0.000248 | Validation Accuracy: 0.728398\n",
      "Step 16 | Training Loss: 0.000170 | Validation Accuracy: 0.746939\n",
      "Step 17 | Training Loss: 0.000690 | Validation Accuracy: 0.800435\n",
      "Step 18 | Training Loss: 0.000115 | Validation Accuracy: 0.773820\n",
      "Step 19 | Training Loss: 0.000313 | Validation Accuracy: 0.796664\n",
      "Step 20 | Training Loss: 0.000137 | Validation Accuracy: 0.792273\n",
      "Accuracy on Test data: 0.7903211712837219\n",
      "Current Layer Attributes - epochs:20 hidden layers:4 features count:8\n",
      "Step 1 | Training Loss: 0.000701 | Validation Accuracy: 0.668027\n",
      "Step 2 | Training Loss: 0.000161 | Validation Accuracy: 0.790410\n",
      "Step 3 | Training Loss: 0.000291 | Validation Accuracy: 0.820839\n",
      "Step 4 | Training Loss: 0.000977 | Validation Accuracy: 0.818888\n",
      "Step 5 | Training Loss: 0.001230 | Validation Accuracy: 0.833836\n",
      "Step 6 | Training Loss: 0.001263 | Validation Accuracy: 0.833925\n",
      "Step 7 | Training Loss: 0.001061 | Validation Accuracy: 0.843151\n",
      "Step 8 | Training Loss: 0.000332 | Validation Accuracy: 0.847543\n",
      "Step 9 | Training Loss: 0.000678 | Validation Accuracy: 0.849228\n",
      "Step 10 | Training Loss: 0.001277 | Validation Accuracy: 0.861560\n",
      "Step 11 | Training Loss: 0.000192 | Validation Accuracy: 0.870387\n",
      "Step 12 | Training Loss: 0.000111 | Validation Accuracy: 0.871540\n",
      "Step 13 | Training Loss: 0.000227 | Validation Accuracy: 0.870165\n",
      "Step 14 | Training Loss: 0.000504 | Validation Accuracy: 0.864753\n",
      "Step 15 | Training Loss: 0.000230 | Validation Accuracy: 0.859031\n",
      "Step 16 | Training Loss: 0.000394 | Validation Accuracy: 0.863822\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 17 | Training Loss: 0.000393 | Validation Accuracy: 0.864576\n",
      "Step 18 | Training Loss: 0.000702 | Validation Accuracy: 0.864931\n",
      "Step 19 | Training Loss: 0.000231 | Validation Accuracy: 0.869145\n",
      "Step 20 | Training Loss: 0.001455 | Validation Accuracy: 0.884936\n",
      "Accuracy on Test data: 0.8837828040122986\n",
      "Current Layer Attributes - epochs:20 hidden layers:4 features count:16\n",
      "Step 1 | Training Loss: 0.001779 | Validation Accuracy: 0.779010\n",
      "Step 2 | Training Loss: 0.000795 | Validation Accuracy: 0.760114\n",
      "Step 3 | Training Loss: 0.360683 | Validation Accuracy: 0.569242\n",
      "Step 4 | Training Loss: 0.801992 | Validation Accuracy: 0.569242\n",
      "Step 5 | Training Loss: 1.767789 | Validation Accuracy: 0.569242\n",
      "Step 6 | Training Loss: 0.480479 | Validation Accuracy: 0.569242\n",
      "Step 7 | Training Loss: 1.030781 | Validation Accuracy: 0.569242\n",
      "Step 8 | Training Loss: 0.084662 | Validation Accuracy: 0.569242\n",
      "Step 9 | Training Loss: 0.814385 | Validation Accuracy: 0.569242\n",
      "Step 10 | Training Loss: 0.994863 | Validation Accuracy: 0.569242\n",
      "Step 11 | Training Loss: 1.244377 | Validation Accuracy: 0.569242\n",
      "Step 12 | Training Loss: 0.133264 | Validation Accuracy: 0.569242\n",
      "Step 13 | Training Loss: 0.333848 | Validation Accuracy: 0.569242\n",
      "Step 14 | Training Loss: 1.279419 | Validation Accuracy: 0.569242\n",
      "Step 15 | Training Loss: 0.671307 | Validation Accuracy: 0.569242\n",
      "Step 16 | Training Loss: 0.038324 | Validation Accuracy: 0.569242\n",
      "Step 17 | Training Loss: 0.809084 | Validation Accuracy: 0.569242\n",
      "Step 18 | Training Loss: 0.065118 | Validation Accuracy: 0.569242\n",
      "Step 19 | Training Loss: 0.573170 | Validation Accuracy: 0.569242\n",
      "Step 20 | Training Loss: 1.444980 | Validation Accuracy: 0.569242\n",
      "Accuracy on Test data: 0.5692423582077026\n",
      "Current Layer Attributes - epochs:20 hidden layers:4 features count:32\n",
      "Step 1 | Training Loss: 0.001396 | Validation Accuracy: 0.771602\n",
      "Step 2 | Training Loss: 0.000367 | Validation Accuracy: 0.825275\n",
      "Step 3 | Training Loss: 0.000206 | Validation Accuracy: 0.851535\n",
      "Step 4 | Training Loss: 0.000511 | Validation Accuracy: 0.835566\n",
      "Step 5 | Training Loss: 0.000581 | Validation Accuracy: 0.812722\n",
      "Step 6 | Training Loss: 0.000005 | Validation Accuracy: 0.861427\n",
      "Step 7 | Training Loss: 0.000440 | Validation Accuracy: 0.854241\n",
      "Step 8 | Training Loss: 0.000201 | Validation Accuracy: 0.861293\n",
      "Step 9 | Training Loss: 0.000605 | Validation Accuracy: 0.835300\n",
      "Step 10 | Training Loss: 0.000400 | Validation Accuracy: 0.859386\n",
      "Step 11 | Training Loss: 0.000297 | Validation Accuracy: 0.893275\n",
      "Step 12 | Training Loss: 0.000259 | Validation Accuracy: 0.872915\n",
      "Step 13 | Training Loss: 0.000060 | Validation Accuracy: 0.874113\n",
      "Step 14 | Training Loss: 0.000506 | Validation Accuracy: 0.871363\n",
      "Step 15 | Training Loss: 0.000015 | Validation Accuracy: 0.875399\n",
      "Step 16 | Training Loss: 0.000294 | Validation Accuracy: 0.875798\n",
      "Step 17 | Training Loss: 0.000410 | Validation Accuracy: 0.879746\n",
      "Step 18 | Training Loss: 0.000025 | Validation Accuracy: 0.874290\n",
      "Step 19 | Training Loss: 0.000385 | Validation Accuracy: 0.873226\n",
      "Step 20 | Training Loss: 0.000270 | Validation Accuracy: 0.872871\n",
      "Accuracy on Test data: 0.8728708028793335\n",
      "Current Layer Attributes - epochs:20 hidden layers:6 features count:4\n",
      "Step 1 | Training Loss: 0.003109 | Validation Accuracy: 0.659377\n",
      "Step 2 | Training Loss: 0.000127 | Validation Accuracy: 0.645538\n",
      "Step 3 | Training Loss: 0.001396 | Validation Accuracy: 0.762997\n",
      "Step 4 | Training Loss: 0.001957 | Validation Accuracy: 0.807931\n",
      "Step 5 | Training Loss: 0.000393 | Validation Accuracy: 0.823589\n",
      "Step 6 | Training Loss: 0.000166 | Validation Accuracy: 0.833747\n",
      "Step 7 | Training Loss: 0.000501 | Validation Accuracy: 0.836498\n",
      "Step 8 | Training Loss: 0.000151 | Validation Accuracy: 0.842441\n",
      "Step 9 | Training Loss: 0.000132 | Validation Accuracy: 0.853974\n",
      "Step 10 | Training Loss: 0.000490 | Validation Accuracy: 0.844704\n",
      "Step 11 | Training Loss: 0.000069 | Validation Accuracy: 0.841776\n",
      "Step 12 | Training Loss: 0.000523 | Validation Accuracy: 0.835921\n",
      "Step 13 | Training Loss: 0.000366 | Validation Accuracy: 0.829489\n",
      "Step 14 | Training Loss: 0.000471 | Validation Accuracy: 0.831707\n",
      "Step 15 | Training Loss: 0.000235 | Validation Accuracy: 0.858188\n",
      "Step 16 | Training Loss: 0.001123 | Validation Accuracy: 0.859918\n",
      "Step 17 | Training Loss: 0.002792 | Validation Accuracy: 0.862225\n",
      "Step 18 | Training Loss: 0.000355 | Validation Accuracy: 0.859209\n",
      "Step 19 | Training Loss: 0.001101 | Validation Accuracy: 0.802076\n",
      "Step 20 | Training Loss: 0.000357 | Validation Accuracy: 0.835965\n",
      "Accuracy on Test data: 0.8360095620155334\n",
      "Current Layer Attributes - epochs:20 hidden layers:6 features count:8\n",
      "Step 1 | Training Loss: 0.001134 | Validation Accuracy: 0.654054\n",
      "Step 2 | Training Loss: 0.001748 | Validation Accuracy: 0.752528\n",
      "Step 3 | Training Loss: 0.001622 | Validation Accuracy: 0.795955\n",
      "Step 4 | Training Loss: 0.000541 | Validation Accuracy: 0.753593\n",
      "Step 5 | Training Loss: 0.000402 | Validation Accuracy: 0.798705\n",
      "Step 6 | Training Loss: 0.000900 | Validation Accuracy: 0.764017\n",
      "Step 7 | Training Loss: 0.205360 | Validation Accuracy: 0.569242\n",
      "Step 8 | Training Loss: 0.986041 | Validation Accuracy: 0.569242\n",
      "Step 9 | Training Loss: 0.582486 | Validation Accuracy: 0.569242\n",
      "Step 10 | Training Loss: 1.881125 | Validation Accuracy: 0.569242\n",
      "Step 11 | Training Loss: 0.445114 | Validation Accuracy: 0.569242\n",
      "Step 12 | Training Loss: 0.384718 | Validation Accuracy: 0.569242\n",
      "Step 13 | Training Loss: 1.455071 | Validation Accuracy: 0.569242\n",
      "Step 14 | Training Loss: 1.244074 | Validation Accuracy: 0.569242\n",
      "Step 15 | Training Loss: 1.229762 | Validation Accuracy: 0.569242\n",
      "Step 16 | Training Loss: 0.471190 | Validation Accuracy: 0.569242\n",
      "Step 17 | Training Loss: 1.234764 | Validation Accuracy: 0.569242\n",
      "Step 18 | Training Loss: 0.161791 | Validation Accuracy: 0.569242\n",
      "Step 19 | Training Loss: 1.116825 | Validation Accuracy: 0.569242\n",
      "Step 20 | Training Loss: 0.772258 | Validation Accuracy: 0.569242\n",
      "Accuracy on Test data: 0.5692423582077026\n",
      "Current Layer Attributes - epochs:20 hidden layers:6 features count:16\n",
      "Step 1 | Training Loss: 0.001769 | Validation Accuracy: 0.626863\n",
      "Step 2 | Training Loss: 0.002454 | Validation Accuracy: 0.824255\n",
      "Step 3 | Training Loss: 0.001080 | Validation Accuracy: 0.805403\n",
      "Step 4 | Training Loss: 0.000029 | Validation Accuracy: 0.831529\n",
      "Step 5 | Training Loss: 0.000450 | Validation Accuracy: 0.859386\n",
      "Step 6 | Training Loss: 0.000102 | Validation Accuracy: 0.847454\n",
      "Step 7 | Training Loss: 0.000519 | Validation Accuracy: 0.865862\n",
      "Step 8 | Training Loss: 0.000156 | Validation Accuracy: 0.838361\n",
      "Step 9 | Training Loss: 0.000145 | Validation Accuracy: 0.772134\n",
      "Step 10 | Training Loss: 0.000358 | Validation Accuracy: 0.802298\n",
      "Step 11 | Training Loss: 0.000144 | Validation Accuracy: 0.866971\n",
      "Step 12 | Training Loss: 0.000517 | Validation Accuracy: 0.864975\n",
      "Step 13 | Training Loss: 0.000678 | Validation Accuracy: 0.804782\n",
      "Step 14 | Training Loss: 0.000076 | Validation Accuracy: 0.849406\n",
      "Step 15 | Training Loss: 0.000129 | Validation Accuracy: 0.848563\n",
      "Step 16 | Training Loss: 0.000006 | Validation Accuracy: 0.868169\n",
      "Step 17 | Training Loss: 0.000576 | Validation Accuracy: 0.850559\n",
      "Step 18 | Training Loss: 0.000314 | Validation Accuracy: 0.865641\n",
      "Step 19 | Training Loss: 0.000663 | Validation Accuracy: 0.845280\n",
      "Step 20 | Training Loss: 0.000608 | Validation Accuracy: 0.843373\n",
      "Accuracy on Test data: 0.8447036743164062\n",
      "Current Layer Attributes - epochs:20 hidden layers:6 features count:32\n",
      "Step 1 | Training Loss: 0.000412 | Validation Accuracy: 0.797330\n",
      "Step 2 | Training Loss: 0.000508 | Validation Accuracy: 0.785397\n",
      "Step 3 | Training Loss: 0.000271 | Validation Accuracy: 0.855305\n",
      "Step 4 | Training Loss: 0.000234 | Validation Accuracy: 0.792672\n",
      "Step 5 | Training Loss: 0.000240 | Validation Accuracy: 0.790011\n",
      "Step 6 | Training Loss: 0.000136 | Validation Accuracy: 0.823589\n",
      "Step 7 | Training Loss: 0.000345 | Validation Accuracy: 0.817202\n",
      "Step 8 | Training Loss: 0.000070 | Validation Accuracy: 0.820484\n",
      "Step 9 | Training Loss: 0.000440 | Validation Accuracy: 0.793027\n",
      "Step 10 | Training Loss: 0.000352 | Validation Accuracy: 0.801943\n",
      "Step 11 | Training Loss: 0.693754 | Validation Accuracy: 0.569242\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 12 | Training Loss: 0.699503 | Validation Accuracy: 0.569242\n",
      "Step 13 | Training Loss: 0.886604 | Validation Accuracy: 0.569242\n",
      "Step 14 | Training Loss: 1.218079 | Validation Accuracy: 0.569242\n",
      "Step 15 | Training Loss: 0.420490 | Validation Accuracy: 0.569242\n",
      "Step 16 | Training Loss: 0.891712 | Validation Accuracy: 0.569242\n",
      "Step 17 | Training Loss: 0.515593 | Validation Accuracy: 0.569242\n",
      "Step 18 | Training Loss: 2.086262 | Validation Accuracy: 0.569242\n",
      "Step 19 | Training Loss: 1.104829 | Validation Accuracy: 0.569242\n",
      "Step 20 | Training Loss: 1.727401 | Validation Accuracy: 0.569242\n",
      "Accuracy on Test data: 0.5692423582077026\n"
     ]
    }
   ],
   "source": [
    "import itertools\n",
    "class Hyperparameters:\n",
    "#    features_arr = [2, 4, 8, 16, 32, 64, 128, 256]\n",
    "#    hidden_layers_arr = [2, 4, 6, 10]\n",
    "    features_arr = [4, 8, 16, 32]\n",
    "    hidden_layers_arr = [2, 4, 6]\n",
    "\n",
    "    epochs = [20]\n",
    "    \n",
    "    for e, h, f in itertools.product(epochs, hidden_layers_arr, features_arr):\n",
    "        print(\"Current Layer Attributes - epochs:{} hidden layers:{} features count:{}\".format(e,h,f))\n",
    "        n = network(2,h,f)\n",
    "        n.build_layers()\n",
    "        Train.train(e, n, h,f)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-05-13T00:44:33.702093Z",
     "start_time": "2017-05-13T00:44:33.698267Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_results = pd.DataFrame(Train.results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-05-13T00:44:33.749809Z",
     "start_time": "2017-05-13T00:44:33.703494Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>epoch</th>\n",
       "      <th>no_of_features</th>\n",
       "      <th>hidden_layers</th>\n",
       "      <th>train_score</th>\n",
       "      <th>test_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>20</td>\n",
       "      <td>8</td>\n",
       "      <td>4</td>\n",
       "      <td>0.884936</td>\n",
       "      <td>0.883783</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>20</td>\n",
       "      <td>8</td>\n",
       "      <td>2</td>\n",
       "      <td>0.879303</td>\n",
       "      <td>0.878549</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>20</td>\n",
       "      <td>32</td>\n",
       "      <td>4</td>\n",
       "      <td>0.872871</td>\n",
       "      <td>0.872871</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>20</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>0.858898</td>\n",
       "      <td>0.857834</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>20</td>\n",
       "      <td>16</td>\n",
       "      <td>6</td>\n",
       "      <td>0.843373</td>\n",
       "      <td>0.844704</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>20</td>\n",
       "      <td>4</td>\n",
       "      <td>6</td>\n",
       "      <td>0.835965</td>\n",
       "      <td>0.836010</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>20</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>0.792273</td>\n",
       "      <td>0.790321</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>20</td>\n",
       "      <td>16</td>\n",
       "      <td>2</td>\n",
       "      <td>0.569242</td>\n",
       "      <td>0.569242</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>20</td>\n",
       "      <td>32</td>\n",
       "      <td>2</td>\n",
       "      <td>0.569242</td>\n",
       "      <td>0.569242</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>20</td>\n",
       "      <td>16</td>\n",
       "      <td>4</td>\n",
       "      <td>0.569242</td>\n",
       "      <td>0.569242</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>20</td>\n",
       "      <td>8</td>\n",
       "      <td>6</td>\n",
       "      <td>0.569242</td>\n",
       "      <td>0.569242</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>20</td>\n",
       "      <td>32</td>\n",
       "      <td>6</td>\n",
       "      <td>0.569242</td>\n",
       "      <td>0.569242</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    epoch  no_of_features  hidden_layers  train_score  test_score\n",
       "5      20               8              4     0.884936    0.883783\n",
       "1      20               8              2     0.879303    0.878549\n",
       "7      20              32              4     0.872871    0.872871\n",
       "0      20               4              2     0.858898    0.857834\n",
       "10     20              16              6     0.843373    0.844704\n",
       "8      20               4              6     0.835965    0.836010\n",
       "4      20               4              4     0.792273    0.790321\n",
       "2      20              16              2     0.569242    0.569242\n",
       "3      20              32              2     0.569242    0.569242\n",
       "6      20              16              4     0.569242    0.569242\n",
       "9      20               8              6     0.569242    0.569242\n",
       "11     20              32              6     0.569242    0.569242"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_results.sort_values(by = 'test_score', ascending = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-05-13T00:44:33.761981Z",
     "start_time": "2017-05-13T00:44:33.751358Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pd.Panel(Train.predictions).to_pickle(\"dataset/tf_vae_dense_trained_together_nsl_kdd_predictions.pkl\")\n",
    "df_results.to_pickle(\"dataset/tf_vae_dense_trained_together_nsl_kdd_scores.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-05-13T00:44:33.827549Z",
     "start_time": "2017-05-13T00:44:33.763514Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import itertools\n",
    "\n",
    "def plot_confusion_matrix(cm, classes,\n",
    "                          normalize=False,\n",
    "                          title='Confusion matrix',\n",
    "                          cmap=plt.cm.Blues):\n",
    "    \"\"\"\n",
    "    This function prints and plots the confusion matrix.\n",
    "    Normalization can be applied by setting `normalize=True`.\n",
    "    \"\"\"\n",
    "    np.set_printoptions(precision=4)\n",
    "\n",
    "    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n",
    "    plt.title(title)\n",
    "    plt.colorbar()\n",
    "    tick_marks = np.arange(len(classes))\n",
    "    plt.xticks(tick_marks, classes, rotation=45)\n",
    "    plt.yticks(tick_marks, classes)\n",
    "\n",
    "    if normalize:\n",
    "        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "        print(\"Normalized confusion matrix\")\n",
    "    else:\n",
    "        print('Confusion matrix, without normalization')\n",
    "\n",
    "    print(cm)\n",
    "\n",
    "    thresh = cm.max() / 2.\n",
    "    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
    "        plt.text(j, i, cm[i, j].round(4),\n",
    "                 horizontalalignment=\"center\",\n",
    "                 color=\"white\" if cm[i, j] > thresh else \"black\")\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.ylabel('True label')\n",
    "    plt.xlabel('Predicted label')\n",
    "\n",
    "def plot(actual_value, pred_value):\n",
    "    from sklearn.metrics import confusion_matrix\n",
    "    cm_2labels = confusion_matrix(y_pred = pred_value, y_true = actual_value)\n",
    "    plt.figure(figsize=[6,6])\n",
    "    plot_confusion_matrix(cm_2labels, preprocess.output_columns_2labels, normalize = True,\n",
    "                         title = Train.best_parameters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-05-13T00:44:34.124553Z",
     "start_time": "2017-05-13T00:44:33.829197Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Normalized confusion matrix\n",
      "[[ 0.9148  0.0852]\n",
      " [ 0.1572  0.8428]]\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAbcAAAGeCAYAAAAXNE8VAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f252e709438>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot(actual_value = Train.actual_value, pred_value = Train.pred_value)"
   ]
  }
 ],
 "metadata": {
  "_draft": {
   "nbviewer_url": "https://gist.github.com/7d1ace18a82178e15ece8fc5252fce88"
  },
  "anaconda-cloud": {},
  "gist": {
   "data": {
    "description": "Hyper parameter tuning",
    "public": false
   },
   "id": "7d1ace18a82178e15ece8fc5252fce88"
  },
  "kernelspec": {
   "display_name": "Python [conda env:p3]",
   "language": "python",
   "name": "conda-env-p3-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
