{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Deep Learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-05-14T18:56:47.494519Z",
     "start_time": "2017-05-14T18:56:44.969339Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.layers import Input, Dense, Lambda, Layer, LSTM, RepeatVector\n",
    "from keras.models import Model\n",
    "from keras.layers.core import Dropout\n",
    "from keras import regularizers\n",
    "import keras\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from keras import backend as K\n",
    "from keras import metrics\n",
    "from collections import namedtuple\n",
    "pd.set_option(\"display.max_rows\",35)\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-05-14T18:56:48.698962Z",
     "start_time": "2017-05-14T18:56:47.496823Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "kdd_train_2labels = pd.read_pickle(\"dataset/kdd_train_2labels.pkl\")\n",
    "kdd_test_2labels = pd.read_pickle(\"dataset/kdd_test_2labels.pkl\")\n",
    "\n",
    "#y_train_labels = pd.read_pickle(\"dataset/kdd_train_2labels_y.pkl\")\n",
    "#y_train_labels = pd.read_pickle(\"dataset/kdd_train_2labels.pkl\")\n",
    "#y_test_labels = pd.read_pickle(\"dataset/kdd_test_2labels_y.pkl\")\n",
    "\n",
    "output_columns_2labels = ['is_Attack','is_Normal']\n",
    "\n",
    "from sklearn import model_selection as ms\n",
    "from sklearn import preprocessing as pp\n",
    "\n",
    "x_input = kdd_train_2labels.drop(output_columns_2labels, axis = 1)\n",
    "y_output = kdd_train_2labels.loc[:,output_columns_2labels]\n",
    "\n",
    "ss = pp.StandardScaler()\n",
    "x_input = ss.fit_transform(x_input)\n",
    "\n",
    "#le = pp.LabelEncoder()\n",
    "#y_train = le.fit_transform(y_train_labels).reshape(-1, 1)\n",
    "#y_test = le.transform(y_test_labels).reshape(-1, 1)\n",
    "\n",
    "y_train = kdd_train_2labels.loc[:,output_columns_2labels].values\n",
    "\n",
    "x_train, x_valid, y_train, y_valid = ms.train_test_split(x_input, \n",
    "                              y_train, \n",
    "                              test_size=0.1)\n",
    "#x_valid, x_test, y_valid, y_test = ms.train_test_split(x_valid, y_valid, test_size = 0.4)\n",
    "\n",
    "x_test = kdd_test_2labels.drop(output_columns_2labels, axis = 1)\n",
    "y_test = kdd_test_2labels.loc[:,output_columns_2labels].values\n",
    "\n",
    "x_test = ss.transform(x_test)\n",
    "\n",
    "#x_train = np.hstack((x_train, y_train))\n",
    "#x_valid = np.hstack((x_valid, y_valid))\n",
    "\n",
    "#x_test = np.hstack((x_test, np.random.normal(loc = 0, scale = 0.01, size = y_test.shape)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-05-14T18:56:49.956543Z",
     "start_time": "2017-05-14T18:56:48.701047Z"
    }
   },
   "outputs": [],
   "source": [
    "input_dim = 122\n",
    "intermediate_dim = 10\n",
    "latent_dim = 32\n",
    "batch_size = 1409\n",
    "hidden_layers = 8\n",
    "classes = 2\n",
    "drop_prob = 0.2\n",
    "timesteps = 1\n",
    "\n",
    "class Train:\n",
    "    def build_lstm_model():\n",
    "        Train.x = Input(shape=(timesteps, input_dim))\n",
    "        encoded = LSTM(input_dim)(Train.x)\n",
    "        \n",
    "        decoded = RepeatVector(timesteps)(encoded)\n",
    "        Train.y = LSTM(classes, return_sequences=True)(decoded)\n",
    "\n",
    "\n",
    "Train.build_lstm_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-05-14T18:59:56.090938Z",
     "start_time": "2017-05-14T18:56:49.959055Z"
    },
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " \n",
      " Current Layer Attributes - epochs:10 hidden layers:2 features count:1\n",
      "Train on 112720 samples, validate on 22544 samples\n",
      "Epoch 1/10\n",
      "109902/112720 [============================>.] - ETA: 0s - loss: 1.4269 - acc: 0.3901Epoch 00000: val_acc improved from -inf to 0.42588, saving model to dataset/epochs_10_hidden layers_2_features count_1\n",
      "112720/112720 [==============================] - 6s - loss: 1.4159 - acc: 0.3875 - val_loss: 1.8100 - val_acc: 0.4259\n",
      "Epoch 2/10\n",
      "109902/112720 [============================>.] - ETA: 0s - loss: 1.5720 - acc: 0.2464Epoch 00001: val_acc did not improve\n",
      "112720/112720 [==============================] - 4s - loss: 1.5817 - acc: 0.2459 - val_loss: 2.0883 - val_acc: 0.3817\n",
      "Epoch 3/10\n",
      "109902/112720 [============================>.] - ETA: 0s - loss: 1.2295 - acc: 0.2917Epoch 00002: val_acc improved from 0.42588 to 0.43187, saving model to dataset/epochs_10_hidden layers_2_features count_1\n",
      "112720/112720 [==============================] - 4s - loss: 1.2072 - acc: 0.2945 - val_loss: 1.6883 - val_acc: 0.4319\n",
      "Epoch 4/10\n",
      "111311/112720 [============================>.] - ETA: 0s - loss: 0.2337 - acc: 0.4029Epoch 00003: val_acc did not improve\n",
      "112720/112720 [==============================] - 4s - loss: 0.2334 - acc: 0.4031 - val_loss: 1.7344 - val_acc: 0.3956\n",
      "Epoch 5/10\n",
      "109902/112720 [============================>.] - ETA: 0s - loss: 0.2449 - acc: 0.4031Epoch 00004: val_acc did not improve\n",
      "112720/112720 [==============================] - 3s - loss: 0.2452 - acc: 0.4033 - val_loss: 1.5604 - val_acc: 0.4167\n",
      "Epoch 6/10\n",
      "111311/112720 [============================>.] - ETA: 0s - loss: 0.2804 - acc: 0.3993Epoch 00005: val_acc did not improve\n",
      "112720/112720 [==============================] - 3s - loss: 0.2797 - acc: 0.3994 - val_loss: 1.5769 - val_acc: 0.4092\n",
      "Epoch 7/10\n",
      "111311/112720 [============================>.] - ETA: 0s - loss: 0.3283 - acc: 0.3999Epoch 00006: val_acc did not improve\n",
      "112720/112720 [==============================] - 3s - loss: 0.3302 - acc: 0.4000 - val_loss: 1.5190 - val_acc: 0.4290\n",
      "Epoch 8/10\n",
      "109902/112720 [============================>.] - ETA: 0s - loss: 0.4831 - acc: 0.4082Epoch 00007: val_acc did not improve\n",
      "112720/112720 [==============================] - 3s - loss: 0.4837 - acc: 0.4079 - val_loss: 1.3606 - val_acc: 0.4287\n",
      "Epoch 9/10\n",
      "111311/112720 [============================>.] - ETA: 0s - loss: 0.6359 - acc: 0.3918Epoch 00008: val_acc improved from 0.43187 to 0.46456, saving model to dataset/epochs_10_hidden layers_2_features count_1\n",
      "112720/112720 [==============================] - 3s - loss: 0.6411 - acc: 0.3913 - val_loss: 1.7208 - val_acc: 0.4646\n",
      "Epoch 10/10\n",
      "109902/112720 [============================>.] - ETA: 0s - loss: 0.7076 - acc: 0.3670Epoch 00009: val_acc did not improve\n",
      "112720/112720 [==============================] - 4s - loss: 0.6988 - acc: 0.3672 - val_loss: 1.4656 - val_acc: 0.4497\n",
      "22544/22544 [==============================] - 0s     \n",
      "\n",
      " Train Acc: 0.3979772888123989, Test Acc: 0.4496983680874109\n",
      " \n",
      " Current Layer Attributes - epochs:10 hidden layers:4 features count:1\n",
      "Train on 112720 samples, validate on 22544 samples\n",
      "Epoch 1/10\n",
      "111311/112720 [============================>.] - ETA: 0s - loss: nan - acc: 0.4608Epoch 00000: val_acc improved from -inf to 0.56924, saving model to dataset/epochs_10_hidden layers_4_features count_1\n",
      "112720/112720 [==============================] - 6s - loss: nan - acc: 0.4613 - val_loss: nan - val_acc: 0.5692\n",
      "Epoch 2/10\n",
      "111311/112720 [============================>.] - ETA: 0s - loss: nan - acc: 0.4653Epoch 00001: val_acc did not improve\n",
      "112720/112720 [==============================] - 4s - loss: nan - acc: 0.4651 - val_loss: nan - val_acc: 0.5692\n",
      "Epoch 3/10\n",
      "111311/112720 [============================>.] - ETA: 0s - loss: nan - acc: 0.4652Epoch 00002: val_acc did not improve\n",
      "112720/112720 [==============================] - 4s - loss: nan - acc: 0.4651 - val_loss: nan - val_acc: 0.5692\n",
      "Epoch 4/10\n",
      "111311/112720 [============================>.] - ETA: 0s - loss: nan - acc: 0.4651Epoch 00003: val_acc did not improve\n",
      "112720/112720 [==============================] - 4s - loss: nan - acc: 0.4651 - val_loss: nan - val_acc: 0.5692\n",
      "Epoch 5/10\n",
      "111311/112720 [============================>.] - ETA: 0s - loss: nan - acc: 0.4651Epoch 00004: val_acc did not improve\n",
      "112720/112720 [==============================] - 4s - loss: nan - acc: 0.4651 - val_loss: nan - val_acc: 0.5692\n",
      "Epoch 6/10\n",
      "109902/112720 [============================>.] - ETA: 0s - loss: nan - acc: 0.4656Epoch 00005: val_acc did not improve\n",
      "112720/112720 [==============================] - 3s - loss: nan - acc: 0.4651 - val_loss: nan - val_acc: 0.5692\n",
      "Epoch 7/10\n",
      "111311/112720 [============================>.] - ETA: 0s - loss: nan - acc: 0.4652Epoch 00006: val_acc did not improve\n",
      "112720/112720 [==============================] - 3s - loss: nan - acc: 0.4651 - val_loss: nan - val_acc: 0.5692\n",
      "Epoch 8/10\n",
      "109902/112720 [============================>.] - ETA: 0s - loss: nan - acc: 0.4650Epoch 00007: val_acc did not improve\n",
      "112720/112720 [==============================] - 4s - loss: nan - acc: 0.4651 - val_loss: nan - val_acc: 0.5692\n",
      "Epoch 9/10\n",
      "109902/112720 [============================>.] - ETA: 0s - loss: nan - acc: 0.4649Epoch 00008: val_acc did not improve\n",
      "112720/112720 [==============================] - 4s - loss: nan - acc: 0.4651 - val_loss: nan - val_acc: 0.5692\n",
      "Epoch 10/10\n",
      "109902/112720 [============================>.] - ETA: 0s - loss: nan - acc: 0.4653Epoch 00009: val_acc did not improve\n",
      "112720/112720 [==============================] - 3s - loss: nan - acc: 0.4651 - val_loss: nan - val_acc: 0.5692\n",
      "22544/22544 [==============================] - 0s     \n",
      "\n",
      " Train Acc: 0.46619942784309387, Test Acc: 0.5692423582077026\n",
      " \n",
      " Current Layer Attributes - epochs:10 hidden layers:6 features count:1\n",
      "Train on 112720 samples, validate on 22544 samples\n",
      "Epoch 1/10\n",
      "111311/112720 [============================>.] - ETA: 0s - loss: nan - acc: 0.4649Epoch 00000: val_acc improved from -inf to 0.56924, saving model to dataset/epochs_10_hidden layers_6_features count_1\n",
      "112720/112720 [==============================] - 6s - loss: nan - acc: 0.4651 - val_loss: nan - val_acc: 0.5692\n",
      "Epoch 2/10\n",
      "111311/112720 [============================>.] - ETA: 0s - loss: nan - acc: 0.4653Epoch 00001: val_acc did not improve\n",
      "112720/112720 [==============================] - 4s - loss: nan - acc: 0.4651 - val_loss: nan - val_acc: 0.5692\n",
      "Epoch 3/10\n",
      "111311/112720 [============================>.] - ETA: 0s - loss: nan - acc: 0.4652Epoch 00002: val_acc did not improve\n",
      "112720/112720 [==============================] - 4s - loss: nan - acc: 0.4651 - val_loss: nan - val_acc: 0.5692\n",
      "Epoch 4/10\n",
      "109902/112720 [============================>.] - ETA: 0s - loss: nan - acc: 0.4653Epoch 00003: val_acc did not improve\n",
      "112720/112720 [==============================] - 3s - loss: nan - acc: 0.4651 - val_loss: nan - val_acc: 0.5692\n",
      "Epoch 5/10\n",
      "109902/112720 [============================>.] - ETA: 0s - loss: nan - acc: 0.4652Epoch 00004: val_acc did not improve\n",
      "112720/112720 [==============================] - 4s - loss: nan - acc: 0.4651 - val_loss: nan - val_acc: 0.5692\n",
      "Epoch 6/10\n",
      "109902/112720 [============================>.] - ETA: 0s - loss: nan - acc: 0.4652Epoch 00005: val_acc did not improve\n",
      "112720/112720 [==============================] - 3s - loss: nan - acc: 0.4651 - val_loss: nan - val_acc: 0.5692\n",
      "Epoch 7/10\n",
      "111311/112720 [============================>.] - ETA: 0s - loss: nan - acc: 0.4650Epoch 00006: val_acc did not improve\n",
      "112720/112720 [==============================] - 3s - loss: nan - acc: 0.4651 - val_loss: nan - val_acc: 0.5692\n",
      "Epoch 8/10\n",
      "111311/112720 [============================>.] - ETA: 0s - loss: nan - acc: 0.4650Epoch 00007: val_acc did not improve\n",
      "112720/112720 [==============================] - 4s - loss: nan - acc: 0.4651 - val_loss: nan - val_acc: 0.5692\n",
      "Epoch 9/10\n",
      "109902/112720 [============================>.] - ETA: 0s - loss: nan - acc: 0.4650Epoch 00008: val_acc did not improve\n",
      "112720/112720 [==============================] - 4s - loss: nan - acc: 0.4651 - val_loss: nan - val_acc: 0.5692\n",
      "Epoch 10/10\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "111311/112720 [============================>.] - ETA: 0s - loss: nan - acc: 0.4652Epoch 00009: val_acc did not improve\n",
      "112720/112720 [==============================] - 4s - loss: nan - acc: 0.4651 - val_loss: nan - val_acc: 0.5692\n",
      "22544/22544 [==============================] - 0s     \n",
      "\n",
      " Train Acc: 0.46619942784309387, Test Acc: 0.5692423582077026\n",
      " \n",
      " Current Layer Attributes - epochs:10 hidden layers:10 features count:1\n",
      "Train on 112720 samples, validate on 22544 samples\n",
      "Epoch 1/10\n",
      "111311/112720 [============================>.] - ETA: 0s - loss: nan - acc: 0.4650Epoch 00000: val_acc improved from -inf to 0.56924, saving model to dataset/epochs_10_hidden layers_10_features count_1\n",
      "112720/112720 [==============================] - 6s - loss: nan - acc: 0.4651 - val_loss: nan - val_acc: 0.5692\n",
      "Epoch 2/10\n",
      "111311/112720 [============================>.] - ETA: 0s - loss: nan - acc: 0.4653Epoch 00001: val_acc did not improve\n",
      "112720/112720 [==============================] - 4s - loss: nan - acc: 0.4651 - val_loss: nan - val_acc: 0.5692\n",
      "Epoch 3/10\n",
      "111311/112720 [============================>.] - ETA: 0s - loss: nan - acc: 0.4648Epoch 00002: val_acc did not improve\n",
      "112720/112720 [==============================] - 4s - loss: nan - acc: 0.4651 - val_loss: nan - val_acc: 0.5692\n",
      "Epoch 4/10\n",
      "111311/112720 [============================>.] - ETA: 0s - loss: nan - acc: 0.4650Epoch 00003: val_acc did not improve\n",
      "112720/112720 [==============================] - 4s - loss: nan - acc: 0.4651 - val_loss: nan - val_acc: 0.5692\n",
      "Epoch 5/10\n",
      "111311/112720 [============================>.] - ETA: 0s - loss: nan - acc: 0.4651Epoch 00004: val_acc did not improve\n",
      "112720/112720 [==============================] - 4s - loss: nan - acc: 0.4651 - val_loss: nan - val_acc: 0.5692\n",
      "Epoch 6/10\n",
      "109902/112720 [============================>.] - ETA: 0s - loss: nan - acc: 0.4650Epoch 00005: val_acc did not improve\n",
      "112720/112720 [==============================] - 4s - loss: nan - acc: 0.4651 - val_loss: nan - val_acc: 0.5692\n",
      "Epoch 7/10\n",
      "111311/112720 [============================>.] - ETA: 0s - loss: nan - acc: 0.4650Epoch 00006: val_acc did not improve\n",
      "112720/112720 [==============================] - 4s - loss: nan - acc: 0.4651 - val_loss: nan - val_acc: 0.5692\n",
      "Epoch 8/10\n",
      "111311/112720 [============================>.] - ETA: 0s - loss: nan - acc: 0.4648Epoch 00007: val_acc did not improve\n",
      "112720/112720 [==============================] - 4s - loss: nan - acc: 0.4651 - val_loss: nan - val_acc: 0.5692\n",
      "Epoch 9/10\n",
      "111311/112720 [============================>.] - ETA: 0s - loss: nan - acc: 0.4650Epoch 00008: val_acc did not improve\n",
      "112720/112720 [==============================] - 4s - loss: nan - acc: 0.4651 - val_loss: nan - val_acc: 0.5692\n",
      "Epoch 10/10\n",
      "109902/112720 [============================>.] - ETA: 0s - loss: nan - acc: 0.4651Epoch 00009: val_acc did not improve\n",
      "112720/112720 [==============================] - 4s - loss: nan - acc: 0.4651 - val_loss: nan - val_acc: 0.5692\n",
      "22544/22544 [==============================] - 0s     \n",
      "\n",
      " Train Acc: 0.46619942784309387, Test Acc: 0.5692423582077026\n"
     ]
    }
   ],
   "source": [
    "import itertools\n",
    "#features_arr = [4, 16, 32, 256, 1024]\n",
    "#hidden_layers_arr = [2, 6, 10, 100]\n",
    "\n",
    "#features_arr = [4, 16, 32]\n",
    "#hidden_layers_arr = [2, 6, 10]\n",
    "\n",
    "features_arr = [1] # [4, 16, 32]\n",
    "hidden_layers_arr = [2, 4, 6, 10]\n",
    "\n",
    "epoch_arr = [10]\n",
    "\n",
    "score = namedtuple(\"score\", ['epoch', 'no_of_features','hidden_layers','train_score', 'test_score'])\n",
    "scores = []\n",
    "predictions = {}\n",
    "\n",
    "for e, h, f in itertools.product(epoch_arr, hidden_layers_arr, features_arr):\n",
    "    \n",
    "    print(\" \\n Current Layer Attributes - epochs:{} hidden layers:{} features count:{}\".format(e,h,f))\n",
    "    latent_dim = f\n",
    "    epochs = e\n",
    "    hidden_layers = h\n",
    "    \n",
    "    train_size = x_train.shape[0] - x_train.shape[0]%batch_size\n",
    "    valid_size = x_valid.shape[0] - x_valid.shape[0]%batch_size\n",
    "\n",
    "    \n",
    "    optimizer = keras.optimizers.Adam()\n",
    "    \n",
    "    seq2seq_model = Model(Train.x, Train.y)\n",
    "    seq2seq_model.compile(optimizer = optimizer, \n",
    "                      loss = keras.losses.categorical_crossentropy, \n",
    "                      metrics = ['accuracy'])\n",
    "    \n",
    "    ckp = keras.callbacks.ModelCheckpoint(\"dataset/epochs_{}_hidden layers_{}_features count_{}\".format(e,h,f), \n",
    "                                          monitor='val_acc', verbose=1, \n",
    "                                          save_best_only=True, save_weights_only=False, \n",
    "                                          mode='auto', period=1)\n",
    "\n",
    "    seq2seq_model.fit(x = x_train[:train_size,np.newaxis,:], y = y_train[:train_size,np.newaxis,:],\n",
    "                 shuffle=True, epochs=epochs, \n",
    "                  batch_size = batch_size, \n",
    "                  validation_data = (x_test[:,np.newaxis,:], y_test[:,np.newaxis,:]),\n",
    "                  verbose = 1, callbacks=[ckp])\n",
    "\n",
    "    score_train = seq2seq_model.evaluate(x_valid[:valid_size,np.newaxis,:], y = y_valid[:valid_size,np.newaxis,:],\n",
    "                               batch_size = batch_size,\n",
    "                               verbose = 1)\n",
    "    \n",
    "    score_test = seq2seq_model.evaluate(x_test[:,np.newaxis,:], y = y_test[:,np.newaxis,:],\n",
    "                           batch_size = batch_size,\n",
    "                           verbose = 1)\n",
    "    \n",
    "    y_test_pred = seq2seq_model.predict(x_test[:,np.newaxis,:], batch_size=batch_size)\n",
    "    y_test_pred = np.squeeze(y_test_pred)\n",
    "\n",
    "    y_pred = y_test_pred #np.argmax(y_test_pred[:,-2:], axis = 1)\n",
    "    \n",
    "    curr_pred = pd.DataFrame({\"Attack_prob\":y_pred[:,0], \"Normal_prob\":y_pred[:,1]})\n",
    "    predictions.update({\"{}_{}_{}\".format(e,f,h):curr_pred})\n",
    "    \n",
    "    scores.append(score(e,f,h,score_train[-1], score_test[-1])) #score_test[-1]))\n",
    "    \n",
    "    print(\"\\n Train Acc: {}, Test Acc: {}\".format(score_train[-1], \n",
    "                                                  score_test[-1])  )\n",
    "    \n",
    "scores = pd.DataFrame(scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-05-14T18:59:56.106342Z",
     "start_time": "2017-05-14T18:59:56.092635Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>epoch</th>\n",
       "      <th>no_of_features</th>\n",
       "      <th>hidden_layers</th>\n",
       "      <th>train_score</th>\n",
       "      <th>test_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>0.466199</td>\n",
       "      <td>0.569242</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>0.466199</td>\n",
       "      <td>0.569242</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "      <td>0.466199</td>\n",
       "      <td>0.569242</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0.397977</td>\n",
       "      <td>0.449698</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   epoch  no_of_features  hidden_layers  train_score  test_score\n",
       "1     10               1              4     0.466199    0.569242\n",
       "2     10               1              6     0.466199    0.569242\n",
       "3     10               1             10     0.466199    0.569242\n",
       "0     10               1              2     0.397977    0.449698"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scores.sort_values(\"test_score\", ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-05-14T18:59:56.131874Z",
     "start_time": "2017-05-14T18:59:56.108374Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pd.Panel(predictions).to_pickle(\"dataset/keras_lstm_nsl_kdd_predictions.pkl\")\n",
    "scores.to_pickle(\"dataset/keras_lstm_nsl_kdd_scores.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-05-14T18:59:56.143308Z",
     "start_time": "2017-05-14T18:59:56.133958Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<class 'pandas.core.panel.Panel'>\n",
       "Dimensions: 4 (items) x 22544 (major_axis) x 2 (minor_axis)\n",
       "Items axis: 10_1_10 to 10_1_6\n",
       "Major_axis axis: 0 to 22543\n",
       "Minor_axis axis: Attack_prob to Normal_prob"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.Panel(predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "_draft": {
   "nbviewer_url": "https://gist.github.com/33dcb1bcf3ca4a3461c4405a003a7591"
  },
  "anaconda-cloud": {},
  "gist": {
   "data": {
    "description": "Final Hyper parameter tuning",
    "public": false
   },
   "id": "33dcb1bcf3ca4a3461c4405a003a7591"
  },
  "kernelspec": {
   "display_name": "Python [conda env:p3]",
   "language": "python",
   "name": "conda-env-p3-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
