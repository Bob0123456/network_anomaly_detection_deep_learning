{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Read Data Sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-07-10T17:26:17.356484Z",
     "start_time": "2017-07-10T17:26:16.290691Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2443"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "#import numpy as np\n",
    "import os\n",
    "pd.set_option(\"display.max_rows\",15)\n",
    "%matplotlib inline\n",
    "from sklearn import model_selection as ms\n",
    "from sklearn import preprocessing as pp\n",
    "os.system(\"taskset -p 0xff %d\" % os.getpid())\n",
    "os.getpid()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-07-10T17:26:17.761114Z",
     "start_time": "2017-07-10T17:26:17.362391Z"
    }
   },
   "outputs": [],
   "source": [
    "category_variables = [\"service\",\"flag\", \"session\"] # 'ids_detection', 'malware_detection', 'ashula_detection',\n",
    "dummy_variables_2labels = category_variables\n",
    "special_variables = ['ids_detection', 'malware_detection', 'ashula_detection']\n",
    "attack_types = {1:'Normal', -1:'Attack', -2:'Attack'}\n",
    "col_names = ['duration', 'service', 'source_bytes', 'destination_bytes',\n",
    "             'count', 'same_srv_rate', 'serror_srv_rate', 'srv_serror_rate',\n",
    "             'dst_host_count', 'dst_host_srv_count', 'dst_host_same_src_port_rate',\n",
    "             'dst_host_serror_rate', 'dst_host_serror_srv_rate', 'flag',\n",
    "             'ids_detection', 'malware_detection', 'ashula_detection', 'label',\n",
    "             'source_ip_address', 'source_port_number', 'destination_ip_address',\n",
    "             'destination_port_number', 'start_time', 'session'\n",
    "            ]\n",
    "\n",
    "\n",
    "class dataset:\n",
    "    def read_data(train_file, test_file):\n",
    "\n",
    "        kdd_train = pd.read_csv(\"{}.txt\".format(train_file),names = col_names, sep='\\t')\n",
    "        kdd_train_label = kdd_train.label.copy()\n",
    "        kdd_train = kdd_train.drop(['start_time', 'source_port_number', 'source_ip_address', 'destination_port_number', 'destination_ip_address', 'label'], axis = 1)\n",
    "        \n",
    "        kdd_train_label = kdd_train_label.map(lambda x: attack_types[x])\n",
    "        \n",
    "        kdd_train.loc[:,special_variables] = kdd_train.loc[:,special_variables].copy().applymap(lambda x: \n",
    "                                                                                                0 if x == '0' \n",
    "                                                                                                or x == 0 else 1)\n",
    "        \n",
    "        kdd_train['session'] = kdd_train['session'].astype(\"category\", categories = ['icmp', 'tcp', 'udp'])\n",
    "        kdd_train['flag'] = kdd_train['flag'].astype(\"category\", categories = ['OTH', 'REJ', 'RSTO', 'RSTOS0', 'RSTR', 'RSTRH', \n",
    "                                                                               'S0', 'S1', 'S2', 'S3', 'SF', 'SH', 'SHR'])\n",
    "        kdd_train['service'] = kdd_train['service'].astype(\"category\", categories = ['dhcp', 'dns', 'http', 'other', 'rdp', \n",
    "                                                                                     'sip', 'smtp', 'smtp,ssl', 'snmp', 'ssh', 'ssl'])\n",
    "        \n",
    "\n",
    "        kdd_train_label = kdd_train_label.astype(\"category\", categories = ['Attack', 'Normal'])\n",
    "        \n",
    "        dataset.kdd_train = kdd_train\n",
    "        dataset.kdd_train_label = kdd_train_label\n",
    "        \n",
    "   \n",
    "\n",
    "class pre_processing:\n",
    "    kdd_train = []\n",
    "    def process(train_file, test_file):\n",
    "        pre_processing.kdd_train = pd.get_dummies(dataset.kdd_train, columns = dummy_variables_2labels, prefix=dummy_variables_2labels)\n",
    "        #preprocessing.kdd_test = pd.get_dummies(dataset.kdd_test, columns = dummy_variables_2labels, prefix=dummy_variables_2labels)\n",
    "\n",
    "        pre_processing.kdd_train_label = pd.get_dummies(dataset.kdd_train_label, prefix='is')\n",
    "        #preprocessing.kdd_test_label = pd.get_dummies(dataset.kdd_test_label, prefix='is')\n",
    "            \n",
    "        output_columns_2labels = ['label']\n",
    "\n",
    "        x_input = pre_processing.kdd_train\n",
    "        y_output = pre_processing.kdd_train_label\n",
    "\n",
    "        ss = pp.StandardScaler()\n",
    "\n",
    "        x_train = ss.fit_transform(x_input)\n",
    "        y_train = y_output.values\n",
    "         \n",
    "            \n",
    "        x_train = pd.DataFrame(x_train)\n",
    "        x_train.columns = pre_processing.kdd_train.columns\n",
    "        \n",
    "        y_train = pd.DataFrame(y_train)\n",
    "        y_train.columns = pre_processing.kdd_train_label.columns\n",
    "        \n",
    "        x_train.to_csv(\"{}_x.csv\".format(train_file), index = False)\n",
    "        #preprocessing.kdd_test.to_csv(\"{}.csv\".format(test_file))\n",
    "        \n",
    "        y_train.to_csv(\"{}_y.csv\".format(train_file), index = False)\n",
    "        #preprocessing.kdd_test.to_csv(\"{}_label.csv\".format(test_file))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-07-10T17:26:17.781448Z",
     "start_time": "2017-07-10T17:26:17.768502Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: []\n",
       "Index: []"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = pd.DataFrame()\n",
    "a.aggregate(max)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-07-10T17:26:18.446752Z",
     "start_time": "2017-07-10T17:26:18.406964Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['dataset/Kyoto2016/2014/01/20140122', 'dataset/Kyoto2016/2014/01/20140110', 'dataset/Kyoto2016/2014/01/20140120', 'dataset/Kyoto2016/2014/01/20140109', 'dataset/Kyoto2016/2014/01/20140115', 'dataset/Kyoto2016/2014/01/20140127', 'dataset/Kyoto2016/2014/01/20140104', 'dataset/Kyoto2016/2014/01/20140124', 'dataset/Kyoto2016/2014/01/20140103', 'dataset/Kyoto2016/2014/01/20140113', 'dataset/Kyoto2016/2014/01/20140114', 'dataset/Kyoto2016/2014/01/20140108', 'dataset/Kyoto2016/2014/01/20140129', 'dataset/Kyoto2016/2014/01/20140106', 'dataset/Kyoto2016/2014/01/20140119', 'dataset/Kyoto2016/2014/01/20140118', 'dataset/Kyoto2016/2014/01/20140101', 'dataset/Kyoto2016/2014/01/20140102', 'dataset/Kyoto2016/2014/01/20140125', 'dataset/Kyoto2016/2014/01/20140116', 'dataset/Kyoto2016/2014/01/20140131', 'dataset/Kyoto2016/2014/01/20140111', 'dataset/Kyoto2016/2014/01/20140126', 'dataset/Kyoto2016/2014/01/20140130', 'dataset/Kyoto2016/2014/01/20140121', 'dataset/Kyoto2016/2014/01/20140112', 'dataset/Kyoto2016/2014/01/20140105', 'dataset/Kyoto2016/2014/01/20140117', 'dataset/Kyoto2016/2014/01/20140107', 'dataset/Kyoto2016/2014/01/20140128', 'dataset/Kyoto2016/2014/01/20140123']\n",
      "--------------------------------------------------------\n",
      "['dataset/Kyoto2016/2015/01/20150117', 'dataset/Kyoto2016/2015/01/20150105', 'dataset/Kyoto2016/2015/01/20150119', 'dataset/Kyoto2016/2015/01/20150120', 'dataset/Kyoto2016/2015/01/20150106', 'dataset/Kyoto2016/2015/01/20150130', 'dataset/Kyoto2016/2015/01/20150110', 'dataset/Kyoto2016/2015/01/20150101', 'dataset/Kyoto2016/2015/01/20150122', 'dataset/Kyoto2016/2015/01/20150114', 'dataset/Kyoto2016/2015/01/20150109', 'dataset/Kyoto2016/2015/01/20150112', 'dataset/Kyoto2016/2015/01/20150128', 'dataset/Kyoto2016/2015/01/20150107', 'dataset/Kyoto2016/2015/01/20150104', 'dataset/Kyoto2016/2015/01/20150115', 'dataset/Kyoto2016/2015/01/20150131', 'dataset/Kyoto2016/2015/01/20150102', 'dataset/Kyoto2016/2015/01/20150116', 'dataset/Kyoto2016/2015/01/20150111', 'dataset/Kyoto2016/2015/01/20150121', 'dataset/Kyoto2016/2015/01/20150129', 'dataset/Kyoto2016/2015/01/20150118', 'dataset/Kyoto2016/2015/01/20150113', 'dataset/Kyoto2016/2015/01/20150123', 'dataset/Kyoto2016/2015/01/20150127', 'dataset/Kyoto2016/2015/01/20150125', 'dataset/Kyoto2016/2015/01/20150103', 'dataset/Kyoto2016/2015/01/20150126', 'dataset/Kyoto2016/2015/01/20150124', 'dataset/Kyoto2016/2015/01/20150108']\n"
     ]
    }
   ],
   "source": [
    "\n",
    "train_paths = []\n",
    "for path, subdirs, files in os.walk(\"dataset/Kyoto2016/2014/01/\"):\n",
    "    for name in files:\n",
    "        if name.endswith(\"txt\"):\n",
    "            fullname = os.path.join(path, name)\n",
    "            train_paths.append(fullname.replace(\".txt\",\"\"))\n",
    "            #print (fullname.replace(\".txt\",\"\"))\n",
    "\n",
    "test_paths = []\n",
    "for path, subdirs, files in os.walk(\"dataset/Kyoto2016/2015/01/\"):\n",
    "    for name in files:\n",
    "        if name.endswith(\"txt\"):\n",
    "            fullname = os.path.join(path, name)\n",
    "            test_paths.append(fullname.replace(\".txt\",\"\"))\n",
    "            #print (fullname.replace(\".txt\",\"\"))\n",
    "print(train_paths)\n",
    "print(\"--------------------------------------------------------\")\n",
    "print(test_paths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-07-10T18:14:41.131125Z",
     "start_time": "2017-07-10T18:14:16.243926Z"
    },
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dataset/Kyoto2016/2014/01/20140122\n",
      "dataset/Kyoto2016/2015/01/20150117\n",
      "Skipping dataset/Kyoto2016/2015/01/20150117\n",
      "dataset/Kyoto2016/2015/01/20150105\n",
      "Skipping dataset/Kyoto2016/2015/01/20150105\n",
      "dataset/Kyoto2016/2015/01/20150119\n",
      "Skipping dataset/Kyoto2016/2015/01/20150119\n",
      "dataset/Kyoto2016/2015/01/20150120\n",
      "Skipping dataset/Kyoto2016/2015/01/20150120\n",
      "dataset/Kyoto2016/2015/01/20150106\n",
      "Skipping dataset/Kyoto2016/2015/01/20150106\n",
      "dataset/Kyoto2016/2015/01/20150130\n",
      "Skipping dataset/Kyoto2016/2015/01/20150130\n",
      "dataset/Kyoto2016/2015/01/20150110\n",
      "Skipping dataset/Kyoto2016/2015/01/20150110\n",
      "dataset/Kyoto2016/2015/01/20150101\n",
      "Skipping dataset/Kyoto2016/2015/01/20150101\n",
      "dataset/Kyoto2016/2015/01/20150122\n",
      "Skipping dataset/Kyoto2016/2015/01/20150122\n",
      "dataset/Kyoto2016/2015/01/20150114\n",
      "Skipping dataset/Kyoto2016/2015/01/20150114\n",
      "dataset/Kyoto2016/2015/01/20150109\n",
      "Skipping dataset/Kyoto2016/2015/01/20150109\n",
      "dataset/Kyoto2016/2015/01/20150112\n",
      "Skipping dataset/Kyoto2016/2015/01/20150112\n",
      "dataset/Kyoto2016/2015/01/20150128\n",
      "Skipping dataset/Kyoto2016/2015/01/20150128\n",
      "dataset/Kyoto2016/2015/01/20150107\n",
      "Skipping dataset/Kyoto2016/2015/01/20150107\n",
      "dataset/Kyoto2016/2015/01/20150104\n",
      "Skipping dataset/Kyoto2016/2015/01/20150104\n",
      "dataset/Kyoto2016/2015/01/20150115\n",
      "Skipping dataset/Kyoto2016/2015/01/20150115\n",
      "dataset/Kyoto2016/2015/01/20150131\n",
      "Skipping dataset/Kyoto2016/2015/01/20150131\n",
      "dataset/Kyoto2016/2015/01/20150102\n",
      "Skipping dataset/Kyoto2016/2015/01/20150102\n",
      "dataset/Kyoto2016/2015/01/20150116\n",
      "Skipping dataset/Kyoto2016/2015/01/20150116\n",
      "dataset/Kyoto2016/2015/01/20150111\n",
      "Skipping dataset/Kyoto2016/2015/01/20150111\n",
      "dataset/Kyoto2016/2015/01/20150121\n",
      "Skipping dataset/Kyoto2016/2015/01/20150121\n",
      "dataset/Kyoto2016/2015/01/20150129\n",
      "Skipping dataset/Kyoto2016/2015/01/20150129\n",
      "dataset/Kyoto2016/2015/01/20150118\n",
      "Skipping dataset/Kyoto2016/2015/01/20150118\n",
      "dataset/Kyoto2016/2015/01/20150113\n",
      "Skipping dataset/Kyoto2016/2015/01/20150113\n",
      "dataset/Kyoto2016/2015/01/20150123\n",
      "Skipping dataset/Kyoto2016/2015/01/20150123\n",
      "dataset/Kyoto2016/2015/01/20150127\n",
      "Skipping dataset/Kyoto2016/2015/01/20150127\n",
      "dataset/Kyoto2016/2015/01/20150125\n",
      "Skipping dataset/Kyoto2016/2015/01/20150125\n",
      "dataset/Kyoto2016/2015/01/20150103\n",
      "Skipping dataset/Kyoto2016/2015/01/20150103\n",
      "dataset/Kyoto2016/2015/01/20150126\n",
      "Skipping dataset/Kyoto2016/2015/01/20150126\n",
      "dataset/Kyoto2016/2015/01/20150124\n",
      "Skipping dataset/Kyoto2016/2015/01/20150124\n",
      "dataset/Kyoto2016/2015/01/20150108\n",
      "Skipping dataset/Kyoto2016/2015/01/20150108\n"
     ]
    }
   ],
   "source": [
    "from multiprocessing import Pool\n",
    "\n",
    "def run(paths):\n",
    "    for path in paths:\n",
    "        #print(train_path)\n",
    "        #print(test_path)\n",
    "        print(path)\n",
    "        if not (os.path.exists(\"{}_x.csv\".format(path)) and os.path.exists(\"{}_y.csv\".format(path))):\n",
    "            dataset.read_data(path, path)\n",
    "            pre_processing.process(path, path)\n",
    "        else:\n",
    "            print(\"Skipping {}\".format(path))\n",
    "            \n",
    "with Pool() as p:\n",
    "    p.map(run, [[train_paths[0]]])\n",
    "    p.map(run, [test_paths])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-07-10T17:09:16.014671Z",
     "start_time": "2017-07-10T17:09:16.005644Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "__main__.pre_processing"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pre_processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-07-10T13:49:38.117709Z",
     "start_time": "2017-07-10T13:45:22.373Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dataset.kdd_train_label.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-07-10T13:49:38.119226Z",
     "start_time": "2017-07-10T13:45:22.378Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dataset.kdd_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-07-10T13:49:38.120753Z",
     "start_time": "2017-07-10T13:45:22.390Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dataset.kdd_train.info(memory_usage = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-07-10T13:49:38.122286Z",
     "start_time": "2017-07-10T13:45:22.395Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dataset.kdd_train.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-07-10T13:49:38.123883Z",
     "start_time": "2017-07-10T13:45:22.398Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "    \n",
    "    #print(\"Length of Categories for {} are {}\".format(cv , len(dataset.kdd_train[cv].cat.categories)))\n",
    "    #print(\"Categories for {} are {} \\n\".format(cv ,dataset.kdd_train[cv].cat.categories))\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-06-30T14:55:01.066892Z",
     "start_time": "2017-06-30T14:55:00.640246Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-07-10T13:49:38.125398Z",
     "start_time": "2017-07-10T13:45:22.409Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "preprocessing.kdd_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-07-10T13:49:38.126906Z",
     "start_time": "2017-07-10T13:45:22.413Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "preprocessing.kdd_train_label"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Zero Data Points"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-07-10T13:49:38.128412Z",
     "start_time": "2017-07-10T13:45:22.416Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "a = dataset.kdd_train.isin([0])\n",
    "a.sum().sum() / a.size\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-07-10T13:49:38.129913Z",
     "start_time": "2017-07-10T13:45:22.419Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import matplotlib\n",
    "from pandas.plotting import andrews_curves\n",
    "from pandas.plotting import parallel_coordinates\n",
    "from sklearn import preprocessing as ps\n",
    "from pandas.plotting import radviz\n",
    "import matplotlib.pyplot as plt\n",
    "matplotlib.style.use('ggplot')\n",
    "\n",
    "df_train = preprocessing.kdd_train\n",
    "df_train = pd.concat([df_train, dataset.kdd_train_label], axis = 1)\n",
    "\n",
    "df_test = preprocessing.kdd_test\n",
    "df_test = pd.concat([df_test, dataset.kdd_test_label], axis = 1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-07-10T13:49:38.131446Z",
     "start_time": "2017-07-10T13:45:22.422Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.manifold import TSNE\n",
    "model = TSNE(n_components=2, random_state=0)\n",
    "#np.set_printoptions(suppress=True)\n",
    "sample = df_train.sample(frac = 0.01) # 10% of total data\n",
    "sample.to_pickle(\"dataset/tsne_sample.pkl\")\n",
    "sample = pd.read_pickle(\"dataset/tsne_sample.pkl\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-07-10T13:49:38.132932Z",
     "start_time": "2017-07-10T13:45:22.425Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sample.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-07-10T13:49:38.134460Z",
     "start_time": "2017-07-10T13:45:22.428Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x_tsne = sample.iloc[:, :-1]\n",
    "y_tsne = sample.iloc[:, -1]\n",
    "\n",
    "\n",
    "from sklearn.decomposition import SparsePCA\n",
    "pca_analysis = SparsePCA(n_components=10)\n",
    "x_tsne_pca = pca_analysis.fit_transform(x_tsne)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-07-10T13:49:38.135961Z",
     "start_time": "2017-07-10T13:45:22.431Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "pd.DataFrame(x_tsne_pca).to_pickle(\"dataset/tsne_pca_df.pkl\")\n",
    "x_tsne_pca = pd.read_pickle(\"dataset/tsne_pca_df.pkl\").values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-07-10T13:49:38.137480Z",
     "start_time": "2017-07-10T13:45:22.434Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(7,3))\n",
    "x_tsne_pca_df = pd.DataFrame(x_tsne_pca)\n",
    "\n",
    "x_tsne_pca_df['label'] = y_tsne.values\n",
    "\n",
    "andrews_curves(x_tsne_pca_df, \"label\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-07-10T13:49:38.138993Z",
     "start_time": "2017-07-10T13:45:22.437Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df = model.fit_transform(x_tsne_pca) \n",
    "df1 = model.fit_transform(df)\n",
    "df2 = model.fit_transform(df1) \n",
    "df3 = model.fit_transform(df2) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-07-10T13:49:38.140484Z",
     "start_time": "2017-07-10T13:45:22.440Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pd.DataFrame(df).to_pickle(\"dataset/tsne_df.pkl\")\n",
    "pd.DataFrame(df1).to_pickle(\"dataset/tsne_df1.pkl\")\n",
    "pd.DataFrame(df2).to_pickle(\"dataset/tsne_df2.pkl\")\n",
    "pd.DataFrame(df3).to_pickle(\"dataset/tsne_df3.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-07-10T13:49:38.141987Z",
     "start_time": "2017-07-10T13:45:22.443Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df = pd.read_pickle(\"dataset/tsne_df.pkl\").values\n",
    "df1 = pd.read_pickle(\"dataset/tsne_df1.pkl\").values\n",
    "df2 = pd.read_pickle(\"dataset/tsne_df2.pkl\").values\n",
    "df3 = pd.read_pickle(\"dataset/tsne_df3.pkl\").values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-07-10T13:49:38.143524Z",
     "start_time": "2017-07-10T13:45:22.446Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "#plt.figure(figsize=(15,8))\n",
    "\n",
    "f, ((ax1, ax2), (ax3, ax4)) = plt.subplots(2, 2, sharex='col', sharey='row', figsize=(10,5))\n",
    "\n",
    "ax1.scatter(x = df[y_tsne=='Normal', 0], y = df[y_tsne=='Normal',1], label = 'Normal')\n",
    "ax1.scatter(x = df[y_tsne=='Attack',0], y = df[y_tsne=='Attack',1], label = 'Attack')\n",
    "ax1.title.set_text(\"After 1000 epochs\")\n",
    "\n",
    "ax2.scatter(x = df1[y_tsne=='Normal',0], y = df1[y_tsne=='Normal',1], label = 'Normal')\n",
    "ax2.scatter(x = df1[y_tsne=='Attack',0], y = df1[y_tsne=='Attack',1], label = 'Attack')\n",
    "ax2.title.set_text(\"After 2000 epochs\")\n",
    "\n",
    "ax3.scatter(x = df2[y_tsne=='Normal',0], y = df2[y_tsne=='Normal',1], label = 'Normal')\n",
    "ax3.scatter(x = df2[y_tsne=='Attack',0], y = df2[y_tsne=='Attack',1], label = 'Attack')\n",
    "ax3.title.set_text(\"After 3000 epochs\")\n",
    "\n",
    "ax4.scatter(x = df3[y_tsne=='Normal',0], y = df3[y_tsne=='Normal',1], label = 'Normal')\n",
    "ax4.scatter(x = df3[y_tsne=='Attack',0], y = df3[y_tsne=='Attack',1], label = 'Attack')\n",
    "ax4.title.set_text(\"After 4000 epochs\")\n",
    "\n",
    "plt.subplots_adjust(wspace=0.05, hspace=0.18)\n",
    "ax1.legend(loc=0)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-07-10T13:49:38.145017Z",
     "start_time": "2017-07-10T13:45:22.450Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "preprocessing.kdd_train.to_pickle(\"dataset/kdd_train.pkl\")\n",
    "preprocessing.kdd_train_label.to_pickle(\"dataset/kdd_train_label.pkl\")\n",
    "\n",
    "preprocessing.kdd_test.to_pickle(\"dataset/kdd_test.pkl\")\n",
    "preprocessing.kdd_test_label.to_pickle(\"dataset/kdd_test_label.pkl\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-07-10T13:49:38.146509Z",
     "start_time": "2017-07-10T13:45:22.453Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "preprocessing.kdd_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-07-10T13:49:38.148007Z",
     "start_time": "2017-07-10T13:45:22.456Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "preprocessing.kdd_train_label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "_draft": {
   "nbviewer_url": "https://gist.github.com/a442376f3fb1d15375cdf44746cfb2fb"
  },
  "anaconda-cloud": {},
  "gist": {
   "data": {
    "description": "With Difficulty level",
    "public": false
   },
   "id": "a442376f3fb1d15375cdf44746cfb2fb"
  },
  "kernelspec": {
   "display_name": "Python [conda env:p3]",
   "language": "python",
   "name": "conda-env-p3-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
