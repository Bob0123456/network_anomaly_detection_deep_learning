{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Read Data Sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-06-28T17:35:16.159195Z",
     "start_time": "2017-06-28T17:35:15.630367Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "from collections import namedtuple\n",
    "pd.set_option(\"display.max_rows\",35)\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-06-28T17:35:16.257682Z",
     "start_time": "2017-06-28T17:35:16.161068Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class dataset:\n",
    "    kdd_train_2labels = pd.read_pickle(\"dataset/kdd_train_2labels.pkl\")\n",
    "    kdd_test_2labels = pd.read_pickle(\"dataset/kdd_test_2labels.pkl\")\n",
    "    kdd_test__2labels = pd.read_pickle(\"dataset/kdd_test__2labels.pkl\")\n",
    "    \n",
    "    kdd_train_5labels = pd.read_pickle(\"dataset/kdd_train_5labels.pkl\")\n",
    "    kdd_test_5labels = pd.read_pickle(\"dataset/kdd_test_5labels.pkl\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-06-28T17:35:16.267219Z",
     "start_time": "2017-06-28T17:35:16.260501Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(125973, 124)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.kdd_train_2labels.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-06-28T17:35:16.283257Z",
     "start_time": "2017-06-28T17:35:16.271563Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(22544, 124)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.kdd_test_2labels.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-06-28T17:35:17.266363Z",
     "start_time": "2017-06-28T17:35:16.285702Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.99186991653217405"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn import model_selection as ms\n",
    "from sklearn import preprocessing as pp\n",
    "\n",
    "class preprocess:\n",
    "    \n",
    "    output_columns_2labels = ['is_Normal','is_Attack']\n",
    "    \n",
    "    x_input = dataset.kdd_train_2labels.drop(output_columns_2labels, axis = 1)\n",
    "    y_output = dataset.kdd_train_2labels.loc[:,output_columns_2labels]\n",
    "\n",
    "    x_test_input = dataset.kdd_test_2labels.drop(output_columns_2labels, axis = 1)\n",
    "    y_test = dataset.kdd_test_2labels.loc[:,output_columns_2labels]\n",
    "\n",
    "    x_test__input = dataset.kdd_test__2labels.drop(output_columns_2labels, axis = 1)\n",
    "    y_test_ = dataset.kdd_test__2labels.loc[:,output_columns_2labels]\n",
    "    \n",
    "    ss = pp.StandardScaler()\n",
    "\n",
    "    x_train = ss.fit_transform(x_input)\n",
    "    x_test = ss.transform(x_test_input)\n",
    "    x_test_ = ss.transform(x_test__input)\n",
    "\n",
    "    y_train = y_output.values\n",
    "    y_test = y_test.values\n",
    "    y_test_ = y_test_.values\n",
    "\n",
    "    x_train = np.hstack((x_train, y_train))\n",
    "    x_test = np.hstack((x_test, np.random.normal(size = (x_test.shape[0], y_train.shape[1]))))\n",
    "    x_test_ = np.hstack((x_test_, np.random.normal(size = (x_test_.shape[0], y_train.shape[1]))))\n",
    "\n",
    "    #x_test = np.hstack((x_test, y_test))\n",
    "    \n",
    "preprocess.x_train.std()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-06-28T17:35:18.618917Z",
     "start_time": "2017-06-28T17:35:17.268655Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-06-28T17:35:19.148712Z",
     "start_time": "2017-06-28T17:35:18.621064Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class network(object):\n",
    "    \n",
    "    input_dim = 124\n",
    "    classes = 2\n",
    "    hidden_encoder_dim = 124\n",
    "    hidden_layers = 1\n",
    "    latent_dim = 10\n",
    "\n",
    "    hidden_decoder_dim = 124\n",
    "    lam = 0.01\n",
    "    \n",
    "    def __init__(self, classes, hidden_layers, num_of_features):\n",
    "        self.classes = classes\n",
    "        self.hidden_layers = hidden_layers\n",
    "        self.latent_dim = num_of_features\n",
    "            \n",
    "    def build_layers(self):\n",
    "        tf.reset_default_graph()\n",
    "        #learning_rate = tf.Variable(initial_value=0.001)\n",
    "\n",
    "        input_dim = self.input_dim\n",
    "        classes = self.classes\n",
    "        hidden_encoder_dim = self.hidden_encoder_dim\n",
    "        hidden_layers = self.hidden_layers\n",
    "        latent_dim = self.latent_dim\n",
    "        hidden_decoder_dim = self.hidden_decoder_dim\n",
    "        lam = self.lam\n",
    "        \n",
    "        with tf.variable_scope(\"Input\"):\n",
    "            self.x = tf.placeholder(\"float\", shape=[None, input_dim])\n",
    "            self.y_ = tf.placeholder(\"float\", shape=[None, classes])\n",
    "            self.keep_prob = tf.placeholder(\"float\")\n",
    "            self.lr = tf.placeholder(\"float\")\n",
    "        \n",
    "        with tf.variable_scope(\"Layer_Encoder\"):\n",
    "\n",
    "            hidden_encoder = tf.layers.dense(self.x, hidden_encoder_dim, activation = tf.nn.relu, kernel_regularizer=tf.nn.l2_loss)\n",
    "            hidden_encoder = tf.nn.dropout(hidden_encoder, self.keep_prob)\n",
    "            for h in range(hidden_layers - 1):\n",
    "                hidden_encoder = tf.layers.dense(hidden_encoder, hidden_encoder_dim, activation = tf.nn.relu, kernel_regularizer=tf.nn.l2_loss)\n",
    "                hidden_encoder = tf.nn.dropout(hidden_encoder, self.keep_prob)\n",
    "                \n",
    "        with tf.variable_scope(\"Layer_Mean\"):\n",
    "            mu_encoder = tf.layers.dense(hidden_encoder, latent_dim, activation = None, kernel_regularizer=tf.nn.l2_loss)\n",
    "\n",
    "        with tf.variable_scope(\"Layer_Variance\"):\n",
    "            logvar_encoder = tf.layers.dense(hidden_encoder, latent_dim, activation = None, kernel_regularizer=tf.nn.l2_loss)\n",
    "\n",
    "        with tf.variable_scope(\"Sampling_Distribution\"):\n",
    "            # Sample epsilon\n",
    "            epsilon = tf.random_normal(tf.shape(logvar_encoder), mean=0, stddev=1, name='epsilon')\n",
    "\n",
    "            # Sample latent variable\n",
    "            std_encoder = tf.exp(0.5 * logvar_encoder)\n",
    "            z = mu_encoder + tf.multiply(std_encoder, epsilon)\n",
    "            \n",
    "            #tf.summary.histogram(\"Sample_Distribution\", z)\n",
    "\n",
    "        with tf.variable_scope(\"Layer_Decoder\"):\n",
    "            hidden_decoder = tf.layers.dense(z, hidden_decoder_dim, activation = tf.nn.relu, kernel_regularizer=tf.nn.l2_loss)\n",
    "            hidden_decoder = tf.nn.dropout(hidden_decoder, self.keep_prob)\n",
    "            for h in range(hidden_layers - 1):\n",
    "                hidden_decoder = tf.layers.dense(hidden_decoder, hidden_decoder_dim, activation = tf.nn.relu, kernel_regularizer=tf.nn.l2_loss)\n",
    "                hidden_decoder = tf.nn.dropout(hidden_decoder, self.keep_prob)\n",
    "                \n",
    "        with tf.variable_scope(\"Layer_Reconstruction\"):\n",
    "            self.x_hat = tf.layers.dense(hidden_decoder, input_dim, activation = None)\n",
    "            \n",
    "            self.y = tf.slice(self.x_hat, [0,input_dim-2], [-1,-1])\n",
    "\n",
    "        with tf.variable_scope(\"Loss\"):\n",
    "            \n",
    "            BCE = tf.reduce_mean(tf.nn.sigmoid_cross_entropy_with_logits(logits=self.x_hat, labels=self.x), reduction_indices=1)\n",
    "            KLD = -0.5 * tf.reduce_mean(1 + logvar_encoder - tf.pow(mu_encoder, 2) - tf.exp(logvar_encoder), reduction_indices=1)\n",
    "            softmax_loss = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(labels = self.y_, logits = self.y))\n",
    "\n",
    "            loss = tf.reduce_mean((BCE + KLD + softmax_loss) * lam)\n",
    "\n",
    "            \n",
    "            self.regularized_loss = tf.abs(loss, name = \"Regularized_loss\")\n",
    "            loss = tf.where(tf.is_nan(self.regularized_loss), 1e-2, self.regularized_loss)\n",
    "            \n",
    "            correct_prediction = tf.equal(tf.argmax(self.y, 1), tf.argmax(self.y_, 1))\n",
    "            self.tf_accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32), name = \"Accuracy\")\n",
    "\n",
    "        with tf.variable_scope(\"Optimizer\"):\n",
    "            learning_rate= self.lr #1e-2\n",
    "            optimizer = tf.train.AdamOptimizer(learning_rate)\n",
    "            gradients, variables = zip(*optimizer.compute_gradients(self.regularized_loss))\n",
    "            gradients = [\n",
    "                None if gradient is None else tf.clip_by_value(gradient, -1, 1)\n",
    "                for gradient in gradients]\n",
    "            self.train_op = optimizer.apply_gradients(zip(gradients, variables))\n",
    "            #self.train_op = optimizer.minimize(self.regularized_loss)\n",
    "            \n",
    "        # add op for merging summary\n",
    "        #self.summary_op = tf.summary.merge_all()\n",
    "        self.pred = tf.argmax(self.y, axis = 1)\n",
    "        self.actual = tf.argmax(self.y_, axis = 1)\n",
    "\n",
    "        # add Saver ops\n",
    "        self.saver = tf.train.Saver()\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-06-28T17:35:19.532681Z",
     "start_time": "2017-06-28T17:35:19.151129Z"
    },
    "collapsed": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import collections\n",
    "import time\n",
    "\n",
    "class Train:    \n",
    "    \n",
    "    result = namedtuple(\"score\", ['epoch', 'no_of_features','hidden_layers','train_score', 'test_score', 'test_score_20', 'time_taken'])\n",
    "\n",
    "    predictions = {}\n",
    "\n",
    "    results = []\n",
    "    best_acc = 0\n",
    "    best_acc_global = 0\n",
    "    \n",
    "    def train(epochs, net, h, f, lrs):\n",
    "        batch_iterations = 200\n",
    "        train_loss = None\n",
    "        Train.best_acc = 0\n",
    "        os.makedirs(\"dataset/tf_vae_only_vae_loss_nsl_kdd/hidden layers_{}_features count_{}\".format(epochs,h,f),\n",
    "                    exist_ok = True)\n",
    "        with tf.Session() as sess:\n",
    "            #summary_writer_train = tf.summary.FileWriter('./logs/kdd/VAE/training', graph=sess.graph)\n",
    "            #summary_writer_valid = tf.summary.FileWriter('./logs/kdd/VAE/validation')\n",
    "\n",
    "            sess.run(tf.global_variables_initializer())\n",
    "            start_time = time.perf_counter()\n",
    "            for lr in lrs:\n",
    "                for epoch in range(1, (epochs+1)):\n",
    "                    #print(\"Step {} | Training Loss:\".format(epoch), end = \" \" )\n",
    "                    x_train, x_valid, y_train, y_valid, = ms.train_test_split(preprocess.x_train, \n",
    "                                                                              preprocess.y_train, \n",
    "                                                                              test_size=0.1)\n",
    "                    batch_indices = np.array_split(np.arange(x_train.shape[0]), \n",
    "                                               batch_iterations)\n",
    "\n",
    "                    for i in batch_indices:\n",
    "\n",
    "                        def train_batch():\n",
    "                            nonlocal train_loss\n",
    "                            _, train_loss = sess.run([net.train_op, \n",
    "                                                      net.regularized_loss, \n",
    "                                                      ], #net.summary_op\n",
    "                                                      feed_dict={net.x: x_train[i,:], \n",
    "                                                                 net.y_: y_train[i,:], \n",
    "                                                                 net.keep_prob:1, net.lr:lr})\n",
    "\n",
    "                        train_batch()\n",
    "\n",
    "                        count = 10\n",
    "                        if((train_loss > 1e9 or np.isnan(train_loss) ) and epoch > 1 and count > 1):\n",
    "                            print(\"Step {} | High Training Loss: {:.6f} ... Restoring Net\".format(epoch, train_loss))\n",
    "                            net.saver.restore(sess, \n",
    "                                              tf.train.latest_checkpoint('dataset/tf_vae_only_vae_loss_nsl_kdd/hidden layers_{}_features count_{}'\n",
    "                                                                         .format(epochs,h,f)))\n",
    "                            train_batch()\n",
    "                            count -= 1\n",
    "\n",
    "                        #summary_writer_train.add_summary(summary_str, epoch)\n",
    "                        #if(train_loss > 1e9):\n",
    "\n",
    "                        #print(\"{:.6f}\".format(train_loss), end = \", \" )\n",
    "\n",
    "                    #print(\"\")\n",
    "                    valid_loss, valid_accuracy = sess.run([net.regularized_loss, net.tf_accuracy], feed_dict={net.x: x_valid, \n",
    "                                                                         net.y_: y_valid, \n",
    "                                                                         net.keep_prob:1, net.lr:lr})\n",
    "\n",
    "\n",
    "                    accuracy, test_loss, pred_value, actual_value, y_pred = sess.run([net.tf_accuracy, net.regularized_loss, \n",
    "                                                                   net.pred, \n",
    "                                                                   net.actual, net.y], \n",
    "                                                                  feed_dict={net.x: preprocess.x_test, \n",
    "                                                                             net.y_: preprocess.y_test, \n",
    "                                                                             net.keep_prob:1, net.lr:lr})\n",
    "                    accuracy_, test_loss_, pred_value_, actual_value_, y_pred_ = sess.run([net.tf_accuracy, net.regularized_loss, \n",
    "                                                                                           net.pred, \n",
    "                                                                                           net.actual, net.y], \n",
    "                                                                                          feed_dict={net.x: preprocess.x_test_, \n",
    "                                                                                                     net.y_: preprocess.y_test_, \n",
    "                                                                                                     net.keep_prob:1, net.lr:lr})\n",
    "                    #print(\"*************** \\n\")\n",
    "                    print(\"Step {} | Training Loss: {:.6f} | Test Loss: {:6f} | Test Accuracy: {:.6f}, {:.6f}\".format(epoch, train_loss, test_loss, accuracy, accuracy_))\n",
    "                    #print(\"*************** \\n\")\n",
    "                    #print(\"Accuracy on Test data: {}\".format(accuracy))\n",
    "\n",
    "\n",
    "                    if accuracy > Train.best_acc_global:\n",
    "                        Train.best_acc_global = accuracy\n",
    "                        Train.pred_value = pred_value\n",
    "                        Train.actual_value = actual_value\n",
    "                        Train.pred_value_ = pred_value_\n",
    "                        Train.actual_value_ = actual_value_\n",
    "                        Train.best_parameters = \"Hidden Layers:{}, Features Count:{}\".format(h, f)\n",
    "\n",
    "                    if accuracy > Train.best_acc:\n",
    "\n",
    "                        #net.saver.save(sess, \"dataset/tf_vae_only_nsl_kdd_hidden layers_{}_features count_{}\".format(epochs,h,f))\n",
    "                        #Train.results.append(Train.result(epochs, f, h,valid_accuracy, accuracy))\n",
    "                        #curr_pred = pd.DataFrame({\"Attack_prob\":y_pred[:,-2], \"Normal_prob\":y_pred[:, -1]})\n",
    "                        #Train.predictions.update({\"{}_{}_{}\".format(epochs,f,h):curr_pred})\n",
    "\n",
    "                        Train.best_acc = accuracy\n",
    "                        if not (np.isnan(train_loss)):\n",
    "                            net.saver.save(sess, \n",
    "                                       \"dataset/tf_vae_only_vae_loss_nsl_kdd/hidden layers_{}_features count_{}/model\"\n",
    "                                       .format(epochs,h,f), \n",
    "                                       global_step = epoch, \n",
    "                                       write_meta_graph=False)\n",
    "\n",
    "                        curr_pred = pd.DataFrame({\"Attack_prob\":y_pred[:,-2], \"Normal_prob\":y_pred[:, -1], \"Prediction\":pred_value})\n",
    "                        Train.predictions.update({\"{}_{}_{}\".format(epochs*len(lrs),f,h):\n",
    "                                                  (curr_pred, \n",
    "                                                   Train.result(epochs*len(lrs), f, h,valid_accuracy, accuracy, accuracy_, time.perf_counter() - start_time))})\n",
    "\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2017-06-28T17:35:17.056Z"
    },
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import itertools\n",
    "class Hyperparameters:\n",
    "#    features_arr = [2, 4, 8, 16, 32, 64, 128, 256]\n",
    "#    hidden_layers_arr = [2, 4, 6, 10]\n",
    "\n",
    "\n",
    "\n",
    "    def start_training():\n",
    "\n",
    "        global df_results\n",
    "        global past_scores\n",
    "        \n",
    "        Train.predictions = {}\n",
    "        Train.results = []\n",
    "        \n",
    "        features_arr = [4, 8, 32, 122]\n",
    "        hidden_layers_arr = [3, 5]\n",
    "\n",
    "        epochs = [15]\n",
    "        lrs = [1e-2, 1e-2, 1e-3]\n",
    "\n",
    "        for e, h, f in itertools.product(epochs, hidden_layers_arr, features_arr):\n",
    "            print(\"Current Layer Attributes - epochs:{} hidden layers:{} features count:{}\".format(e,h,f))\n",
    "            n = network(2,h,f)\n",
    "            n.build_layers()\n",
    "            Train.train(e, n, h,f, lrs)\n",
    "\n",
    "        dict1 = {}\n",
    "        dict2 = []\n",
    "        for k, (v1, v2) in Train.predictions.items():\n",
    "            dict1.update({k: v1})\n",
    "            dict2.append(v2)\n",
    "            \n",
    "        Train.predictions = dict1\n",
    "        Train.results = dict2\n",
    "        df_results = pd.DataFrame(Train.results)\n",
    "        temp = df_results.set_index(['no_of_features', 'hidden_layers'])\n",
    "\n",
    "        if not os.path.isfile('dataset/tf_vae_only_vae_loss_nsl_kdd_all.pkl'):\n",
    "            past_scores = temp\n",
    "        else:\n",
    "            past_scores = pd.read_pickle(\"dataset/tf_vae_only_vae_loss_nsl_kdd_all.pkl\")\n",
    "\n",
    "        past_scores.append(temp).to_pickle(\"dataset/tf_vae_only_vae_loss_nsl_kdd_all.pkl\")\n",
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2017-06-28T17:35:17.062Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current Layer Attributes - epochs:15 hidden layers:3 features count:4\n",
      "Step 1 | Training Loss: 0.000779 | Test Loss: 0.004162 | Test Accuracy: 0.812899, 0.719662\n",
      "Step 2 | Training Loss: 0.000968 | Test Loss: 0.003908 | Test Accuracy: 0.820085, 0.737468\n",
      "Step 3 | Training Loss: 0.000938 | Test Loss: 0.003552 | Test Accuracy: 0.798128, 0.671477\n",
      "Step 4 | Training Loss: 0.000378 | Test Loss: 0.004560 | Test Accuracy: 0.792229, 0.638565\n",
      "Step 5 | Training Loss: 0.000038 | Test Loss: 0.004106 | Test Accuracy: 0.802608, 0.675190\n",
      "Step 6 | Training Loss: 0.000358 | Test Loss: 0.004417 | Test Accuracy: 0.807532, 0.754684\n",
      "Step 7 | Training Loss: 0.000040 | Test Loss: 0.004060 | Test Accuracy: 0.809129, 0.709958\n",
      "Step 8 | Training Loss: 0.000322 | Test Loss: 0.004401 | Test Accuracy: 0.796930, 0.715021\n",
      "Step 9 | Training Loss: 0.000813 | Test Loss: 0.006197 | Test Accuracy: 0.814585, 0.794093\n",
      "Step 10 | Training Loss: 0.000422 | Test Loss: 0.004057 | Test Accuracy: 0.820396, 0.769536\n",
      "Step 11 | Training Loss: 0.000428 | Test Loss: 0.005174 | Test Accuracy: 0.822791, 0.802700\n",
      "Step 12 | Training Loss: 0.001148 | Test Loss: 0.002081 | Test Accuracy: 0.880057, 0.804135\n",
      "Step 13 | Training Loss: 0.000462 | Test Loss: 0.003088 | Test Accuracy: 0.871718, 0.796793\n",
      "Step 14 | Training Loss: 0.000015 | Test Loss: 0.003205 | Test Accuracy: 0.840179, 0.756540\n",
      "Step 15 | Training Loss: 0.000793 | Test Loss: 0.002836 | Test Accuracy: 0.880767, 0.799156\n",
      "Step 1 | Training Loss: 0.000548 | Test Loss: 0.002607 | Test Accuracy: 0.863511, 0.790127\n",
      "Step 2 | Training Loss: 0.000753 | Test Loss: 0.002396 | Test Accuracy: 0.870609, 0.787004\n",
      "Step 3 | Training Loss: 0.000676 | Test Loss: 0.002544 | Test Accuracy: 0.867814, 0.801097\n",
      "Step 4 | Training Loss: 0.000615 | Test Loss: 0.002806 | Test Accuracy: 0.865286, 0.780169\n",
      "Step 5 | Training Loss: 0.000239 | Test Loss: 0.002865 | Test Accuracy: 0.871318, 0.791477\n",
      "Step 6 | Training Loss: 0.000017 | Test Loss: 0.003275 | Test Accuracy: 0.872560, 0.795781\n",
      "Step 7 | Training Loss: 0.000611 | Test Loss: 0.003768 | Test Accuracy: 0.858676, 0.814937\n",
      "Step 8 | Training Loss: 0.000109 | Test Loss: 0.005003 | Test Accuracy: 0.847409, 0.806498\n",
      "Step 9 | Training Loss: 0.000382 | Test Loss: 0.003145 | Test Accuracy: 0.805625, 0.704895\n",
      "Step 10 | Training Loss: 0.000032 | Test Loss: 0.002602 | Test Accuracy: 0.827626, 0.699241\n",
      "Step 11 | Training Loss: 0.000690 | Test Loss: 0.002180 | Test Accuracy: 0.828203, 0.701772\n",
      "Step 12 | Training Loss: 0.000666 | Test Loss: 0.002558 | Test Accuracy: 0.834634, 0.706076\n",
      "Step 13 | Training Loss: 0.000077 | Test Loss: 0.002449 | Test Accuracy: 0.829800, 0.704641\n",
      "Step 14 | Training Loss: 0.000172 | Test Loss: 0.002651 | Test Accuracy: 0.812899, 0.708186\n",
      "Step 15 | Training Loss: 0.000313 | Test Loss: 0.003280 | Test Accuracy: 0.801544, 0.642278\n",
      "Step 1 | Training Loss: 0.000416 | Test Loss: 0.001640 | Test Accuracy: 0.798882, 0.651392\n",
      "Step 2 | Training Loss: 0.000363 | Test Loss: 0.001405 | Test Accuracy: 0.804915, 0.666920\n",
      "Step 3 | Training Loss: 0.000374 | Test Loss: 0.001590 | Test Accuracy: 0.806512, 0.669114\n",
      "Step 4 | Training Loss: 0.000237 | Test Loss: 0.001666 | Test Accuracy: 0.806822, 0.665570\n",
      "Step 5 | Training Loss: 0.000237 | Test Loss: 0.001775 | Test Accuracy: 0.804560, 0.665823\n",
      "Step 6 | Training Loss: 0.000147 | Test Loss: 0.001617 | Test Accuracy: 0.811169, 0.665148\n",
      "Step 7 | Training Loss: 0.000171 | Test Loss: 0.001653 | Test Accuracy: 0.814274, 0.668523\n",
      "Step 8 | Training Loss: 0.000003 | Test Loss: 0.001556 | Test Accuracy: 0.811702, 0.667595\n",
      "Step 9 | Training Loss: 0.000094 | Test Loss: 0.001602 | Test Accuracy: 0.811657, 0.665823\n",
      "Step 10 | Training Loss: 0.000013 | Test Loss: 0.001574 | Test Accuracy: 0.807576, 0.662363\n",
      "Step 11 | Training Loss: 0.000217 | Test Loss: 0.001680 | Test Accuracy: 0.810681, 0.666498\n",
      "Step 12 | Training Loss: 0.000005 | Test Loss: 0.001535 | Test Accuracy: 0.810770, 0.666498\n",
      "Step 13 | Training Loss: 0.000422 | Test Loss: 0.001624 | Test Accuracy: 0.812766, 0.667933\n",
      "Step 14 | Training Loss: 0.000099 | Test Loss: 0.001770 | Test Accuracy: 0.811169, 0.666667\n",
      "Step 15 | Training Loss: 0.000453 | Test Loss: 0.001900 | Test Accuracy: 0.804294, 0.653249\n",
      "Current Layer Attributes - epochs:15 hidden layers:3 features count:8\n",
      "Step 1 | Training Loss: 0.000405 | Test Loss: 0.008008 | Test Accuracy: 0.848430, 0.760844\n",
      "Step 2 | Training Loss: 0.000577 | Test Loss: 0.007329 | Test Accuracy: 0.743834, 0.596203\n",
      "Step 3 | Training Loss: 0.000676 | Test Loss: 0.004998 | Test Accuracy: 0.804072, 0.662110\n",
      "Step 4 | Training Loss: 0.000554 | Test Loss: 0.005358 | Test Accuracy: 0.795777, 0.676878\n",
      "Step 5 | Training Loss: 0.000293 | Test Loss: 0.008510 | Test Accuracy: 0.768009, 0.656034\n",
      "Step 6 | Training Loss: 0.000178 | Test Loss: 0.009307 | Test Accuracy: 0.755190, 0.676118\n",
      "Step 7 | Training Loss: 0.000263 | Test Loss: 0.007851 | Test Accuracy: 0.759847, 0.678819\n",
      "Step 8 | Training Loss: 0.001361 | Test Loss: 0.011045 | Test Accuracy: 0.697259, 0.574768\n",
      "Step 9 | Training Loss: 0.000084 | Test Loss: 0.008341 | Test Accuracy: 0.793160, 0.706076\n",
      "Step 10 | Training Loss: 0.000321 | Test Loss: 0.008065 | Test Accuracy: 0.760513, 0.688270\n",
      "Step 11 | Training Loss: 0.000008 | Test Loss: 0.011470 | Test Accuracy: 0.730837, 0.609789\n",
      "Step 12 | Training Loss: 0.000327 | Test Loss: 0.008673 | Test Accuracy: 0.720813, 0.645907\n",
      "Step 13 | Training Loss: 0.000068 | Test Loss: 0.010146 | Test Accuracy: 0.744855, 0.735696\n",
      "Step 14 | Training Loss: 0.000796 | Test Loss: 0.009203 | Test Accuracy: 0.740774, 0.657553\n",
      "Step 15 | Training Loss: 0.000789 | Test Loss: 0.007297 | Test Accuracy: 0.740862, 0.685654\n",
      "Step 1 | Training Loss: 0.000311 | Test Loss: 0.007700 | Test Accuracy: 0.749556, 0.722785\n",
      "Step 2 | Training Loss: 0.000587 | Test Loss: 0.007106 | Test Accuracy: 0.772179, 0.756203\n",
      "Step 3 | Training Loss: 0.000156 | Test Loss: 0.006646 | Test Accuracy: 0.776748, 0.760338\n",
      "Step 4 | Training Loss: 0.000278 | Test Loss: 0.005751 | Test Accuracy: 0.797773, 0.757046\n",
      "Step 5 | Training Loss: 0.000072 | Test Loss: 0.006958 | Test Accuracy: 0.777901, 0.705738\n",
      "Step 6 | Training Loss: 0.000286 | Test Loss: 0.004970 | Test Accuracy: 0.791386, 0.704051\n",
      "Step 7 | Training Loss: 0.000405 | Test Loss: 0.005895 | Test Accuracy: 0.794580, 0.764894\n",
      "Step 8 | Training Loss: 0.000042 | Test Loss: 0.006683 | Test Accuracy: 0.795378, 0.760000\n",
      "Step 9 | Training Loss: 0.000154 | Test Loss: 0.007163 | Test Accuracy: 0.778167, 0.768270\n",
      "Step 10 | Training Loss: 0.000039 | Test Loss: 0.007570 | Test Accuracy: 0.774840, 0.748692\n",
      "Step 11 | Training Loss: 0.000406 | Test Loss: 0.006420 | Test Accuracy: 0.782425, 0.723882\n",
      "Step 12 | Training Loss: 0.000146 | Test Loss: 0.006476 | Test Accuracy: 0.806556, 0.776709\n",
      "Step 13 | Training Loss: 0.000454 | Test Loss: 0.006037 | Test Accuracy: 0.784289, 0.801013\n",
      "Step 14 | Training Loss: 0.000231 | Test Loss: 0.006278 | Test Accuracy: 0.792628, 0.810464\n",
      "Step 15 | Training Loss: 0.000274 | Test Loss: 0.005800 | Test Accuracy: 0.797685, 0.808523\n",
      "Step 1 | Training Loss: 0.000376 | Test Loss: 0.005755 | Test Accuracy: 0.805935, 0.807764\n",
      "Step 2 | Training Loss: 0.000422 | Test Loss: 0.005689 | Test Accuracy: 0.802431, 0.810633\n",
      "Step 3 | Training Loss: 0.000281 | Test Loss: 0.005719 | Test Accuracy: 0.799148, 0.808270\n",
      "Step 4 | Training Loss: 0.000559 | Test Loss: 0.005793 | Test Accuracy: 0.804161, 0.811646\n",
      "Step 5 | Training Loss: 0.000334 | Test Loss: 0.005682 | Test Accuracy: 0.807798, 0.809536\n",
      "Step 6 | Training Loss: 0.000363 | Test Loss: 0.005716 | Test Accuracy: 0.804161, 0.805823\n",
      "Step 7 | Training Loss: 0.000201 | Test Loss: 0.005565 | Test Accuracy: 0.802475, 0.810633\n",
      "Step 8 | Training Loss: 0.000266 | Test Loss: 0.005570 | Test Accuracy: 0.802830, 0.810464\n",
      "Step 9 | Training Loss: 0.000108 | Test Loss: 0.005505 | Test Accuracy: 0.800701, 0.816118\n",
      "Step 10 | Training Loss: 0.000354 | Test Loss: 0.005554 | Test Accuracy: 0.801810, 0.808270\n",
      "Step 11 | Training Loss: 0.000016 | Test Loss: 0.005714 | Test Accuracy: 0.801544, 0.807679\n",
      "Step 12 | Training Loss: 0.000193 | Test Loss: 0.005575 | Test Accuracy: 0.795511, 0.811392\n",
      "Step 13 | Training Loss: 0.000034 | Test Loss: 0.005717 | Test Accuracy: 0.797108, 0.812827\n",
      "Step 14 | Training Loss: 0.000045 | Test Loss: 0.005794 | Test Accuracy: 0.794358, 0.812658\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 15 | Training Loss: 0.000099 | Test Loss: 0.005792 | Test Accuracy: 0.791208, 0.812911\n",
      "Current Layer Attributes - epochs:15 hidden layers:3 features count:32\n",
      "Step 1 | Training Loss: 0.000420 | Test Loss: 0.003586 | Test Accuracy: 0.847720, 0.730464\n",
      "Step 2 | Training Loss: 0.000844 | Test Loss: 0.339398 | Test Accuracy: 0.767920, 0.643797\n",
      "Step 3 | Training Loss: 0.000760 | Test Loss: 0.006361 | Test Accuracy: 0.854374, 0.734937\n",
      "Step 4 | Training Loss: 0.000915 | Test Loss: 0.003443 | Test Accuracy: 0.843994, 0.772996\n",
      "Step 5 | Training Loss: 0.000187 | Test Loss: 0.004042 | Test Accuracy: 0.847454, 0.782869\n",
      "Step 6 | Training Loss: 0.000032 | Test Loss: 0.005870 | Test Accuracy: 0.815561, 0.829283\n",
      "Step 7 | Training Loss: 0.000102 | Test Loss: 0.006415 | Test Accuracy: 0.757097, 0.834093\n",
      "Step 8 | Training Loss: 0.000378 | Test Loss: 0.005476 | Test Accuracy: 0.784954, 0.812321\n",
      "Step 9 | Training Loss: 0.000401 | Test Loss: 0.005198 | Test Accuracy: 0.776304, 0.825654\n",
      "Step 10 | Training Loss: 0.000147 | Test Loss: 0.005472 | Test Accuracy: 0.773199, 0.830211\n",
      "Step 11 | Training Loss: 0.000668 | Test Loss: 0.005300 | Test Accuracy: 0.789168, 0.799409\n",
      "Step 12 | Training Loss: 0.000103 | Test Loss: 0.005833 | Test Accuracy: 0.790898, 0.809114\n",
      "Step 13 | Training Loss: 0.000349 | Test Loss: 0.005972 | Test Accuracy: 0.795422, 0.814852\n",
      "Step 14 | Training Loss: 0.000045 | Test Loss: 0.005581 | Test Accuracy: 0.801011, 0.790802\n",
      "Step 15 | Training Loss: 0.000351 | Test Loss: 0.006749 | Test Accuracy: 0.776703, 0.806751\n",
      "Step 1 | Training Loss: 0.000031 | Test Loss: 0.006731 | Test Accuracy: 0.781583, 0.767764\n",
      "Step 2 | Training Loss: 0.000612 | Test Loss: 0.005410 | Test Accuracy: 0.792051, 0.815696\n",
      "Step 3 | Training Loss: 0.000227 | Test Loss: 0.006523 | Test Accuracy: 0.768763, 0.771139\n",
      "Step 4 | Training Loss: 0.000273 | Test Loss: 0.007568 | Test Accuracy: 0.744145, 0.823291\n",
      "Step 5 | Training Loss: 0.000423 | Test Loss: 0.005769 | Test Accuracy: 0.782736, 0.790295\n",
      "Step 6 | Training Loss: 0.000773 | Test Loss: 0.006081 | Test Accuracy: 0.763751, 0.808101\n",
      "Step 7 | Training Loss: 0.000461 | Test Loss: 0.005758 | Test Accuracy: 0.795334, 0.816118\n",
      "Step 8 | Training Loss: 0.001081 | Test Loss: 0.005299 | Test Accuracy: 0.788103, 0.811561\n",
      "Step 9 | Training Loss: 0.000286 | Test Loss: 0.005870 | Test Accuracy: 0.785752, 0.793755\n",
      "Step 10 | Training Loss: 0.000484 | Test Loss: 0.005799 | Test Accuracy: 0.793293, 0.793080\n",
      "Step 11 | High Training Loss: 4688286123193466817085440.000000 ... Restoring Net\n",
      "INFO:tensorflow:Restoring parameters from dataset/tf_vae_only_vae_loss_nsl_kdd/hidden layers_15_features count_3/model-3\n",
      "Step 11 | Training Loss: 0.000133 | Test Loss: 0.004433 | Test Accuracy: 0.800568, 0.785738\n",
      "Step 12 | Training Loss: 0.001119 | Test Loss: 0.005632 | Test Accuracy: 0.774397, 0.790295\n",
      "Step 13 | Training Loss: 0.000018 | Test Loss: 0.005745 | Test Accuracy: 0.771558, 0.813502\n",
      "Step 14 | Training Loss: 0.000229 | Test Loss: 0.006988 | Test Accuracy: 0.735983, 0.825401\n",
      "Step 15 | Training Loss: 0.000076 | Test Loss: 0.007078 | Test Accuracy: 0.773465, 0.806076\n",
      "Step 1 | Training Loss: 0.000410 | Test Loss: 0.006472 | Test Accuracy: 0.772844, 0.797806\n",
      "Step 2 | Training Loss: 0.000338 | Test Loss: 0.006238 | Test Accuracy: 0.769961, 0.802363\n",
      "Step 3 | Training Loss: 0.000166 | Test Loss: 0.006304 | Test Accuracy: 0.765348, 0.801435\n",
      "Step 4 | Training Loss: 0.000224 | Test Loss: 0.006142 | Test Accuracy: 0.771824, 0.802532\n",
      "Step 5 | Training Loss: 0.000250 | Test Loss: 0.006152 | Test Accuracy: 0.770050, 0.800169\n",
      "Step 6 | Training Loss: 0.000049 | Test Loss: 0.006158 | Test Accuracy: 0.769207, 0.795612\n",
      "Step 7 | Training Loss: 0.000655 | Test Loss: 0.006064 | Test Accuracy: 0.768941, 0.800506\n",
      "Step 8 | Training Loss: 0.000067 | Test Loss: 0.006129 | Test Accuracy: 0.763707, 0.802278\n",
      "Step 9 | Training Loss: 0.000354 | Test Loss: 0.006378 | Test Accuracy: 0.757408, 0.802532\n",
      "Step 10 | Training Loss: 0.000198 | Test Loss: 0.006256 | Test Accuracy: 0.769739, 0.795190\n",
      "Step 11 | Training Loss: 0.000008 | Test Loss: 0.006243 | Test Accuracy: 0.765481, 0.797975\n",
      "Step 12 | Training Loss: 0.000107 | Test Loss: 0.006241 | Test Accuracy: 0.762775, 0.799325\n",
      "Step 13 | Training Loss: 0.000216 | Test Loss: 0.006088 | Test Accuracy: 0.761533, 0.805232\n",
      "Step 14 | Training Loss: 0.000063 | Test Loss: 0.006138 | Test Accuracy: 0.766501, 0.795105\n",
      "Step 15 | Training Loss: 0.000141 | Test Loss: 0.006147 | Test Accuracy: 0.762775, 0.796034\n",
      "Current Layer Attributes - epochs:15 hidden layers:3 features count:122\n",
      "Step 1 | Training Loss: 0.000436 | Test Loss: 0.007302 | Test Accuracy: 0.682000, 0.486076\n",
      "Step 2 | Training Loss: 0.000798 | Test Loss: 0.006063 | Test Accuracy: 0.779986, 0.624979\n",
      "Step 3 | Training Loss: 0.001159 | Test Loss: 0.006520 | Test Accuracy: 0.776703, 0.618734\n",
      "Step 4 | Training Loss: 0.000022 | Test Loss: 0.007788 | Test Accuracy: 0.741971, 0.543713\n",
      "Step 5 | Training Loss: 0.000293 | Test Loss: 0.007060 | Test Accuracy: 0.765969, 0.634684\n",
      "Step 6 | Training Loss: 0.000252 | Test Loss: 0.010574 | Test Accuracy: 0.732878, 0.570042\n",
      "Step 7 | Training Loss: 0.000373 | Test Loss: 0.009102 | Test Accuracy: 0.743923, 0.634852\n",
      "Step 8 | Training Loss: 0.000181 | Test Loss: 0.010101 | Test Accuracy: 0.727644, 0.566751\n",
      "Step 9 | Training Loss: 0.000147 | Test Loss: 0.012307 | Test Accuracy: 0.701384, 0.570633\n",
      "Step 10 | Training Loss: 0.000283 | Test Loss: 0.010814 | Test Accuracy: 0.710034, 0.643291\n",
      "Step 11 | Training Loss: 0.000142 | Test Loss: 0.009536 | Test Accuracy: 0.690516, 0.660928\n",
      "Step 12 | Training Loss: 0.000100 | Test Loss: 0.016380 | Test Accuracy: 0.678895, 0.618903\n",
      "Step 13 | High Training Loss: 31563181120286621696.000000 ... Restoring Net\n",
      "INFO:tensorflow:Restoring parameters from dataset/tf_vae_only_vae_loss_nsl_kdd/hidden layers_15_features count_3/model-2\n",
      "Step 13 | Training Loss: 0.000464 | Test Loss: 0.006870 | Test Accuracy: 0.731547, 0.509789\n",
      "Step 14 | Training Loss: 0.000261 | Test Loss: 0.006666 | Test Accuracy: 0.778078, 0.659916\n",
      "Step 15 | Training Loss: 0.000060 | Test Loss: 0.007918 | Test Accuracy: 0.727333, 0.587848\n",
      "Step 1 | Training Loss: 0.000751 | Test Loss: 0.011664 | Test Accuracy: 0.747205, 0.705823\n",
      "Step 2 | Training Loss: 0.000113 | Test Loss: 0.011250 | Test Accuracy: 0.672418, 0.534346\n",
      "Step 3 | Training Loss: 0.000142 | Test Loss: 0.008166 | Test Accuracy: 0.770094, 0.736371\n",
      "Step 4 | Training Loss: 0.000170 | Test Loss: 0.007931 | Test Accuracy: 0.744411, 0.688523\n",
      "Step 5 | Training Loss: 0.000126 | Test Loss: 0.009173 | Test Accuracy: 0.691270, 0.616709\n",
      "Step 6 | Training Loss: 0.000218 | Test Loss: 0.011340 | Test Accuracy: 0.664700, 0.536118\n",
      "Step 7 | Training Loss: 0.000147 | Test Loss: 0.009616 | Test Accuracy: 0.690738, 0.603460\n",
      "Step 8 | Training Loss: 0.000932 | Test Loss: 0.010652 | Test Accuracy: 0.673261, 0.596287\n",
      "Step 9 | Training Loss: 0.000191 | Test Loss: 0.009589 | Test Accuracy: 0.705731, 0.677722\n",
      "Step 10 | Training Loss: 0.000160 | Test Loss: 0.014196 | Test Accuracy: 0.696726, 0.653418\n",
      "Step 11 | Training Loss: 0.000075 | Test Loss: 0.012386 | Test Accuracy: 0.645050, 0.575105\n",
      "Step 12 | Training Loss: 0.000016 | Test Loss: 0.010750 | Test Accuracy: 0.723252, 0.751730\n",
      "Step 13 | Training Loss: 0.000235 | Test Loss: 0.016580 | Test Accuracy: 0.682399, 0.695021\n",
      "Step 14 | Training Loss: 0.000163 | Test Loss: 0.012645 | Test Accuracy: 0.709058, 0.742532\n",
      "Step 15 | Training Loss: 0.000465 | Test Loss: 0.010719 | Test Accuracy: 0.716466, 0.770127\n",
      "Step 1 | Training Loss: 0.000086 | Test Loss: 0.009961 | Test Accuracy: 0.718062, 0.770380\n",
      "Step 2 | Training Loss: 0.000206 | Test Loss: 0.010104 | Test Accuracy: 0.718994, 0.773080\n",
      "Step 3 | Training Loss: 0.000191 | Test Loss: 0.010186 | Test Accuracy: 0.713006, 0.767004\n",
      "Step 4 | Training Loss: 0.000026 | Test Loss: 0.010327 | Test Accuracy: 0.713449, 0.762616\n",
      "Step 5 | Training Loss: 0.000341 | Test Loss: 0.009725 | Test Accuracy: 0.713760, 0.769958\n",
      "Step 6 | Training Loss: 0.000047 | Test Loss: 0.010227 | Test Accuracy: 0.713094, 0.766076\n",
      "Step 7 | Training Loss: 0.000218 | Test Loss: 0.009924 | Test Accuracy: 0.711852, 0.766920\n",
      "Step 8 | Training Loss: 0.000156 | Test Loss: 0.010011 | Test Accuracy: 0.711054, 0.771392\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 9 | Training Loss: 0.000026 | Test Loss: 0.010109 | Test Accuracy: 0.709413, 0.766920\n",
      "Step 10 | Training Loss: 0.000055 | Test Loss: 0.010330 | Test Accuracy: 0.709856, 0.768270\n",
      "Step 11 | Training Loss: 0.000090 | Test Loss: 0.009965 | Test Accuracy: 0.710211, 0.768017\n",
      "Step 12 | Training Loss: 0.000245 | Test Loss: 0.010381 | Test Accuracy: 0.706352, 0.763122\n",
      "Step 13 | Training Loss: 0.000130 | Test Loss: 0.010262 | Test Accuracy: 0.704622, 0.766751\n",
      "Step 14 | Training Loss: 0.000131 | Test Loss: 0.011017 | Test Accuracy: 0.701029, 0.761603\n",
      "Step 15 | Training Loss: 0.000033 | Test Loss: 0.010811 | Test Accuracy: 0.704223, 0.764135\n",
      "Current Layer Attributes - epochs:15 hidden layers:5 features count:4\n",
      "Step 1 | Training Loss: 0.000742 | Test Loss: 0.008072 | Test Accuracy: 0.430758, 0.181603\n",
      "Step 2 | Training Loss: 0.000200 | Test Loss: 0.001446 | Test Accuracy: 0.769251, 0.735443\n",
      "Step 3 | Training Loss: 0.001428 | Test Loss: 0.002576 | Test Accuracy: 0.792095, 0.666329\n",
      "Step 4 | Training Loss: 0.000354 | Test Loss: 0.005853 | Test Accuracy: 0.718018, 0.526245\n",
      "Step 5 | Training Loss: 0.000705 | Test Loss: 0.003613 | Test Accuracy: 0.840091, 0.754262\n",
      "Step 6 | Training Loss: 0.000140 | Test Loss: 0.003557 | Test Accuracy: 0.850160, 0.747595\n",
      "Step 7 | Training Loss: 0.000500 | Test Loss: 0.003476 | Test Accuracy: 0.843462, 0.760338\n",
      "Step 8 | Training Loss: 0.002518 | Test Loss: 0.003610 | Test Accuracy: 0.836453, 0.736287\n",
      "Step 9 | Training Loss: 0.001093 | Test Loss: 0.002819 | Test Accuracy: 0.871141, 0.770211\n",
      "Step 10 | Training Loss: 0.000765 | Test Loss: 0.003289 | Test Accuracy: 0.866040, 0.767426\n",
      "Step 11 | Training Loss: 0.000137 | Test Loss: 0.003335 | Test Accuracy: 0.833082, 0.706920\n",
      "Step 12 | Training Loss: 0.000900 | Test Loss: 0.002444 | Test Accuracy: 0.829134, 0.764473\n",
      "Step 13 | Training Loss: 0.000385 | Test Loss: 0.002785 | Test Accuracy: 0.865020, 0.753755\n",
      "Step 14 | Training Loss: 0.000485 | Test Loss: 0.002188 | Test Accuracy: 0.854640, 0.789873\n",
      "Step 15 | Training Loss: 0.000076 | Test Loss: 0.002109 | Test Accuracy: 0.869145, 0.773587\n",
      "Step 1 | Training Loss: 0.000762 | Test Loss: 0.002297 | Test Accuracy: 0.866883, 0.770549\n",
      "Step 2 | Training Loss: 0.000491 | Test Loss: 0.004405 | Test Accuracy: 0.804249, 0.653165\n",
      "Step 3 | Training Loss: 0.000487 | Test Loss: 0.003349 | Test Accuracy: 0.795999, 0.644641\n",
      "Step 4 | Training Loss: 0.000274 | Test Loss: 0.003557 | Test Accuracy: 0.789922, 0.623460\n",
      "Step 5 | Training Loss: 0.000177 | Test Loss: 0.002949 | Test Accuracy: 0.830820, 0.700928\n",
      "Step 6 | Training Loss: 0.000560 | Test Loss: 0.002899 | Test Accuracy: 0.837961, 0.714515\n",
      "Step 7 | Training Loss: 0.000447 | Test Loss: 0.003267 | Test Accuracy: 0.812323, 0.664641\n",
      "Step 8 | Training Loss: 0.000587 | Test Loss: 0.003780 | Test Accuracy: 0.796576, 0.624473\n",
      "Step 9 | Training Loss: 0.000128 | Test Loss: 0.002385 | Test Accuracy: 0.798483, 0.630970\n",
      "Step 10 | Training Loss: 0.000194 | Test Loss: 0.002842 | Test Accuracy: 0.801056, 0.633924\n",
      "Step 11 | Training Loss: 0.001415 | Test Loss: 0.002313 | Test Accuracy: 0.805403, 0.646582\n",
      "Step 12 | Training Loss: 0.000036 | Test Loss: 0.002744 | Test Accuracy: 0.812988, 0.655105\n",
      "Step 13 | Training Loss: 0.000528 | Test Loss: 0.005795 | Test Accuracy: 0.737846, 0.531055\n",
      "Step 14 | Training Loss: 0.000085 | Test Loss: 0.003579 | Test Accuracy: 0.808419, 0.642194\n",
      "Step 15 | Training Loss: 0.000302 | Test Loss: 0.003139 | Test Accuracy: 0.809129, 0.653249\n",
      "Step 1 | Training Loss: 0.000000 | Test Loss: 0.002824 | Test Accuracy: 0.808109, 0.655612\n",
      "Step 2 | Training Loss: 0.000016 | Test Loss: 0.002681 | Test Accuracy: 0.816625, 0.665992\n",
      "Step 3 | Training Loss: 0.000272 | Test Loss: 0.002584 | Test Accuracy: 0.823501, 0.674430\n",
      "Step 4 | Training Loss: 0.000435 | Test Loss: 0.002413 | Test Accuracy: 0.821993, 0.670380\n",
      "Step 5 | Training Loss: 0.000062 | Test Loss: 0.002316 | Test Accuracy: 0.824920, 0.677215\n",
      "Step 6 | Training Loss: 0.000161 | Test Loss: 0.002306 | Test Accuracy: 0.823900, 0.676962\n",
      "Step 7 | Training Loss: 0.000341 | Test Loss: 0.002392 | Test Accuracy: 0.825053, 0.678565\n",
      "Step 8 | Training Loss: 0.000054 | Test Loss: 0.002248 | Test Accuracy: 0.824610, 0.676624\n",
      "Step 9 | Training Loss: 0.000154 | Test Loss: 0.002080 | Test Accuracy: 0.825231, 0.679831\n",
      "Step 10 | Training Loss: 0.000024 | Test Loss: 0.002088 | Test Accuracy: 0.825896, 0.681266\n",
      "Step 11 | Training Loss: 0.000099 | Test Loss: 0.002032 | Test Accuracy: 0.826872, 0.679325\n",
      "Step 12 | Training Loss: 0.000116 | Test Loss: 0.002124 | Test Accuracy: 0.825053, 0.677131\n",
      "Step 13 | Training Loss: 0.000072 | Test Loss: 0.001899 | Test Accuracy: 0.826118, 0.679578\n",
      "Step 14 | Training Loss: 0.000088 | Test Loss: 0.001819 | Test Accuracy: 0.826828, 0.679072\n",
      "Step 15 | Training Loss: 0.000317 | Test Loss: 0.001947 | Test Accuracy: 0.826872, 0.681266\n",
      "Current Layer Attributes - epochs:15 hidden layers:5 features count:8\n",
      "Step 1 | Training Loss: 0.001133 | Test Loss: 0.004623 | Test Accuracy: 0.430758, 0.181603\n",
      "Step 2 | Training Loss: 0.000808 | Test Loss: 0.001804 | Test Accuracy: 0.761089, 0.769536\n",
      "Step 3 | Training Loss: 0.000981 | Test Loss: 0.003185 | Test Accuracy: 0.749556, 0.675021\n",
      "Step 4 | Training Loss: 0.000749 | Test Loss: 0.005130 | Test Accuracy: 0.760158, 0.589198\n",
      "Step 5 | Training Loss: 0.000642 | Test Loss: 0.005389 | Test Accuracy: 0.742903, 0.546245\n",
      "Step 6 | Training Loss: 0.000150 | Test Loss: 0.008198 | Test Accuracy: 0.708171, 0.480169\n",
      "Step 7 | Training Loss: 0.000684 | Test Loss: 0.006473 | Test Accuracy: 0.771425, 0.579072\n",
      "Step 8 | Training Loss: 0.001038 | Test Loss: 0.006823 | Test Accuracy: 0.775018, 0.610717\n",
      "Step 9 | Training Loss: 0.000168 | Test Loss: 0.005779 | Test Accuracy: 0.791031, 0.627595\n",
      "Step 10 | Training Loss: 0.000574 | Test Loss: 0.006007 | Test Accuracy: 0.777812, 0.589367\n",
      "Step 11 | Training Loss: 0.000107 | Test Loss: 0.004161 | Test Accuracy: 0.818488, 0.669789\n",
      "Step 12 | Training Loss: 0.000273 | Test Loss: 0.002789 | Test Accuracy: 0.834058, 0.737215\n",
      "Step 13 | Training Loss: 0.000393 | Test Loss: 0.002617 | Test Accuracy: 0.802209, 0.639916\n",
      "Step 14 | Training Loss: 0.000646 | Test Loss: 0.002297 | Test Accuracy: 0.832461, 0.704726\n",
      "Step 15 | Training Loss: 0.000714 | Test Loss: 0.001924 | Test Accuracy: 0.819065, 0.674093\n",
      "Step 1 | Training Loss: 0.000575 | Test Loss: 0.003236 | Test Accuracy: 0.816226, 0.664810\n",
      "Step 2 | Training Loss: 0.000298 | Test Loss: 0.003866 | Test Accuracy: 0.807665, 0.643629\n",
      "Step 3 | Training Loss: 0.000027 | Test Loss: 0.002926 | Test Accuracy: 0.819952, 0.671899\n",
      "Step 4 | Training Loss: 0.000085 | Test Loss: 0.001270 | Test Accuracy: 0.873314, 0.784388\n",
      "Step 5 | Training Loss: 0.000064 | Test Loss: 0.002070 | Test Accuracy: 0.880145, 0.779578\n",
      "Step 6 | Training Loss: 0.000146 | Test Loss: 0.001543 | Test Accuracy: 0.822525, 0.744304\n",
      "Step 7 | Training Loss: 0.000748 | Test Loss: 0.002463 | Test Accuracy: 0.810770, 0.675612\n",
      "Step 8 | Training Loss: 0.000058 | Test Loss: 0.003386 | Test Accuracy: 0.797906, 0.627932\n",
      "Step 9 | Training Loss: 0.000083 | Test Loss: 0.003624 | Test Accuracy: 0.810016, 0.671139\n",
      "Step 10 | Training Loss: 0.000227 | Test Loss: 0.003854 | Test Accuracy: 0.814984, 0.659494\n",
      "Step 11 | Training Loss: 0.000184 | Test Loss: 0.002868 | Test Accuracy: 0.832727, 0.698819\n",
      "Step 12 | Training Loss: 0.000304 | Test Loss: 0.003113 | Test Accuracy: 0.822702, 0.672152\n",
      "Step 13 | Training Loss: 0.000791 | Test Loss: 0.003151 | Test Accuracy: 0.818577, 0.672658\n",
      "Step 14 | Training Loss: 0.000091 | Test Loss: 0.002457 | Test Accuracy: 0.835655, 0.703882\n",
      "Step 15 | Training Loss: 0.000221 | Test Loss: 0.006389 | Test Accuracy: 0.866395, 0.818397\n",
      "Step 1 | Training Loss: 0.000317 | Test Loss: 0.002403 | Test Accuracy: 0.838094, 0.830549\n",
      "Step 2 | Training Loss: 0.000155 | Test Loss: 0.002086 | Test Accuracy: 0.825896, 0.830295\n",
      "Step 3 | Training Loss: 0.000037 | Test Loss: 0.002320 | Test Accuracy: 0.848607, 0.830549\n",
      "Step 4 | Training Loss: 0.000282 | Test Loss: 0.002038 | Test Accuracy: 0.860007, 0.827426\n",
      "Step 5 | Training Loss: 0.000394 | Test Loss: 0.001823 | Test Accuracy: 0.852067, 0.829367\n",
      "Step 6 | Training Loss: 0.000181 | Test Loss: 0.002130 | Test Accuracy: 0.838937, 0.822700\n",
      "Step 7 | Training Loss: 0.000715 | Test Loss: 0.002422 | Test Accuracy: 0.827493, 0.821181\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 8 | Training Loss: 0.000292 | Test Loss: 0.002426 | Test Accuracy: 0.820396, 0.807257\n",
      "Step 9 | Training Loss: 0.000223 | Test Loss: 0.002804 | Test Accuracy: 0.801499, 0.822025\n",
      "Step 10 | Training Loss: 0.000093 | Test Loss: 0.002226 | Test Accuracy: 0.836897, 0.827426\n",
      "Step 11 | Training Loss: 0.000057 | Test Loss: 0.002553 | Test Accuracy: 0.832594, 0.828270\n",
      "Step 12 | Training Loss: 0.000114 | Test Loss: 0.002114 | Test Accuracy: 0.848652, 0.824726\n",
      "Step 13 | Training Loss: 0.000297 | Test Loss: 0.002052 | Test Accuracy: 0.859120, 0.823797\n",
      "Step 14 | Training Loss: 0.000482 | Test Loss: 0.002032 | Test Accuracy: 0.861382, 0.822532\n",
      "Step 15 | Training Loss: 0.000090 | Test Loss: 0.001906 | Test Accuracy: 0.863511, 0.822532\n",
      "Current Layer Attributes - epochs:15 hidden layers:5 features count:32\n",
      "Step 1 | Training Loss: 0.000226 | Test Loss: 0.003575 | Test Accuracy: 0.793870, 0.695696\n",
      "Step 2 | Training Loss: 0.000984 | Test Loss: 0.003467 | Test Accuracy: 0.772800, 0.664641\n",
      "Step 3 | Training Loss: 0.000626 | Test Loss: 0.003219 | Test Accuracy: 0.776836, 0.625232\n",
      "Step 4 | Training Loss: 0.000792 | Test Loss: 0.005157 | Test Accuracy: 0.771647, 0.638903\n",
      "Step 5 | Training Loss: 0.003292 | Test Loss: 0.011185 | Test Accuracy: 0.614354, 0.411139\n",
      "Step 6 | Training Loss: 0.000906 | Test Loss: 0.004153 | Test Accuracy: 0.791652, 0.645401\n",
      "Step 7 | Training Loss: 0.000361 | Test Loss: 0.005122 | Test Accuracy: 0.761577, 0.607426\n",
      "Step 8 | Training Loss: 0.000309 | Test Loss: 0.004313 | Test Accuracy: 0.752528, 0.583797\n",
      "Step 9 | Training Loss: 0.000702 | Test Loss: 0.004358 | Test Accuracy: 0.768098, 0.569705\n",
      "Step 10 | Training Loss: 0.000575 | Test Loss: 0.004354 | Test Accuracy: 0.689807, 0.430717\n",
      "Step 11 | Training Loss: 0.000669 | Test Loss: 0.005592 | Test Accuracy: 0.690916, 0.432152\n",
      "Step 12 | Training Loss: 0.000309 | Test Loss: 0.004227 | Test Accuracy: 0.721123, 0.491561\n",
      "Step 13 | Training Loss: 0.000732 | Test Loss: 0.004395 | Test Accuracy: 0.701916, 0.461181\n",
      "Step 14 | Training Loss: 0.000301 | Test Loss: 0.005171 | Test Accuracy: 0.690339, 0.440506\n",
      "Step 15 | Training Loss: 0.000642 | Test Loss: 0.006420 | Test Accuracy: 0.688742, 0.434177\n",
      "Step 1 | Training Loss: 0.000039 | Test Loss: 0.007196 | Test Accuracy: 0.624911, 0.346329\n",
      "Step 2 | Training Loss: 0.001262 | Test Loss: 0.004917 | Test Accuracy: 0.719659, 0.489451\n",
      "Step 3 | Training Loss: 0.000857 | Test Loss: 0.004226 | Test Accuracy: 0.683907, 0.422869\n",
      "Step 4 | Training Loss: 0.001044 | Test Loss: 0.004970 | Test Accuracy: 0.546176, 0.316624\n",
      "Step 5 | Training Loss: 0.000845 | Test Loss: 0.005443 | Test Accuracy: 0.493125, 0.228101\n",
      "Step 6 | Training Loss: 0.001648 | Test Loss: 0.004657 | Test Accuracy: 0.502706, 0.241603\n",
      "Step 7 | Training Loss: 0.000280 | Test Loss: 0.007058 | Test Accuracy: 0.511267, 0.253755\n",
      "Step 8 | Training Loss: 0.000185 | Test Loss: 0.008015 | Test Accuracy: 0.508472, 0.249114\n",
      "Step 9 | Training Loss: 0.001507 | Test Loss: 0.004845 | Test Accuracy: 0.507984, 0.248861\n",
      "Step 10 | Training Loss: 0.000240 | Test Loss: 0.005018 | Test Accuracy: 0.508029, 0.248186\n",
      "Step 11 | Training Loss: 0.000120 | Test Loss: 0.004538 | Test Accuracy: 0.507452, 0.249114\n",
      "Step 12 | Training Loss: 0.000034 | Test Loss: 0.004306 | Test Accuracy: 0.508783, 0.255359\n",
      "Step 13 | Training Loss: 0.006685 | Test Loss: 0.006275 | Test Accuracy: 0.431645, 0.183966\n",
      "Step 14 | Training Loss: 0.000788 | Test Loss: 0.004779 | Test Accuracy: 0.500621, 0.236371\n",
      "Step 15 | Training Loss: 0.000135 | Test Loss: 0.005680 | Test Accuracy: 0.526437, 0.282110\n",
      "Step 1 | Training Loss: 0.000030 | Test Loss: 0.004729 | Test Accuracy: 0.524086, 0.277806\n",
      "Step 2 | Training Loss: 0.000228 | Test Loss: 0.004306 | Test Accuracy: 0.527324, 0.282869\n",
      "Step 3 | Training Loss: 0.000013 | Test Loss: 0.003915 | Test Accuracy: 0.527679, 0.282785\n",
      "Step 4 | Training Loss: 0.000155 | Test Loss: 0.003772 | Test Accuracy: 0.526836, 0.281941\n",
      "Step 5 | Training Loss: 0.000155 | Test Loss: 0.003659 | Test Accuracy: 0.523864, 0.278312\n",
      "Step 6 | Training Loss: 0.000422 | Test Loss: 0.003454 | Test Accuracy: 0.522844, 0.275021\n",
      "Step 7 | Training Loss: 0.000340 | Test Loss: 0.003521 | Test Accuracy: 0.522977, 0.276793\n",
      "Step 8 | Training Loss: 0.000467 | Test Loss: 0.003396 | Test Accuracy: 0.523332, 0.274599\n",
      "Step 9 | Training Loss: 0.000057 | Test Loss: 0.003238 | Test Accuracy: 0.521824, 0.273249\n",
      "Step 10 | Training Loss: 0.000053 | Test Loss: 0.003095 | Test Accuracy: 0.520893, 0.272068\n",
      "Step 11 | Training Loss: 0.000109 | Test Loss: 0.003108 | Test Accuracy: 0.521114, 0.272911\n",
      "Step 12 | Training Loss: 0.000405 | Test Loss: 0.003179 | Test Accuracy: 0.521868, 0.274937\n",
      "Step 13 | Training Loss: 0.000222 | Test Loss: 0.003064 | Test Accuracy: 0.523243, 0.277806\n",
      "Step 14 | Training Loss: 0.000100 | Test Loss: 0.003161 | Test Accuracy: 0.522223, 0.272827\n",
      "Step 15 | Training Loss: 0.000223 | Test Loss: 0.002936 | Test Accuracy: 0.523598, 0.273924\n",
      "Current Layer Attributes - epochs:15 hidden layers:5 features count:122\n",
      "Step 1 | Training Loss: 0.000566 | Test Loss: 0.004408 | Test Accuracy: 0.882940, 0.783966\n",
      "Step 2 | Training Loss: 0.000859 | Test Loss: 0.003250 | Test Accuracy: 0.887952, 0.821097\n",
      "Step 3 | Training Loss: 0.000456 | Test Loss: 0.003140 | Test Accuracy: 0.885912, 0.809030\n",
      "Step 4 | Training Loss: 0.000363 | Test Loss: 0.003837 | Test Accuracy: 0.882452, 0.792236\n",
      "Step 5 | Training Loss: 0.000212 | Test Loss: 0.003462 | Test Accuracy: 0.885690, 0.793418\n",
      "Step 6 | Training Loss: 0.000211 | Test Loss: 0.002716 | Test Accuracy: 0.887065, 0.802700\n",
      "Step 7 | High Training Loss: 12613689717638633095168.000000 ... Restoring Net\n",
      "INFO:tensorflow:Restoring parameters from dataset/tf_vae_only_vae_loss_nsl_kdd/hidden layers_15_features count_5/model-2\n",
      "Step 7 | Training Loss: 0.000021 | Test Loss: 0.003182 | Test Accuracy: 0.861560, 0.770295\n",
      "Step 8 | Training Loss: 0.000009 | Test Loss: 0.002020 | Test Accuracy: 0.838494, 0.734684\n",
      "Step 9 | Training Loss: 0.000030 | Test Loss: 0.003313 | Test Accuracy: 0.866838, 0.766329\n",
      "Step 10 | Training Loss: 0.000831 | Test Loss: 0.005135 | Test Accuracy: 0.849406, 0.731139\n",
      "Step 11 | Training Loss: 0.000373 | Test Loss: 553.838074 | Test Accuracy: 0.792184, 0.656878\n",
      "Step 12 | Training Loss: 0.001401 | Test Loss: 0.008067 | Test Accuracy: 0.495387, 0.227932\n",
      "Step 13 | Training Loss: 0.000841 | Test Loss: 0.005812 | Test Accuracy: 0.533002, 0.756456\n",
      "Step 14 | Training Loss: 0.001456 | Test Loss: 0.006494 | Test Accuracy: 0.508029, 0.251224\n",
      "Step 15 | Training Loss: 0.000772 | Test Loss: 0.005780 | Test Accuracy: 0.500621, 0.238397\n",
      "Step 1 | Training Loss: 0.001549 | Test Loss: 0.012668 | Test Accuracy: 0.430891, 0.181772\n",
      "Step 2 | Training Loss: 0.008483 | Test Loss: 0.010695 | Test Accuracy: 0.433330, 0.186920\n",
      "Step 3 | Training Loss: 0.007957 | Test Loss: 0.010179 | Test Accuracy: 0.430758, 0.181603\n",
      "Step 4 | Training Loss: 0.007565 | Test Loss: 0.008735 | Test Accuracy: 0.430358, 0.182278\n",
      "Step 5 | Training Loss: 0.007752 | Test Loss: 0.007904 | Test Accuracy: 0.430758, 0.181603\n",
      "Step 6 | Training Loss: 0.007416 | Test Loss: 0.007550 | Test Accuracy: 0.430758, 0.181603\n",
      "Step 7 | Training Loss: 0.007703 | Test Loss: 0.007908 | Test Accuracy: 0.430935, 0.181772\n",
      "Step 8 | Training Loss: 0.007341 | Test Loss: 0.007588 | Test Accuracy: 0.430758, 0.181603\n",
      "Step 9 | Training Loss: 0.007188 | Test Loss: 0.007698 | Test Accuracy: 0.430758, 0.181603\n",
      "Step 10 | Training Loss: 0.007489 | Test Loss: 0.007816 | Test Accuracy: 0.430669, 0.181772\n",
      "Step 11 | Training Loss: 0.007260 | Test Loss: 0.007671 | Test Accuracy: 0.430758, 0.181603\n",
      "Step 12 | Training Loss: 0.007063 | Test Loss: 0.007712 | Test Accuracy: 0.431068, 0.185992\n",
      "Step 13 | Training Loss: 0.007760 | Test Loss: 0.007859 | Test Accuracy: 0.431246, 0.182785\n",
      "Step 14 | Training Loss: 0.007252 | Test Loss: 0.007548 | Test Accuracy: 0.431867, 0.185232\n",
      "Step 15 | Training Loss: 0.007253 | Test Loss: 0.007936 | Test Accuracy: 0.430846, 0.181941\n",
      "Step 1 | Training Loss: 0.007472 | Test Loss: 0.007946 | Test Accuracy: 0.431112, 0.181857\n",
      "Step 2 | Training Loss: 0.006337 | Test Loss: 0.007950 | Test Accuracy: 0.430846, 0.181857\n",
      "Step 3 | Training Loss: 0.006933 | Test Loss: 0.007936 | Test Accuracy: 0.430802, 0.182278\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 4 | Training Loss: 0.007777 | Test Loss: 0.007947 | Test Accuracy: 0.430580, 0.181603\n",
      "Step 5 | Training Loss: 0.006798 | Test Loss: 0.007985 | Test Accuracy: 0.431112, 0.182194\n",
      "Step 6 | Training Loss: 0.007634 | Test Loss: 0.007945 | Test Accuracy: 0.431290, 0.182278\n",
      "Step 7 | Training Loss: 0.006643 | Test Loss: 0.007973 | Test Accuracy: 0.434129, 0.197384\n",
      "Step 8 | Training Loss: 0.008388 | Test Loss: 0.009309 | Test Accuracy: 0.431068, 0.181941\n",
      "Step 9 | Training Loss: 0.007546 | Test Loss: 0.009203 | Test Accuracy: 0.436790, 0.209114\n",
      "Step 10 | Training Loss: 0.006003 | Test Loss: 0.008675 | Test Accuracy: 0.430802, 0.181772\n",
      "Step 11 | Training Loss: 0.006841 | Test Loss: 0.009053 | Test Accuracy: 0.430713, 0.181688\n",
      "Step 12 | Training Loss: 0.007820 | Test Loss: 0.009737 | Test Accuracy: 0.434839, 0.198059\n",
      "Step 13 | Training Loss: 0.008648 | Test Loss: 0.009188 | Test Accuracy: 0.450186, 0.262700\n",
      "Step 14 | Training Loss: 0.010158 | Test Loss: 0.008977 | Test Accuracy: 0.430491, 0.181857\n",
      "Step 15 | Training Loss: 0.006094 | Test Loss: 0.008214 | Test Accuracy: 0.431112, 0.183713\n",
      "Current Layer Attributes - epochs:15 hidden layers:3 features count:4\n",
      "Step 1 | Training Loss: 0.000467 | Test Loss: 0.013513 | Test Accuracy: 0.689008, 0.486667\n",
      "Step 2 | Training Loss: 0.000617 | Test Loss: 0.004112 | Test Accuracy: 0.803717, 0.687004\n",
      "Step 3 | Training Loss: 0.001341 | Test Loss: 0.009976 | Test Accuracy: 0.771070, 0.597553\n",
      "Step 4 | Training Loss: 0.000202 | Test Loss: 0.007522 | Test Accuracy: 0.811879, 0.670464\n",
      "Step 5 | Training Loss: 0.000205 | Test Loss: 0.011320 | Test Accuracy: 0.783889, 0.622954\n",
      "Step 6 | Training Loss: 0.001109 | Test Loss: 0.005929 | Test Accuracy: 0.793426, 0.693080\n",
      "Step 7 | Training Loss: 1.675417 | Test Loss: 0.006007 | Test Accuracy: 0.845857, 0.735949\n",
      "Step 8 | Training Loss: 0.001973 | Test Loss: 0.008095 | Test Accuracy: 0.783623, 0.652827\n",
      "Step 9 | Training Loss: 0.000601 | Test Loss: 0.006762 | Test Accuracy: 0.829001, 0.704895\n",
      "Step 10 | Training Loss: 0.000012 | Test Loss: 0.005831 | Test Accuracy: 0.825364, 0.696793\n",
      "Step 11 | Training Loss: 0.000141 | Test Loss: 0.005791 | Test Accuracy: 0.812500, 0.682700\n",
      "Step 12 | Training Loss: 0.000064 | Test Loss: 0.007517 | Test Accuracy: 0.773864, 0.600084\n",
      "Step 13 | Training Loss: 0.000371 | Test Loss: 0.005263 | Test Accuracy: 0.841288, 0.777722\n",
      "Step 14 | Training Loss: 0.000365 | Test Loss: 0.007964 | Test Accuracy: 0.793471, 0.771983\n",
      "Step 15 | Training Loss: 0.001057 | Test Loss: 0.004611 | Test Accuracy: 0.834723, 0.756793\n",
      "Step 1 | Training Loss: 0.000130 | Test Loss: 0.006390 | Test Accuracy: 0.801411, 0.770970\n",
      "Step 2 | Training Loss: 0.000175 | Test Loss: 0.005901 | Test Accuracy: 0.801810, 0.782447\n",
      "Step 3 | Training Loss: 0.000436 | Test Loss: 0.005908 | Test Accuracy: 0.812500, 0.774008\n",
      "Step 4 | Training Loss: 0.000318 | Test Loss: 0.005453 | Test Accuracy: 0.819642, 0.778565\n",
      "Step 5 | Training Loss: 0.000091 | Test Loss: 0.005558 | Test Accuracy: 0.823323, 0.788270\n",
      "Step 6 | Training Loss: 0.000100 | Test Loss: 0.006071 | Test Accuracy: 0.803407, 0.788945\n",
      "Step 7 | Training Loss: 0.001101 | Test Loss: 0.007115 | Test Accuracy: 0.803141, 0.787089\n",
      "Step 8 | Training Loss: 0.000335 | Test Loss: 0.006414 | Test Accuracy: 0.790232, 0.751561\n",
      "Step 9 | Training Loss: 0.000059 | Test Loss: 0.005537 | Test Accuracy: 0.810770, 0.790633\n",
      "Step 10 | Training Loss: 0.000289 | Test Loss: 0.005482 | Test Accuracy: 0.794269, 0.783460\n",
      "Step 11 | Training Loss: 0.000137 | Test Loss: 0.003582 | Test Accuracy: 0.844038, 0.783207\n",
      "Step 12 | Training Loss: 0.000145 | Test Loss: 0.004079 | Test Accuracy: 0.850825, 0.781857\n",
      "Step 13 | Training Loss: 0.000503 | Test Loss: 0.003779 | Test Accuracy: 0.843817, 0.757553\n",
      "Step 14 | Training Loss: 0.000365 | Test Loss: 0.005019 | Test Accuracy: 0.832860, 0.724388\n",
      "Step 15 | Training Loss: 0.000610 | Test Loss: 0.005294 | Test Accuracy: 0.837074, 0.754177\n",
      "Step 1 | Training Loss: 0.000037 | Test Loss: 0.004588 | Test Accuracy: 0.838405, 0.745063\n",
      "Step 2 | Training Loss: 0.000261 | Test Loss: 0.004172 | Test Accuracy: 0.840490, 0.744726\n",
      "Step 3 | Training Loss: 0.000391 | Test Loss: 0.003853 | Test Accuracy: 0.842175, 0.754515\n",
      "Step 4 | Training Loss: 0.000466 | Test Loss: 0.003845 | Test Accuracy: 0.844659, 0.754768\n",
      "Step 5 | Training Loss: 0.000189 | Test Loss: 0.003957 | Test Accuracy: 0.842841, 0.754262\n",
      "Step 6 | Training Loss: 0.000251 | Test Loss: 0.003578 | Test Accuracy: 0.841421, 0.758481\n",
      "Step 7 | Training Loss: 0.000200 | Test Loss: 0.003751 | Test Accuracy: 0.840268, 0.754093\n",
      "Step 8 | Training Loss: 0.000210 | Test Loss: 0.003591 | Test Accuracy: 0.843240, 0.754599\n",
      "Step 9 | Training Loss: 0.000082 | Test Loss: 0.003554 | Test Accuracy: 0.842131, 0.754768\n",
      "Step 10 | Training Loss: 0.000135 | Test Loss: 0.003632 | Test Accuracy: 0.840135, 0.760000\n",
      "Step 11 | Training Loss: 0.000206 | Test Loss: 0.003753 | Test Accuracy: 0.840224, 0.761097\n",
      "Step 12 | Training Loss: 0.000025 | Test Loss: 0.003774 | Test Accuracy: 0.837695, 0.760422\n",
      "Step 13 | Training Loss: 0.000097 | Test Loss: 0.003753 | Test Accuracy: 0.838272, 0.758397\n",
      "Step 14 | Training Loss: 0.000246 | Test Loss: 0.003789 | Test Accuracy: 0.839203, 0.761350\n",
      "Step 15 | Training Loss: 0.000203 | Test Loss: 0.003653 | Test Accuracy: 0.838982, 0.763207\n",
      "Current Layer Attributes - epochs:15 hidden layers:3 features count:8\n",
      "Step 1 | Training Loss: 0.000144 | Test Loss: 0.010104 | Test Accuracy: 0.793692, 0.670042\n",
      "Step 2 | Training Loss: 0.000885 | Test Loss: 0.005391 | Test Accuracy: 0.807576, 0.669873\n",
      "Step 3 | Training Loss: 0.000255 | Test Loss: 0.006820 | Test Accuracy: 0.701739, 0.469789\n",
      "Step 4 | Training Loss: 0.000167 | Test Loss: 0.005813 | Test Accuracy: 0.769828, 0.599325\n",
      "Step 5 | Training Loss: 0.001045 | Test Loss: 0.004605 | Test Accuracy: 0.758384, 0.596203\n",
      "Step 6 | High Training Loss: 276859033383205863424.000000 ... Restoring Net\n",
      "INFO:tensorflow:Restoring parameters from dataset/tf_vae_only_vae_loss_nsl_kdd/hidden layers_15_features count_3/model-2\n",
      "Step 6 | Training Loss: 0.003535 | Test Loss: 0.009494 | Test Accuracy: 0.817246, 0.689873\n",
      "Step 7 | High Training Loss: 1821618510553608617984.000000 ... Restoring Net\n",
      "INFO:tensorflow:Restoring parameters from dataset/tf_vae_only_vae_loss_nsl_kdd/hidden layers_15_features count_3/model-6\n",
      "Step 7 | Training Loss: 0.001168 | Test Loss: 0.006945 | Test Accuracy: 0.797418, 0.661013\n",
      "Step 8 | Training Loss: 0.002216 | Test Loss: 25304569856.000000 | Test Accuracy: 0.788902, 0.618059\n",
      "Step 9 | High Training Loss: inf ... Restoring Net\n",
      "INFO:tensorflow:Restoring parameters from dataset/tf_vae_only_vae_loss_nsl_kdd/hidden layers_15_features count_3/model-6\n",
      "Step 9 | Training Loss: 0.005736 | Test Loss: 0.012001 | Test Accuracy: 0.464603, 0.236287\n",
      "Step 10 | High Training Loss: 147411647081230630912.000000 ... Restoring Net\n",
      "INFO:tensorflow:Restoring parameters from dataset/tf_vae_only_vae_loss_nsl_kdd/hidden layers_15_features count_3/model-6\n",
      "Step 10 | Training Loss: 0.000223 | Test Loss: 0.003452 | Test Accuracy: 0.801544, 0.688101\n",
      "Step 11 | Training Loss: 0.000254 | Test Loss: 0.004945 | Test Accuracy: 0.791874, 0.715527\n",
      "Step 12 | Training Loss: 0.001545 | Test Loss: 0.028164 | Test Accuracy: 0.791741, 0.677806\n",
      "Step 13 | Training Loss: 0.000735 | Test Loss: 0.005131 | Test Accuracy: 0.752928, 0.677722\n",
      "Step 14 | Training Loss: 0.000431 | Test Loss: 0.006823 | Test Accuracy: 0.736870, 0.621603\n",
      "Step 15 | Training Loss: 0.000332 | Test Loss: 0.005734 | Test Accuracy: 0.764194, 0.748270\n",
      "Step 1 | Training Loss: 0.000074 | Test Loss: 0.003869 | Test Accuracy: 0.833171, 0.751224\n",
      "Step 2 | Training Loss: 0.000812 | Test Loss:    nan | Test Accuracy: 0.832771, 0.735359\n",
      "Step 3 | High Training Loss: nan ... Restoring Net\n",
      "INFO:tensorflow:Restoring parameters from dataset/tf_vae_only_vae_loss_nsl_kdd/hidden layers_15_features count_3/model-1\n",
      "Step 3 | Training Loss: 0.000769 | Test Loss: 0.003791 | Test Accuracy: 0.860672, 0.779916\n",
      "Step 4 | High Training Loss: 26314625451409013285112248270848.000000 ... Restoring Net\n",
      "INFO:tensorflow:Restoring parameters from dataset/tf_vae_only_vae_loss_nsl_kdd/hidden layers_15_features count_3/model-3\n",
      "Step 4 | Training Loss: 0.000022 | Test Loss: 46084816017393975296.000000 | Test Accuracy: 0.830154, 0.773418\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 5 | High Training Loss: inf ... Restoring Net\n",
      "INFO:tensorflow:Restoring parameters from dataset/tf_vae_only_vae_loss_nsl_kdd/hidden layers_15_features count_3/model-3\n",
      "Step 5 | Training Loss: 0.000244 | Test Loss: 0.015177 | Test Accuracy: 0.771336, 0.739831\n",
      "Step 6 | Training Loss: 0.000028 | Test Loss: 0.003691 | Test Accuracy: 0.828824, 0.777553\n",
      "Step 7 | Training Loss: 0.000158 | Test Loss: 0.003799 | Test Accuracy: 0.799636, 0.813080\n",
      "Step 8 | Training Loss: 0.000320 | Test Loss: 0.003485 | Test Accuracy: 0.825940, 0.821857\n",
      "Step 9 | Training Loss: 0.000788 | Test Loss: 0.003473 | Test Accuracy: 0.805447, 0.804641\n",
      "Step 10 | Training Loss: 0.000355 | Test Loss: 0.003478 | Test Accuracy: 0.815295, 0.807342\n",
      "Step 11 | Training Loss: 0.001143 | Test Loss: 0.005187 | Test Accuracy: 0.798483, 0.784304\n",
      "Step 12 | Training Loss: 0.000467 | Test Loss: 0.005605 | Test Accuracy: 0.751508, 0.797975\n",
      "Step 13 | Training Loss: 0.000330 | Test Loss: 0.004757 | Test Accuracy: 0.794801, 0.796118\n",
      "Step 14 | Training Loss: 0.000392 | Test Loss: 0.005169 | Test Accuracy: 0.802032, 0.808017\n",
      "Step 15 | Training Loss: 0.000625 | Test Loss: 0.005065 | Test Accuracy: 0.797551, 0.797637\n",
      "Step 1 | Training Loss: 0.000154 | Test Loss: 0.004974 | Test Accuracy: 0.797995, 0.807004\n",
      "Step 2 | Training Loss: 0.000249 | Test Loss: 0.004978 | Test Accuracy: 0.789878, 0.810633\n",
      "Step 3 | Training Loss: 0.000273 | Test Loss: 0.004892 | Test Accuracy: 0.786950, 0.810886\n",
      "Step 4 | Training Loss: 0.000069 | Test Loss: 0.004961 | Test Accuracy: 0.783712, 0.813165\n",
      "Step 5 | Training Loss: 0.000412 | Test Loss: 0.004899 | Test Accuracy: 0.788769, 0.812743\n",
      "Step 6 | Training Loss: 0.000042 | Test Loss: 0.005073 | Test Accuracy: 0.784022, 0.810633\n",
      "Step 7 | Training Loss: 0.000061 | Test Loss: 0.004945 | Test Accuracy: 0.787127, 0.809789\n",
      "Step 8 | Training Loss: 0.000143 | Test Loss: 0.004877 | Test Accuracy: 0.780562, 0.811139\n",
      "Step 9 | Training Loss: 0.000196 | Test Loss: 0.005006 | Test Accuracy: 0.781583, 0.812658\n",
      "Step 10 | Training Loss: 0.000515 | Test Loss: 0.004867 | Test Accuracy: 0.785043, 0.807848\n",
      "Step 11 | Training Loss: 0.000201 | Test Loss: 0.004919 | Test Accuracy: 0.780562, 0.808523\n",
      "Step 12 | Training Loss: 0.000320 | Test Loss: 0.005105 | Test Accuracy: 0.774397, 0.808439\n",
      "Step 13 | Training Loss: 0.000043 | Test Loss: 0.004945 | Test Accuracy: 0.780341, 0.809789\n",
      "Step 14 | Training Loss: 0.000502 | Test Loss: 0.005044 | Test Accuracy: 0.784510, 0.807848\n",
      "Step 15 | Training Loss: 0.000102 | Test Loss: 0.004990 | Test Accuracy: 0.784333, 0.808776\n",
      "Current Layer Attributes - epochs:15 hidden layers:3 features count:32\n",
      "Step 1 | Training Loss: 0.000444 | Test Loss: 0.003408 | Test Accuracy: 0.835078, 0.693671\n",
      "Step 2 | Training Loss: 0.003760 | Test Loss: 491086.625000 | Test Accuracy: 0.852644, 0.766329\n",
      "Step 3 | High Training Loss: 17412122624.000000 ... Restoring Net\n",
      "INFO:tensorflow:Restoring parameters from dataset/tf_vae_only_vae_loss_nsl_kdd/hidden layers_15_features count_3/model-2\n",
      "Step 3 | Training Loss: 0.001308 | Test Loss: 0.021354 | Test Accuracy: 0.794446, 0.787511\n",
      "Step 4 | Training Loss: 0.001428 | Test Loss: 0.016658 | Test Accuracy: 0.802653, 0.783460\n",
      "Step 5 | Training Loss: 0.000685 | Test Loss: 3.582757 | Test Accuracy: 0.831396, 0.785401\n",
      "Step 6 | Training Loss: 0.000845 | Test Loss: 0.013489 | Test Accuracy: 0.821416, 0.774262\n",
      "Step 7 | Training Loss: 0.000304 | Test Loss: 0.009652 | Test Accuracy: 0.816403, 0.783291\n",
      "Step 8 | Training Loss: 0.000049 | Test Loss: 0.009178 | Test Accuracy: 0.820041, 0.773924\n",
      "Step 9 | Training Loss: 0.000400 | Test Loss: 0.009079 | Test Accuracy: 0.820218, 0.764810\n",
      "Step 10 | Training Loss: 0.000062 | Test Loss: 0.011441 | Test Accuracy: 0.838183, 0.778481\n",
      "Step 11 | High Training Loss: inf ... Restoring Net\n",
      "INFO:tensorflow:Restoring parameters from dataset/tf_vae_only_vae_loss_nsl_kdd/hidden layers_15_features count_3/model-2\n",
      "Step 11 | Training Loss: 0.003083 | Test Loss: 0.033027 | Test Accuracy: 0.826473, 0.737384\n",
      "Step 12 | Training Loss: 0.007362 | Test Loss: 2673.445068 | Test Accuracy: 0.808730, 0.745401\n",
      "Step 13 | High Training Loss: 4172507136.000000 ... Restoring Net\n",
      "INFO:tensorflow:Restoring parameters from dataset/tf_vae_only_vae_loss_nsl_kdd/hidden layers_15_features count_3/model-2\n",
      "Step 13 | High Training Loss: 341186182233872702206115840.000000 ... Restoring Net\n",
      "INFO:tensorflow:Restoring parameters from dataset/tf_vae_only_vae_loss_nsl_kdd/hidden layers_15_features count_3/model-2\n",
      "Step 13 | High Training Loss: 88633458688.000000 ... Restoring Net\n",
      "INFO:tensorflow:Restoring parameters from dataset/tf_vae_only_vae_loss_nsl_kdd/hidden layers_15_features count_3/model-2\n",
      "Step 13 | Training Loss: 0.000189 | Test Loss: 0.009019 | Test Accuracy: 0.833925, 0.754852\n",
      "Step 14 | Training Loss: 0.000364 | Test Loss: 0.008234 | Test Accuracy: 0.822037, 0.710549\n",
      "Step 15 | Training Loss: 0.000581 | Test Loss: 0.005564 | Test Accuracy: 0.819021, 0.743713\n",
      "Step 1 | Training Loss: 0.000284 | Test Loss: 0.014763 | Test Accuracy: 0.788281, 0.749114\n",
      "Step 2 | Training Loss: 0.000539 | Test Loss: 0.382385 | Test Accuracy: 0.794358, 0.766414\n",
      "Step 3 | Training Loss: 0.002157 | Test Loss: 0.010252 | Test Accuracy: 0.790987, 0.725485\n",
      "Step 4 | Training Loss: 0.000671 | Test Loss: 0.007483 | Test Accuracy: 0.774619, 0.758734\n",
      "Step 5 | Training Loss: 0.000014 | Test Loss: 0.008301 | Test Accuracy: 0.771292, 0.771224\n",
      "Step 6 | Training Loss: 0.000538 | Test Loss: 0.008065 | Test Accuracy: 0.769207, 0.763713\n",
      "Step 7 | Training Loss: 0.000090 | Test Loss: 0.006720 | Test Accuracy: 0.782736, 0.767932\n",
      "Step 8 | Training Loss: 0.000125 | Test Loss: 0.008574 | Test Accuracy: 0.771513, 0.728945\n",
      "Step 9 | Training Loss: 0.000128 | Test Loss: 0.008604 | Test Accuracy: 0.786418, 0.746076\n",
      "Step 10 | Training Loss: 0.000517 | Test Loss: 0.010915 | Test Accuracy: 0.794934, 0.741181\n",
      "Step 11 | Training Loss: 0.000577 | Test Loss: 0.007396 | Test Accuracy: 0.784200, 0.780844\n",
      "Step 12 | Training Loss: 0.000640 | Test Loss: 0.007559 | Test Accuracy: 0.777191, 0.775696\n",
      "Step 13 | Training Loss: 0.000175 | Test Loss: 0.007987 | Test Accuracy: 0.783889, 0.762785\n",
      "Step 14 | Training Loss: 0.000487 | Test Loss: 0.009105 | Test Accuracy: 0.781228, 0.755612\n",
      "Step 15 | Training Loss: 0.000081 | Test Loss: 0.009687 | Test Accuracy: 0.775594, 0.770380\n",
      "Step 1 | Training Loss: 0.000065 | Test Loss: 0.009266 | Test Accuracy: 0.772134, 0.769620\n",
      "Step 2 | Training Loss: 0.000529 | Test Loss: 0.008785 | Test Accuracy: 0.771913, 0.769536\n",
      "Step 3 | Training Loss: 0.000035 | Test Loss: 0.008488 | Test Accuracy: 0.771114, 0.768861\n",
      "Step 4 | Training Loss: 0.000014 | Test Loss: 0.008270 | Test Accuracy: 0.771203, 0.769789\n",
      "Step 5 | Training Loss: 0.000138 | Test Loss: 0.007639 | Test Accuracy: 0.771336, 0.775274\n",
      "Step 6 | Training Loss: 0.000150 | Test Loss: 0.008080 | Test Accuracy: 0.775861, 0.768017\n",
      "Step 7 | Training Loss: 0.000132 | Test Loss: 0.007899 | Test Accuracy: 0.775461, 0.768608\n",
      "Step 8 | Training Loss: 0.000228 | Test Loss: 0.007884 | Test Accuracy: 0.775861, 0.767932\n",
      "Step 9 | Training Loss: 0.000049 | Test Loss: 0.007680 | Test Accuracy: 0.773199, 0.767511\n",
      "Step 10 | Training Loss: 0.000098 | Test Loss: 0.007503 | Test Accuracy: 0.770804, 0.767426\n",
      "Step 11 | Training Loss: 0.000313 | Test Loss: 0.007031 | Test Accuracy: 0.773731, 0.770549\n",
      "Step 12 | Training Loss: 0.000243 | Test Loss: 0.007268 | Test Accuracy: 0.775594, 0.770549\n",
      "Step 13 | Training Loss: 0.000413 | Test Loss: 0.007171 | Test Accuracy: 0.774707, 0.765401\n",
      "Step 14 | Training Loss: 0.000466 | Test Loss: 0.007133 | Test Accuracy: 0.775772, 0.770802\n",
      "Step 15 | Training Loss: 0.000015 | Test Loss: 0.007167 | Test Accuracy: 0.778877, 0.767342\n",
      "Current Layer Attributes - epochs:15 hidden layers:3 features count:122\n",
      "Step 1 | Training Loss: 0.000336 | Test Loss: 0.008927 | Test Accuracy: 0.811036, 0.650211\n",
      "Step 2 | Training Loss: 0.000495 | Test Loss: 0.009813 | Test Accuracy: 0.772489, 0.593502\n",
      "Step 3 | Training Loss: 0.000984 | Test Loss: 0.008888 | Test Accuracy: 0.722232, 0.503122\n",
      "Step 4 | Training Loss: 0.000059 | Test Loss: 0.007296 | Test Accuracy: 0.752218, 0.559916\n",
      "Step 5 | Training Loss: 0.000452 | Test Loss: 0.006496 | Test Accuracy: 0.750932, 0.562616\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 6 | Training Loss: 0.000048 | Test Loss: 0.006551 | Test Accuracy: 0.747339, 0.555274\n",
      "Step 7 | Training Loss: 0.000080 | Test Loss: 0.007011 | Test Accuracy: 0.737669, 0.547257\n",
      "Step 8 | Training Loss: 0.000231 | Test Loss: 0.006766 | Test Accuracy: 0.735140, 0.525485\n",
      "Step 9 | Training Loss: 0.000021 | Test Loss: 0.007842 | Test Accuracy: 0.708747, 0.481941\n",
      "Step 10 | Training Loss: 0.000594 | Test Loss: 0.007595 | Test Accuracy: 0.767078, 0.594768\n",
      "Step 11 | Training Loss: 0.000153 | Test Loss: 0.009384 | Test Accuracy: 0.665188, 0.438650\n",
      "Step 12 | Training Loss: 0.000024 | Test Loss: 0.006071 | Test Accuracy: 0.711143, 0.489030\n",
      "Step 13 | Training Loss: 0.000185 | Test Loss: 0.007291 | Test Accuracy: 0.712429, 0.496287\n",
      "Step 14 | Training Loss: 0.000092 | Test Loss: 0.006352 | Test Accuracy: 0.726446, 0.537300\n",
      "Step 15 | Training Loss: 0.000233 | Test Loss: 0.007558 | Test Accuracy: 0.727289, 0.530211\n",
      "Step 1 | Training Loss: 0.000248 | Test Loss: 0.009962 | Test Accuracy: 0.717397, 0.496371\n",
      "Step 2 | Training Loss: 0.000111 | Test Loss: 0.008398 | Test Accuracy: 0.724982, 0.512236\n",
      "Step 3 | Training Loss: 0.000006 | Test Loss: 0.007178 | Test Accuracy: 0.738068, 0.540338\n",
      "Step 4 | Training Loss: 0.000143 | Test Loss: 0.007131 | Test Accuracy: 0.735051, 0.525148\n",
      "Step 5 | Training Loss: 0.000361 | Test Loss: 0.008098 | Test Accuracy: 0.769163, 0.604135\n",
      "Step 6 | Training Loss: 0.000234 | Test Loss: 0.006847 | Test Accuracy: 0.734031, 0.539409\n",
      "Step 7 | Training Loss: 0.000046 | Test Loss: 0.010869 | Test Accuracy: 0.778389, 0.616203\n",
      "Step 8 | Training Loss: 0.000082 | Test Loss: 0.011251 | Test Accuracy: 0.690694, 0.479409\n",
      "Step 9 | Training Loss: 0.000153 | Test Loss: 0.009527 | Test Accuracy: 0.710965, 0.509030\n",
      "Step 10 | Training Loss: 0.000033 | Test Loss: 0.011849 | Test Accuracy: 0.738511, 0.529536\n",
      "Step 11 | Training Loss: 0.000503 | Test Loss: 0.010937 | Test Accuracy: 0.661285, 0.442278\n",
      "Step 12 | Training Loss: 0.000053 | Test Loss: 0.533581 | Test Accuracy: 0.718905, 0.507089\n",
      "Step 13 | Training Loss: 0.001091 | Test Loss: 0.010314 | Test Accuracy: 0.718728, 0.793333\n",
      "Step 14 | Training Loss: 0.000816 | Test Loss: 0.009430 | Test Accuracy: 0.778389, 0.771224\n",
      "Step 15 | Training Loss: 0.000170 | Test Loss: 0.007911 | Test Accuracy: 0.465357, 0.221181\n",
      "Step 1 | Training Loss: 0.000391 | Test Loss: 0.008778 | Test Accuracy: 0.478620, 0.243882\n",
      "Step 2 | Training Loss: 0.000173 | Test Loss: 0.008660 | Test Accuracy: 0.478353, 0.242532\n",
      "Step 3 | Training Loss: 0.000249 | Test Loss: 0.008135 | Test Accuracy: 0.479817, 0.244135\n",
      "Step 4 | Training Loss: 0.000389 | Test Loss: 0.008013 | Test Accuracy: 0.483233, 0.246498\n",
      "Step 5 | Training Loss: 0.000240 | Test Loss: 0.007764 | Test Accuracy: 0.487136, 0.253502\n",
      "Step 6 | Training Loss: 0.000299 | Test Loss: 0.007997 | Test Accuracy: 0.491128, 0.257890\n",
      "Step 7 | Training Loss: 0.000030 | Test Loss: 0.007467 | Test Accuracy: 0.487003, 0.251814\n",
      "Step 8 | Training Loss: 0.000095 | Test Loss: 0.007411 | Test Accuracy: 0.487225, 0.255612\n",
      "Step 9 | Training Loss: 0.000424 | Test Loss: 0.007062 | Test Accuracy: 0.485229, 0.250295\n",
      "Step 10 | Training Loss: 0.000264 | Test Loss: 0.007641 | Test Accuracy: 0.490685, 0.258397\n",
      "Step 11 | Training Loss: 0.000201 | Test Loss: 0.007153 | Test Accuracy: 0.487580, 0.256540\n",
      "Step 12 | Training Loss: 0.000653 | Test Loss: 0.007003 | Test Accuracy: 0.488689, 0.255443\n",
      "Step 13 | Training Loss: 0.000384 | Test Loss: 0.007166 | Test Accuracy: 0.489177, 0.256371\n",
      "Step 14 | Training Loss: 0.000224 | Test Loss: 0.007154 | Test Accuracy: 0.490020, 0.258650\n",
      "Step 15 | Training Loss: 0.000082 | Test Loss: 0.007091 | Test Accuracy: 0.489044, 0.258903\n",
      "Current Layer Attributes - epochs:15 hidden layers:5 features count:4\n",
      "Step 1 | Training Loss: 0.005399 | Test Loss: 0.006689 | Test Accuracy: 0.746274, 0.647511\n",
      "Step 2 | Training Loss: 0.001541 | Test Loss: 0.003314 | Test Accuracy: 0.785619, 0.698143\n",
      "Step 3 | Training Loss: 0.000488 | Test Loss: 0.003624 | Test Accuracy: 0.839957, 0.746329\n",
      "Step 4 | Training Loss: 0.000358 | Test Loss: 0.003268 | Test Accuracy: 0.826340, 0.728523\n",
      "Step 5 | Training Loss: 0.002864 | Test Loss: 0.006059 | Test Accuracy: 0.881875, 0.814515\n",
      "Step 6 | Training Loss: 0.001553 | Test Loss: 0.003277 | Test Accuracy: 0.855749, 0.784304\n",
      "Step 7 | Training Loss: 0.000896 | Test Loss: 0.003927 | Test Accuracy: 0.864487, 0.774852\n",
      "Step 8 | Training Loss: 0.002469 | Test Loss: 0.001184 | Test Accuracy: 0.884936, 0.817975\n",
      "Step 9 | Training Loss: 0.001292 | Test Loss: 0.005525 | Test Accuracy: 0.877972, 0.806751\n",
      "Step 10 | Training Loss: 0.000641 | Test Loss: 0.002893 | Test Accuracy: 0.875133, 0.804388\n",
      "Step 11 | Training Loss: 0.001099 | Test Loss: 0.004428 | Test Accuracy: 0.855749, 0.783207\n",
      "Step 12 | Training Loss: 0.000033 | Test Loss: 0.002819 | Test Accuracy: 0.886622, 0.803797\n",
      "Step 13 | Training Loss: 0.000472 | Test Loss: 0.002507 | Test Accuracy: 0.887642, 0.804304\n",
      "Step 14 | Training Loss: 0.000370 | Test Loss: 0.002483 | Test Accuracy: 0.880145, 0.807511\n",
      "Step 15 | Training Loss: 0.000387 | Test Loss: 0.001846 | Test Accuracy: 0.885069, 0.831983\n",
      "Step 1 | Training Loss: 0.000440 | Test Loss: 0.001543 | Test Accuracy: 0.894384, 0.838481\n",
      "Step 2 | Training Loss: 0.000822 | Test Loss: 0.002216 | Test Accuracy: 0.893896, 0.839240\n",
      "Step 3 | Training Loss: 0.000787 | Test Loss: 0.001505 | Test Accuracy: 0.854862, 0.782954\n",
      "Step 4 | Training Loss: 0.000767 | Test Loss: 0.003855 | Test Accuracy: 0.825186, 0.698143\n",
      "Step 5 | Training Loss: 0.000322 | Test Loss: 0.003927 | Test Accuracy: 0.837119, 0.712743\n",
      "Step 6 | Training Loss: 0.000055 | Test Loss: 0.001895 | Test Accuracy: 0.843595, 0.738059\n",
      "Step 7 | Training Loss: 0.000507 | Test Loss: 0.003409 | Test Accuracy: 0.847809, 0.729958\n",
      "Step 8 | Training Loss: 0.000422 | Test Loss: 0.002003 | Test Accuracy: 0.850869, 0.733418\n",
      "Step 9 | Training Loss: 0.000087 | Test Loss: 0.002428 | Test Accuracy: 0.860495, 0.749283\n",
      "Step 10 | Training Loss: 0.000089 | Test Loss: 0.001709 | Test Accuracy: 0.858987, 0.750802\n",
      "Step 11 | Training Loss: 0.000334 | Test Loss: 0.001706 | Test Accuracy: 0.836852, 0.733924\n",
      "Step 12 | Training Loss: 0.000727 | Test Loss: 0.001820 | Test Accuracy: 0.835699, 0.738987\n",
      "Step 13 | Training Loss: 0.000759 | Test Loss: 0.002714 | Test Accuracy: 0.809883, 0.686498\n",
      "Step 14 | Training Loss: 0.000352 | Test Loss: 0.001831 | Test Accuracy: 0.806024, 0.676709\n",
      "Step 15 | Training Loss: 0.000381 | Test Loss: 0.002189 | Test Accuracy: 0.825985, 0.715359\n",
      "Step 1 | Training Loss: 0.000167 | Test Loss: 0.002228 | Test Accuracy: 0.829312, 0.720169\n",
      "Step 2 | Training Loss: 0.000033 | Test Loss: 0.002374 | Test Accuracy: 0.826872, 0.714937\n",
      "Step 3 | Training Loss: 0.000378 | Test Loss: 0.002437 | Test Accuracy: 0.823767, 0.714262\n",
      "Step 4 | Training Loss: 0.000045 | Test Loss: 0.002231 | Test Accuracy: 0.827094, 0.712743\n",
      "Step 5 | Training Loss: 0.000064 | Test Loss: 0.002498 | Test Accuracy: 0.826916, 0.717215\n",
      "Step 6 | Training Loss: 0.000187 | Test Loss: 0.002154 | Test Accuracy: 0.826783, 0.716203\n",
      "Step 7 | Training Loss: 0.001264 | Test Loss: 0.002750 | Test Accuracy: 0.824344, 0.716034\n",
      "Step 8 | Training Loss: 0.000048 | Test Loss: 0.002448 | Test Accuracy: 0.825940, 0.711899\n",
      "Step 9 | Training Loss: 0.000285 | Test Loss: 0.002274 | Test Accuracy: 0.824876, 0.713840\n",
      "Step 10 | Training Loss: 0.000427 | Test Loss: 0.002233 | Test Accuracy: 0.826783, 0.714515\n",
      "Step 11 | Training Loss: 0.000217 | Test Loss: 0.002362 | Test Accuracy: 0.826961, 0.715105\n",
      "Step 12 | Training Loss: 0.000177 | Test Loss: 0.002492 | Test Accuracy: 0.826783, 0.715021\n",
      "Step 13 | Training Loss: 0.000016 | Test Loss: 0.002405 | Test Accuracy: 0.827715, 0.719578\n",
      "Step 14 | Training Loss: 0.000294 | Test Loss: 0.002287 | Test Accuracy: 0.828513, 0.718481\n",
      "Step 15 | Training Loss: 0.000195 | Test Loss: 0.002275 | Test Accuracy: 0.826162, 0.715190\n",
      "Current Layer Attributes - epochs:15 hidden layers:5 features count:8\n",
      "Step 1 | Training Loss: 0.001200 | Test Loss: 0.003171 | Test Accuracy: 0.702005, 0.643460\n",
      "Step 2 | Training Loss: 0.001761 | Test Loss: 0.005785 | Test Accuracy: 0.697392, 0.602869\n",
      "Step 3 | Training Loss: 0.000574 | Test Loss: 0.003315 | Test Accuracy: 0.722143, 0.579662\n",
      "Step 4 | Training Loss: 0.000432 | Test Loss: 0.003331 | Test Accuracy: 0.700319, 0.556540\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 5 | Training Loss: 0.000053 | Test Loss: 0.004857 | Test Accuracy: 0.647401, 0.421266\n",
      "Step 6 | Training Loss: 0.001331 | Test Loss: 0.007529 | Test Accuracy: 0.577936, 0.356371\n",
      "Step 7 | Training Loss: 0.000890 | Test Loss: 0.002974 | Test Accuracy: 0.706219, 0.504473\n",
      "Step 8 | Training Loss: 0.000262 | Test Loss: 0.003449 | Test Accuracy: 0.683419, 0.437131\n",
      "Step 9 | Training Loss: 0.000055 | Test Loss: 0.002961 | Test Accuracy: 0.700275, 0.491730\n",
      "Step 10 | Training Loss: 0.000480 | Test Loss: 0.002835 | Test Accuracy: 0.712119, 0.507257\n",
      "Step 11 | Training Loss: 0.000276 | Test Loss: 0.006097 | Test Accuracy: 0.676765, 0.414262\n",
      "Step 12 | Training Loss: 0.002061 | Test Loss: 0.008707 | Test Accuracy: 0.768630, 0.615021\n",
      "Step 13 | Training Loss: 0.003022 | Test Loss: 0.003497 | Test Accuracy: 0.775639, 0.673502\n",
      "Step 14 | Training Loss: 0.000717 | Test Loss: 0.002577 | Test Accuracy: 0.849184, 0.768101\n",
      "Step 15 | Training Loss: 0.000018 | Test Loss: 0.002161 | Test Accuracy: 0.838139, 0.759662\n",
      "Step 1 | Training Loss: 0.000242 | Test Loss: 0.002203 | Test Accuracy: 0.818710, 0.767089\n",
      "Step 2 | Training Loss: 0.000539 | Test Loss: 0.002298 | Test Accuracy: 0.810859, 0.776709\n",
      "Step 3 | Training Loss: 0.000894 | Test Loss: 0.003863 | Test Accuracy: 0.816581, 0.797300\n",
      "Step 4 | Training Loss: 0.000495 | Test Loss: 0.002676 | Test Accuracy: 0.832062, 0.784051\n",
      "Step 5 | Training Loss: 0.000497 | Test Loss: 0.001692 | Test Accuracy: 0.841954, 0.767089\n",
      "Step 6 | Training Loss: 0.000496 | Test Loss: 0.003201 | Test Accuracy: 0.835300, 0.776371\n",
      "Step 7 | Training Loss: 0.000697 | Test Loss: 0.002842 | Test Accuracy: 0.843994, 0.778397\n",
      "Step 8 | Training Loss: 0.000034 | Test Loss: 0.002279 | Test Accuracy: 0.837207, 0.751983\n",
      "Step 9 | Training Loss: 0.000896 | Test Loss: 0.005098 | Test Accuracy: 0.702803, 0.723544\n",
      "Step 10 | Training Loss: 0.000442 | Test Loss: 0.002568 | Test Accuracy: 0.807000, 0.779494\n",
      "Step 11 | Training Loss: 0.000118 | Test Loss: 0.002270 | Test Accuracy: 0.846611, 0.791899\n",
      "Step 12 | Training Loss: 0.000352 | Test Loss: 0.002945 | Test Accuracy: 0.836941, 0.789451\n",
      "Step 13 | Training Loss: 0.000083 | Test Loss: 0.002945 | Test Accuracy: 0.841288, 0.790970\n",
      "Step 14 | Training Loss: 0.000745 | Test Loss: 0.006944 | Test Accuracy: 0.636932, 0.798650\n",
      "Step 15 | Training Loss: 0.000937 | Test Loss: 0.001776 | Test Accuracy: 0.791297, 0.792827\n",
      "Step 1 | Training Loss: 0.000136 | Test Loss: 0.002518 | Test Accuracy: 0.789123, 0.792574\n",
      "Step 2 | Training Loss: 0.000037 | Test Loss: 0.002121 | Test Accuracy: 0.793692, 0.791646\n",
      "Step 3 | Training Loss: 0.000669 | Test Loss: 0.002361 | Test Accuracy: 0.792983, 0.791392\n",
      "Step 4 | Training Loss: 0.000275 | Test Loss: 0.002180 | Test Accuracy: 0.793737, 0.793418\n",
      "Step 5 | Training Loss: 0.000597 | Test Loss: 0.002666 | Test Accuracy: 0.792628, 0.795021\n",
      "Step 6 | Training Loss: 0.000290 | Test Loss: 0.002842 | Test Accuracy: 0.791829, 0.792321\n",
      "Step 7 | Training Loss: 0.000194 | Test Loss: 0.002948 | Test Accuracy: 0.784067, 0.791983\n",
      "Step 8 | Training Loss: 0.000053 | Test Loss: 0.002770 | Test Accuracy: 0.784998, 0.792068\n",
      "Step 9 | Training Loss: 0.000643 | Test Loss: 0.002787 | Test Accuracy: 0.789611, 0.791561\n",
      "Step 10 | Training Loss: 0.000471 | Test Loss: 0.002870 | Test Accuracy: 0.784599, 0.789620\n",
      "Step 11 | Training Loss: 0.000879 | Test Loss: 0.002843 | Test Accuracy: 0.781006, 0.795359\n",
      "Step 12 | Training Loss: 0.000016 | Test Loss: 0.003024 | Test Accuracy: 0.777679, 0.796962\n",
      "Step 13 | Training Loss: 0.000294 | Test Loss: 0.003518 | Test Accuracy: 0.755678, 0.799241\n",
      "Step 14 | Training Loss: 0.000273 | Test Loss: 0.004095 | Test Accuracy: 0.741528, 0.798987\n",
      "Step 15 | Training Loss: 0.000014 | Test Loss: 0.004138 | Test Accuracy: 0.743568, 0.797890\n",
      "Current Layer Attributes - epochs:15 hidden layers:5 features count:32\n",
      "Step 1 | Training Loss: 0.000280 | Test Loss: 0.004892 | Test Accuracy: 0.669668, 0.488186\n",
      "Step 2 | Training Loss: 0.000074 | Test Loss: 0.004208 | Test Accuracy: 0.813254, 0.687595\n",
      "Step 3 | Training Loss: 0.000601 | Test Loss: 0.004593 | Test Accuracy: 0.852511, 0.779240\n",
      "Step 4 | High Training Loss: 453937332224.000000 ... Restoring Net\n",
      "INFO:tensorflow:Restoring parameters from dataset/tf_vae_only_vae_loss_nsl_kdd/hidden layers_15_features count_5/model-3\n",
      "Step 4 | Training Loss: 0.000650 | Test Loss: 0.005530 | Test Accuracy: 0.823856, 0.693671\n",
      "Step 5 | Training Loss: 0.000199 | Test Loss: 0.004233 | Test Accuracy: 0.821505, 0.684895\n",
      "Step 6 | Training Loss: 0.000058 | Test Loss: 0.004876 | Test Accuracy: 0.814984, 0.679325\n",
      "Step 7 | Training Loss: 0.000243 | Test Loss: 0.003911 | Test Accuracy: 0.820795, 0.691730\n",
      "Step 8 | Training Loss: 0.000452 | Test Loss: 0.005603 | Test Accuracy: 0.764949, 0.718734\n",
      "Step 9 | Training Loss: 0.000160 | Test Loss: 0.004113 | Test Accuracy: 0.836187, 0.729367\n",
      "Step 10 | Training Loss: 0.000718 | Test Loss: 0.004110 | Test Accuracy: 0.833747, 0.721519\n",
      "Step 11 | Training Loss: 0.001190 | Test Loss: 0.004356 | Test Accuracy: 0.811835, 0.692152\n",
      "Step 12 | Training Loss: 0.000341 | Test Loss: 0.004567 | Test Accuracy: 0.807266, 0.732743\n",
      "Step 13 | Training Loss: 0.000133 | Test Loss: 0.003957 | Test Accuracy: 0.834901, 0.754768\n",
      "Step 14 | Training Loss: 0.000508 | Test Loss: 0.006342 | Test Accuracy: 0.804116, 0.786751\n",
      "Step 15 | Training Loss: 0.000602 | Test Loss: 0.005980 | Test Accuracy: 0.774175, 0.775865\n",
      "Step 1 | Training Loss: 0.001357 | Test Loss: 0.004352 | Test Accuracy: 0.850648, 0.745654\n",
      "Step 2 | Training Loss: 0.000365 | Test Loss: 0.003603 | Test Accuracy: 0.850781, 0.741097\n",
      "Step 3 | Training Loss: 0.000386 | Test Loss: 0.003596 | Test Accuracy: 0.849006, 0.760759\n",
      "Step 4 | Training Loss: 0.000291 | Test Loss: 0.003019 | Test Accuracy: 0.849982, 0.755865\n",
      "Step 5 | Training Loss: 0.001032 | Test Loss: 0.006650 | Test Accuracy: 0.740907, 0.791814\n",
      "Step 6 | Training Loss: 0.000012 | Test Loss: 0.004417 | Test Accuracy: 0.826694, 0.697215\n",
      "Step 7 | Training Loss: 0.000379 | Test Loss: 0.005221 | Test Accuracy: 0.819065, 0.704895\n",
      "Step 8 | Training Loss: 0.000094 | Test Loss: 0.004431 | Test Accuracy: 0.835433, 0.696203\n",
      "Step 9 | Training Loss: 0.000082 | Test Loss: 0.004872 | Test Accuracy: 0.820307, 0.670464\n",
      "Step 10 | Training Loss: 0.000183 | Test Loss: 0.004987 | Test Accuracy: 0.788103, 0.610633\n",
      "Step 11 | Training Loss: 0.000062 | Test Loss: 0.004340 | Test Accuracy: 0.777901, 0.588101\n",
      "Step 12 | Training Loss: 0.000348 | Test Loss: 0.004878 | Test Accuracy: 0.781405, 0.595527\n",
      "Step 13 | Training Loss: 0.000649 | Test Loss: 0.003620 | Test Accuracy: 0.782292, 0.598059\n",
      "Step 14 | Training Loss: 0.000398 | Test Loss: 0.004010 | Test Accuracy: 0.782647, 0.599240\n",
      "Step 15 | Training Loss: 0.000864 | Test Loss: 0.004744 | Test Accuracy: 0.618125, 0.465485\n",
      "Step 1 | Training Loss: 0.000106 | Test Loss: 0.003953 | Test Accuracy: 0.630456, 0.478312\n",
      "Step 2 | Training Loss: 0.000211 | Test Loss: 0.002871 | Test Accuracy: 0.681556, 0.537975\n",
      "Step 3 | Training Loss: 0.000287 | Test Loss: 0.001819 | Test Accuracy: 0.733632, 0.552405\n",
      "Step 4 | Training Loss: 0.000151 | Test Loss: 0.002273 | Test Accuracy: 0.709679, 0.551899\n",
      "Step 5 | Training Loss: 0.000406 | Test Loss: 0.003004 | Test Accuracy: 0.678318, 0.542363\n",
      "Step 6 | Training Loss: 0.000443 | Test Loss: 0.003846 | Test Accuracy: 0.641146, 0.499156\n",
      "Step 7 | Training Loss: 0.000449 | Test Loss: 0.003430 | Test Accuracy: 0.639150, 0.491055\n",
      "Step 8 | Training Loss: 0.000052 | Test Loss: 0.003289 | Test Accuracy: 0.640481, 0.492489\n",
      "Step 9 | Training Loss: 0.000066 | Test Loss: 0.003305 | Test Accuracy: 0.643719, 0.492911\n",
      "Step 10 | Training Loss: 0.000082 | Test Loss: 0.003379 | Test Accuracy: 0.640525, 0.491392\n",
      "Step 11 | Training Loss: 0.000390 | Test Loss: 0.002996 | Test Accuracy: 0.640836, 0.489198\n",
      "Step 12 | Training Loss: 0.000214 | Test Loss: 0.003185 | Test Accuracy: 0.631343, 0.475105\n",
      "Step 13 | Training Loss: 0.000006 | Test Loss: 0.003024 | Test Accuracy: 0.627218, 0.470717\n",
      "Step 14 | Training Loss: 0.000146 | Test Loss: 0.002958 | Test Accuracy: 0.622205, 0.457046\n",
      "Step 15 | Training Loss: 0.000140 | Test Loss: 0.003053 | Test Accuracy: 0.634404, 0.478565\n",
      "Current Layer Attributes - epochs:15 hidden layers:5 features count:122\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 1 | Training Loss: 0.000796 | Test Loss: 0.003853 | Test Accuracy: 0.823678, 0.704219\n",
      "Step 2 | Training Loss: 0.001726 | Test Loss: 0.009079 | Test Accuracy: 0.802608, 0.676371\n",
      "Step 3 | Training Loss: 0.000582 | Test Loss: 0.006755 | Test Accuracy: 0.759803, 0.587089\n",
      "Step 4 | Training Loss: 0.000074 | Test Loss: 0.008030 | Test Accuracy: 0.543471, 0.280675\n",
      "Step 5 | Training Loss: 0.001359 | Test Loss: 1.172646 | Test Accuracy: 0.579622, 0.415949\n",
      "Step 6 | Training Loss: 0.001335 | Test Loss: 0.005927 | Test Accuracy: 0.502795, 0.249367\n",
      "Step 7 | Training Loss: 0.001361 | Test Loss: 0.005988 | Test Accuracy: 0.555935, 0.352321\n",
      "Step 8 | Training Loss: 0.001939 | Test Loss: 0.005990 | Test Accuracy: 0.511888, 0.275359\n",
      "Step 9 | Training Loss: 0.000426 | Test Loss: 0.006144 | Test Accuracy: 0.524264, 0.282363\n",
      "Step 10 | Training Loss: 0.001546 | Test Loss: 0.004872 | Test Accuracy: 0.519118, 0.276709\n",
      "Step 11 | Training Loss: 0.001838 | Test Loss: 0.006991 | Test Accuracy: 0.518852, 0.273249\n",
      "Step 12 | Training Loss: 0.001919 | Test Loss: 0.007451 | Test Accuracy: 0.519650, 0.332743\n",
      "Step 13 | Training Loss: 0.000194 | Test Loss: 0.005807 | Test Accuracy: 0.513307, 0.261688\n",
      "Step 14 | Training Loss: 0.000124 | Test Loss: 0.005471 | Test Accuracy: 0.515481, 0.267089\n",
      "Step 15 | Training Loss: 0.000627 | Test Loss: 0.005177 | Test Accuracy: 0.523332, 0.280000\n",
      "Step 1 | Training Loss: 0.000548 | Test Loss: 0.004419 | Test Accuracy: 0.524752, 0.285738\n",
      "Step 2 | Training Loss: 0.000464 | Test Loss: 0.004330 | Test Accuracy: 0.579933, 0.381181\n",
      "Step 3 | Training Loss: 0.000653 | Test Loss: 0.005077 | Test Accuracy: 0.589336, 0.402700\n",
      "Step 4 | Training Loss: 0.000214 | Test Loss: 0.004184 | Test Accuracy: 0.570662, 0.375949\n",
      "Step 5 | Training Loss: 0.000082 | Test Loss: 0.003530 | Test Accuracy: 0.598385, 0.419072\n",
      "Step 6 | Training Loss: 0.003034 | Test Loss: 0.001877 | Test Accuracy: 0.569420, 0.818143\n",
      "Step 7 | Training Loss: 0.000324 | Test Loss: 0.003866 | Test Accuracy: 0.589115, 0.399916\n",
      "Step 8 | Training Loss: 0.000177 | Test Loss: 0.003035 | Test Accuracy: 0.590667, 0.403376\n",
      "Step 9 | Training Loss: 0.000097 | Test Loss: 0.003156 | Test Accuracy: 0.581485, 0.387342\n",
      "Step 10 | Training Loss: 0.000199 | Test Loss: 0.003580 | Test Accuracy: 0.580953, 0.386667\n",
      "Step 11 | Training Loss: 0.000553 | Test Loss: 0.002609 | Test Accuracy: 0.581086, 0.386920\n",
      "Step 12 | Training Loss: 0.000196 | Test Loss: 0.002835 | Test Accuracy: 0.580864, 0.386245\n",
      "Step 13 | Training Loss: 0.000948 | Test Loss: 0.003741 | Test Accuracy: 0.580997, 0.386667\n",
      "Step 14 | Training Loss: 0.000826 | Test Loss: 0.002146 | Test Accuracy: 0.581086, 0.386751\n",
      "Step 15 | Training Loss: 0.000170 | Test Loss: 0.001983 | Test Accuracy: 0.581441, 0.386835\n",
      "Step 1 | Training Loss: 0.000284 | Test Loss: 0.002080 | Test Accuracy: 0.581352, 0.386835\n",
      "Step 2 | Training Loss: 0.000267 | Test Loss: 0.002277 | Test Accuracy: 0.581441, 0.386920\n",
      "Step 3 | Training Loss: 0.000451 | Test Loss: 0.002032 | Test Accuracy: 0.581308, 0.386835\n",
      "Step 4 | Training Loss: 0.000163 | Test Loss: 0.002071 | Test Accuracy: 0.581352, 0.386835\n",
      "Step 5 | Training Loss: 0.000068 | Test Loss: 0.001999 | Test Accuracy: 0.581796, 0.388186\n",
      "Step 6 | Training Loss: 0.000048 | Test Loss: 0.002018 | Test Accuracy: 0.581796, 0.388017\n",
      "Step 7 | Training Loss: 0.000095 | Test Loss: 0.002098 | Test Accuracy: 0.581529, 0.388523\n",
      "Step 8 | Training Loss: 0.000099 | Test Loss: 0.001984 | Test Accuracy: 0.581263, 0.389030\n",
      "Step 9 | Training Loss: 0.000147 | Test Loss: 0.001798 | Test Accuracy: 0.581840, 0.389705\n",
      "Step 10 | Training Loss: 0.000286 | Test Loss: 0.001820 | Test Accuracy: 0.581707, 0.388017\n",
      "Step 11 | Training Loss: 0.000060 | Test Loss: 0.001725 | Test Accuracy: 0.581840, 0.388017\n",
      "Step 12 | Training Loss: 0.000146 | Test Loss: 0.001878 | Test Accuracy: 0.581308, 0.387848\n",
      "Step 13 | Training Loss: 0.000130 | Test Loss: 0.001874 | Test Accuracy: 0.581796, 0.388186\n",
      "Step 14 | Training Loss: 0.000233 | Test Loss: 0.001687 | Test Accuracy: 0.581751, 0.388439\n",
      "Step 15 | Training Loss: 0.000152 | Test Loss: 0.001719 | Test Accuracy: 0.581663, 0.388608\n",
      "Current Layer Attributes - epochs:15 hidden layers:3 features count:4\n",
      "Step 1 | Training Loss: 0.000849 | Test Loss: 0.002918 | Test Accuracy: 0.802209, 0.666076\n",
      "Step 2 | Training Loss: 0.000045 | Test Loss: 0.004560 | Test Accuracy: 0.809351, 0.673671\n",
      "Step 3 | Training Loss: 0.000552 | Test Loss: 0.003379 | Test Accuracy: 0.836231, 0.737975\n",
      "Step 4 | Training Loss: 0.001284 | Test Loss: 0.006504 | Test Accuracy: 0.776304, 0.616709\n",
      "Step 5 | Training Loss: 0.000568 | Test Loss: 0.006052 | Test Accuracy: 0.756432, 0.617131\n",
      "Step 6 | Training Loss: 0.001168 | Test Loss: 0.005146 | Test Accuracy: 0.768586, 0.595865\n",
      "Step 7 | Training Loss: 0.000202 | Test Loss: 0.005770 | Test Accuracy: 0.803407, 0.688017\n",
      "Step 8 | Training Loss: 0.001580 | Test Loss: 0.006124 | Test Accuracy: 0.757363, 0.586329\n",
      "Step 9 | Training Loss: 0.000668 | Test Loss: 0.006124 | Test Accuracy: 0.743125, 0.608523\n",
      "Step 10 | Training Loss: 0.000338 | Test Loss: 0.007197 | Test Accuracy: 0.737358, 0.545063\n",
      "Step 11 | Training Loss: 0.000547 | Test Loss: 0.006200 | Test Accuracy: 0.775727, 0.620844\n",
      "Step 12 | Training Loss: 0.000970 | Test Loss: 0.005169 | Test Accuracy: 0.790099, 0.645823\n",
      "Step 13 | Training Loss: 0.000225 | Test Loss: 0.004756 | Test Accuracy: 0.793825, 0.644895\n",
      "Step 14 | Training Loss: 0.000406 | Test Loss: 0.002341 | Test Accuracy: 0.775461, 0.646667\n",
      "Step 15 | Training Loss: 0.000634 | Test Loss: 0.003973 | Test Accuracy: 0.770005, 0.584304\n",
      "Step 1 | Training Loss: 0.000768 | Test Loss: 0.003926 | Test Accuracy: 0.774264, 0.603460\n",
      "Step 2 | Training Loss: 0.000046 | Test Loss: 0.005321 | Test Accuracy: 0.770893, 0.583207\n",
      "Step 3 | Training Loss: 0.000494 | Test Loss: 0.002784 | Test Accuracy: 0.817291, 0.720506\n",
      "Step 4 | Training Loss: 0.000923 | Test Loss: 0.002340 | Test Accuracy: 0.845724, 0.749789\n",
      "Step 5 | Training Loss: 0.000741 | Test Loss: 0.002740 | Test Accuracy: 0.850071, 0.738819\n",
      "Step 6 | Training Loss: 0.000224 | Test Loss: 0.002760 | Test Accuracy: 0.839425, 0.717131\n",
      "Step 7 | Training Loss: 0.000738 | Test Loss: 0.003839 | Test Accuracy: 0.830820, 0.702194\n",
      "Step 8 | Training Loss: 0.000217 | Test Loss: 0.003758 | Test Accuracy: 0.836453, 0.703713\n",
      "Step 9 | Training Loss: 0.000114 | Test Loss: 0.002817 | Test Accuracy: 0.818621, 0.691646\n",
      "Step 10 | Training Loss: 0.000274 | Test Loss: 0.003719 | Test Accuracy: 0.829356, 0.691477\n",
      "Step 11 | Training Loss: 0.000159 | Test Loss: 0.002786 | Test Accuracy: 0.821859, 0.684895\n",
      "Step 12 | Training Loss: 0.000089 | Test Loss: 0.004686 | Test Accuracy: 0.778966, 0.597975\n",
      "Step 13 | Training Loss: 0.000454 | Test Loss: 0.003680 | Test Accuracy: 0.728487, 0.512911\n",
      "Step 14 | Training Loss: 0.000162 | Test Loss: 0.004338 | Test Accuracy: 0.722321, 0.488608\n",
      "Step 15 | Training Loss: 0.000283 | Test Loss: 0.004130 | Test Accuracy: 0.707417, 0.465738\n",
      "Step 1 | Training Loss: 0.000098 | Test Loss: 0.003418 | Test Accuracy: 0.707106, 0.464979\n",
      "Step 2 | Training Loss: 0.000250 | Test Loss: 0.003134 | Test Accuracy: 0.708348, 0.463797\n",
      "Step 3 | Training Loss: 0.000083 | Test Loss: 0.002979 | Test Accuracy: 0.710788, 0.467679\n",
      "Step 4 | Training Loss: 0.000210 | Test Loss: 0.003044 | Test Accuracy: 0.709856, 0.468523\n",
      "Step 5 | Training Loss: 0.000150 | Test Loss: 0.003276 | Test Accuracy: 0.709901, 0.467257\n",
      "Step 6 | Training Loss: 0.000035 | Test Loss: 0.003139 | Test Accuracy: 0.708792, 0.463544\n",
      "Step 7 | Training Loss: 0.000101 | Test Loss: 0.002984 | Test Accuracy: 0.708703, 0.463797\n",
      "Step 8 | Training Loss: 0.000333 | Test Loss: 0.002763 | Test Accuracy: 0.708659, 0.466413\n",
      "Step 9 | Training Loss: 0.000330 | Test Loss: 0.002853 | Test Accuracy: 0.708481, 0.464726\n",
      "Step 10 | Training Loss: 0.000218 | Test Loss: 0.002813 | Test Accuracy: 0.711276, 0.466329\n",
      "Step 11 | Training Loss: 0.000180 | Test Loss: 0.002939 | Test Accuracy: 0.710788, 0.465063\n",
      "Step 12 | Training Loss: 0.000344 | Test Loss: 0.002736 | Test Accuracy: 0.713183, 0.470970\n",
      "Step 13 | Training Loss: 0.000658 | Test Loss: 0.002532 | Test Accuracy: 0.713050, 0.471139\n",
      "Step 14 | Training Loss: 0.000031 | Test Loss: 0.002538 | Test Accuracy: 0.714957, 0.472236\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 15 | Training Loss: 0.000406 | Test Loss: 0.002580 | Test Accuracy: 0.715046, 0.475865\n",
      "Current Layer Attributes - epochs:15 hidden layers:3 features count:8\n",
      "Step 1 | Training Loss: 0.000350 | Test Loss: 0.007818 | Test Accuracy: 0.785531, 0.617975\n",
      "Step 2 | Training Loss: 0.000667 | Test Loss: 0.007308 | Test Accuracy: 0.771159, 0.593671\n",
      "Step 3 | Training Loss: 0.000604 | Test Loss: 0.008927 | Test Accuracy: 0.771070, 0.603544\n",
      "Step 4 | Training Loss: 0.002147 | Test Loss: 0.008470 | Test Accuracy: 0.798128, 0.679662\n",
      "Step 5 | Training Loss: 0.000070 | Test Loss: 0.006349 | Test Accuracy: 0.824743, 0.718903\n",
      "Step 6 | High Training Loss: 201584992416782939586560.000000 ... Restoring Net\n",
      "INFO:tensorflow:Restoring parameters from dataset/tf_vae_only_vae_loss_nsl_kdd/hidden layers_15_features count_3/model-5\n",
      "Step 6 | Training Loss: 0.000599 | Test Loss: 0.006661 | Test Accuracy: 0.834989, 0.730717\n",
      "Step 7 | Training Loss: 0.000089 | Test Loss: 0.006081 | Test Accuracy: 0.829578, 0.718397\n",
      "Step 8 | Training Loss: 0.000976 | Test Loss: 0.005058 | Test Accuracy: 0.772844, 0.642363\n",
      "Step 9 | Training Loss: 0.000198 | Test Loss: 0.005348 | Test Accuracy: 0.781272, 0.685570\n",
      "Step 10 | Training Loss: 0.000152 | Test Loss: 0.005345 | Test Accuracy: 0.790898, 0.735359\n",
      "Step 11 | Training Loss: 0.000875 | Test Loss: 0.010822 | Test Accuracy: 0.771691, 0.717637\n",
      "Step 12 | Training Loss: 0.000167 | Test Loss: 0.003360 | Test Accuracy: 0.830110, 0.729536\n",
      "Step 13 | Training Loss: 0.000420 | Test Loss: 0.005221 | Test Accuracy: 0.822880, 0.726582\n",
      "Step 14 | Training Loss: 0.001794 | Test Loss: 0.006415 | Test Accuracy: 0.760335, 0.742025\n",
      "Step 15 | Training Loss: 0.000673 | Test Loss: 0.006490 | Test Accuracy: 0.780163, 0.725907\n",
      "Step 1 | Training Loss: 0.000475 | Test Loss: 0.006640 | Test Accuracy: 0.779010, 0.704979\n",
      "Step 2 | Training Loss: 0.000290 | Test Loss: 0.005540 | Test Accuracy: 0.795112, 0.747848\n",
      "Step 3 | Training Loss: 0.000015 | Test Loss: 0.006085 | Test Accuracy: 0.783357, 0.754008\n",
      "Step 4 | Training Loss: 0.000384 | Test Loss: 0.007119 | Test Accuracy: 0.759714, 0.773165\n",
      "Step 5 | Training Loss: 0.000085 | Test Loss: 0.006327 | Test Accuracy: 0.780341, 0.779747\n",
      "Step 6 | Training Loss: 0.000356 | Test Loss: 0.005980 | Test Accuracy: 0.780784, 0.782700\n",
      "Step 7 | Training Loss: 0.000133 | Test Loss: 0.007963 | Test Accuracy: 0.729862, 0.710127\n",
      "Step 8 | High Training Loss: 33548984320.000000 ... Restoring Net\n",
      "INFO:tensorflow:Restoring parameters from dataset/tf_vae_only_vae_loss_nsl_kdd/hidden layers_15_features count_3/model-6\n",
      "Step 8 | Training Loss: 0.000901 | Test Loss: 0.006453 | Test Accuracy: 0.783845, 0.636878\n",
      "Step 9 | Training Loss: 0.000721 | Test Loss: 0.004301 | Test Accuracy: 0.847143, 0.724135\n",
      "Step 10 | Training Loss: 0.000336 | Test Loss: 0.003630 | Test Accuracy: 0.854241, 0.754768\n",
      "Step 11 | Training Loss: 0.000343 | Test Loss: 0.005018 | Test Accuracy: 0.840578, 0.713165\n",
      "Step 12 | Training Loss: 0.000003 | Test Loss: 0.004915 | Test Accuracy: 0.845280, 0.720928\n",
      "Step 13 | Training Loss: 0.000200 | Test Loss: 0.004821 | Test Accuracy: 0.828203, 0.706667\n",
      "Step 14 | Training Loss: 0.000250 | Test Loss: 0.005310 | Test Accuracy: 0.816448, 0.758734\n",
      "Step 15 | Training Loss: 0.000169 | Test Loss: 0.005252 | Test Accuracy: 0.810282, 0.700759\n",
      "Step 1 | Training Loss: 0.000349 | Test Loss: 0.004837 | Test Accuracy: 0.809439, 0.707764\n",
      "Step 2 | Training Loss: 0.000437 | Test Loss: 0.004565 | Test Accuracy: 0.820351, 0.716793\n",
      "Step 3 | Training Loss: 0.000079 | Test Loss: 0.004476 | Test Accuracy: 0.816936, 0.720591\n",
      "Step 4 | Training Loss: 0.000173 | Test Loss: 0.004494 | Test Accuracy: 0.813875, 0.709705\n",
      "Step 5 | Training Loss: 0.000040 | Test Loss: 0.004488 | Test Accuracy: 0.811613, 0.711561\n",
      "Step 6 | Training Loss: 0.000113 | Test Loss: 0.004415 | Test Accuracy: 0.815738, 0.710295\n",
      "Step 7 | Training Loss: 0.000144 | Test Loss: 0.004416 | Test Accuracy: 0.815250, 0.719325\n",
      "Step 8 | Training Loss: 0.000028 | Test Loss: 0.004399 | Test Accuracy: 0.818888, 0.730717\n",
      "Step 9 | Training Loss: 0.000187 | Test Loss: 0.004658 | Test Accuracy: 0.818976, 0.724895\n",
      "Step 10 | Training Loss: 0.000192 | Test Loss: 0.004709 | Test Accuracy: 0.813077, 0.722616\n",
      "Step 11 | Training Loss: 0.000034 | Test Loss: 0.004967 | Test Accuracy: 0.806246, 0.731392\n",
      "Step 12 | Training Loss: 0.000040 | Test Loss: 0.004865 | Test Accuracy: 0.809661, 0.736624\n",
      "Step 13 | Training Loss: 0.000130 | Test Loss: 0.004864 | Test Accuracy: 0.809084, 0.737131\n",
      "Step 14 | Training Loss: 0.000043 | Test Loss: 0.004689 | Test Accuracy: 0.815694, 0.736709\n",
      "Step 15 | Training Loss: 0.000130 | Test Loss: 0.004875 | Test Accuracy: 0.805625, 0.742532\n",
      "Current Layer Attributes - epochs:15 hidden layers:3 features count:32\n",
      "Step 1 | Training Loss: 0.002288 | Test Loss: 0.009562 | Test Accuracy: 0.825630, 0.770211\n",
      "Step 2 | Training Loss: 0.000430 | Test Loss: 0.007664 | Test Accuracy: 0.818045, 0.726920\n",
      "Step 3 | Training Loss: 0.000402 | Test Loss: 0.006759 | Test Accuracy: 0.821194, 0.719916\n",
      "Step 4 | Training Loss: 0.000191 | Test Loss: 0.009141 | Test Accuracy: 0.830420, 0.726920\n",
      "Step 5 | Training Loss: 0.000308 | Test Loss: 0.007788 | Test Accuracy: 0.802520, 0.719325\n",
      "Step 6 | Training Loss: 0.000832 | Test Loss: 0.008135 | Test Accuracy: 0.806068, 0.740591\n",
      "Step 7 | Training Loss: 0.000665 | Test Loss: 0.010455 | Test Accuracy: 0.795866, 0.664810\n",
      "Step 8 | Training Loss: 0.000646 | Test Loss: 0.007489 | Test Accuracy: 0.769296, 0.688017\n",
      "Step 9 | Training Loss: 0.000243 | Test Loss: 0.008642 | Test Accuracy: 0.756432, 0.634008\n",
      "Step 10 | Training Loss: 0.000426 | Test Loss: 0.008709 | Test Accuracy: 0.752484, 0.643966\n",
      "Step 11 | Training Loss: 0.000283 | Test Loss: 0.008782 | Test Accuracy: 0.718240, 0.610127\n",
      "Step 12 | Training Loss: 0.000125 | Test Loss: 0.008752 | Test Accuracy: 0.748226, 0.670886\n",
      "Step 13 | Training Loss: 0.000368 | Test Loss: 0.008135 | Test Accuracy: 0.743036, 0.628270\n",
      "Step 14 | Training Loss: 0.000221 | Test Loss: 0.009985 | Test Accuracy: 0.717929, 0.603544\n",
      "Step 15 | Training Loss: 0.000358 | Test Loss: 0.008373 | Test Accuracy: 0.778211, 0.682616\n",
      "Step 1 | Training Loss: 0.000069 | Test Loss: 0.009152 | Test Accuracy: 0.753770, 0.658143\n",
      "Step 2 | Training Loss: 0.000061 | Test Loss: 0.009815 | Test Accuracy: 0.761755, 0.724388\n",
      "Step 3 | Training Loss: 0.000134 | Test Loss: 0.010255 | Test Accuracy: 0.768630, 0.691814\n",
      "Step 4 | Training Loss: 0.000186 | Test Loss: 0.008941 | Test Accuracy: 0.766191, 0.754093\n",
      "Step 5 | Training Loss: 0.000150 | Test Loss: 0.011418 | Test Accuracy: 0.759626, 0.693924\n",
      "Step 6 | Training Loss: 0.000073 | Test Loss: 0.011179 | Test Accuracy: 0.746718, 0.681350\n",
      "Step 7 | Training Loss: 0.000139 | Test Loss: 0.009498 | Test Accuracy: 0.756521, 0.695527\n",
      "Step 8 | Training Loss: 0.000306 | Test Loss: 0.010606 | Test Accuracy: 0.725381, 0.655190\n",
      "Step 9 | Training Loss: 0.000133 | Test Loss: 0.009549 | Test Accuracy: 0.710433, 0.609536\n",
      "Step 10 | Training Loss: 0.000313 | Test Loss: 0.011227 | Test Accuracy: 0.706042, 0.585992\n",
      "Step 11 | Training Loss: 0.000390 | Test Loss: 0.011356 | Test Accuracy: 0.701207, 0.586498\n",
      "Step 12 | Training Loss: 0.000302 | Test Loss: 0.009596 | Test Accuracy: 0.733011, 0.661013\n",
      "Step 13 | Training Loss: 0.000074 | Test Loss: 0.011360 | Test Accuracy: 0.711631, 0.628776\n",
      "Step 14 | Training Loss: 0.000087 | Test Loss: 0.012451 | Test Accuracy: 0.692557, 0.617300\n",
      "Step 15 | Training Loss: 0.000268 | Test Loss: 0.012953 | Test Accuracy: 0.693133, 0.607257\n",
      "Step 1 | Training Loss: 0.000026 | Test Loss: 0.012211 | Test Accuracy: 0.695440, 0.611814\n",
      "Step 2 | Training Loss: 0.000062 | Test Loss: 0.012006 | Test Accuracy: 0.694908, 0.614177\n",
      "Step 3 | Training Loss: 0.000048 | Test Loss: 0.012464 | Test Accuracy: 0.693311, 0.610380\n",
      "Step 4 | Training Loss: 0.000112 | Test Loss: 0.012349 | Test Accuracy: 0.691936, 0.605738\n",
      "Step 5 | Training Loss: 0.000249 | Test Loss: 0.012149 | Test Accuracy: 0.691049, 0.603038\n",
      "Step 6 | Training Loss: 0.000041 | Test Loss: 0.012735 | Test Accuracy: 0.688653, 0.601435\n",
      "Step 7 | Training Loss: 0.000192 | Test Loss: 0.012418 | Test Accuracy: 0.690561, 0.606582\n",
      "Step 8 | Training Loss: 0.000094 | Test Loss: 0.012385 | Test Accuracy: 0.689585, 0.605316\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 9 | Training Loss: 0.000019 | Test Loss: 0.012292 | Test Accuracy: 0.690561, 0.610211\n",
      "Step 10 | Training Loss: 0.000044 | Test Loss: 0.012251 | Test Accuracy: 0.687988, 0.608354\n",
      "Step 11 | Training Loss: 0.000072 | Test Loss: 0.012404 | Test Accuracy: 0.687633, 0.608186\n",
      "Step 12 | Training Loss: 0.000089 | Test Loss: 0.012562 | Test Accuracy: 0.690472, 0.612574\n",
      "Step 13 | Training Loss: 0.000174 | Test Loss: 0.012367 | Test Accuracy: 0.691581, 0.627173\n",
      "Step 14 | Training Loss: 0.000096 | Test Loss: 0.012645 | Test Accuracy: 0.687456, 0.612827\n",
      "Step 15 | Training Loss: 0.000069 | Test Loss: 0.012429 | Test Accuracy: 0.688387, 0.618987\n",
      "Current Layer Attributes - epochs:15 hidden layers:3 features count:122\n",
      "Step 1 | Training Loss: 0.000009 | Test Loss: 0.076514 | Test Accuracy: 0.715135, 0.483713\n",
      "Step 2 | High Training Loss: 43928624855777280.000000 ... Restoring Net\n",
      "INFO:tensorflow:Restoring parameters from dataset/tf_vae_only_vae_loss_nsl_kdd/hidden layers_15_features count_3/model-1\n",
      "Step 2 | Training Loss: 0.000952 | Test Loss: 0.003207 | Test Accuracy: 0.831796, 0.714177\n",
      "Step 3 | Training Loss: 0.004294 | Test Loss: 0.072041 | Test Accuracy: 0.851579, 0.732405\n",
      "Step 4 | Training Loss: 0.000113 | Test Loss: 0.005720 | Test Accuracy: 0.807887, 0.706076\n",
      "Step 5 | Training Loss: 0.000362 | Test Loss: 0.005247 | Test Accuracy: 0.816980, 0.746414\n",
      "Step 6 | Training Loss: 0.000590 | Test Loss: 0.005655 | Test Accuracy: 0.810814, 0.778143\n",
      "Step 7 | Training Loss: 0.000390 | Test Loss: 0.006230 | Test Accuracy: 0.784909, 0.806414\n",
      "Step 8 | Training Loss: 0.000128 | Test Loss: 0.006675 | Test Accuracy: 0.779232, 0.777553\n",
      "Step 9 | Training Loss: 0.000499 | Test Loss: 0.007624 | Test Accuracy: 0.777457, 0.756540\n",
      "Step 10 | Training Loss: 0.000706 | Test Loss: 0.010689 | Test Accuracy: 0.782470, 0.750802\n",
      "Step 11 | Training Loss: 0.000101 | Test Loss: 0.007573 | Test Accuracy: 0.762997, 0.776625\n",
      "Step 12 | Training Loss: 0.000178 | Test Loss: 0.008401 | Test Accuracy: 0.763174, 0.779578\n",
      "Step 13 | Training Loss: 0.000193 | Test Loss: 0.008618 | Test Accuracy: 0.754524, 0.784557\n",
      "Step 14 | Training Loss: 0.001092 | Test Loss: 0.009124 | Test Accuracy: 0.712473, 0.814262\n",
      "Step 15 | Training Loss: 0.000144 | Test Loss: 0.008235 | Test Accuracy: 0.744500, 0.781013\n",
      "Step 1 | Training Loss: 0.000033 | Test Loss: 0.009683 | Test Accuracy: 0.707638, 0.730295\n",
      "Step 2 | Training Loss: 0.000295 | Test Loss: 0.009080 | Test Accuracy: 0.709679, 0.779662\n",
      "Step 3 | Training Loss: 0.000059 | Test Loss: 0.011448 | Test Accuracy: 0.707328, 0.726160\n",
      "Step 4 | Training Loss: 0.000720 | Test Loss: 0.010157 | Test Accuracy: 0.712340, 0.787933\n",
      "Step 5 | Training Loss: 0.000147 | Test Loss: 0.014195 | Test Accuracy: 0.698279, 0.713924\n",
      "Step 6 | Training Loss: 0.000075 | Test Loss: 0.017885 | Test Accuracy: 0.693754, 0.692996\n",
      "Step 7 | Training Loss: 0.000049 | Test Loss: 0.010849 | Test Accuracy: 0.718950, 0.785148\n",
      "Step 8 | Training Loss: 0.000000 | Test Loss: 0.011314 | Test Accuracy: 0.708836, 0.784810\n",
      "Step 9 | Training Loss: 0.000055 | Test Loss: 0.011760 | Test Accuracy: 0.716111, 0.771646\n",
      "Step 10 | Training Loss: 0.000655 | Test Loss: 0.011209 | Test Accuracy: 0.691315, 0.764388\n",
      "Step 11 | Training Loss: 0.000047 | Test Loss: 0.011801 | Test Accuracy: 0.679560, 0.773333\n",
      "Step 12 | Training Loss: 0.000780 | Test Loss: 0.011933 | Test Accuracy: 0.700452, 0.768523\n",
      "Step 13 | Training Loss: 0.000028 | Test Loss: 0.010387 | Test Accuracy: 0.694819, 0.764894\n",
      "Step 14 | Training Loss: 0.000352 | Test Loss: 0.010899 | Test Accuracy: 0.695529, 0.777890\n",
      "Step 15 | Training Loss: 0.000387 | Test Loss: 0.012562 | Test Accuracy: 0.653966, 0.715190\n",
      "Step 1 | Training Loss: 0.000098 | Test Loss: 0.011769 | Test Accuracy: 0.659732, 0.736203\n",
      "Step 2 | Training Loss: 0.000017 | Test Loss: 0.011375 | Test Accuracy: 0.660131, 0.731983\n",
      "Step 3 | Training Loss: 0.000151 | Test Loss: 0.011368 | Test Accuracy: 0.663724, 0.736709\n",
      "Step 4 | Training Loss: 0.000302 | Test Loss: 0.011315 | Test Accuracy: 0.665987, 0.732236\n",
      "Step 5 | Training Loss: 0.000142 | Test Loss: 0.011127 | Test Accuracy: 0.666253, 0.735443\n",
      "Step 6 | Training Loss: 0.000045 | Test Loss: 0.010952 | Test Accuracy: 0.664301, 0.742785\n",
      "Step 7 | Training Loss: 0.000087 | Test Loss: 0.011097 | Test Accuracy: 0.667938, 0.742954\n",
      "Step 8 | Training Loss: 0.000161 | Test Loss: 0.011132 | Test Accuracy: 0.668160, 0.747089\n",
      "Step 9 | Training Loss: 0.000391 | Test Loss: 0.011182 | Test Accuracy: 0.668337, 0.746245\n",
      "Step 10 | Training Loss: 0.000093 | Test Loss: 0.010948 | Test Accuracy: 0.662660, 0.746414\n",
      "Step 11 | Training Loss: 0.000111 | Test Loss: 0.011067 | Test Accuracy: 0.666563, 0.740675\n",
      "Step 12 | Training Loss: 0.000075 | Test Loss: 0.011007 | Test Accuracy: 0.674148, 0.744810\n",
      "Step 13 | Training Loss: 0.000301 | Test Loss: 0.011101 | Test Accuracy: 0.674769, 0.747595\n",
      "Step 14 | Training Loss: 0.000124 | Test Loss: 0.011575 | Test Accuracy: 0.676100, 0.745907\n",
      "Step 15 | Training Loss: 0.000288 | Test Loss: 0.010735 | Test Accuracy: 0.673971, 0.754852\n",
      "Current Layer Attributes - epochs:15 hidden layers:5 features count:4\n",
      "Step 1 | Training Loss: 0.001290 | Test Loss: 0.003445 | Test Accuracy: 0.622383, 0.550633\n",
      "Step 2 | Training Loss: 0.001836 | Test Loss: 0.004987 | Test Accuracy: 0.735672, 0.660591\n",
      "Step 3 | Training Loss: 0.000484 | Test Loss: 0.004625 | Test Accuracy: 0.724716, 0.612827\n",
      "Step 4 | Training Loss: 0.000780 | Test Loss: 0.003548 | Test Accuracy: 0.728753, 0.552996\n",
      "Step 5 | Training Loss: 0.000155 | Test Loss: 0.006108 | Test Accuracy: 0.750710, 0.541603\n",
      "Step 6 | Training Loss: 0.000346 | Test Loss: 0.005714 | Test Accuracy: 0.714115, 0.481519\n",
      "Step 7 | Training Loss: 0.000442 | Test Loss: 0.003257 | Test Accuracy: 0.753504, 0.554515\n",
      "Step 8 | Training Loss: 0.000366 | Test Loss: 0.003004 | Test Accuracy: 0.766856, 0.581603\n",
      "Step 9 | Training Loss: 0.000866 | Test Loss: 0.003076 | Test Accuracy: 0.734830, 0.529030\n",
      "Step 10 | Training Loss: 0.000031 | Test Loss: 0.002437 | Test Accuracy: 0.772268, 0.585316\n",
      "Step 11 | Training Loss: 0.000124 | Test Loss: 0.003578 | Test Accuracy: 0.738023, 0.518819\n",
      "Step 12 | Training Loss: 0.000906 | Test Loss: 0.003241 | Test Accuracy: 0.731547, 0.524304\n",
      "Step 13 | Training Loss: 0.000770 | Test Loss: 0.003780 | Test Accuracy: 0.755767, 0.557468\n",
      "Step 14 | Training Loss: 0.000425 | Test Loss: 0.003936 | Test Accuracy: 0.755722, 0.549873\n",
      "Step 15 | Training Loss: 0.000374 | Test Loss: 0.002923 | Test Accuracy: 0.741173, 0.522616\n",
      "Step 1 | Training Loss: 0.000358 | Test Loss: 0.003038 | Test Accuracy: 0.722853, 0.488692\n",
      "Step 2 | Training Loss: 0.000534 | Test Loss: 0.002684 | Test Accuracy: 0.725293, 0.526076\n",
      "Step 3 | Training Loss: 0.000334 | Test Loss: 0.002490 | Test Accuracy: 0.736382, 0.511814\n",
      "Step 4 | Training Loss: 0.000114 | Test Loss: 0.002962 | Test Accuracy: 0.753770, 0.542025\n",
      "Step 5 | Training Loss: 0.000066 | Test Loss: 0.002610 | Test Accuracy: 0.744721, 0.527679\n",
      "Step 6 | Training Loss: 0.000066 | Test Loss: 0.003091 | Test Accuracy: 0.750710, 0.538312\n",
      "Step 7 | Training Loss: 0.000271 | Test Loss: 0.001232 | Test Accuracy: 0.794890, 0.630970\n",
      "Step 8 | Training Loss: 0.000082 | Test Loss: 0.001157 | Test Accuracy: 0.788148, 0.620253\n",
      "Step 9 | Training Loss: 0.000166 | Test Loss: 0.002133 | Test Accuracy: 0.800346, 0.631646\n",
      "Step 10 | Training Loss: 0.000181 | Test Loss: 0.001581 | Test Accuracy: 0.784289, 0.600084\n",
      "Step 11 | Training Loss: 0.000026 | Test Loss: 0.001331 | Test Accuracy: 0.772800, 0.599747\n",
      "Step 12 | Training Loss: 0.000033 | Test Loss: 0.002652 | Test Accuracy: 0.778522, 0.598819\n",
      "Step 13 | Training Loss: 0.000134 | Test Loss: 0.002527 | Test Accuracy: 0.788015, 0.605738\n",
      "Step 14 | Training Loss: 0.000883 | Test Loss: 0.002908 | Test Accuracy: 0.771292, 0.620422\n",
      "Step 15 | Training Loss: 0.000175 | Test Loss: 0.001925 | Test Accuracy: 0.787083, 0.608439\n",
      "Step 1 | Training Loss: 0.000099 | Test Loss: 0.002126 | Test Accuracy: 0.786684, 0.607257\n",
      "Step 2 | Training Loss: 0.000716 | Test Loss: 0.002068 | Test Accuracy: 0.786285, 0.606498\n",
      "Step 3 | Training Loss: 0.000330 | Test Loss: 0.001760 | Test Accuracy: 0.785930, 0.606920\n",
      "Step 4 | Training Loss: 0.000163 | Test Loss: 0.001764 | Test Accuracy: 0.787260, 0.606160\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 5 | Training Loss: 0.000475 | Test Loss: 0.001805 | Test Accuracy: 0.786373, 0.607679\n",
      "Step 6 | Training Loss: 0.000447 | Test Loss: 0.001953 | Test Accuracy: 0.787172, 0.606160\n",
      "Step 7 | Training Loss: 0.000197 | Test Loss: 0.001766 | Test Accuracy: 0.785397, 0.604051\n",
      "Step 8 | Training Loss: 0.000402 | Test Loss: 0.001726 | Test Accuracy: 0.786418, 0.606582\n",
      "Step 9 | Training Loss: 0.000099 | Test Loss: 0.001839 | Test Accuracy: 0.787748, 0.607257\n",
      "Step 10 | Training Loss: 0.000092 | Test Loss: 0.001553 | Test Accuracy: 0.786817, 0.607089\n",
      "Step 11 | Training Loss: 0.000152 | Test Loss: 0.001636 | Test Accuracy: 0.787349, 0.606835\n",
      "Step 12 | Training Loss: 0.000007 | Test Loss: 0.001661 | Test Accuracy: 0.787881, 0.607764\n",
      "Step 13 | Training Loss: 0.000117 | Test Loss: 0.001593 | Test Accuracy: 0.787881, 0.609283\n",
      "Step 14 | Training Loss: 0.000205 | Test Loss: 0.001582 | Test Accuracy: 0.787527, 0.609114\n",
      "Step 15 | Training Loss: 0.000362 | Test Loss: 0.001819 | Test Accuracy: 0.788236, 0.608354\n",
      "Current Layer Attributes - epochs:15 hidden layers:5 features count:8\n",
      "Step 1 | Training Loss: 0.001273 | Test Loss: 0.004969 | Test Accuracy: 0.624468, 0.492321\n",
      "Step 2 | Training Loss: 0.001735 | Test Loss: 0.003709 | Test Accuracy: 0.771292, 0.750042\n",
      "Step 3 | Training Loss: 0.000944 | Test Loss: 0.004414 | Test Accuracy: 0.739886, 0.621603\n",
      "Step 4 | Training Loss: 0.001417 | Test Loss: 0.004022 | Test Accuracy: 0.743391, 0.654008\n",
      "Step 5 | Training Loss: 0.001105 | Test Loss: 0.002288 | Test Accuracy: 0.796797, 0.675527\n",
      "Step 6 | Training Loss: 0.000077 | Test Loss: 0.003580 | Test Accuracy: 0.814895, 0.690633\n",
      "Step 7 | Training Loss: 0.000801 | Test Loss: 0.002784 | Test Accuracy: 0.781538, 0.630802\n",
      "Step 8 | Training Loss: 0.000300 | Test Loss: 0.003454 | Test Accuracy: 0.774973, 0.628270\n",
      "Step 9 | Training Loss: 0.000110 | Test Loss: 0.004109 | Test Accuracy: 0.747294, 0.612574\n",
      "Step 10 | Training Loss: 0.000277 | Test Loss: 0.003923 | Test Accuracy: 0.749423, 0.582194\n",
      "Step 11 | Training Loss: 0.000593 | Test Loss: 0.005822 | Test Accuracy: 0.695839, 0.482954\n",
      "Step 12 | Training Loss: 0.000718 | Test Loss: 0.003948 | Test Accuracy: 0.768320, 0.591224\n",
      "Step 13 | Training Loss: 0.000317 | Test Loss: 0.004067 | Test Accuracy: 0.781804, 0.617300\n",
      "Step 14 | Training Loss: 0.000111 | Test Loss: 0.003565 | Test Accuracy: 0.786240, 0.626160\n",
      "Step 15 | Training Loss: 0.000085 | Test Loss: 0.003039 | Test Accuracy: 0.797019, 0.649198\n",
      "Step 1 | Training Loss: 0.000148 | Test Loss: 0.005556 | Test Accuracy: 0.748714, 0.536456\n",
      "Step 2 | Training Loss: 0.000669 | Test Loss: 0.004967 | Test Accuracy: 0.751286, 0.544219\n",
      "Step 3 | Training Loss: 0.000678 | Test Loss: 0.003943 | Test Accuracy: 0.761356, 0.564135\n",
      "Step 4 | Training Loss: 0.000782 | Test Loss: 0.003961 | Test Accuracy: 0.747117, 0.547257\n",
      "Step 5 | Training Loss: 0.000329 | Test Loss: 0.003116 | Test Accuracy: 0.735229, 0.533249\n",
      "Step 6 | Training Loss: 0.000308 | Test Loss: 0.004244 | Test Accuracy: 0.743391, 0.525485\n",
      "Step 7 | Training Loss: 0.000190 | Test Loss: 0.004392 | Test Accuracy: 0.753371, 0.543544\n",
      "Step 8 | Training Loss: 0.000331 | Test Loss: 0.005486 | Test Accuracy: 0.723075, 0.503376\n",
      "Step 9 | Training Loss: 0.000396 | Test Loss: 0.002428 | Test Accuracy: 0.749335, 0.536878\n",
      "Step 10 | Training Loss: 0.000360 | Test Loss: 0.002100 | Test Accuracy: 0.763928, 0.567511\n",
      "Step 11 | Training Loss: 0.000494 | Test Loss: 0.003136 | Test Accuracy: 0.749601, 0.595443\n",
      "Step 12 | Training Loss: 0.000423 | Test Loss: 0.003319 | Test Accuracy: 0.769384, 0.574346\n",
      "Step 13 | Training Loss: 0.000854 | Test Loss: 0.004266 | Test Accuracy: 0.768719, 0.582363\n",
      "Step 14 | Training Loss: 0.000712 | Test Loss: 0.003029 | Test Accuracy: 0.767477, 0.570802\n",
      "Step 15 | Training Loss: 0.000705 | Test Loss: 0.002423 | Test Accuracy: 0.762110, 0.579578\n",
      "Step 1 | Training Loss: 0.000158 | Test Loss: 0.002273 | Test Accuracy: 0.762420, 0.576287\n",
      "Step 2 | Training Loss: 0.000253 | Test Loss: 0.002158 | Test Accuracy: 0.764283, 0.572743\n",
      "Step 3 | Training Loss: 0.000144 | Test Loss: 0.002281 | Test Accuracy: 0.764682, 0.571308\n",
      "Step 4 | Training Loss: 0.000026 | Test Loss: 0.002101 | Test Accuracy: 0.767477, 0.570633\n",
      "Step 5 | Training Loss: 0.000322 | Test Loss: 0.002010 | Test Accuracy: 0.764815, 0.572996\n",
      "Step 6 | Training Loss: 0.000453 | Test Loss: 0.001979 | Test Accuracy: 0.767166, 0.570042\n",
      "Step 7 | Training Loss: 0.000292 | Test Loss: 0.002038 | Test Accuracy: 0.764239, 0.572405\n",
      "Step 8 | Training Loss: 0.000185 | Test Loss: 0.001924 | Test Accuracy: 0.763307, 0.571139\n",
      "Step 9 | Training Loss: 0.000275 | Test Loss: 0.001907 | Test Accuracy: 0.765836, 0.570211\n",
      "Step 10 | Training Loss: 0.000019 | Test Loss: 0.001819 | Test Accuracy: 0.766102, 0.571055\n",
      "Step 11 | Training Loss: 0.000100 | Test Loss: 0.001867 | Test Accuracy: 0.765703, 0.566414\n",
      "Step 12 | Training Loss: 0.000506 | Test Loss: 0.001852 | Test Accuracy: 0.767920, 0.570295\n",
      "Step 13 | Training Loss: 0.000424 | Test Loss: 0.001789 | Test Accuracy: 0.768453, 0.570717\n",
      "Step 14 | Training Loss: 0.000178 | Test Loss: 0.001863 | Test Accuracy: 0.768586, 0.571139\n",
      "Step 15 | Training Loss: 0.000024 | Test Loss: 0.001792 | Test Accuracy: 0.767699, 0.572321\n",
      "Current Layer Attributes - epochs:15 hidden layers:5 features count:32\n",
      "Step 1 | Training Loss: 0.000652 | Test Loss: 0.005190 | Test Accuracy: 0.684173, 0.523966\n",
      "Step 2 | Training Loss: 0.000849 | Test Loss: 0.005427 | Test Accuracy: 0.748625, 0.589114\n",
      "Step 3 | Training Loss: 0.000892 | Test Loss: 0.004498 | Test Accuracy: 0.776570, 0.654430\n",
      "Step 4 | Training Loss: 0.001571 | Test Loss: 0.006632 | Test Accuracy: 0.758916, 0.589789\n",
      "Step 5 | Training Loss: 0.000667 | Test Loss: 0.004750 | Test Accuracy: 0.806955, 0.657215\n",
      "Step 6 | Training Loss: 0.000590 | Test Loss: 0.004992 | Test Accuracy: 0.801588, 0.651224\n",
      "Step 7 | Training Loss: 0.000058 | Test Loss: 42661.074219 | Test Accuracy: 0.813609, 0.663713\n",
      "Step 8 | High Training Loss: 197661776936960.000000 ... Restoring Net\n",
      "INFO:tensorflow:Restoring parameters from dataset/tf_vae_only_vae_loss_nsl_kdd/hidden layers_15_features count_5/model-7\n",
      "Step 8 | Training Loss: 0.005122 | Test Loss: 0.007429 | Test Accuracy: 0.696726, 0.526498\n",
      "Step 9 | Training Loss: 0.000961 | Test Loss: 0.006589 | Test Accuracy: 0.668958, 0.412827\n",
      "Step 10 | Training Loss: 0.000157 | Test Loss: 0.004683 | Test Accuracy: 0.734918, 0.515865\n",
      "Step 11 | Training Loss: 0.000896 | Test Loss: 0.003410 | Test Accuracy: 0.707905, 0.463629\n",
      "Step 12 | Training Loss: 0.000435 | Test Loss: 0.004382 | Test Accuracy: 0.735628, 0.509789\n",
      "Step 13 | Training Loss: 0.000510 | Test Loss: 0.003392 | Test Accuracy: 0.754658, 0.549198\n",
      "Step 14 | Training Loss: 0.000101 | Test Loss: 0.002951 | Test Accuracy: 0.737624, 0.572743\n",
      "Step 15 | Training Loss: 0.000643 | Test Loss: 0.003559 | Test Accuracy: 0.719393, 0.477806\n",
      "Step 1 | Training Loss: 0.000973 | Test Loss: 0.379625 | Test Accuracy: 0.828247, 0.692911\n",
      "Step 2 | Training Loss: 0.000699 | Test Loss: 0.004679 | Test Accuracy: 0.816714, 0.689198\n",
      "Step 3 | Training Loss: 0.000747 | Test Loss: 0.004888 | Test Accuracy: 0.800967, 0.672489\n",
      "Step 4 | Training Loss: 0.000601 | Test Loss: 0.008003 | Test Accuracy: 0.721567, 0.701857\n",
      "Step 5 | Training Loss: 0.000036 | Test Loss: 0.004016 | Test Accuracy: 0.797330, 0.648523\n",
      "Step 6 | Training Loss: 0.000964 | Test Loss: 0.003985 | Test Accuracy: 0.798616, 0.656371\n",
      "Step 7 | Training Loss: 0.000297 | Test Loss: 0.004048 | Test Accuracy: 0.800523, 0.658397\n",
      "Step 8 | Training Loss: 0.000085 | Test Loss: 0.003605 | Test Accuracy: 0.801455, 0.662616\n",
      "Step 9 | Training Loss: 0.000400 | Test Loss: 0.005572 | Test Accuracy: 0.788281, 0.666667\n",
      "Step 10 | Training Loss: 0.000299 | Test Loss: 0.004375 | Test Accuracy: 0.785043, 0.674008\n",
      "Step 11 | Training Loss: 0.000523 | Test Loss: 0.004360 | Test Accuracy: 0.781450, 0.660928\n",
      "Step 12 | Training Loss: 0.000029 | Test Loss: 0.003677 | Test Accuracy: 0.816448, 0.659494\n",
      "Step 13 | Training Loss: 0.000005 | Test Loss: 0.003010 | Test Accuracy: 0.818754, 0.665485\n",
      "Step 14 | Training Loss: 0.000171 | Test Loss: 0.002711 | Test Accuracy: 0.819331, 0.667764\n",
      "Step 15 | Training Loss: 0.000198 | Test Loss: 0.001943 | Test Accuracy: 0.815605, 0.663207\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 1 | Training Loss: 0.000238 | Test Loss: 0.002215 | Test Accuracy: 0.813786, 0.660422\n",
      "Step 2 | Training Loss: 0.000054 | Test Loss: 0.002385 | Test Accuracy: 0.813520, 0.659831\n",
      "Step 3 | Training Loss: 0.000332 | Test Loss: 0.002324 | Test Accuracy: 0.816004, 0.662194\n",
      "Step 4 | Training Loss: 0.000222 | Test Loss: 0.002352 | Test Accuracy: 0.816492, 0.663291\n",
      "Step 5 | Training Loss: 0.000053 | Test Loss: 0.002323 | Test Accuracy: 0.812944, 0.657722\n",
      "Step 6 | Training Loss: 0.000167 | Test Loss: 0.002314 | Test Accuracy: 0.811036, 0.655021\n",
      "Step 7 | Training Loss: 0.000061 | Test Loss: 0.002297 | Test Accuracy: 0.813210, 0.658987\n",
      "Step 8 | Training Loss: 0.000023 | Test Loss: 0.002362 | Test Accuracy: 0.815161, 0.661097\n",
      "Step 9 | Training Loss: 0.000111 | Test Loss: 0.002207 | Test Accuracy: 0.814895, 0.663122\n",
      "Step 10 | Training Loss: 0.000015 | Test Loss: 0.002071 | Test Accuracy: 0.816847, 0.665148\n",
      "Step 11 | Training Loss: 0.000081 | Test Loss: 0.002202 | Test Accuracy: 0.814363, 0.662532\n",
      "Step 12 | Training Loss: 0.000097 | Test Loss: 0.002201 | Test Accuracy: 0.815117, 0.663038\n",
      "Step 13 | Training Loss: 0.000157 | Test Loss: 0.002077 | Test Accuracy: 0.815649, 0.662278\n",
      "Step 14 | Training Loss: 0.000124 | Test Loss: 0.002194 | Test Accuracy: 0.815472, 0.662954\n",
      "Step 15 | Training Loss: 0.000137 | Test Loss: 0.002165 | Test Accuracy: 0.816182, 0.662954\n",
      "Current Layer Attributes - epochs:15 hidden layers:5 features count:122\n",
      "Step 1 | Training Loss: 0.002129 | Test Loss: 0.004489 | Test Accuracy: 0.779720, 0.608945\n",
      "Step 2 | Training Loss: 0.000466 | Test Loss: 0.004932 | Test Accuracy: 0.791120, 0.635781\n",
      "Step 3 | Training Loss: 0.000445 | Test Loss: 0.005543 | Test Accuracy: 0.751153, 0.541435\n",
      "Step 4 | Training Loss: 0.000051 | Test Loss: 0.008763 | Test Accuracy: 0.745875, 0.541266\n",
      "Step 5 | Training Loss: 0.001084 | Test Loss: 0.007783 | Test Accuracy: 0.703114, 0.468608\n",
      "Step 6 | Training Loss: 0.000026 | Test Loss: 0.006529 | Test Accuracy: 0.713893, 0.499409\n",
      "Step 7 | Training Loss: 0.000043 | Test Loss: 0.003544 | Test Accuracy: 0.845502, 0.751055\n",
      "Step 8 | Training Loss: 0.000521 | Test Loss: 0.004532 | Test Accuracy: 0.835211, 0.718312\n",
      "Step 9 | Training Loss: 0.000054 | Test Loss: 0.003689 | Test Accuracy: 0.848208, 0.735612\n",
      "Step 10 | Training Loss: 0.000449 | Test Loss: 0.002395 | Test Accuracy: 0.884359, 0.811730\n",
      "Step 11 | Training Loss: 0.000155 | Test Loss: 0.002274 | Test Accuracy: 0.872117, 0.773502\n",
      "Step 12 | Training Loss: 0.000073 | Test Loss: 0.002277 | Test Accuracy: 0.868967, 0.777046\n",
      "Step 13 | Training Loss: 0.000597 | Test Loss: 0.002711 | Test Accuracy: 0.872383, 0.772827\n",
      "Step 14 | Training Loss: 0.000523 | Test Loss: 0.001980 | Test Accuracy: 0.873181, 0.774515\n",
      "Step 15 | Training Loss: 0.000417 | Test Loss: 0.002225 | Test Accuracy: 0.874024, 0.777553\n",
      "Step 1 | Training Loss: 0.000043 | Test Loss: 0.002465 | Test Accuracy: 0.866217, 0.774093\n",
      "Step 2 | Training Loss: 0.000193 | Test Loss: 0.002777 | Test Accuracy: 0.871496, 0.774599\n",
      "Step 3 | Training Loss: 0.000010 | Test Loss: 0.003627 | Test Accuracy: 0.871895, 0.775781\n",
      "Step 4 | Training Loss: 0.000279 | Test Loss: 0.002237 | Test Accuracy: 0.860273, 0.780253\n",
      "Step 5 | Training Loss: 0.000285 | Test Loss: 0.001744 | Test Accuracy: 0.884404, 0.809705\n",
      "Step 6 | Training Loss: 0.000003 | Test Loss: 0.000927 | Test Accuracy: 0.873935, 0.776540\n",
      "Step 7 | Training Loss: 0.000311 | Test Loss: 0.002050 | Test Accuracy: 0.891989, 0.823882\n",
      "Step 8 | Training Loss: 0.001238 | Test Loss: 0.001981 | Test Accuracy: 0.882008, 0.833755\n",
      "Step 9 | Training Loss: 0.000551 | Test Loss: 0.001933 | Test Accuracy: 0.888707, 0.832658\n",
      "Step 10 | Training Loss: 0.000333 | Test Loss: 0.001867 | Test Accuracy: 0.877351, 0.836878\n",
      "Step 11 | Training Loss: 0.000098 | Test Loss: 0.000998 | Test Accuracy: 0.879081, 0.838481\n",
      "Step 12 | Training Loss: 0.000311 | Test Loss: 0.002007 | Test Accuracy: 0.877839, 0.834177\n",
      "Step 13 | Training Loss: 0.000206 | Test Loss: 0.001309 | Test Accuracy: 0.877573, 0.833502\n",
      "Step 14 | Training Loss: 0.000507 | Test Loss: 0.002173 | Test Accuracy: 0.878016, 0.833587\n",
      "Step 15 | Training Loss: 0.001013 | Test Loss: 0.001712 | Test Accuracy: 0.872960, 0.825401\n",
      "Step 1 | Training Loss: 0.000077 | Test Loss: 0.001743 | Test Accuracy: 0.874423, 0.828354\n",
      "Step 2 | Training Loss: 0.000711 | Test Loss: 0.001565 | Test Accuracy: 0.873359, 0.825148\n",
      "Step 3 | Training Loss: 0.000164 | Test Loss: 0.001309 | Test Accuracy: 0.872871, 0.825738\n",
      "Step 4 | Training Loss: 0.000257 | Test Loss: 0.001378 | Test Accuracy: 0.873447, 0.827511\n",
      "Step 5 | Training Loss: 0.000099 | Test Loss: 0.001557 | Test Accuracy: 0.871673, 0.825148\n",
      "Step 6 | Training Loss: 0.000068 | Test Loss: 0.001289 | Test Accuracy: 0.867282, 0.815443\n",
      "Step 7 | Training Loss: 0.000087 | Test Loss: 0.001317 | Test Accuracy: 0.868879, 0.818059\n",
      "Step 8 | Training Loss: 0.000112 | Test Loss: 0.001182 | Test Accuracy: 0.867415, 0.817806\n",
      "Step 9 | Training Loss: 0.000065 | Test Loss: 0.001191 | Test Accuracy: 0.874556, 0.828270\n",
      "Step 10 | Training Loss: 0.000107 | Test Loss: 0.001160 | Test Accuracy: 0.876508, 0.833249\n",
      "Step 11 | Training Loss: 0.000066 | Test Loss: 0.000981 | Test Accuracy: 0.876375, 0.833080\n"
     ]
    }
   ],
   "source": [
    "%%timeit -r 10\n",
    "\n",
    "Hyperparameters.start_training()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-06-29T12:10:07.608432Z",
     "start_time": "2017-06-29T12:10:07.587123Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>epoch</th>\n",
       "      <th>no_of_features</th>\n",
       "      <th>hidden_layers</th>\n",
       "      <th>train_score</th>\n",
       "      <th>test_score</th>\n",
       "      <th>test_score_20</th>\n",
       "      <th>time_taken</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>45</td>\n",
       "      <td>32</td>\n",
       "      <td>3</td>\n",
       "      <td>0.897285</td>\n",
       "      <td>0.893808</td>\n",
       "      <td>0.824726</td>\n",
       "      <td>3.912326</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>45</td>\n",
       "      <td>122</td>\n",
       "      <td>3</td>\n",
       "      <td>0.910700</td>\n",
       "      <td>0.860894</td>\n",
       "      <td>0.811814</td>\n",
       "      <td>9.294263</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>45</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>0.925464</td>\n",
       "      <td>0.854640</td>\n",
       "      <td>0.795021</td>\n",
       "      <td>89.629435</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>45</td>\n",
       "      <td>8</td>\n",
       "      <td>5</td>\n",
       "      <td>0.907604</td>\n",
       "      <td>0.839603</td>\n",
       "      <td>0.702616</td>\n",
       "      <td>124.541892</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   epoch  no_of_features  hidden_layers  train_score  test_score  \\\n",
       "2     45              32              3     0.897285    0.893808   \n",
       "3     45             122              3     0.910700    0.860894   \n",
       "0     45               4              3     0.925464    0.854640   \n",
       "5     45               8              5     0.907604    0.839603   \n",
       "\n",
       "   test_score_20  time_taken  \n",
       "2       0.824726    3.912326  \n",
       "3       0.811814    9.294263  \n",
       "0       0.795021   89.629435  \n",
       "5       0.702616  124.541892  "
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "g = df_results.groupby(by=['no_of_features'])\n",
    "idx = g['test_score'].transform(max) == df_results['test_score']\n",
    "df_results[idx].sort_values(by = 'test_score', ascending = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-06-03T01:25:48.273401Z",
     "start_time": "2017-06-03T01:25:48.269113Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-06-29T12:10:12.608768Z",
     "start_time": "2017-06-29T12:10:12.316545Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>epoch</th>\n",
       "      <th>no_of_features</th>\n",
       "      <th>hidden_layers</th>\n",
       "      <th>train_score</th>\n",
       "      <th>test_score</th>\n",
       "      <th>test_score_20</th>\n",
       "      <th>time_taken</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>45</td>\n",
       "      <td>32</td>\n",
       "      <td>3</td>\n",
       "      <td>0.897285</td>\n",
       "      <td>0.893808</td>\n",
       "      <td>0.824726</td>\n",
       "      <td>3.912326</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>45</td>\n",
       "      <td>32</td>\n",
       "      <td>5</td>\n",
       "      <td>0.914272</td>\n",
       "      <td>0.877085</td>\n",
       "      <td>0.794430</td>\n",
       "      <td>11.106694</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>45</td>\n",
       "      <td>122</td>\n",
       "      <td>3</td>\n",
       "      <td>0.910700</td>\n",
       "      <td>0.860894</td>\n",
       "      <td>0.811814</td>\n",
       "      <td>9.294263</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>45</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>0.925464</td>\n",
       "      <td>0.854640</td>\n",
       "      <td>0.795021</td>\n",
       "      <td>89.629435</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>45</td>\n",
       "      <td>8</td>\n",
       "      <td>5</td>\n",
       "      <td>0.907604</td>\n",
       "      <td>0.839603</td>\n",
       "      <td>0.702616</td>\n",
       "      <td>124.541892</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>45</td>\n",
       "      <td>122</td>\n",
       "      <td>5</td>\n",
       "      <td>0.937292</td>\n",
       "      <td>0.834679</td>\n",
       "      <td>0.724979</td>\n",
       "      <td>170.694251</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>45</td>\n",
       "      <td>8</td>\n",
       "      <td>3</td>\n",
       "      <td>0.939594</td>\n",
       "      <td>0.820174</td>\n",
       "      <td>0.753586</td>\n",
       "      <td>11.025270</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>45</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>0.848468</td>\n",
       "      <td>0.812633</td>\n",
       "      <td>0.688186</td>\n",
       "      <td>32.484117</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   epoch  no_of_features  hidden_layers  train_score  test_score  \\\n",
       "2     45              32              3     0.897285    0.893808   \n",
       "6     45              32              5     0.914272    0.877085   \n",
       "3     45             122              3     0.910700    0.860894   \n",
       "0     45               4              3     0.925464    0.854640   \n",
       "5     45               8              5     0.907604    0.839603   \n",
       "7     45             122              5     0.937292    0.834679   \n",
       "1     45               8              3     0.939594    0.820174   \n",
       "4     45               4              5     0.848468    0.812633   \n",
       "\n",
       "   test_score_20  time_taken  \n",
       "2       0.824726    3.912326  \n",
       "6       0.794430   11.106694  \n",
       "3       0.811814    9.294263  \n",
       "0       0.795021   89.629435  \n",
       "5       0.702616  124.541892  \n",
       "7       0.724979  170.694251  \n",
       "1       0.753586   11.025270  \n",
       "4       0.688186   32.484117  "
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_results.sort_values(by = 'test_score', ascending = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-06-29T12:10:13.203477Z",
     "start_time": "2017-06-29T12:10:13.180944Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pd.Panel(Train.predictions).to_pickle(\"dataset/tf_vae_only_vae_loss_nsl_kdd_predictions.pkl\")\n",
    "df_results.to_pickle(\"dataset/tf_vae_only_vae_loss_nsl_kdd_scores.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-06-29T12:10:14.162913Z",
     "start_time": "2017-06-29T12:10:14.103754Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import itertools\n",
    "\n",
    "def plot_confusion_matrix(cm, classes,\n",
    "                          normalize=False,\n",
    "                          title='Confusion matrix',\n",
    "                          cmap=plt.cm.Blues):\n",
    "    \"\"\"\n",
    "    This function prints and plots the confusion matrix.\n",
    "    Normalization can be applied by setting `normalize=True`.\n",
    "    \"\"\"\n",
    "    np.set_printoptions(precision=4)\n",
    "\n",
    "    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n",
    "    plt.title(title)\n",
    "    plt.colorbar()\n",
    "    tick_marks = np.arange(len(classes))\n",
    "    plt.xticks(tick_marks, classes, rotation=45)\n",
    "    plt.yticks(tick_marks, classes)\n",
    "\n",
    "    if normalize:\n",
    "        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "        print(\"Normalized confusion matrix\")\n",
    "    else:\n",
    "        print('Confusion matrix, without normalization')\n",
    "\n",
    "    print(cm)\n",
    "\n",
    "    thresh = cm.max() / 2.\n",
    "    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
    "        plt.text(j, i, cm[i, j].round(4),\n",
    "                 horizontalalignment=\"center\",\n",
    "                 color=\"white\" if cm[i, j] > thresh else \"black\")\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.ylabel('True label')\n",
    "    plt.xlabel('Predicted label')\n",
    "\n",
    "def plot(actual_value, pred_value):\n",
    "    from sklearn.metrics import confusion_matrix\n",
    "    cm_2labels = confusion_matrix(y_pred = pred_value, y_true = actual_value)\n",
    "    plt.figure(figsize=[6,6])\n",
    "    plot_confusion_matrix(cm_2labels, preprocess.output_columns_2labels, normalize = True,\n",
    "                         title = Train.best_parameters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-06-29T12:10:15.452063Z",
     "start_time": "2017-06-29T12:10:15.187099Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Normalized confusion matrix\n",
      "[[ 0.9321  0.0679]\n",
      " [ 0.1308  0.8692]]\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAbcAAAGeCAYAAAAXNE8VAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f1fc6c25860>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot(actual_value = Train.actual_value, pred_value = Train.pred_value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-06-29T12:10:16.283739Z",
     "start_time": "2017-06-29T12:10:16.025311Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Normalized confusion matrix\n",
      "[[ 0.7858  0.2142]\n",
      " [ 0.1754  0.8246]]\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAbUAAAGgCAYAAAAtsfn1AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f1ffc4fb710>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot(actual_value = Train.actual_value_, pred_value = Train.pred_value_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-06-29T12:10:16.879002Z",
     "start_time": "2017-06-29T12:10:16.854112Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>epoch</th>\n",
       "      <th>train_score</th>\n",
       "      <th>test_score</th>\n",
       "      <th>test_score_20</th>\n",
       "      <th>time_taken</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>no_of_features</th>\n",
       "      <th>hidden_layers</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <th>3</th>\n",
       "      <td>45</td>\n",
       "      <td>0.933878</td>\n",
       "      <td>0.864487</td>\n",
       "      <td>0.773080</td>\n",
       "      <td>56.184884</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <th>3</th>\n",
       "      <td>45</td>\n",
       "      <td>0.942769</td>\n",
       "      <td>0.814895</td>\n",
       "      <td>0.750380</td>\n",
       "      <td>149.667458</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>122</th>\n",
       "      <th>3</th>\n",
       "      <td>45</td>\n",
       "      <td>0.946738</td>\n",
       "      <td>0.768675</td>\n",
       "      <td>0.575612</td>\n",
       "      <td>6.564366</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <th>5</th>\n",
       "      <td>45</td>\n",
       "      <td>0.783775</td>\n",
       "      <td>0.858632</td>\n",
       "      <td>0.786160</td>\n",
       "      <td>182.730184</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <th>5</th>\n",
       "      <td>45</td>\n",
       "      <td>0.835450</td>\n",
       "      <td>0.824610</td>\n",
       "      <td>0.723038</td>\n",
       "      <td>190.228723</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>122</th>\n",
       "      <th>5</th>\n",
       "      <td>45</td>\n",
       "      <td>0.926893</td>\n",
       "      <td>0.806290</td>\n",
       "      <td>0.679072</td>\n",
       "      <td>9.157173</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <th>3</th>\n",
       "      <td>45</td>\n",
       "      <td>0.933878</td>\n",
       "      <td>0.864487</td>\n",
       "      <td>0.773080</td>\n",
       "      <td>56.184884</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <th>3</th>\n",
       "      <td>45</td>\n",
       "      <td>0.942769</td>\n",
       "      <td>0.814895</td>\n",
       "      <td>0.750380</td>\n",
       "      <td>149.667458</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>122</th>\n",
       "      <th>3</th>\n",
       "      <td>45</td>\n",
       "      <td>0.946738</td>\n",
       "      <td>0.768675</td>\n",
       "      <td>0.575612</td>\n",
       "      <td>6.564366</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <th>5</th>\n",
       "      <td>45</td>\n",
       "      <td>0.783775</td>\n",
       "      <td>0.858632</td>\n",
       "      <td>0.786160</td>\n",
       "      <td>182.730184</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <th>5</th>\n",
       "      <td>45</td>\n",
       "      <td>0.835450</td>\n",
       "      <td>0.824610</td>\n",
       "      <td>0.723038</td>\n",
       "      <td>190.228723</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>122</th>\n",
       "      <th>5</th>\n",
       "      <td>45</td>\n",
       "      <td>0.926893</td>\n",
       "      <td>0.806290</td>\n",
       "      <td>0.679072</td>\n",
       "      <td>9.157173</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <th>3</th>\n",
       "      <td>45</td>\n",
       "      <td>0.911811</td>\n",
       "      <td>0.821017</td>\n",
       "      <td>0.689705</td>\n",
       "      <td>5.060908</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <th>3</th>\n",
       "      <td>45</td>\n",
       "      <td>0.912208</td>\n",
       "      <td>0.864221</td>\n",
       "      <td>0.761519</td>\n",
       "      <td>5.399013</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>122</th>\n",
       "      <th>3</th>\n",
       "      <td>45</td>\n",
       "      <td>0.930941</td>\n",
       "      <td>0.816936</td>\n",
       "      <td>0.770042</td>\n",
       "      <td>18.663067</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <th>5</th>\n",
       "      <td>45</td>\n",
       "      <td>0.942769</td>\n",
       "      <td>0.838227</td>\n",
       "      <td>0.706498</td>\n",
       "      <td>75.094590</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <th>5</th>\n",
       "      <td>45</td>\n",
       "      <td>0.923401</td>\n",
       "      <td>0.866616</td>\n",
       "      <td>0.775190</td>\n",
       "      <td>23.876250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>122</th>\n",
       "      <th>5</th>\n",
       "      <td>45</td>\n",
       "      <td>0.906969</td>\n",
       "      <td>0.827094</td>\n",
       "      <td>0.754768</td>\n",
       "      <td>12.914905</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <th>3</th>\n",
       "      <td>45</td>\n",
       "      <td>0.898635</td>\n",
       "      <td>0.780119</td>\n",
       "      <td>0.742532</td>\n",
       "      <td>3.725165</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <th>3</th>\n",
       "      <td>45</td>\n",
       "      <td>0.933799</td>\n",
       "      <td>0.846389</td>\n",
       "      <td>0.755443</td>\n",
       "      <td>73.963892</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <th>3</th>\n",
       "      <td>45</td>\n",
       "      <td>0.953485</td>\n",
       "      <td>0.836187</td>\n",
       "      <td>0.708776</td>\n",
       "      <td>3.930030</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>122</th>\n",
       "      <th>3</th>\n",
       "      <td>45</td>\n",
       "      <td>0.946023</td>\n",
       "      <td>0.829666</td>\n",
       "      <td>0.723713</td>\n",
       "      <td>4.631668</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <td>45</td>\n",
       "      <td>0.782346</td>\n",
       "      <td>0.857035</td>\n",
       "      <td>0.786076</td>\n",
       "      <td>227.792873</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <th>5</th>\n",
       "      <td>45</td>\n",
       "      <td>0.900540</td>\n",
       "      <td>0.878416</td>\n",
       "      <td>0.802869</td>\n",
       "      <td>82.466326</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <th>5</th>\n",
       "      <td>45</td>\n",
       "      <td>0.927687</td>\n",
       "      <td>0.862535</td>\n",
       "      <td>0.764135</td>\n",
       "      <td>112.570260</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>122</th>\n",
       "      <th>5</th>\n",
       "      <td>45</td>\n",
       "      <td>0.843467</td>\n",
       "      <td>0.820706</td>\n",
       "      <td>0.758059</td>\n",
       "      <td>6.386500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <th>3</th>\n",
       "      <td>45</td>\n",
       "      <td>0.922527</td>\n",
       "      <td>0.882186</td>\n",
       "      <td>0.799409</td>\n",
       "      <td>93.924781</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <th>3</th>\n",
       "      <td>45</td>\n",
       "      <td>0.962613</td>\n",
       "      <td>0.783534</td>\n",
       "      <td>0.640844</td>\n",
       "      <td>29.498731</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <th>3</th>\n",
       "      <td>45</td>\n",
       "      <td>0.910462</td>\n",
       "      <td>0.813254</td>\n",
       "      <td>0.659409</td>\n",
       "      <td>19.190202</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>122</th>\n",
       "      <th>3</th>\n",
       "      <td>45</td>\n",
       "      <td>0.922527</td>\n",
       "      <td>0.829001</td>\n",
       "      <td>0.697468</td>\n",
       "      <td>4.617370</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <td>45</td>\n",
       "      <td>0.880616</td>\n",
       "      <td>0.885779</td>\n",
       "      <td>0.812321</td>\n",
       "      <td>81.086735</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <th>5</th>\n",
       "      <td>45</td>\n",
       "      <td>0.918797</td>\n",
       "      <td>0.855172</td>\n",
       "      <td>0.756371</td>\n",
       "      <td>27.435359</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <th>5</th>\n",
       "      <td>45</td>\n",
       "      <td>0.868709</td>\n",
       "      <td>0.809040</td>\n",
       "      <td>0.651561</td>\n",
       "      <td>83.432832</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>122</th>\n",
       "      <th>5</th>\n",
       "      <td>45</td>\n",
       "      <td>0.917368</td>\n",
       "      <td>0.824698</td>\n",
       "      <td>0.699409</td>\n",
       "      <td>19.066890</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>184 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                              epoch  train_score  test_score  test_score_20  \\\n",
       "no_of_features hidden_layers                                                  \n",
       "8              3                 45     0.933878    0.864487       0.773080   \n",
       "32             3                 45     0.942769    0.814895       0.750380   \n",
       "122            3                 45     0.946738    0.768675       0.575612   \n",
       "8              5                 45     0.783775    0.858632       0.786160   \n",
       "32             5                 45     0.835450    0.824610       0.723038   \n",
       "122            5                 45     0.926893    0.806290       0.679072   \n",
       "8              3                 45     0.933878    0.864487       0.773080   \n",
       "32             3                 45     0.942769    0.814895       0.750380   \n",
       "122            3                 45     0.946738    0.768675       0.575612   \n",
       "8              5                 45     0.783775    0.858632       0.786160   \n",
       "32             5                 45     0.835450    0.824610       0.723038   \n",
       "122            5                 45     0.926893    0.806290       0.679072   \n",
       "8              3                 45     0.911811    0.821017       0.689705   \n",
       "32             3                 45     0.912208    0.864221       0.761519   \n",
       "122            3                 45     0.930941    0.816936       0.770042   \n",
       "8              5                 45     0.942769    0.838227       0.706498   \n",
       "32             5                 45     0.923401    0.866616       0.775190   \n",
       "...                             ...          ...         ...            ...   \n",
       "122            5                 45     0.906969    0.827094       0.754768   \n",
       "4              3                 45     0.898635    0.780119       0.742532   \n",
       "8              3                 45     0.933799    0.846389       0.755443   \n",
       "32             3                 45     0.953485    0.836187       0.708776   \n",
       "122            3                 45     0.946023    0.829666       0.723713   \n",
       "4              5                 45     0.782346    0.857035       0.786076   \n",
       "8              5                 45     0.900540    0.878416       0.802869   \n",
       "32             5                 45     0.927687    0.862535       0.764135   \n",
       "122            5                 45     0.843467    0.820706       0.758059   \n",
       "4              3                 45     0.922527    0.882186       0.799409   \n",
       "8              3                 45     0.962613    0.783534       0.640844   \n",
       "32             3                 45     0.910462    0.813254       0.659409   \n",
       "122            3                 45     0.922527    0.829001       0.697468   \n",
       "4              5                 45     0.880616    0.885779       0.812321   \n",
       "8              5                 45     0.918797    0.855172       0.756371   \n",
       "32             5                 45     0.868709    0.809040       0.651561   \n",
       "122            5                 45     0.917368    0.824698       0.699409   \n",
       "\n",
       "                              time_taken  \n",
       "no_of_features hidden_layers              \n",
       "8              3               56.184884  \n",
       "32             3              149.667458  \n",
       "122            3                6.564366  \n",
       "8              5              182.730184  \n",
       "32             5              190.228723  \n",
       "122            5                9.157173  \n",
       "8              3               56.184884  \n",
       "32             3              149.667458  \n",
       "122            3                6.564366  \n",
       "8              5              182.730184  \n",
       "32             5              190.228723  \n",
       "122            5                9.157173  \n",
       "8              3                5.060908  \n",
       "32             3                5.399013  \n",
       "122            3               18.663067  \n",
       "8              5               75.094590  \n",
       "32             5               23.876250  \n",
       "...                                  ...  \n",
       "122            5               12.914905  \n",
       "4              3                3.725165  \n",
       "8              3               73.963892  \n",
       "32             3                3.930030  \n",
       "122            3                4.631668  \n",
       "4              5              227.792873  \n",
       "8              5               82.466326  \n",
       "32             5              112.570260  \n",
       "122            5                6.386500  \n",
       "4              3               93.924781  \n",
       "8              3               29.498731  \n",
       "32             3               19.190202  \n",
       "122            3                4.617370  \n",
       "4              5               81.086735  \n",
       "8              5               27.435359  \n",
       "32             5               83.432832  \n",
       "122            5               19.066890  \n",
       "\n",
       "[184 rows x 5 columns]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "past_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-06-29T12:11:27.960176Z",
     "start_time": "2017-06-29T12:11:27.943976Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>epoch</th>\n",
       "      <th>train_score</th>\n",
       "      <th>test_score</th>\n",
       "      <th>test_score_20</th>\n",
       "      <th>time_taken</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>no_of_features</th>\n",
       "      <th>hidden_layers</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">4</th>\n",
       "      <th>3</th>\n",
       "      <td>45</td>\n",
       "      <td>0.905478</td>\n",
       "      <td>0.848246</td>\n",
       "      <td>0.762869</td>\n",
       "      <td>68.463217</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>45</td>\n",
       "      <td>0.874430</td>\n",
       "      <td>0.853582</td>\n",
       "      <td>0.760030</td>\n",
       "      <td>105.413531</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">8</th>\n",
       "      <th>3</th>\n",
       "      <td>45</td>\n",
       "      <td>0.932218</td>\n",
       "      <td>0.836769</td>\n",
       "      <td>0.741220</td>\n",
       "      <td>53.515072</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>45</td>\n",
       "      <td>0.878241</td>\n",
       "      <td>0.849433</td>\n",
       "      <td>0.745122</td>\n",
       "      <td>105.267146</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">32</th>\n",
       "      <th>3</th>\n",
       "      <td>45</td>\n",
       "      <td>0.930502</td>\n",
       "      <td>0.842015</td>\n",
       "      <td>0.741285</td>\n",
       "      <td>36.442210</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>45</td>\n",
       "      <td>0.900726</td>\n",
       "      <td>0.841872</td>\n",
       "      <td>0.733661</td>\n",
       "      <td>85.737220</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">122</th>\n",
       "      <th>3</th>\n",
       "      <td>45</td>\n",
       "      <td>0.930080</td>\n",
       "      <td>0.821276</td>\n",
       "      <td>0.712713</td>\n",
       "      <td>30.276869</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>45</td>\n",
       "      <td>0.908478</td>\n",
       "      <td>0.833360</td>\n",
       "      <td>0.723307</td>\n",
       "      <td>69.061075</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                              epoch  train_score  test_score  test_score_20  \\\n",
       "no_of_features hidden_layers                                                  \n",
       "4              3                 45     0.905478    0.848246       0.762869   \n",
       "               5                 45     0.874430    0.853582       0.760030   \n",
       "8              3                 45     0.932218    0.836769       0.741220   \n",
       "               5                 45     0.878241    0.849433       0.745122   \n",
       "32             3                 45     0.930502    0.842015       0.741285   \n",
       "               5                 45     0.900726    0.841872       0.733661   \n",
       "122            3                 45     0.930080    0.821276       0.712713   \n",
       "               5                 45     0.908478    0.833360       0.723307   \n",
       "\n",
       "                              time_taken  \n",
       "no_of_features hidden_layers              \n",
       "4              3               68.463217  \n",
       "               5              105.413531  \n",
       "8              3               53.515072  \n",
       "               5              105.267146  \n",
       "32             3               36.442210  \n",
       "               5               85.737220  \n",
       "122            3               30.276869  \n",
       "               5               69.061075  "
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pgb = past_scores.groupby(by=['no_of_features', 'hidden_layers'])\n",
    "pgb.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-06-29T12:10:19.068384Z",
     "start_time": "2017-06-29T12:10:19.053096Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>epoch</th>\n",
       "      <th>train_score</th>\n",
       "      <th>test_score</th>\n",
       "      <th>test_score_20</th>\n",
       "      <th>time_taken</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>no_of_features</th>\n",
       "      <th>hidden_layers</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">4</th>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.027673</td>\n",
       "      <td>0.030943</td>\n",
       "      <td>0.052406</td>\n",
       "      <td>49.880257</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.038355</td>\n",
       "      <td>0.033142</td>\n",
       "      <td>0.054344</td>\n",
       "      <td>62.122828</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">8</th>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.017941</td>\n",
       "      <td>0.026494</td>\n",
       "      <td>0.041137</td>\n",
       "      <td>48.249231</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.041464</td>\n",
       "      <td>0.033766</td>\n",
       "      <td>0.070242</td>\n",
       "      <td>61.405989</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">32</th>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.015369</td>\n",
       "      <td>0.022095</td>\n",
       "      <td>0.046647</td>\n",
       "      <td>50.888603</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.041707</td>\n",
       "      <td>0.033306</td>\n",
       "      <td>0.056131</td>\n",
       "      <td>66.039826</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">122</th>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.027497</td>\n",
       "      <td>0.029783</td>\n",
       "      <td>0.063613</td>\n",
       "      <td>40.722067</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.033715</td>\n",
       "      <td>0.029876</td>\n",
       "      <td>0.059322</td>\n",
       "      <td>97.432520</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                              epoch  train_score  test_score  test_score_20  \\\n",
       "no_of_features hidden_layers                                                  \n",
       "4              3                0.0     0.027673    0.030943       0.052406   \n",
       "               5                0.0     0.038355    0.033142       0.054344   \n",
       "8              3                0.0     0.017941    0.026494       0.041137   \n",
       "               5                0.0     0.041464    0.033766       0.070242   \n",
       "32             3                0.0     0.015369    0.022095       0.046647   \n",
       "               5                0.0     0.041707    0.033306       0.056131   \n",
       "122            3                0.0     0.027497    0.029783       0.063613   \n",
       "               5                0.0     0.033715    0.029876       0.059322   \n",
       "\n",
       "                              time_taken  \n",
       "no_of_features hidden_layers              \n",
       "4              3               49.880257  \n",
       "               5               62.122828  \n",
       "8              3               48.249231  \n",
       "               5               61.405989  \n",
       "32             3               50.888603  \n",
       "               5               66.039826  \n",
       "122            3               40.722067  \n",
       "               5               97.432520  "
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pgb.std()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "_draft": {
   "nbviewer_url": "https://gist.github.com/7d1ace18a82178e15ece8fc5252fce88"
  },
  "anaconda-cloud": {},
  "gist": {
   "data": {
    "description": "Hyper parameter tuning",
    "public": false
   },
   "id": "7d1ace18a82178e15ece8fc5252fce88"
  },
  "kernelspec": {
   "display_name": "Python [conda env:p3]",
   "language": "python",
   "name": "conda-env-p3-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
