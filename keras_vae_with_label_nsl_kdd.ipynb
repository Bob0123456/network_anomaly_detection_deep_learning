{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Deep Learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.layers import Input, Dense, Lambda, Layer\n",
    "from keras.models import Model\n",
    "from keras import regularizers\n",
    "import keras\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from keras import backend as K\n",
    "from keras import metrics\n",
    "from collections import namedtuple\n",
    "pd.set_option(\"display.max_rows\",35)\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "kdd_train_2labels = pd.read_pickle(\"dataset/kdd_train_2labels.pkl\")\n",
    "kdd_test_2labels = pd.read_pickle(\"dataset/kdd_test_2labels.pkl\")\n",
    "\n",
    "#y_train_labels = pd.read_pickle(\"dataset/kdd_train_2labels_y.pkl\")\n",
    "#y_train_labels = pd.read_pickle(\"dataset/kdd_train_2labels.pkl\")\n",
    "#y_test_labels = pd.read_pickle(\"dataset/kdd_test_2labels_y.pkl\")\n",
    "\n",
    "output_columns_2labels = ['is_Attack','is_Normal']\n",
    "\n",
    "from sklearn import model_selection as ms\n",
    "from sklearn import preprocessing as pp\n",
    "\n",
    "x_input = kdd_train_2labels.drop(output_columns_2labels, axis = 1)\n",
    "y_output = kdd_train_2labels.loc[:,output_columns_2labels]\n",
    "\n",
    "ss = pp.StandardScaler()\n",
    "x_input = ss.fit_transform(x_input)\n",
    "\n",
    "#le = pp.LabelEncoder()\n",
    "#y_train = le.fit_transform(y_train_labels).reshape(-1, 1)\n",
    "#y_test = le.transform(y_test_labels).reshape(-1, 1)\n",
    "\n",
    "y_train = kdd_train_2labels.loc[:,output_columns_2labels]\n",
    "\n",
    "x_train, x_valid, y_train, y_valid = ms.train_test_split(x_input, \n",
    "                              y_train, \n",
    "                              test_size=0.1)\n",
    "#x_valid, x_test, y_valid, y_test = ms.train_test_split(x_valid, y_valid, test_size = 0.4)\n",
    "\n",
    "x_test = kdd_test_2labels.drop(output_columns_2labels, axis = 1)\n",
    "y_test = kdd_test_2labels.loc[:,output_columns_2labels]\n",
    "\n",
    "x_test = ss.transform(x_test)\n",
    "\n",
    "x_train = np.hstack((x_train, y_train))\n",
    "x_valid = np.hstack((x_valid, y_valid))\n",
    "\n",
    "x_test = np.hstack((x_test, np.random.normal(loc = 0, scale = 0.01, size = y_test.shape)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "input_dim = 124\n",
    "intermediate_dim = 124\n",
    "latent_dim = 32\n",
    "batch_size = 1409\n",
    "epochs = 5\n",
    "hidden_layers = 8\n",
    "\n",
    "class Train:\n",
    "    def train():\n",
    "        Train.x = Input(shape=(input_dim,))\n",
    "        \n",
    "        hidden_encoder = Train.x\n",
    "        for i in range(hidden_layers):\n",
    "            hidden_encoder = Dense(intermediate_dim, activation='relu')(hidden_encoder)\n",
    "\n",
    "        mean_encoder = Dense(latent_dim, activation=None)(hidden_encoder)\n",
    "\n",
    "        logvar_encoder = Dense(latent_dim, activation=None)(hidden_encoder)\n",
    "\n",
    "        def get_distrib(args):\n",
    "\n",
    "            Train.mean_encoder, Train.logvar_encoder = args\n",
    "\n",
    "            # Sample epsilon\n",
    "            epsilon = np.random.normal(loc=0.0, scale=0.05, size = (batch_size, latent_dim))\n",
    "\n",
    "            # Sample latent variable\n",
    "            z = mean_encoder + K.exp(logvar_encoder / 2) * epsilon\n",
    "            return z\n",
    "\n",
    "        z = Lambda(get_distrib)([mean_encoder, logvar_encoder])\n",
    "\n",
    "        hidden_decoder = z\n",
    "        for i in range(hidden_layers):\n",
    "            hidden_decoder = Dense(intermediate_dim, activation=\"relu\")(hidden_decoder)\n",
    "\n",
    "        Train.x_ = Dense(input_dim, activation=None)(hidden_decoder)\n",
    "\n",
    "def get_loss(args):\n",
    "    x, x_ = args\n",
    "    xent_loss = metrics.binary_crossentropy(x, x_) #input_dim *\n",
    "    kl_loss = - 0.5 * K.sum(1 + Train.logvar_encoder - K.square(Train.mean_encoder) - K.exp(Train.logvar_encoder), axis=-1)\n",
    "    label_loss = K.mean(K.argmax(Train.x[:,-2:], axis = 1) - K.argmax(Train.x_[:,-2:], axis = 1))\n",
    "    \n",
    "    ls = xent_loss + kl_loss\n",
    "    #ls += label_loss\n",
    "    \n",
    "    return ls\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " \n",
      " Current Layer Attributes - epochs:50 hidden layers:2 features count:4\n",
      "Train on 112720 samples, validate on 22544 samples\n",
      "Epoch 1/50\n",
      "112720/112720 [==============================] - 1s - loss: 1.6581 - acc: 0.0165 - label_accuracy: 0.0165 - val_loss: 1.7722 - val_acc: 0.0841 - val_label_accuracy: 0.0841\n",
      "Epoch 2/50\n",
      "112720/112720 [==============================] - 1s - loss: 276.1450 - acc: 0.2064 - label_accuracy: 0.2064 - val_loss: 1.7912 - val_acc: 0.3401 - val_label_accuracy: 0.3401\n",
      "Epoch 3/50\n",
      "112720/112720 [==============================] - 0s - loss: 0.7537 - acc: 0.2612 - label_accuracy: 0.2612 - val_loss: 1.6966 - val_acc: 0.3467 - val_label_accuracy: 0.3467\n",
      "Epoch 4/50\n",
      "112720/112720 [==============================] - 0s - loss: 0.6940 - acc: 0.5030 - label_accuracy: 0.5030 - val_loss: 1.6625 - val_acc: 0.6281 - val_label_accuracy: 0.6281\n",
      "Epoch 5/50\n",
      "112720/112720 [==============================] - 0s - loss: 0.6735 - acc: 0.5327 - label_accuracy: 0.5327 - val_loss: 1.6423 - val_acc: 0.6217 - val_label_accuracy: 0.6217\n",
      "Epoch 6/50\n",
      "112720/112720 [==============================] - 1s - loss: 0.6577 - acc: 0.5577 - label_accuracy: 0.5577 - val_loss: 1.6193 - val_acc: 0.6427 - val_label_accuracy: 0.6427\n",
      "Epoch 7/50\n",
      "112720/112720 [==============================] - 1s - loss: 0.6435 - acc: 0.5924 - label_accuracy: 0.5924 - val_loss: 1.6028 - val_acc: 0.6439 - val_label_accuracy: 0.6439\n",
      "Epoch 8/50\n",
      "112720/112720 [==============================] - 1s - loss: 0.6302 - acc: 0.6123 - label_accuracy: 0.6123 - val_loss: 1.5832 - val_acc: 0.5719 - val_label_accuracy: 0.5719\n",
      "Epoch 9/50\n",
      "112720/112720 [==============================] - 1s - loss: 0.6176 - acc: 0.6239 - label_accuracy: 0.6239 - val_loss: 1.5551 - val_acc: 0.6588 - val_label_accuracy: 0.6588\n",
      "Epoch 10/50\n",
      "112720/112720 [==============================] - 1s - loss: 0.6044 - acc: 0.6325 - label_accuracy: 0.6325 - val_loss: 1.5215 - val_acc: 0.6811 - val_label_accuracy: 0.6811\n",
      "Epoch 11/50\n",
      "112720/112720 [==============================] - 1s - loss: 0.5916 - acc: 0.6459 - label_accuracy: 0.6459 - val_loss: 1.4912 - val_acc: 0.6962 - val_label_accuracy: 0.6962\n",
      "Epoch 12/50\n",
      "112720/112720 [==============================] - 1s - loss: 0.5787 - acc: 0.6549 - label_accuracy: 0.6549 - val_loss: 1.4656 - val_acc: 0.7098 - val_label_accuracy: 0.7098\n",
      "Epoch 13/50\n",
      "112720/112720 [==============================] - 1s - loss: 0.5679 - acc: 0.6628 - label_accuracy: 0.6628 - val_loss: 1.4358 - val_acc: 0.7060 - val_label_accuracy: 0.7060\n",
      "Epoch 14/50\n",
      "112720/112720 [==============================] - 1s - loss: 0.5561 - acc: 0.6733 - label_accuracy: 0.6733 - val_loss: 1.3953 - val_acc: 0.7207 - val_label_accuracy: 0.7207\n",
      "Epoch 15/50\n",
      "112720/112720 [==============================] - 1s - loss: 0.5442 - acc: 0.6861 - label_accuracy: 0.6861 - val_loss: 1.3708 - val_acc: 0.7331 - val_label_accuracy: 0.7331\n",
      "Epoch 16/50\n",
      "112720/112720 [==============================] - 1s - loss: 0.5353 - acc: 0.6884 - label_accuracy: 0.6884 - val_loss: 1.3554 - val_acc: 0.7120 - val_label_accuracy: 0.7120\n",
      "Epoch 17/50\n",
      "112720/112720 [==============================] - 1s - loss: 0.5219 - acc: 0.6949 - label_accuracy: 0.6949 - val_loss: 1.3067 - val_acc: 0.7537 - val_label_accuracy: 0.7537\n",
      "Epoch 18/50\n",
      "112720/112720 [==============================] - 1s - loss: 0.5130 - acc: 0.6973 - label_accuracy: 0.6973 - val_loss: 1.2843 - val_acc: 0.7449 - val_label_accuracy: 0.7449\n",
      "Epoch 19/50\n",
      "112720/112720 [==============================] - 1s - loss: 0.5014 - acc: 0.7075 - label_accuracy: 0.7075 - val_loss: 1.2456 - val_acc: 0.7644 - val_label_accuracy: 0.7644\n",
      "Epoch 20/50\n",
      "112720/112720 [==============================] - 1s - loss: 0.4900 - acc: 0.7082 - label_accuracy: 0.7082 - val_loss: 1.2381 - val_acc: 0.7591 - val_label_accuracy: 0.7591\n",
      "Epoch 21/50\n",
      "112720/112720 [==============================] - 1s - loss: 0.4812 - acc: 0.7180 - label_accuracy: 0.7180 - val_loss: 1.2131 - val_acc: 0.7574 - val_label_accuracy: 0.7574\n",
      "Epoch 22/50\n",
      "112720/112720 [==============================] - 0s - loss: 0.4707 - acc: 0.7246 - label_accuracy: 0.7246 - val_loss: 1.1731 - val_acc: 0.7624 - val_label_accuracy: 0.7624\n",
      "Epoch 23/50\n",
      "112720/112720 [==============================] - 0s - loss: 0.4633 - acc: 0.7402 - label_accuracy: 0.7402 - val_loss: 1.1642 - val_acc: 0.7700 - val_label_accuracy: 0.7700\n",
      "Epoch 24/50\n",
      "112720/112720 [==============================] - 1s - loss: 0.4554 - acc: 0.7473 - label_accuracy: 0.7473 - val_loss: 1.1354 - val_acc: 0.7410 - val_label_accuracy: 0.7410\n",
      "Epoch 25/50\n",
      "112720/112720 [==============================] - 1s - loss: 0.4468 - acc: 0.7519 - label_accuracy: 0.7519 - val_loss: 1.1234 - val_acc: 0.7754 - val_label_accuracy: 0.7754\n",
      "Epoch 26/50\n",
      "112720/112720 [==============================] - 1s - loss: 0.4381 - acc: 0.7677 - label_accuracy: 0.7677 - val_loss: 1.1026 - val_acc: 0.7206 - val_label_accuracy: 0.7206\n",
      "Epoch 27/50\n",
      "112720/112720 [==============================] - 1s - loss: 0.4279 - acc: 0.7789 - label_accuracy: 0.7789 - val_loss: 1.1018 - val_acc: 0.7263 - val_label_accuracy: 0.7263\n",
      "Epoch 28/50\n",
      "112720/112720 [==============================] - 1s - loss: 0.4198 - acc: 0.7811 - label_accuracy: 0.7811 - val_loss: 1.0606 - val_acc: 0.7341 - val_label_accuracy: 0.7341\n",
      "Epoch 29/50\n",
      "112720/112720 [==============================] - 1s - loss: 0.4123 - acc: 0.8028 - label_accuracy: 0.8028 - val_loss: 1.0734 - val_acc: 0.7173 - val_label_accuracy: 0.7173\n",
      "Epoch 30/50\n",
      "112720/112720 [==============================] - 1s - loss: 0.4055 - acc: 0.7937 - label_accuracy: 0.7937 - val_loss: 1.0534 - val_acc: 0.7224 - val_label_accuracy: 0.7224\n",
      "Epoch 31/50\n",
      "112720/112720 [==============================] - 1s - loss: 0.3978 - acc: 0.8068 - label_accuracy: 0.8068 - val_loss: 1.0210 - val_acc: 0.7088 - val_label_accuracy: 0.7088\n",
      "Epoch 32/50\n",
      "112720/112720 [==============================] - 1s - loss: 0.3890 - acc: 0.8133 - label_accuracy: 0.8133 - val_loss: 1.0189 - val_acc: 0.7295 - val_label_accuracy: 0.7295\n",
      "Epoch 33/50\n",
      "112720/112720 [==============================] - 1s - loss: 0.3885 - acc: 0.7927 - label_accuracy: 0.7927 - val_loss: 1.0183 - val_acc: 0.6914 - val_label_accuracy: 0.6914\n",
      "Epoch 34/50\n",
      "112720/112720 [==============================] - 1s - loss: 0.3816 - acc: 0.7998 - label_accuracy: 0.7998 - val_loss: 0.9968 - val_acc: 0.7252 - val_label_accuracy: 0.7252\n",
      "Epoch 35/50\n",
      "112720/112720 [==============================] - 1s - loss: 0.3743 - acc: 0.8151 - label_accuracy: 0.8151 - val_loss: 1.0041 - val_acc: 0.7195 - val_label_accuracy: 0.7195\n",
      "Epoch 36/50\n",
      "112720/112720 [==============================] - 1s - loss: 0.3684 - acc: 0.8145 - label_accuracy: 0.8145 - val_loss: 0.9846 - val_acc: 0.7221 - val_label_accuracy: 0.7221\n",
      "Epoch 37/50\n",
      "112720/112720 [==============================] - 1s - loss: 0.3638 - acc: 0.8074 - label_accuracy: 0.8074 - val_loss: 0.9897 - val_acc: 0.7708 - val_label_accuracy: 0.7708\n",
      "Epoch 38/50\n",
      "112720/112720 [==============================] - 1s - loss: 0.3603 - acc: 0.8069 - label_accuracy: 0.8069 - val_loss: 0.9581 - val_acc: 0.6812 - val_label_accuracy: 0.6812\n",
      "Epoch 39/50\n",
      "112720/112720 [==============================] - 1s - loss: 0.3527 - acc: 0.8135 - label_accuracy: 0.8135 - val_loss: 0.9475 - val_acc: 0.7394 - val_label_accuracy: 0.7394\n",
      "Epoch 40/50\n",
      "112720/112720 [==============================] - 1s - loss: 0.3491 - acc: 0.8126 - label_accuracy: 0.8126 - val_loss: 0.9234 - val_acc: 0.7701 - val_label_accuracy: 0.7701\n",
      "Epoch 41/50\n",
      "112720/112720 [==============================] - 1s - loss: 0.3439 - acc: 0.8126 - label_accuracy: 0.8126 - val_loss: 0.9200 - val_acc: 0.7832 - val_label_accuracy: 0.7832\n",
      "Epoch 42/50\n",
      "112720/112720 [==============================] - 1s - loss: 0.3348 - acc: 0.8255 - label_accuracy: 0.8255 - val_loss: 0.9072 - val_acc: 0.7857 - val_label_accuracy: 0.7857\n",
      "Epoch 43/50\n",
      "112720/112720 [==============================] - 1s - loss: 0.3344 - acc: 0.8270 - label_accuracy: 0.8270 - val_loss: 0.9190 - val_acc: 0.7863 - val_label_accuracy: 0.7863\n",
      "Epoch 44/50\n",
      "112720/112720 [==============================] - 1s - loss: 0.3343 - acc: 0.8193 - label_accuracy: 0.8193 - val_loss: 0.9046 - val_acc: 0.7792 - val_label_accuracy: 0.7792\n",
      "Epoch 45/50\n",
      "112720/112720 [==============================] - 1s - loss: 0.3283 - acc: 0.8248 - label_accuracy: 0.8248 - val_loss: 0.8756 - val_acc: 0.7688 - val_label_accuracy: 0.7688\n",
      "Epoch 46/50\n",
      "112720/112720 [==============================] - 1s - loss: 0.3242 - acc: 0.8247 - label_accuracy: 0.8247 - val_loss: 0.8893 - val_acc: 0.7839 - val_label_accuracy: 0.7839\n",
      "Epoch 47/50\n",
      "112720/112720 [==============================] - 1s - loss: 0.3212 - acc: 0.8281 - label_accuracy: 0.8281 - val_loss: 0.8755 - val_acc: 0.7765 - val_label_accuracy: 0.7765\n",
      "Epoch 48/50\n",
      "112720/112720 [==============================] - 1s - loss: 0.3142 - acc: 0.8323 - label_accuracy: 0.8323 - val_loss: 0.8573 - val_acc: 0.7697 - val_label_accuracy: 0.7697\n",
      "Epoch 49/50\n",
      "112720/112720 [==============================] - 1s - loss: 0.3214 - acc: 0.8187 - label_accuracy: 0.8187 - val_loss: 0.8433 - val_acc: 0.7457 - val_label_accuracy: 0.7457\n",
      "Epoch 50/50\n",
      "112720/112720 [==============================] - 1s - loss: 0.3175 - acc: 0.8106 - label_accuracy: 0.8106 - val_loss: 0.8399 - val_acc: 0.7563 - val_label_accuracy: 0.7563\n",
      "12681/22544 [===============>..............] - ETA: 0s\n",
      " Train Acc: 0.8445706218481064, Test Acc: 0.7562987916171551, Label Acc: 0.77541696238467\n",
      " \n",
      " Current Layer Attributes - epochs:50 hidden layers:2 features count:16\n",
      "Train on 112720 samples, validate on 22544 samples\n",
      "Epoch 1/50\n",
      "112720/112720 [==============================] - 1s - loss: 24559.3123 - acc: 0.2334 - label_accuracy: 0.2334 - val_loss: 1.7802 - val_acc: 0.3658 - val_label_accuracy: 0.3658\n",
      "Epoch 2/50\n",
      "112720/112720 [==============================] - 1s - loss: 81662.2312 - acc: 0.3653 - label_accuracy: 0.3653 - val_loss: 1.6910 - val_acc: 0.5898 - val_label_accuracy: 0.5898\n",
      "Epoch 3/50\n",
      "112720/112720 [==============================] - 1s - loss: 668632935.0687 - acc: 0.4445 - label_accuracy: 0.4445 - val_loss: 1.6228 - val_acc: 0.4658 - val_label_accuracy: 0.4658\n",
      "Epoch 4/50\n",
      "112720/112720 [==============================] - 1s - loss: 0.6428 - acc: 0.3184 - label_accuracy: 0.3184 - val_loss: 1.5828 - val_acc: 0.5105 - val_label_accuracy: 0.5105\n",
      "Epoch 5/50\n",
      "112720/112720 [==============================] - 1s - loss: 0.6099 - acc: 0.4622 - label_accuracy: 0.4622 - val_loss: 1.5070 - val_acc: 0.6068 - val_label_accuracy: 0.6068\n",
      "Epoch 6/50\n",
      "112720/112720 [==============================] - 1s - loss: 0.5845 - acc: 0.5062 - label_accuracy: 0.5062 - val_loss: 1.4680 - val_acc: 0.6998 - val_label_accuracy: 0.6998\n",
      "Epoch 7/50\n",
      "112720/112720 [==============================] - 1s - loss: 0.5634 - acc: 0.5365 - label_accuracy: 0.5365 - val_loss: 1.4150 - val_acc: 0.7108 - val_label_accuracy: 0.7108\n",
      "Epoch 8/50\n",
      "112720/112720 [==============================] - 1s - loss: 0.5455 - acc: 0.5827 - label_accuracy: 0.5827 - val_loss: 1.3928 - val_acc: 0.7596 - val_label_accuracy: 0.7596\n",
      "Epoch 9/50\n",
      "112720/112720 [==============================] - 1s - loss: 0.5307 - acc: 0.6044 - label_accuracy: 0.6044 - val_loss: 1.3719 - val_acc: 0.7736 - val_label_accuracy: 0.7736\n",
      "Epoch 10/50\n",
      "112720/112720 [==============================] - 1s - loss: 0.5173 - acc: 0.6468 - label_accuracy: 0.6468 - val_loss: 1.3484 - val_acc: 0.7553 - val_label_accuracy: 0.7553\n",
      "Epoch 11/50\n",
      "112720/112720 [==============================] - 1s - loss: 0.5062 - acc: 0.6560 - label_accuracy: 0.6560 - val_loss: 1.3342 - val_acc: 0.7548 - val_label_accuracy: 0.7548\n",
      "Epoch 12/50\n",
      "112720/112720 [==============================] - ETA: 0s - loss: 0.4977 - acc: 0.6269 - label_accuracy: 0.6269 ETA: 1s - loss: 0.5304  - 1s - loss: 0.4962 - acc: 0.6265 - label_accuracy: 0.6265 - val_loss: 1.3184 - val_acc: 0.7033 - val_label_accuracy: 0.7033\n",
      "Epoch 13/50\n",
      "112720/112720 [==============================] - 1s - loss: 0.4877 - acc: 0.6122 - label_accuracy: 0.6122 - val_loss: 1.3060 - val_acc: 0.7480 - val_label_accuracy: 0.7480\n",
      "Epoch 14/50\n",
      "112720/112720 [==============================] - 1s - loss: 0.4795 - acc: 0.6074 - label_accuracy: 0.6074 - val_loss: 1.2841 - val_acc: 0.6833 - val_label_accuracy: 0.6833\n",
      "Epoch 15/50\n",
      "112720/112720 [==============================] - 1s - loss: 0.4722 - acc: 0.6086 - label_accuracy: 0.6086 - val_loss: 1.2650 - val_acc: 0.6887 - val_label_accuracy: 0.6887\n",
      "Epoch 16/50\n",
      "112720/112720 [==============================] - 1s - loss: 0.4650 - acc: 0.6019 - label_accuracy: 0.6019 - val_loss: 1.2401 - val_acc: 0.6883 - val_label_accuracy: 0.6883\n",
      "Epoch 17/50\n",
      "112720/112720 [==============================] - 1s - loss: 0.4575 - acc: 0.6056 - label_accuracy: 0.6056 - val_loss: 1.1583 - val_acc: 0.6964 - val_label_accuracy: 0.6964\n",
      "Epoch 18/50\n",
      "112720/112720 [==============================] - 1s - loss: 0.4475 - acc: 0.6127 - label_accuracy: 0.6127 - val_loss: 1.1501 - val_acc: 0.7071 - val_label_accuracy: 0.7071\n",
      "Epoch 19/50\n",
      "112720/112720 [==============================] - 1s - loss: 0.4418 - acc: 0.6310 - label_accuracy: 0.6310 - val_loss: 1.1316 - val_acc: 0.7390 - val_label_accuracy: 0.7390\n",
      "Epoch 20/50\n",
      "112720/112720 [==============================] - 1s - loss: 0.4365 - acc: 0.6162 - label_accuracy: 0.6162 - val_loss: 1.1192 - val_acc: 0.7066 - val_label_accuracy: 0.7066\n",
      "Epoch 21/50\n",
      "112720/112720 [==============================] - 1s - loss: 0.4323 - acc: 0.6081 - label_accuracy: 0.6081 - val_loss: 1.1089 - val_acc: 0.7035 - val_label_accuracy: 0.7035\n",
      "Epoch 22/50\n",
      "112720/112720 [==============================] - 1s - loss: 0.4276 - acc: 0.6238 - label_accuracy: 0.6238 - val_loss: 1.1051 - val_acc: 0.7006 - val_label_accuracy: 0.7006\n",
      "Epoch 23/50\n",
      "112720/112720 [==============================] - 1s - loss: 0.4243 - acc: 0.6337 - label_accuracy: 0.6337 - val_loss: 1.0934 - val_acc: 0.7340 - val_label_accuracy: 0.7340\n",
      "Epoch 24/50\n",
      "112720/112720 [==============================] - 1s - loss: 0.4201 - acc: 0.6226 - label_accuracy: 0.6226 - val_loss: 1.0987 - val_acc: 0.6609 - val_label_accuracy: 0.6609\n",
      "Epoch 25/50\n",
      "112720/112720 [==============================] - 1s - loss: 0.4172 - acc: 0.6323 - label_accuracy: 0.6323 - val_loss: 1.0907 - val_acc: 0.7302 - val_label_accuracy: 0.7302\n",
      "Epoch 26/50\n",
      "112720/112720 [==============================] - 1s - loss: 0.4142 - acc: 0.6304 - label_accuracy: 0.6304 - val_loss: 1.0807 - val_acc: 0.7377 - val_label_accuracy: 0.7377\n",
      "Epoch 27/50\n",
      "112720/112720 [==============================] - 1s - loss: 0.4114 - acc: 0.6365 - label_accuracy: 0.6365 - val_loss: 1.0658 - val_acc: 0.7578 - val_label_accuracy: 0.7578\n",
      "Epoch 28/50\n",
      "112720/112720 [==============================] - 1s - loss: 0.4088 - acc: 0.6279 - label_accuracy: 0.6279 - val_loss: 1.0768 - val_acc: 0.7391 - val_label_accuracy: 0.7391\n",
      "Epoch 29/50\n",
      "112720/112720 [==============================] - 1s - loss: 0.4081 - acc: 0.6457 - label_accuracy: 0.6457 - val_loss: 1.0621 - val_acc: 0.7673 - val_label_accuracy: 0.7673\n",
      "Epoch 30/50\n",
      "112720/112720 [==============================] - 1s - loss: 0.4043 - acc: 0.6433 - label_accuracy: 0.6433 - val_loss: 1.0582 - val_acc: 0.7754 - val_label_accuracy: 0.7754\n",
      "Epoch 31/50\n",
      "112720/112720 [==============================] - 1s - loss: 0.4033 - acc: 0.6653 - label_accuracy: 0.6653 - val_loss: 1.0480 - val_acc: 0.7771 - val_label_accuracy: 0.7771\n",
      "Epoch 32/50\n",
      "112720/112720 [==============================] - 1s - loss: 0.3997 - acc: 0.6671 - label_accuracy: 0.6671 - val_loss: 1.0383 - val_acc: 0.7744 - val_label_accuracy: 0.7744\n",
      "Epoch 33/50\n",
      "112720/112720 [==============================] - 1s - loss: 0.3965 - acc: 0.6772 - label_accuracy: 0.6772 - val_loss: 1.0411 - val_acc: 0.8197 - val_label_accuracy: 0.8197\n",
      "Epoch 34/50\n",
      "112720/112720 [==============================] - 1s - loss: 0.3951 - acc: 0.6892 - label_accuracy: 0.6892 - val_loss: 1.0361 - val_acc: 0.8062 - val_label_accuracy: 0.8062\n",
      "Epoch 35/50\n",
      "112720/112720 [==============================] - 1s - loss: 0.3935 - acc: 0.6907 - label_accuracy: 0.6907 - val_loss: 1.0301 - val_acc: 0.7693 - val_label_accuracy: 0.7693\n",
      "Epoch 36/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "112720/112720 [==============================] - 1s - loss: 0.3913 - acc: 0.7055 - label_accuracy: 0.7055 - val_loss: 1.0318 - val_acc: 0.8428 - val_label_accuracy: 0.8428\n",
      "Epoch 37/50\n",
      "112720/112720 [==============================] - 1s - loss: 0.3896 - acc: 0.7103 - label_accuracy: 0.7103 - val_loss: 1.0252 - val_acc: 0.8341 - val_label_accuracy: 0.8341\n",
      "Epoch 38/50\n",
      "112720/112720 [==============================] - 1s - loss: 0.3885 - acc: 0.6997 - label_accuracy: 0.6997 - val_loss: 1.0161 - val_acc: 0.8283 - val_label_accuracy: 0.8283\n",
      "Epoch 39/50\n",
      "112720/112720 [==============================] - 1s - loss: 0.3869 - acc: 0.7292 - label_accuracy: 0.7292 - val_loss: 1.0161 - val_acc: 0.8325 - val_label_accuracy: 0.8325\n",
      "Epoch 40/50\n",
      "112720/112720 [==============================] - 1s - loss: 0.3855 - acc: 0.7279 - label_accuracy: 0.7279 - val_loss: 1.0216 - val_acc: 0.8439 - val_label_accuracy: 0.8439\n",
      "Epoch 41/50\n",
      "112720/112720 [==============================] - 1s - loss: 0.3841 - acc: 0.7332 - label_accuracy: 0.7332 - val_loss: 1.0362 - val_acc: 0.8453 - val_label_accuracy: 0.8453\n",
      "Epoch 42/50\n",
      "112720/112720 [==============================] - 1s - loss: 0.3851 - acc: 0.7250 - label_accuracy: 0.7250 - val_loss: 1.0235 - val_acc: 0.8567 - val_label_accuracy: 0.8567\n",
      "Epoch 43/50\n",
      "112720/112720 [==============================] - 1s - loss: 0.3806 - acc: 0.7353 - label_accuracy: 0.7353 - val_loss: 1.0285 - val_acc: 0.8225 - val_label_accuracy: 0.8225\n",
      "Epoch 44/50\n",
      "112720/112720 [==============================] - 1s - loss: 0.3801 - acc: 0.7291 - label_accuracy: 0.7291 - val_loss: 1.0078 - val_acc: 0.8522 - val_label_accuracy: 0.8522\n",
      "Epoch 45/50\n",
      "112720/112720 [==============================] - 1s - loss: 0.3756 - acc: 0.7417 - label_accuracy: 0.7417 - val_loss: 1.0069 - val_acc: 0.8445 - val_label_accuracy: 0.8445\n",
      "Epoch 46/50\n",
      "112720/112720 [==============================] - 1s - loss: 0.3740 - acc: 0.7378 - label_accuracy: 0.7378 - val_loss: 1.0027 - val_acc: 0.8450 - val_label_accuracy: 0.8450\n",
      "Epoch 47/50\n",
      "112720/112720 [==============================] - 1s - loss: 0.3724 - acc: 0.7318 - label_accuracy: 0.7318 - val_loss: 0.9881 - val_acc: 0.8462 - val_label_accuracy: 0.8462\n",
      "Epoch 48/50\n",
      "112720/112720 [==============================] - 1s - loss: 0.3711 - acc: 0.7433 - label_accuracy: 0.7433 - val_loss: 1.0100 - val_acc: 0.8494 - val_label_accuracy: 0.8494\n",
      "Epoch 49/50\n",
      "112720/112720 [==============================] - 1s - loss: 0.3713 - acc: 0.7462 - label_accuracy: 0.7462 - val_loss: 1.0111 - val_acc: 0.8370 - val_label_accuracy: 0.8370\n",
      "Epoch 50/50\n",
      "112720/112720 [==============================] - 1s - loss: 0.3707 - acc: 0.7461 - label_accuracy: 0.7461 - val_loss: 1.0048 - val_acc: 0.8757 - val_label_accuracy: 0.8757\n",
      "11272/11272 [==============================] - 0s     \n",
      "22544/22544 [==============================] - 0s     \n",
      "\n",
      " Train Acc: 0.7657026275992393, Test Acc: 0.8757097236812115, Label Acc: 0.8129435770049681\n",
      " \n",
      " Current Layer Attributes - epochs:50 hidden layers:2 features count:32\n",
      "Train on 112720 samples, validate on 22544 samples\n",
      "Epoch 1/50\n",
      "112720/112720 [==============================] - 2s - loss: 35029115.0798 - acc: 0.0749 - label_accuracy: 0.0749 - val_loss: 89052.0426 - val_acc: 0.0885 - val_label_accuracy: 0.0885\n",
      "Epoch 2/50\n",
      "112720/112720 [==============================] - 1s - loss: 42076.2756 - acc: 0.1086 - label_accuracy: 0.1086 - val_loss: 3343407407104.5928 - val_acc: 0.2728 - val_label_accuracy: 0.2728\n",
      "Epoch 3/50\n",
      "112720/112720 [==============================] - 1s - loss: 47868737.3366 - acc: 0.1036 - label_accuracy: 0.1036 - val_loss: 12702564.6071 - val_acc: 0.2716 - val_label_accuracy: 0.2716\n",
      "Epoch 4/50\n",
      "112720/112720 [==============================] - 1s - loss: nan - acc: 0.1064 - label_accuracy: 0.1064 - val_loss: nan - val_acc: 0.0000e+00 - val_label_accuracy: 0.0000e+00\n",
      "Epoch 5/50\n",
      "112720/112720 [==============================] - 1s - loss: nan - acc: 0.0000e+00 - label_accuracy: 0.0000e+00 - val_loss: nan - val_acc: 0.0000e+00 - val_label_accuracy: 0.0000e+00\n",
      "Epoch 6/50\n",
      "112720/112720 [==============================] - 1s - loss: nan - acc: 0.0000e+00 - label_accuracy: 0.0000e+00 - val_loss: nan - val_acc: 0.0000e+00 - val_label_accuracy: 0.0000e+00\n",
      "Epoch 7/50\n",
      "112720/112720 [==============================] - 1s - loss: nan - acc: 0.0000e+00 - label_accuracy: 0.0000e+00 - val_loss: nan - val_acc: 0.0000e+00 - val_label_accuracy: 0.0000e+00\n",
      "Epoch 8/50\n",
      "112720/112720 [==============================] - 1s - loss: nan - acc: 0.0000e+00 - label_accuracy: 0.0000e+00 - val_loss: nan - val_acc: 0.0000e+00 - val_label_accuracy: 0.0000e+00\n",
      "Epoch 9/50\n",
      "112720/112720 [==============================] - 1s - loss: nan - acc: 0.0000e+00 - label_accuracy: 0.0000e+00 - val_loss: nan - val_acc: 0.0000e+00 - val_label_accuracy: 0.0000e+00\n",
      "Epoch 10/50\n",
      "112720/112720 [==============================] - 1s - loss: nan - acc: 0.0000e+00 - label_accuracy: 0.0000e+00 - val_loss: nan - val_acc: 0.0000e+00 - val_label_accuracy: 0.0000e+00\n",
      "Epoch 11/50\n",
      "112720/112720 [==============================] - 1s - loss: nan - acc: 0.0000e+00 - label_accuracy: 0.0000e+00 - val_loss: nan - val_acc: 0.0000e+00 - val_label_accuracy: 0.0000e+00\n",
      "Epoch 12/50\n",
      "112720/112720 [==============================] - 1s - loss: nan - acc: 0.0000e+00 - label_accuracy: 0.0000e+00 - val_loss: nan - val_acc: 0.0000e+00 - val_label_accuracy: 0.0000e+00\n",
      "Epoch 13/50\n",
      "112720/112720 [==============================] - 1s - loss: nan - acc: 0.0000e+00 - label_accuracy: 0.0000e+00 - val_loss: nan - val_acc: 0.0000e+00 - val_label_accuracy: 0.0000e+00\n",
      "Epoch 14/50\n",
      "112720/112720 [==============================] - 1s - loss: nan - acc: 0.0000e+00 - label_accuracy: 0.0000e+00 - val_loss: nan - val_acc: 0.0000e+00 - val_label_accuracy: 0.0000e+00\n",
      "Epoch 15/50\n",
      "112720/112720 [==============================] - 1s - loss: nan - acc: 0.0000e+00 - label_accuracy: 0.0000e+00 - val_loss: nan - val_acc: 0.0000e+00 - val_label_accuracy: 0.0000e+00\n",
      "Epoch 16/50\n",
      "112720/112720 [==============================] - 1s - loss: nan - acc: 0.0000e+00 - label_accuracy: 0.0000e+00 - val_loss: nan - val_acc: 0.0000e+00 - val_label_accuracy: 0.0000e+00\n",
      "Epoch 17/50\n",
      "112720/112720 [==============================] - 1s - loss: nan - acc: 0.0000e+00 - label_accuracy: 0.0000e+00 - val_loss: nan - val_acc: 0.0000e+00 - val_label_accuracy: 0.0000e+00\n",
      "Epoch 18/50\n",
      "112720/112720 [==============================] - 1s - loss: nan - acc: 0.0000e+00 - label_accuracy: 0.0000e+00 - val_loss: nan - val_acc: 0.0000e+00 - val_label_accuracy: 0.0000e+00\n",
      "Epoch 19/50\n",
      "112720/112720 [==============================] - 1s - loss: nan - acc: 0.0000e+00 - label_accuracy: 0.0000e+00 - val_loss: nan - val_acc: 0.0000e+00 - val_label_accuracy: 0.0000e+00\n",
      "Epoch 20/50\n",
      "112720/112720 [==============================] - 1s - loss: nan - acc: 0.0000e+00 - label_accuracy: 0.0000e+00 - val_loss: nan - val_acc: 0.0000e+00 - val_label_accuracy: 0.0000e+00\n",
      "Epoch 21/50\n",
      "112720/112720 [==============================] - 1s - loss: nan - acc: 0.0000e+00 - label_accuracy: 0.0000e+00 - val_loss: nan - val_acc: 0.0000e+00 - val_label_accuracy: 0.0000e+00\n",
      "Epoch 22/50\n",
      "112720/112720 [==============================] - 1s - loss: nan - acc: 0.0000e+00 - label_accuracy: 0.0000e+00 - val_loss: nan - val_acc: 0.0000e+00 - val_label_accuracy: 0.0000e+00\n",
      "Epoch 23/50\n",
      "112720/112720 [==============================] - 1s - loss: nan - acc: 0.0000e+00 - label_accuracy: 0.0000e+00 - val_loss: nan - val_acc: 0.0000e+00 - val_label_accuracy: 0.0000e+00\n",
      "Epoch 24/50\n",
      "112720/112720 [==============================] - 1s - loss: nan - acc: 0.0000e+00 - label_accuracy: 0.0000e+00 - val_loss: nan - val_acc: 0.0000e+00 - val_label_accuracy: 0.0000e+00\n",
      "Epoch 25/50\n",
      "112720/112720 [==============================] - 1s - loss: nan - acc: 0.0000e+00 - label_accuracy: 0.0000e+00 - val_loss: nan - val_acc: 0.0000e+00 - val_label_accuracy: 0.0000e+00\n",
      "Epoch 26/50\n",
      "112720/112720 [==============================] - 1s - loss: nan - acc: 0.0000e+00 - label_accuracy: 0.0000e+00 - val_loss: nan - val_acc: 0.0000e+00 - val_label_accuracy: 0.0000e+00\n",
      "Epoch 27/50\n",
      "112720/112720 [==============================] - 1s - loss: nan - acc: 0.0000e+00 - label_accuracy: 0.0000e+00 - val_loss: nan - val_acc: 0.0000e+00 - val_label_accuracy: 0.0000e+00\n",
      "Epoch 28/50\n",
      "112720/112720 [==============================] - 1s - loss: nan - acc: 0.0000e+00 - label_accuracy: 0.0000e+00 - val_loss: nan - val_acc: 0.0000e+00 - val_label_accuracy: 0.0000e+00\n",
      "Epoch 29/50\n",
      "112720/112720 [==============================] - 1s - loss: nan - acc: 0.0000e+00 - label_accuracy: 0.0000e+00 - val_loss: nan - val_acc: 0.0000e+00 - val_label_accuracy: 0.0000e+00\n",
      "Epoch 30/50\n",
      "112720/112720 [==============================] - 1s - loss: nan - acc: 0.0000e+00 - label_accuracy: 0.0000e+00 - val_loss: nan - val_acc: 0.0000e+00 - val_label_accuracy: 0.0000e+00\n",
      "Epoch 31/50\n",
      "112720/112720 [==============================] - 1s - loss: nan - acc: 0.0000e+00 - label_accuracy: 0.0000e+00 - val_loss: nan - val_acc: 0.0000e+00 - val_label_accuracy: 0.0000e+00\n",
      "Epoch 32/50\n",
      "112720/112720 [==============================] - 1s - loss: nan - acc: 0.0000e+00 - label_accuracy: 0.0000e+00 - val_loss: nan - val_acc: 0.0000e+00 - val_label_accuracy: 0.0000e+00\n",
      "Epoch 33/50\n",
      "112720/112720 [==============================] - 1s - loss: nan - acc: 0.0000e+00 - label_accuracy: 0.0000e+00 - val_loss: nan - val_acc: 0.0000e+00 - val_label_accuracy: 0.0000e+00\n",
      "Epoch 34/50\n",
      "112720/112720 [==============================] - 1s - loss: nan - acc: 0.0000e+00 - label_accuracy: 0.0000e+00 - val_loss: nan - val_acc: 0.0000e+00 - val_label_accuracy: 0.0000e+00\n",
      "Epoch 35/50\n",
      "112720/112720 [==============================] - 1s - loss: nan - acc: 0.0000e+00 - label_accuracy: 0.0000e+00 - val_loss: nan - val_acc: 0.0000e+00 - val_label_accuracy: 0.0000e+00\n",
      "Epoch 36/50\n",
      "112720/112720 [==============================] - 1s - loss: nan - acc: 0.0000e+00 - label_accuracy: 0.0000e+00 - val_loss: nan - val_acc: 0.0000e+00 - val_label_accuracy: 0.0000e+00\n",
      "Epoch 37/50\n",
      "112720/112720 [==============================] - 1s - loss: nan - acc: 0.0000e+00 - label_accuracy: 0.0000e+00 - val_loss: nan - val_acc: 0.0000e+00 - val_label_accuracy: 0.0000e+00\n",
      "Epoch 38/50\n",
      "112720/112720 [==============================] - 1s - loss: nan - acc: 0.0000e+00 - label_accuracy: 0.0000e+00 - val_loss: nan - val_acc: 0.0000e+00 - val_label_accuracy: 0.0000e+00\n",
      "Epoch 39/50\n",
      "112720/112720 [==============================] - 1s - loss: nan - acc: 0.0000e+00 - label_accuracy: 0.0000e+00 - val_loss: nan - val_acc: 0.0000e+00 - val_label_accuracy: 0.0000e+00\n",
      "Epoch 40/50\n",
      "112720/112720 [==============================] - 1s - loss: nan - acc: 0.0000e+00 - label_accuracy: 0.0000e+00 - val_loss: nan - val_acc: 0.0000e+00 - val_label_accuracy: 0.0000e+00\n",
      "Epoch 41/50\n",
      "112720/112720 [==============================] - 1s - loss: nan - acc: 0.0000e+00 - label_accuracy: 0.0000e+00 - val_loss: nan - val_acc: 0.0000e+00 - val_label_accuracy: 0.0000e+00\n",
      "Epoch 42/50\n",
      "112720/112720 [==============================] - 1s - loss: nan - acc: 0.0000e+00 - label_accuracy: 0.0000e+00 - val_loss: nan - val_acc: 0.0000e+00 - val_label_accuracy: 0.0000e+00\n",
      "Epoch 43/50\n",
      "112720/112720 [==============================] - 1s - loss: nan - acc: 0.0000e+00 - label_accuracy: 0.0000e+00 - val_loss: nan - val_acc: 0.0000e+00 - val_label_accuracy: 0.0000e+00\n",
      "Epoch 44/50\n",
      "112720/112720 [==============================] - 1s - loss: nan - acc: 0.0000e+00 - label_accuracy: 0.0000e+00 - val_loss: nan - val_acc: 0.0000e+00 - val_label_accuracy: 0.0000e+00\n",
      "Epoch 45/50\n",
      "112720/112720 [==============================] - 1s - loss: nan - acc: 0.0000e+00 - label_accuracy: 0.0000e+00 - val_loss: nan - val_acc: 0.0000e+00 - val_label_accuracy: 0.0000e+00\n",
      "Epoch 46/50\n",
      "112720/112720 [==============================] - 1s - loss: nan - acc: 0.0000e+00 - label_accuracy: 0.0000e+00 - val_loss: nan - val_acc: 0.0000e+00 - val_label_accuracy: 0.0000e+00\n",
      "Epoch 47/50\n",
      "112720/112720 [==============================] - 1s - loss: nan - acc: 0.0000e+00 - label_accuracy: 0.0000e+00 - val_loss: nan - val_acc: 0.0000e+00 - val_label_accuracy: 0.0000e+00\n",
      "Epoch 48/50\n",
      "112720/112720 [==============================] - 1s - loss: nan - acc: 0.0000e+00 - label_accuracy: 0.0000e+00 - val_loss: nan - val_acc: 0.0000e+00 - val_label_accuracy: 0.0000e+00\n",
      "Epoch 49/50\n",
      "112720/112720 [==============================] - 1s - loss: nan - acc: 0.0000e+00 - label_accuracy: 0.0000e+00 - val_loss: nan - val_acc: 0.0000e+00 - val_label_accuracy: 0.0000e+00\n",
      "Epoch 50/50\n",
      "112720/112720 [==============================] - 1s - loss: nan - acc: 0.0000e+00 - label_accuracy: 0.0000e+00 - val_loss: nan - val_acc: 0.0000e+00 - val_label_accuracy: 0.0000e+00\n",
      "22544/22544 [==============================] - 0s     \n",
      "\n",
      " Train Acc: 0.0, Test Acc: 0.0, Label Acc: 0.43075762952448543\n",
      " \n",
      " Current Layer Attributes - epochs:50 hidden layers:2 features count:122\n",
      "Train on 112720 samples, validate on 22544 samples\n",
      "Epoch 1/50\n",
      "112720/112720 [==============================] - 2s - loss: 6522482.6798 - acc: 0.1328 - label_accuracy: 0.1328 - val_loss: 14734.6035 - val_acc: 0.2002 - val_label_accuracy: 0.2002\n",
      "Epoch 2/50\n",
      "112720/112720 [==============================] - 1s - loss: 81257526078.1282 - acc: 0.1244 - label_accuracy: 0.1244 - val_loss: 13137561924.6139 - val_acc: 0.1864 - val_label_accuracy: 0.1864\n",
      "Epoch 3/50\n",
      "112720/112720 [==============================] - 1s - loss: 1187462708.3482 - acc: 0.1213 - label_accuracy: 0.1213 - val_loss: 1513407.7830 - val_acc: 0.2200 - val_label_accuracy: 0.2200\n",
      "Epoch 4/50\n",
      "112720/112720 [==============================] - 1s - loss: 6445957707.2964 - acc: 0.0899 - label_accuracy: 0.0899 - val_loss: 317146987008.6182 - val_acc: 0.1799 - val_label_accuracy: 0.1799\n",
      "Epoch 5/50\n",
      "112720/112720 [==============================] - 1s - loss: 226937626420.3174 - acc: 0.0413 - label_accuracy: 0.0413 - val_loss: 25522621284352.6250 - val_acc: 0.0401 - val_label_accuracy: 0.0401\n",
      "Epoch 6/50\n",
      "112720/112720 [==============================] - 1s - loss: 176498381.2040 - acc: 0.0285 - label_accuracy: 0.0285 - val_loss: 483532427008.6147 - val_acc: 0.0589 - val_label_accuracy: 0.0589\n",
      "Epoch 7/50\n",
      "112720/112720 [==============================] - 1s - loss: 6216553703108858.0000 - acc: 0.0100 - label_accuracy: 0.0100 - val_loss: 1.9633 - val_acc: 0.0000e+00 - val_label_accuracy: 0.0000e+00\n",
      "Epoch 8/50\n",
      "112720/112720 [==============================] - 1s - loss: 0.9889 - acc: 0.0000e+00 - label_accuracy: 0.0000e+00 - val_loss: 1.9633 - val_acc: 0.0000e+00 - val_label_accuracy: 0.0000e+00\n",
      "Epoch 9/50\n",
      "112720/112720 [==============================] - 1s - loss: 0.9889 - acc: 0.0000e+00 - label_accuracy: 0.0000e+00 - val_loss: 1.9633 - val_acc: 0.0000e+00 - val_label_accuracy: 0.0000e+00\n",
      "Epoch 10/50\n",
      "112720/112720 [==============================] - 1s - loss: 0.9889 - acc: 0.0000e+00 - label_accuracy: 0.0000e+00 - val_loss: 1.9633 - val_acc: 0.0000e+00 - val_label_accuracy: 0.0000e+00\n",
      "Epoch 11/50\n",
      "112720/112720 [==============================] - 1s - loss: 0.9889 - acc: 0.0000e+00 - label_accuracy: 0.0000e+00 - val_loss: 1.9633 - val_acc: 0.0000e+00 - val_label_accuracy: 0.0000e+00\n",
      "Epoch 12/50\n",
      "112720/112720 [==============================] - 1s - loss: 0.9889 - acc: 0.0000e+00 - label_accuracy: 0.0000e+00 - val_loss: 1.9633 - val_acc: 0.0000e+00 - val_label_accuracy: 0.0000e+00\n",
      "Epoch 13/50\n",
      "112720/112720 [==============================] - 1s - loss: 0.9889 - acc: 0.0000e+00 - label_accuracy: 0.0000e+00 - val_loss: 1.9633 - val_acc: 0.0000e+00 - val_label_accuracy: 0.0000e+00\n",
      "Epoch 14/50\n",
      "112720/112720 [==============================] - 1s - loss: 0.9889 - acc: 0.0000e+00 - label_accuracy: 0.0000e+00 - val_loss: 1.9633 - val_acc: 0.0000e+00 - val_label_accuracy: 0.0000e+00\n",
      "Epoch 15/50\n",
      "112720/112720 [==============================] - 1s - loss: 0.9889 - acc: 0.0000e+00 - label_accuracy: 0.0000e+00 - val_loss: 1.9633 - val_acc: 0.0000e+00 - val_label_accuracy: 0.0000e+00\n",
      "Epoch 16/50\n",
      "112720/112720 [==============================] - 1s - loss: 0.9889 - acc: 0.0000e+00 - label_accuracy: 0.0000e+00 - val_loss: 1.9633 - val_acc: 0.0000e+00 - val_label_accuracy: 0.0000e+00\n",
      "Epoch 17/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "112720/112720 [==============================] - 1s - loss: 0.9889 - acc: 0.0000e+00 - label_accuracy: 0.0000e+00 - val_loss: 1.9633 - val_acc: 0.0000e+00 - val_label_accuracy: 0.0000e+00\n",
      "Epoch 18/50\n",
      "112720/112720 [==============================] - 1s - loss: 0.9889 - acc: 0.0000e+00 - label_accuracy: 0.0000e+00 - val_loss: 1.9633 - val_acc: 0.0000e+00 - val_label_accuracy: 0.0000e+00\n",
      "Epoch 19/50\n",
      "112720/112720 [==============================] - 1s - loss: 0.9889 - acc: 0.0000e+00 - label_accuracy: 0.0000e+00 - val_loss: 1.9633 - val_acc: 0.0000e+00 - val_label_accuracy: 0.0000e+00\n",
      "Epoch 20/50\n",
      "112720/112720 [==============================] - 1s - loss: 0.9889 - acc: 0.0000e+00 - label_accuracy: 0.0000e+00 - val_loss: 1.9633 - val_acc: 0.0000e+00 - val_label_accuracy: 0.0000e+00\n",
      "Epoch 21/50\n",
      "112720/112720 [==============================] - 1s - loss: 0.9889 - acc: 0.0000e+00 - label_accuracy: 0.0000e+00 - val_loss: 1.9633 - val_acc: 0.0000e+00 - val_label_accuracy: 0.0000e+00\n",
      "Epoch 22/50\n",
      "112720/112720 [==============================] - 1s - loss: 0.9889 - acc: 0.0000e+00 - label_accuracy: 0.0000e+00 - val_loss: 1.9633 - val_acc: 0.0000e+00 - val_label_accuracy: 0.0000e+00\n",
      "Epoch 23/50\n",
      "112720/112720 [==============================] - 1s - loss: 0.9889 - acc: 0.0000e+00 - label_accuracy: 0.0000e+00 - val_loss: 1.9633 - val_acc: 0.0000e+00 - val_label_accuracy: 0.0000e+00\n",
      "Epoch 24/50\n",
      "112720/112720 [==============================] - 1s - loss: 0.9889 - acc: 0.0000e+00 - label_accuracy: 0.0000e+00 - val_loss: 1.9633 - val_acc: 0.0000e+00 - val_label_accuracy: 0.0000e+00\n",
      "Epoch 25/50\n",
      "112720/112720 [==============================] - 1s - loss: 0.9889 - acc: 0.0000e+00 - label_accuracy: 0.0000e+00 - val_loss: 1.9633 - val_acc: 0.0000e+00 - val_label_accuracy: 0.0000e+00\n",
      "Epoch 26/50\n",
      "112720/112720 [==============================] - 1s - loss: 0.9889 - acc: 0.0000e+00 - label_accuracy: 0.0000e+00 - val_loss: 1.9633 - val_acc: 0.0000e+00 - val_label_accuracy: 0.0000e+00\n",
      "Epoch 27/50\n",
      "112720/112720 [==============================] - 1s - loss: 0.9888 - acc: 0.0000e+00 - label_accuracy: 0.0000e+00 - val_loss: 1.9633 - val_acc: 0.0000e+00 - val_label_accuracy: 0.0000e+00\n",
      "Epoch 28/50\n",
      "112720/112720 [==============================] - 1s - loss: 0.9888 - acc: 0.0000e+00 - label_accuracy: 0.0000e+00 - val_loss: 1.9633 - val_acc: 0.0000e+00 - val_label_accuracy: 0.0000e+00\n",
      "Epoch 29/50\n",
      "112720/112720 [==============================] - 1s - loss: 0.9888 - acc: 0.0000e+00 - label_accuracy: 0.0000e+00 - val_loss: 1.9633 - val_acc: 0.0000e+00 - val_label_accuracy: 0.0000e+00\n",
      "Epoch 30/50\n",
      "112720/112720 [==============================] - 1s - loss: 0.9888 - acc: 0.0000e+00 - label_accuracy: 0.0000e+00 - val_loss: 1.9633 - val_acc: 0.0000e+00 - val_label_accuracy: 0.0000e+00\n",
      "Epoch 31/50\n",
      "112720/112720 [==============================] - 1s - loss: 0.9888 - acc: 0.0000e+00 - label_accuracy: 0.0000e+00 - val_loss: 1.9633 - val_acc: 0.0000e+00 - val_label_accuracy: 0.0000e+00\n",
      "Epoch 32/50\n",
      "112720/112720 [==============================] - 1s - loss: 0.9888 - acc: 0.0000e+00 - label_accuracy: 0.0000e+00 - val_loss: 1.9633 - val_acc: 0.0000e+00 - val_label_accuracy: 0.0000e+00\n",
      "Epoch 33/50\n",
      "112720/112720 [==============================] - 1s - loss: 0.9888 - acc: 0.0000e+00 - label_accuracy: 0.0000e+00 - val_loss: 1.9633 - val_acc: 0.0000e+00 - val_label_accuracy: 0.0000e+00\n",
      "Epoch 34/50\n",
      "112720/112720 [==============================] - 1s - loss: 0.9888 - acc: 0.0000e+00 - label_accuracy: 0.0000e+00 - val_loss: 1.9633 - val_acc: 0.0000e+00 - val_label_accuracy: 0.0000e+00\n",
      "Epoch 35/50\n",
      "112720/112720 [==============================] - 1s - loss: 0.9888 - acc: 0.0000e+00 - label_accuracy: 0.0000e+00 - val_loss: 1.9633 - val_acc: 0.0000e+00 - val_label_accuracy: 0.0000e+00\n",
      "Epoch 36/50\n",
      "112720/112720 [==============================] - 1s - loss: 0.9888 - acc: 0.0000e+00 - label_accuracy: 0.0000e+00 - val_loss: 1.9634 - val_acc: 0.0000e+00 - val_label_accuracy: 0.0000e+00\n",
      "Epoch 37/50\n",
      "112720/112720 [==============================] - 1s - loss: 0.9888 - acc: 0.0000e+00 - label_accuracy: 0.0000e+00 - val_loss: 1.9634 - val_acc: 0.0000e+00 - val_label_accuracy: 0.0000e+00\n",
      "Epoch 38/50\n",
      "112720/112720 [==============================] - 1s - loss: 0.9888 - acc: 0.0000e+00 - label_accuracy: 0.0000e+00 - val_loss: 1.9634 - val_acc: 0.0000e+00 - val_label_accuracy: 0.0000e+00\n",
      "Epoch 39/50\n",
      "112720/112720 [==============================] - 1s - loss: 0.9888 - acc: 0.0000e+00 - label_accuracy: 0.0000e+00 - val_loss: 1.9634 - val_acc: 0.0000e+00 - val_label_accuracy: 0.0000e+00\n",
      "Epoch 40/50\n",
      "112720/112720 [==============================] - 1s - loss: 0.9888 - acc: 0.0000e+00 - label_accuracy: 0.0000e+00 - val_loss: 1.9634 - val_acc: 0.0000e+00 - val_label_accuracy: 0.0000e+00\n",
      "Epoch 41/50\n",
      "112720/112720 [==============================] - 1s - loss: 0.9888 - acc: 0.0000e+00 - label_accuracy: 0.0000e+00 - val_loss: 1.9634 - val_acc: 0.0000e+00 - val_label_accuracy: 0.0000e+00\n",
      "Epoch 42/50\n",
      "112720/112720 [==============================] - 1s - loss: 0.9888 - acc: 0.0000e+00 - label_accuracy: 0.0000e+00 - val_loss: 1.9634 - val_acc: 0.0000e+00 - val_label_accuracy: 0.0000e+00\n",
      "Epoch 43/50\n",
      "112720/112720 [==============================] - 1s - loss: 0.9888 - acc: 0.0000e+00 - label_accuracy: 0.0000e+00 - val_loss: 1.9634 - val_acc: 0.0000e+00 - val_label_accuracy: 0.0000e+00\n",
      "Epoch 44/50\n",
      "112720/112720 [==============================] - 1s - loss: 0.9888 - acc: 0.0000e+00 - label_accuracy: 0.0000e+00 - val_loss: 1.9634 - val_acc: 0.0000e+00 - val_label_accuracy: 0.0000e+00\n",
      "Epoch 45/50\n",
      "112720/112720 [==============================] - 1s - loss: 0.9888 - acc: 0.0000e+00 - label_accuracy: 0.0000e+00 - val_loss: 1.9634 - val_acc: 0.0000e+00 - val_label_accuracy: 0.0000e+00\n",
      "Epoch 46/50\n",
      "112720/112720 [==============================] - 1s - loss: 0.9888 - acc: 0.0000e+00 - label_accuracy: 0.0000e+00 - val_loss: 1.9634 - val_acc: 0.0000e+00 - val_label_accuracy: 0.0000e+00\n",
      "Epoch 47/50\n",
      "112720/112720 [==============================] - 1s - loss: 0.9888 - acc: 0.0000e+00 - label_accuracy: 0.0000e+00 - val_loss: 1.9634 - val_acc: 0.0000e+00 - val_label_accuracy: 0.0000e+00\n",
      "Epoch 48/50\n",
      "112720/112720 [==============================] - 1s - loss: 0.9888 - acc: 0.0000e+00 - label_accuracy: 0.0000e+00 - val_loss: 1.9634 - val_acc: 0.0000e+00 - val_label_accuracy: 0.0000e+00\n",
      "Epoch 49/50\n",
      "112720/112720 [==============================] - 1s - loss: 0.9888 - acc: 0.0000e+00 - label_accuracy: 0.0000e+00 - val_loss: 1.9634 - val_acc: 0.0000e+00 - val_label_accuracy: 0.0000e+00\n",
      "Epoch 50/50\n",
      "112720/112720 [==============================] - 1s - loss: 0.9888 - acc: 0.0000e+00 - label_accuracy: 0.0000e+00 - val_loss: 1.9634 - val_acc: 0.0000e+00 - val_label_accuracy: 0.0000e+00\n",
      "18317/22544 [=======================>......] - ETA: 0s\n",
      " Train Acc: 0.0, Test Acc: 0.0, Label Acc: 0.43075762952448543\n",
      " \n",
      " Current Layer Attributes - epochs:50 hidden layers:6 features count:4\n",
      "Train on 112720 samples, validate on 22544 samples\n",
      "Epoch 1/50\n",
      "112720/112720 [==============================] - 4s - loss: 0.8673 - acc: 0.0103 - label_accuracy: 0.0103 - val_loss: 1.7930 - val_acc: 0.0407 - val_label_accuracy: 0.0407\n",
      "Epoch 2/50\n",
      "112720/112720 [==============================] - 2s - loss: 0.7100 - acc: 0.4239 - label_accuracy: 0.4239 - val_loss: 1.6716 - val_acc: 0.6084 - val_label_accuracy: 0.6084\n",
      "Epoch 3/50\n",
      "112720/112720 [==============================] - 2s - loss: 0.6130 - acc: 0.6527 - label_accuracy: 0.6527 - val_loss: 1.5820 - val_acc: 0.6929 - val_label_accuracy: 0.6929\n",
      "Epoch 4/50\n",
      "112720/112720 [==============================] - 2s - loss: 0.5258 - acc: 0.7824 - label_accuracy: 0.7824 - val_loss: 1.5217 - val_acc: 0.7117 - val_label_accuracy: 0.7117\n",
      "Epoch 5/50\n",
      "112720/112720 [==============================] - 2s - loss: 0.4571 - acc: 0.8267 - label_accuracy: 0.8267 - val_loss: 1.3947 - val_acc: 0.7164 - val_label_accuracy: 0.7164\n",
      "Epoch 6/50\n",
      "112720/112720 [==============================] - 2s - loss: 0.3913 - acc: 0.8488 - label_accuracy: 0.8488 - val_loss: 1.2817 - val_acc: 0.7231 - val_label_accuracy: 0.7231\n",
      "Epoch 7/50\n",
      "112720/112720 [==============================] - 2s - loss: 0.3483 - acc: 0.8562 - label_accuracy: 0.8562 - val_loss: 1.2068 - val_acc: 0.7348 - val_label_accuracy: 0.7348\n",
      "Epoch 8/50\n",
      "112720/112720 [==============================] - 2s - loss: 0.3163 - acc: 0.8650 - label_accuracy: 0.8650 - val_loss: 1.1495 - val_acc: 0.7999 - val_label_accuracy: 0.7999\n",
      "Epoch 9/50\n",
      "112720/112720 [==============================] - 2s - loss: 0.2937 - acc: 0.8694 - label_accuracy: 0.8694 - val_loss: 1.0885 - val_acc: 0.8119 - val_label_accuracy: 0.8119\n",
      "Epoch 10/50\n",
      "112720/112720 [==============================] - 2s - loss: 0.2797 - acc: 0.8732 - label_accuracy: 0.8732 - val_loss: 1.0732 - val_acc: 0.8127 - val_label_accuracy: 0.8127\n",
      "Epoch 11/50\n",
      "112720/112720 [==============================] - 3s - loss: 0.2620 - acc: 0.8746 - label_accuracy: 0.8746 - val_loss: 1.0125 - val_acc: 0.8235 - val_label_accuracy: 0.8235\n",
      "Epoch 12/50\n",
      "112720/112720 [==============================] - 2s - loss: 0.2471 - acc: 0.8740 - label_accuracy: 0.8740 - val_loss: 0.9481 - val_acc: 0.8204 - val_label_accuracy: 0.8204\n",
      "Epoch 13/50\n",
      "112720/112720 [==============================] - 2s - loss: 0.2308 - acc: 0.8807 - label_accuracy: 0.8807 - val_loss: 0.9208 - val_acc: 0.8204 - val_label_accuracy: 0.8204\n",
      "Epoch 14/50\n",
      "112720/112720 [==============================] - 2s - loss: 0.2363 - acc: 0.8773 - label_accuracy: 0.8773 - val_loss: 0.8801 - val_acc: 0.8263 - val_label_accuracy: 0.8263\n",
      "Epoch 15/50\n",
      "112720/112720 [==============================] - 2s - loss: 0.2081 - acc: 0.8844 - label_accuracy: 0.8844 - val_loss: 0.8536 - val_acc: 0.8348 - val_label_accuracy: 0.8348\n",
      "Epoch 16/50\n",
      "112720/112720 [==============================] - 2s - loss: 0.1996 - acc: 0.8890 - label_accuracy: 0.8890 - val_loss: 0.8062 - val_acc: 0.8454 - val_label_accuracy: 0.8454\n",
      "Epoch 17/50\n",
      "112720/112720 [==============================] - 2s - loss: 0.1925 - acc: 0.8909 - label_accuracy: 0.8909 - val_loss: 0.8021 - val_acc: 0.8405 - val_label_accuracy: 0.8405\n",
      "Epoch 18/50\n",
      "112720/112720 [==============================] - 2s - loss: 0.2260 - acc: 0.8836 - label_accuracy: 0.8836 - val_loss: 0.8469 - val_acc: 0.8428 - val_label_accuracy: 0.8428\n",
      "Epoch 19/50\n",
      "112720/112720 [==============================] - 2s - loss: 0.2571 - acc: 0.8545 - label_accuracy: 0.8545 - val_loss: 0.8741 - val_acc: 0.7948 - val_label_accuracy: 0.7948\n",
      "Epoch 20/50\n",
      "112720/112720 [==============================] - 3s - loss: 0.2042 - acc: 0.8848 - label_accuracy: 0.8848 - val_loss: 0.8959 - val_acc: 0.8422 - val_label_accuracy: 0.8422\n",
      "Epoch 21/50\n",
      "112720/112720 [==============================] - 2s - loss: 0.1896 - acc: 0.8963 - label_accuracy: 0.8963 - val_loss: 0.7738 - val_acc: 0.8515 - val_label_accuracy: 0.8515\n",
      "Epoch 22/50\n",
      "112720/112720 [==============================] - 2s - loss: 0.1963 - acc: 0.8979 - label_accuracy: 0.8979 - val_loss: 0.8345 - val_acc: 0.8427 - val_label_accuracy: 0.8427\n",
      "Epoch 23/50\n",
      "112720/112720 [==============================] - 2s - loss: 0.1723 - acc: 0.9009 - label_accuracy: 0.9009 - val_loss: 0.7432 - val_acc: 0.8522 - val_label_accuracy: 0.8522\n",
      "Epoch 24/50\n",
      "112720/112720 [==============================] - 3s - loss: 0.1539 - acc: 0.9063 - label_accuracy: 0.9063 - val_loss: 0.7571 - val_acc: 0.8617 - val_label_accuracy: 0.8617\n",
      "Epoch 25/50\n",
      "112720/112720 [==============================] - 2s - loss: 0.1654 - acc: 0.9047 - label_accuracy: 0.9047 - val_loss: 0.7260 - val_acc: 0.8386 - val_label_accuracy: 0.8386\n",
      "Epoch 26/50\n",
      "112720/112720 [==============================] - 2s - loss: 0.1769 - acc: 0.9031 - label_accuracy: 0.9031 - val_loss: 0.7759 - val_acc: 0.8330 - val_label_accuracy: 0.8330\n",
      "Epoch 27/50\n",
      "112720/112720 [==============================] - 2s - loss: 0.1783 - acc: 0.9057 - label_accuracy: 0.9057 - val_loss: 0.7443 - val_acc: 0.8560 - val_label_accuracy: 0.8560\n",
      "Epoch 28/50\n",
      "112720/112720 [==============================] - 2s - loss: 0.2094 - acc: 0.8980 - label_accuracy: 0.8980 - val_loss: 0.6705 - val_acc: 0.8578 - val_label_accuracy: 0.8578\n",
      "Epoch 29/50\n",
      "112720/112720 [==============================] - 2s - loss: 0.1731 - acc: 0.9072 - label_accuracy: 0.9072 - val_loss: 0.6332 - val_acc: 0.8657 - val_label_accuracy: 0.8657\n",
      "Epoch 30/50\n",
      "112720/112720 [==============================] - 2s - loss: 0.1755 - acc: 0.8997 - label_accuracy: 0.8997 - val_loss: 0.6511 - val_acc: 0.8456 - val_label_accuracy: 0.8456\n",
      "Epoch 31/50\n",
      "112720/112720 [==============================] - 2s - loss: 0.2224 - acc: 0.8960 - label_accuracy: 0.8960 - val_loss: 0.7973 - val_acc: 0.8548 - val_label_accuracy: 0.8548\n",
      "Epoch 32/50\n",
      "112720/112720 [==============================] - 2s - loss: 0.1758 - acc: 0.9032 - label_accuracy: 0.9032 - val_loss: 0.5237 - val_acc: 0.8605 - val_label_accuracy: 0.8605\n",
      "Epoch 33/50\n",
      "112720/112720 [==============================] - 2s - loss: 0.1335 - acc: 0.9119 - label_accuracy: 0.9119 - val_loss: 0.5633 - val_acc: 0.8624 - val_label_accuracy: 0.8624\n",
      "Epoch 34/50\n",
      "112720/112720 [==============================] - 2s - loss: 0.1288 - acc: 0.9145 - label_accuracy: 0.9145 - val_loss: 0.6046 - val_acc: 0.8416 - val_label_accuracy: 0.8416\n",
      "Epoch 35/50\n",
      "112720/112720 [==============================] - 2s - loss: 0.1241 - acc: 0.9127 - label_accuracy: 0.9127 - val_loss: 0.6338 - val_acc: 0.8411 - val_label_accuracy: 0.8411\n",
      "Epoch 36/50\n",
      "112720/112720 [==============================] - 2s - loss: 0.1229 - acc: 0.9147 - label_accuracy: 0.9147 - val_loss: 0.5724 - val_acc: 0.8491 - val_label_accuracy: 0.8491\n",
      "Epoch 37/50\n",
      "112720/112720 [==============================] - 2s - loss: 0.1196 - acc: 0.9139 - label_accuracy: 0.9139 - val_loss: 0.3762 - val_acc: 0.8453 - val_label_accuracy: 0.8453\n",
      "Epoch 38/50\n",
      "112720/112720 [==============================] - 2s - loss: 0.1149 - acc: 0.9142 - label_accuracy: 0.9142 - val_loss: 0.3779 - val_acc: 0.8434 - val_label_accuracy: 0.8434\n",
      "Epoch 39/50\n",
      "112720/112720 [==============================] - 2s - loss: 0.1153 - acc: 0.9157 - label_accuracy: 0.9157 - val_loss: 0.4194 - val_acc: 0.8484 - val_label_accuracy: 0.8484\n",
      "Epoch 40/50\n",
      "112720/112720 [==============================] - 2s - loss: 0.1083 - acc: 0.9179 - label_accuracy: 0.9179 - val_loss: 0.3322 - val_acc: 0.8489 - val_label_accuracy: 0.8489\n",
      "Epoch 41/50\n",
      "112720/112720 [==============================] - 3s - loss: 0.1082 - acc: 0.9248 - label_accuracy: 0.9248 - val_loss: 0.3131 - val_acc: 0.8547 - val_label_accuracy: 0.8547\n",
      "Epoch 42/50\n",
      "112720/112720 [==============================] - 2s - loss: 0.1073 - acc: 0.9255 - label_accuracy: 0.9255 - val_loss: 0.4949 - val_acc: 0.8571 - val_label_accuracy: 0.8571\n",
      "Epoch 43/50\n",
      "112720/112720 [==============================] - 3s - loss: 0.1179 - acc: 0.9253 - label_accuracy: 0.9253 - val_loss: 0.3626 - val_acc: 0.8504 - val_label_accuracy: 0.8504\n",
      "Epoch 44/50\n",
      "112720/112720 [==============================] - 2s - loss: 0.1143 - acc: 0.9284 - label_accuracy: 0.9284 - val_loss: 0.8851 - val_acc: 0.8512 - val_label_accuracy: 0.8512\n",
      "Epoch 45/50\n",
      "112720/112720 [==============================] - 3s - loss: 0.1169 - acc: 0.9274 - label_accuracy: 0.9274 - val_loss: 0.6324 - val_acc: 0.8625 - val_label_accuracy: 0.8625\n",
      "Epoch 46/50\n",
      "112720/112720 [==============================] - 2s - loss: 0.1074 - acc: 0.9278 - label_accuracy: 0.9278 - val_loss: 0.4648 - val_acc: 0.8473 - val_label_accuracy: 0.8473\n",
      "Epoch 47/50\n",
      "112720/112720 [==============================] - 3s - loss: 0.1121 - acc: 0.9259 - label_accuracy: 0.9259 - val_loss: 0.5501 - val_acc: 0.8530 - val_label_accuracy: 0.8530\n",
      "Epoch 48/50\n",
      "112720/112720 [==============================] - 3s - loss: 0.2495 - acc: 0.8863 - label_accuracy: 0.8863 - val_loss: 0.9134 - val_acc: 0.8335 - val_label_accuracy: 0.8335\n",
      "Epoch 49/50\n",
      "112720/112720 [==============================] - 2s - loss: 0.2079 - acc: 0.8971 - label_accuracy: 0.8971 - val_loss: 0.6472 - val_acc: 0.8311 - val_label_accuracy: 0.8311\n",
      "Epoch 50/50\n",
      "112720/112720 [==============================] - 2s - loss: 0.2333 - acc: 0.8984 - label_accuracy: 0.8984 - val_loss: 0.8395 - val_acc: 0.8421 - val_label_accuracy: 0.8421\n",
      "22544/22544 [==============================] - 0s     \n",
      "\n",
      " Train Acc: 0.9021469131112099, Test Acc: 0.8421309366822243, Label Acc: 0.79236160397445\n",
      " \n",
      " Current Layer Attributes - epochs:50 hidden layers:6 features count:16\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 112720 samples, validate on 22544 samples\n",
      "Epoch 1/50\n",
      "112720/112720 [==============================] - 4s - loss: 1.2773 - acc: 0.0620 - label_accuracy: 0.0620 - val_loss: 1.8103 - val_acc: 0.2112 - val_label_accuracy: 0.2112\n",
      "Epoch 2/50\n",
      "112720/112720 [==============================] - 3s - loss: 0.7548 - acc: 0.3573 - label_accuracy: 0.3573 - val_loss: 1.7016 - val_acc: 0.3506 - val_label_accuracy: 0.3506\n",
      "Epoch 3/50\n",
      "112720/112720 [==============================] - 3s - loss: 0.6520 - acc: 0.5683 - label_accuracy: 0.5683 - val_loss: 1.6174 - val_acc: 0.6113 - val_label_accuracy: 0.6113\n",
      "Epoch 4/50\n",
      "112720/112720 [==============================] - 3s - loss: 0.5930 - acc: 0.6673 - label_accuracy: 0.6673 - val_loss: 1.5312 - val_acc: 0.7381 - val_label_accuracy: 0.7381\n",
      "Epoch 5/50\n",
      "112720/112720 [==============================] - 3s - loss: 0.5350 - acc: 0.7566 - label_accuracy: 0.7566 - val_loss: 1.4787 - val_acc: 0.7889 - val_label_accuracy: 0.7889\n",
      "Epoch 6/50\n",
      "112720/112720 [==============================] - 3s - loss: 0.4737 - acc: 0.8529 - label_accuracy: 0.8529 - val_loss: 1.3741 - val_acc: 0.8191 - val_label_accuracy: 0.8191\n",
      "Epoch 7/50\n",
      "112720/112720 [==============================] - 3s - loss: 0.4393 - acc: 0.8504 - label_accuracy: 0.8504 - val_loss: 1.2803 - val_acc: 0.8525 - val_label_accuracy: 0.8525\n",
      "Epoch 8/50\n",
      "112720/112720 [==============================] - 2s - loss: 0.3879 - acc: 0.8788 - label_accuracy: 0.8788 - val_loss: 1.2053 - val_acc: 0.8648 - val_label_accuracy: 0.8648\n",
      "Epoch 9/50\n",
      "112720/112720 [==============================] - 3s - loss: 0.3632 - acc: 0.8784 - label_accuracy: 0.8784 - val_loss: 1.1787 - val_acc: 0.8680 - val_label_accuracy: 0.8680\n",
      "Epoch 10/50\n",
      "112720/112720 [==============================] - 3s - loss: 0.3406 - acc: 0.8792 - label_accuracy: 0.8792 - val_loss: 1.0848 - val_acc: 0.8760 - val_label_accuracy: 0.8760\n",
      "Epoch 11/50\n",
      "112720/112720 [==============================] - 3s - loss: 0.3125 - acc: 0.8921 - label_accuracy: 0.8921 - val_loss: 1.0816 - val_acc: 0.8369 - val_label_accuracy: 0.8369\n",
      "Epoch 12/50\n",
      "112720/112720 [==============================] - 3s - loss: 0.2848 - acc: 0.8949 - label_accuracy: 0.8949 - val_loss: 1.0279 - val_acc: 0.8020 - val_label_accuracy: 0.8020\n",
      "Epoch 13/50\n",
      "112720/112720 [==============================] - 3s - loss: 0.2696 - acc: 0.8986 - label_accuracy: 0.8986 - val_loss: 0.9620 - val_acc: 0.8779 - val_label_accuracy: 0.8779\n",
      "Epoch 14/50\n",
      "112720/112720 [==============================] - 3s - loss: 0.2527 - acc: 0.8991 - label_accuracy: 0.8991 - val_loss: 0.9542 - val_acc: 0.8884 - val_label_accuracy: 0.8884\n",
      "Epoch 15/50\n",
      "112720/112720 [==============================] - 3s - loss: 0.2338 - acc: 0.9033 - label_accuracy: 0.9033 - val_loss: 0.9285 - val_acc: 0.8881 - val_label_accuracy: 0.8881\n",
      "Epoch 16/50\n",
      "112720/112720 [==============================] - 2s - loss: 0.2185 - acc: 0.9065 - label_accuracy: 0.9065 - val_loss: 0.8258 - val_acc: 0.8910 - val_label_accuracy: 0.8910\n",
      "Epoch 17/50\n",
      "112720/112720 [==============================] - 3s - loss: 0.1987 - acc: 0.9076 - label_accuracy: 0.9076 - val_loss: 0.8252 - val_acc: 0.8926 - val_label_accuracy: 0.8926\n",
      "Epoch 18/50\n",
      "112720/112720 [==============================] - 3s - loss: 0.2024 - acc: 0.9072 - label_accuracy: 0.9072 - val_loss: 0.9757 - val_acc: 0.8899 - val_label_accuracy: 0.8899\n",
      "Epoch 19/50\n",
      "112720/112720 [==============================] - 3s - loss: 0.1968 - acc: 0.9052 - label_accuracy: 0.9052 - val_loss: 0.7750 - val_acc: 0.9014 - val_label_accuracy: 0.9014\n",
      "Epoch 20/50\n",
      "112720/112720 [==============================] - 2s - loss: 0.1709 - acc: 0.9100 - label_accuracy: 0.9100 - val_loss: 0.7514 - val_acc: 0.9005 - val_label_accuracy: 0.9005\n",
      "Epoch 21/50\n",
      "112720/112720 [==============================] - 3s - loss: 0.1710 - acc: 0.9051 - label_accuracy: 0.9051 - val_loss: 0.9017 - val_acc: 0.8880 - val_label_accuracy: 0.8880\n",
      "Epoch 22/50\n",
      "112720/112720 [==============================] - 3s - loss: 0.1810 - acc: 0.9053 - label_accuracy: 0.9053 - val_loss: 0.8143 - val_acc: 0.8986 - val_label_accuracy: 0.8986\n",
      "Epoch 23/50\n",
      "112720/112720 [==============================] - 3s - loss: 0.1607 - acc: 0.9088 - label_accuracy: 0.9088 - val_loss: 0.7105 - val_acc: 0.9008 - val_label_accuracy: 0.9008\n",
      "Epoch 24/50\n",
      "112720/112720 [==============================] - 3s - loss: 0.1297 - acc: 0.9103 - label_accuracy: 0.9103 - val_loss: 0.6934 - val_acc: 0.9038 - val_label_accuracy: 0.9038\n",
      "Epoch 25/50\n",
      "112720/112720 [==============================] - 3s - loss: 0.1161 - acc: 0.9150 - label_accuracy: 0.9150 - val_loss: 0.6841 - val_acc: 0.9027 - val_label_accuracy: 0.9027\n",
      "Epoch 26/50\n",
      "112720/112720 [==============================] - 3s - loss: 0.1333 - acc: 0.9139 - label_accuracy: 0.9139 - val_loss: 0.6521 - val_acc: 0.9032 - val_label_accuracy: 0.9032\n",
      "Epoch 27/50\n",
      "112720/112720 [==============================] - 3s - loss: 0.1155 - acc: 0.9143 - label_accuracy: 0.9143 - val_loss: 0.6359 - val_acc: 0.9065 - val_label_accuracy: 0.9065\n",
      "Epoch 28/50\n",
      "112720/112720 [==============================] - 2s - loss: 0.1045 - acc: 0.9157 - label_accuracy: 0.9157 - val_loss: 0.5981 - val_acc: 0.9045 - val_label_accuracy: 0.9045\n",
      "Epoch 29/50\n",
      "112720/112720 [==============================] - 2s - loss: 0.1009 - acc: 0.9167 - label_accuracy: 0.9167 - val_loss: 0.6174 - val_acc: 0.9044 - val_label_accuracy: 0.9044\n",
      "Epoch 30/50\n",
      "112720/112720 [==============================] - 2s - loss: 0.1073 - acc: 0.9171 - label_accuracy: 0.9171 - val_loss: 0.6102 - val_acc: 0.9063 - val_label_accuracy: 0.9063\n",
      "Epoch 31/50\n",
      "112720/112720 [==============================] - 3s - loss: 0.1035 - acc: 0.9190 - label_accuracy: 0.9190 - val_loss: 0.5606 - val_acc: 0.9073 - val_label_accuracy: 0.9073\n",
      "Epoch 32/50\n",
      "112720/112720 [==============================] - 3s - loss: 0.0893 - acc: 0.9189 - label_accuracy: 0.9189 - val_loss: 0.6092 - val_acc: 0.8826 - val_label_accuracy: 0.8826\n",
      "Epoch 33/50\n",
      "112720/112720 [==============================] - 3s - loss: 0.0985 - acc: 0.9209 - label_accuracy: 0.9209 - val_loss: 0.5939 - val_acc: 0.9101 - val_label_accuracy: 0.9101\n",
      "Epoch 34/50\n",
      "112720/112720 [==============================] - 3s - loss: 0.0975 - acc: 0.9209 - label_accuracy: 0.9209 - val_loss: 0.5167 - val_acc: 0.8972 - val_label_accuracy: 0.8972\n",
      "Epoch 35/50\n",
      "112720/112720 [==============================] - 3s - loss: 0.0893 - acc: 0.9203 - label_accuracy: 0.9203 - val_loss: 0.5406 - val_acc: 0.9075 - val_label_accuracy: 0.9075\n",
      "Epoch 36/50\n",
      "112720/112720 [==============================] - 3s - loss: 0.0852 - acc: 0.9243 - label_accuracy: 0.9243 - val_loss: 0.5951 - val_acc: 0.9041 - val_label_accuracy: 0.9041\n",
      "Epoch 37/50\n",
      "112720/112720 [==============================] - 3s - loss: 0.0870 - acc: 0.9227 - label_accuracy: 0.9227 - val_loss: 0.5247 - val_acc: 0.9115 - val_label_accuracy: 0.9115\n",
      "Epoch 38/50\n",
      "112720/112720 [==============================] - 3s - loss: 0.0802 - acc: 0.9251 - label_accuracy: 0.9251 - val_loss: 0.4632 - val_acc: 0.8970 - val_label_accuracy: 0.8970\n",
      "Epoch 39/50\n",
      "112720/112720 [==============================] - 3s - loss: 0.0787 - acc: 0.9256 - label_accuracy: 0.9256 - val_loss: 0.4153 - val_acc: 0.8974 - val_label_accuracy: 0.8974\n",
      "Epoch 40/50\n",
      "112720/112720 [==============================] - 3s - loss: 0.0687 - acc: 0.9270 - label_accuracy: 0.9270 - val_loss: 0.3927 - val_acc: 0.8982 - val_label_accuracy: 0.8982\n",
      "Epoch 41/50\n",
      "112720/112720 [==============================] - 3s - loss: 0.0677 - acc: 0.9284 - label_accuracy: 0.9284 - val_loss: 0.3784 - val_acc: 0.9181 - val_label_accuracy: 0.9181\n",
      "Epoch 42/50\n",
      "112720/112720 [==============================] - 3s - loss: 0.0681 - acc: 0.9276 - label_accuracy: 0.9276 - val_loss: 0.3858 - val_acc: 0.9146 - val_label_accuracy: 0.9146\n",
      "Epoch 43/50\n",
      "112720/112720 [==============================] - 3s - loss: 0.0724 - acc: 0.9309 - label_accuracy: 0.9309 - val_loss: 0.3286 - val_acc: 0.9068 - val_label_accuracy: 0.9068\n",
      "Epoch 44/50\n",
      "112720/112720 [==============================] - 3s - loss: 0.0752 - acc: 0.9304 - label_accuracy: 0.9304 - val_loss: 0.3861 - val_acc: 0.9013 - val_label_accuracy: 0.9013\n",
      "Epoch 45/50\n",
      "112720/112720 [==============================] - 3s - loss: 0.0700 - acc: 0.9313 - label_accuracy: 0.9313 - val_loss: 0.2826 - val_acc: 0.8984 - val_label_accuracy: 0.8984\n",
      "Epoch 46/50\n",
      "112720/112720 [==============================] - 3s - loss: 0.0764 - acc: 0.9343 - label_accuracy: 0.9343 - val_loss: 0.2936 - val_acc: 0.9042 - val_label_accuracy: 0.9042\n",
      "Epoch 47/50\n",
      "112720/112720 [==============================] - 3s - loss: 0.0771 - acc: 0.9348 - label_accuracy: 0.9348 - val_loss: 0.3314 - val_acc: 0.9033 - val_label_accuracy: 0.9033\n",
      "Epoch 48/50\n",
      "112720/112720 [==============================] - 3s - loss: 0.0634 - acc: 0.9408 - label_accuracy: 0.9408 - val_loss: 0.2523 - val_acc: 0.8960 - val_label_accuracy: 0.8960\n",
      "Epoch 49/50\n",
      "112720/112720 [==============================] - 3s - loss: 0.0644 - acc: 0.9408 - label_accuracy: 0.9408 - val_loss: 0.3679 - val_acc: 0.8998 - val_label_accuracy: 0.8998\n",
      "Epoch 50/50\n",
      "112720/112720 [==============================] - 3s - loss: 0.0588 - acc: 0.9403 - label_accuracy: 0.9403 - val_loss: 0.2058 - val_acc: 0.8989 - val_label_accuracy: 0.8989\n",
      "18317/22544 [=======================>......] - ETA: 0s\n",
      " Train Acc: 0.9361249059438705, Test Acc: 0.8989088013768196, Label Acc: 0.7813165365507452\n",
      " \n",
      " Current Layer Attributes - epochs:50 hidden layers:6 features count:32\n",
      "Train on 112720 samples, validate on 22544 samples\n",
      "Epoch 1/50\n",
      "112720/112720 [==============================] - 4s - loss: 35278000.8584 - acc: 0.0246 - label_accuracy: 0.0246 - val_loss: 3055615.7211 - val_acc: 0.0383 - val_label_accuracy: 0.0383\n",
      "Epoch 2/50\n",
      "112720/112720 [==============================] - 3s - loss: 3086238.9791 - acc: 0.0783 - label_accuracy: 0.0783 - val_loss: 1.9839 - val_acc: 0.0977 - val_label_accuracy: 0.0977\n",
      "Epoch 3/50\n",
      "112720/112720 [==============================] - 3s - loss: 0.7491 - acc: 0.1580 - label_accuracy: 0.1580 - val_loss: 1.6729 - val_acc: 0.2241 - val_label_accuracy: 0.2241\n",
      "Epoch 4/50\n",
      "112720/112720 [==============================] - 3s - loss: 0.6611 - acc: 0.2884 - label_accuracy: 0.2884 - val_loss: 1.6424 - val_acc: 0.2577 - val_label_accuracy: 0.2577\n",
      "Epoch 5/50\n",
      "112720/112720 [==============================] - 3s - loss: 0.6217 - acc: 0.3705 - label_accuracy: 0.3705 - val_loss: 1.5961 - val_acc: 0.4022 - val_label_accuracy: 0.4022\n",
      "Epoch 6/50\n",
      "112720/112720 [==============================] - 3s - loss: 0.5858 - acc: 0.4274 - label_accuracy: 0.4274 - val_loss: 1.5390 - val_acc: 0.4938 - val_label_accuracy: 0.4938\n",
      "Epoch 7/50\n",
      "112720/112720 [==============================] - 3s - loss: 0.5499 - acc: 0.5119 - label_accuracy: 0.5119 - val_loss: 1.4533 - val_acc: 0.7645 - val_label_accuracy: 0.7645\n",
      "Epoch 8/50\n",
      "112720/112720 [==============================] - 3s - loss: 0.5185 - acc: 0.6483 - label_accuracy: 0.6483 - val_loss: 1.3613 - val_acc: 0.5897 - val_label_accuracy: 0.5897\n",
      "Epoch 9/50\n",
      "112720/112720 [==============================] - 3s - loss: 0.4911 - acc: 0.7022 - label_accuracy: 0.7022 - val_loss: 1.2832 - val_acc: 0.7749 - val_label_accuracy: 0.7749\n",
      "Epoch 10/50\n",
      "112720/112720 [==============================] - 3s - loss: 0.4693 - acc: 0.7341 - label_accuracy: 0.7341 - val_loss: 1.2189 - val_acc: 0.8393 - val_label_accuracy: 0.8393\n",
      "Epoch 11/50\n",
      "112720/112720 [==============================] - 3s - loss: 0.4474 - acc: 0.7485 - label_accuracy: 0.7485 - val_loss: 1.1660 - val_acc: 0.8267 - val_label_accuracy: 0.8267\n",
      "Epoch 12/50\n",
      "112720/112720 [==============================] - 3s - loss: 0.4311 - acc: 0.7658 - label_accuracy: 0.7658 - val_loss: 1.0980 - val_acc: 0.8234 - val_label_accuracy: 0.8234\n",
      "Epoch 13/50\n",
      "112720/112720 [==============================] - 3s - loss: 0.4135 - acc: 0.7792 - label_accuracy: 0.7792 - val_loss: 1.0457 - val_acc: 0.7331 - val_label_accuracy: 0.7331\n",
      "Epoch 14/50\n",
      "112720/112720 [==============================] - 3s - loss: 0.3981 - acc: 0.7990 - label_accuracy: 0.7990 - val_loss: 0.9897 - val_acc: 0.7931 - val_label_accuracy: 0.7931\n",
      "Epoch 15/50\n",
      "112720/112720 [==============================] - 3s - loss: 0.3870 - acc: 0.8121 - label_accuracy: 0.8121 - val_loss: 0.9927 - val_acc: 0.7610 - val_label_accuracy: 0.7610\n",
      "Epoch 16/50\n",
      "112720/112720 [==============================] - 3s - loss: 0.3798 - acc: 0.8156 - label_accuracy: 0.8156 - val_loss: 0.9474 - val_acc: 0.7642 - val_label_accuracy: 0.7642\n",
      "Epoch 17/50\n",
      "112720/112720 [==============================] - 3s - loss: 0.3678 - acc: 0.8257 - label_accuracy: 0.8257 - val_loss: 1.0013 - val_acc: 0.7281 - val_label_accuracy: 0.7281\n",
      "Epoch 18/50\n",
      "112720/112720 [==============================] - 2s - loss: 0.3657 - acc: 0.7595 - label_accuracy: 0.7595 - val_loss: 0.9798 - val_acc: 0.7081 - val_label_accuracy: 0.7081\n",
      "Epoch 19/50\n",
      "112720/112720 [==============================] - 2s - loss: 0.3540 - acc: 0.8018 - label_accuracy: 0.8018 - val_loss: 0.9079 - val_acc: 0.6876 - val_label_accuracy: 0.6876\n",
      "Epoch 20/50\n",
      "112720/112720 [==============================] - 3s - loss: 0.3525 - acc: 0.7755 - label_accuracy: 0.7755 - val_loss: 0.8830 - val_acc: 0.6024 - val_label_accuracy: 0.6024\n",
      "Epoch 21/50\n",
      "112720/112720 [==============================] - 3s - loss: 0.3450 - acc: 0.7558 - label_accuracy: 0.7558 - val_loss: 0.8197 - val_acc: 0.7311 - val_label_accuracy: 0.7311\n",
      "Epoch 22/50\n",
      "112720/112720 [==============================] - 3s - loss: 0.3332 - acc: 0.7437 - label_accuracy: 0.7437 - val_loss: 0.8187 - val_acc: 0.6369 - val_label_accuracy: 0.6369\n",
      "Epoch 23/50\n",
      "112720/112720 [==============================] - 3s - loss: 0.3386 - acc: 0.7354 - label_accuracy: 0.7354 - val_loss: 0.7820 - val_acc: 0.7072 - val_label_accuracy: 0.7072\n",
      "Epoch 24/50\n",
      "112720/112720 [==============================] - 3s - loss: 0.3222 - acc: 0.7270 - label_accuracy: 0.7270 - val_loss: 0.8288 - val_acc: 0.7315 - val_label_accuracy: 0.7315\n",
      "Epoch 25/50\n",
      "112720/112720 [==============================] - 3s - loss: 0.3223 - acc: 0.7245 - label_accuracy: 0.7245 - val_loss: 0.7982 - val_acc: 0.7234 - val_label_accuracy: 0.7234\n",
      "Epoch 26/50\n",
      "112720/112720 [==============================] - 3s - loss: 0.3191 - acc: 0.7404 - label_accuracy: 0.7404 - val_loss: 0.7598 - val_acc: 0.7171 - val_label_accuracy: 0.7171\n",
      "Epoch 27/50\n",
      "112720/112720 [==============================] - 3s - loss: 0.3117 - acc: 0.7179 - label_accuracy: 0.7179 - val_loss: 0.7306 - val_acc: 0.7196 - val_label_accuracy: 0.7196\n",
      "Epoch 28/50\n",
      "112720/112720 [==============================] - 3s - loss: 0.3040 - acc: 0.7377 - label_accuracy: 0.7377 - val_loss: 0.7327 - val_acc: 0.7079 - val_label_accuracy: 0.7079\n",
      "Epoch 29/50\n",
      "112720/112720 [==============================] - 3s - loss: 0.3063 - acc: 0.7566 - label_accuracy: 0.7566 - val_loss: 0.7101 - val_acc: 0.7134 - val_label_accuracy: 0.7134\n",
      "Epoch 30/50\n",
      "112720/112720 [==============================] - 3s - loss: 0.2966 - acc: 0.7454 - label_accuracy: 0.7454 - val_loss: 0.6875 - val_acc: 0.7331 - val_label_accuracy: 0.7331\n",
      "Epoch 31/50\n",
      "112720/112720 [==============================] - 3s - loss: 0.2899 - acc: 0.7538 - label_accuracy: 0.7538 - val_loss: 0.7280 - val_acc: 0.7044 - val_label_accuracy: 0.7044\n",
      "Epoch 32/50\n",
      "112720/112720 [==============================] - 3s - loss: 0.2918 - acc: 0.7435 - label_accuracy: 0.7435 - val_loss: 0.7427 - val_acc: 0.7269 - val_label_accuracy: 0.7269\n",
      "Epoch 33/50\n",
      "112720/112720 [==============================] - 3s - loss: 0.2936 - acc: 0.7654 - label_accuracy: 0.7654 - val_loss: 0.6844 - val_acc: 0.7289 - val_label_accuracy: 0.7289\n",
      "Epoch 34/50\n",
      "112720/112720 [==============================] - 3s - loss: 0.2888 - acc: 0.7544 - label_accuracy: 0.7544 - val_loss: 0.6533 - val_acc: 0.7257 - val_label_accuracy: 0.7257\n",
      "Epoch 35/50\n",
      "112720/112720 [==============================] - 3s - loss: 0.2856 - acc: 0.7594 - label_accuracy: 0.7594 - val_loss: 0.6609 - val_acc: 0.7300 - val_label_accuracy: 0.7300\n",
      "Epoch 36/50\n",
      "112720/112720 [==============================] - 3s - loss: 0.2819 - acc: 0.7605 - label_accuracy: 0.7605 - val_loss: 0.6794 - val_acc: 0.6419 - val_label_accuracy: 0.6419\n",
      "Epoch 37/50\n",
      "112720/112720 [==============================] - 3s - loss: 0.2831 - acc: 0.7529 - label_accuracy: 0.7529 - val_loss: 0.6603 - val_acc: 0.7130 - val_label_accuracy: 0.7130\n",
      "Epoch 38/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "112720/112720 [==============================] - 3s - loss: 0.2766 - acc: 0.7697 - label_accuracy: 0.7697 - val_loss: 0.6388 - val_acc: 0.6978 - val_label_accuracy: 0.6978\n",
      "Epoch 39/50\n",
      "112720/112720 [==============================] - 3s - loss: 0.2765 - acc: 0.7643 - label_accuracy: 0.7643 - val_loss: 0.6887 - val_acc: 0.7376 - val_label_accuracy: 0.7376\n",
      "Epoch 40/50\n",
      "112720/112720 [==============================] - 3s - loss: 0.2740 - acc: 0.8012 - label_accuracy: 0.8012 - val_loss: 0.6400 - val_acc: 0.7349 - val_label_accuracy: 0.7349\n",
      "Epoch 41/50\n",
      "112720/112720 [==============================] - 3s - loss: 0.2754 - acc: 0.7981 - label_accuracy: 0.7981 - val_loss: 0.6308 - val_acc: 0.7355 - val_label_accuracy: 0.7355\n",
      "Epoch 42/50\n",
      "112720/112720 [==============================] - 3s - loss: 0.2725 - acc: 0.7941 - label_accuracy: 0.7941 - val_loss: 0.6093 - val_acc: 0.7421 - val_label_accuracy: 0.7421\n",
      "Epoch 43/50\n",
      "112720/112720 [==============================] - 3s - loss: 0.2604 - acc: 0.7802 - label_accuracy: 0.7802 - val_loss: 0.6104 - val_acc: 0.6966 - val_label_accuracy: 0.6966\n",
      "Epoch 44/50\n",
      "112720/112720 [==============================] - 3s - loss: 0.2620 - acc: 0.7984 - label_accuracy: 0.7984 - val_loss: 0.5866 - val_acc: 0.7165 - val_label_accuracy: 0.7165\n",
      "Epoch 45/50\n",
      "112720/112720 [==============================] - 3s - loss: 0.2624 - acc: 0.8482 - label_accuracy: 0.8482 - val_loss: 0.5841 - val_acc: 0.7512 - val_label_accuracy: 0.7512\n",
      "Epoch 46/50\n",
      "112720/112720 [==============================] - 3s - loss: 0.2701 - acc: 0.8394 - label_accuracy: 0.8394 - val_loss: 0.6092 - val_acc: 0.7120 - val_label_accuracy: 0.7120\n",
      "Epoch 47/50\n",
      "112720/112720 [==============================] - 3s - loss: 0.2595 - acc: 0.8294 - label_accuracy: 0.8294 - val_loss: 0.5697 - val_acc: 0.7345 - val_label_accuracy: 0.7345\n",
      "Epoch 48/50\n",
      "112720/112720 [==============================] - 3s - loss: 0.2576 - acc: 0.8308 - label_accuracy: 0.8308 - val_loss: 0.5806 - val_acc: 0.7021 - val_label_accuracy: 0.7021\n",
      "Epoch 49/50\n",
      "112720/112720 [==============================] - 3s - loss: 0.2598 - acc: 0.8426 - label_accuracy: 0.8426 - val_loss: 0.5887 - val_acc: 0.6738 - val_label_accuracy: 0.6738\n",
      "Epoch 50/50\n",
      "112720/112720 [==============================] - 3s - loss: 0.2506 - acc: 0.8538 - label_accuracy: 0.8538 - val_loss: 0.5710 - val_acc: 0.7437 - val_label_accuracy: 0.7437\n",
      "21135/22544 [===========================>..] - ETA: 0s\n",
      " Train Acc: 0.891944631934166, Test Acc: 0.743745569139719, Label Acc: 0.7535042583392477\n",
      " \n",
      " Current Layer Attributes - epochs:50 hidden layers:6 features count:122\n",
      "Train on 112720 samples, validate on 22544 samples\n",
      "Epoch 1/50\n",
      "112720/112720 [==============================] - 4s - loss: 741.0946 - acc: 0.0808 - label_accuracy: 0.0808 - val_loss: 1.7829 - val_acc: 0.3621 - val_label_accuracy: 0.3621\n",
      "Epoch 2/50\n",
      "112720/112720 [==============================] - 3s - loss: 0.7241 - acc: 0.4693 - label_accuracy: 0.4693 - val_loss: 1.6473 - val_acc: 0.5009 - val_label_accuracy: 0.5009\n",
      "Epoch 3/50\n",
      "112720/112720 [==============================] - 3s - loss: 0.6376 - acc: 0.5887 - label_accuracy: 0.5887 - val_loss: 1.5074 - val_acc: 0.5955 - val_label_accuracy: 0.5955\n",
      "Epoch 4/50\n",
      "112720/112720 [==============================] - 3s - loss: 0.5720 - acc: 0.6781 - label_accuracy: 0.6781 - val_loss: 1.4016 - val_acc: 0.7447 - val_label_accuracy: 0.7447\n",
      "Epoch 5/50\n",
      "112720/112720 [==============================] - 3s - loss: 0.5170 - acc: 0.7246 - label_accuracy: 0.7246 - val_loss: 1.3088 - val_acc: 0.7730 - val_label_accuracy: 0.7730\n",
      "Epoch 6/50\n",
      "112720/112720 [==============================] - 3s - loss: 0.4704 - acc: 0.7435 - label_accuracy: 0.7435 - val_loss: 1.2369 - val_acc: 0.8017 - val_label_accuracy: 0.8017\n",
      "Epoch 7/50\n",
      "112720/112720 [==============================] - 3s - loss: 0.4406 - acc: 0.7554 - label_accuracy: 0.7554 - val_loss: 1.1498 - val_acc: 0.8212 - val_label_accuracy: 0.8212\n",
      "Epoch 8/50\n",
      "112720/112720 [==============================] - 2s - loss: 0.4125 - acc: 0.7660 - label_accuracy: 0.7660 - val_loss: 1.1311 - val_acc: 0.8105 - val_label_accuracy: 0.8105\n",
      "Epoch 9/50\n",
      "112720/112720 [==============================] - 2s - loss: 0.3973 - acc: 0.7669 - label_accuracy: 0.7669 - val_loss: 1.1009 - val_acc: 0.7548 - val_label_accuracy: 0.7548\n",
      "Epoch 10/50\n",
      "112720/112720 [==============================] - 2s - loss: 0.3775 - acc: 0.7655 - label_accuracy: 0.7655 - val_loss: 1.0604 - val_acc: 0.8182 - val_label_accuracy: 0.8182\n",
      "Epoch 11/50\n",
      "112720/112720 [==============================] - 2s - loss: 0.3595 - acc: 0.7677 - label_accuracy: 0.7677 - val_loss: 1.0049 - val_acc: 0.7622 - val_label_accuracy: 0.7622\n",
      "Epoch 12/50\n",
      "112720/112720 [==============================] - 2s - loss: 0.3482 - acc: 0.7650 - label_accuracy: 0.7650 - val_loss: 0.9732 - val_acc: 0.8423 - val_label_accuracy: 0.8423\n",
      "Epoch 13/50\n",
      "112720/112720 [==============================] - 2s - loss: 0.3517 - acc: 0.7693 - label_accuracy: 0.7693 - val_loss: 0.9796 - val_acc: 0.7881 - val_label_accuracy: 0.7881\n",
      "Epoch 14/50\n",
      "112720/112720 [==============================] - 2s - loss: 0.3319 - acc: 0.7764 - label_accuracy: 0.7764 - val_loss: 0.9490 - val_acc: 0.8538 - val_label_accuracy: 0.8538\n",
      "Epoch 15/50\n",
      "112720/112720 [==============================] - 2s - loss: 0.3305 - acc: 0.7746 - label_accuracy: 0.7746 - val_loss: 0.9844 - val_acc: 0.7933 - val_label_accuracy: 0.7933\n",
      "Epoch 16/50\n",
      "112720/112720 [==============================] - 2s - loss: 0.3092 - acc: 0.7758 - label_accuracy: 0.7758 - val_loss: 0.9062 - val_acc: 0.7817 - val_label_accuracy: 0.7817\n",
      "Epoch 17/50\n",
      "112720/112720 [==============================] - 2s - loss: 0.2991 - acc: 0.7761 - label_accuracy: 0.7761 - val_loss: 0.8980 - val_acc: 0.7810 - val_label_accuracy: 0.7810\n",
      "Epoch 18/50\n",
      "112720/112720 [==============================] - 2s - loss: 0.3041 - acc: 0.7748 - label_accuracy: 0.7748 - val_loss: 0.9283 - val_acc: 0.7831 - val_label_accuracy: 0.7831\n",
      "Epoch 19/50\n",
      "112720/112720 [==============================] - 2s - loss: 186.3089 - acc: 0.6828 - label_accuracy: 0.6828 - val_loss: 38252.4781 - val_acc: 0.0050 - val_label_accuracy: 0.0050\n",
      "Epoch 20/50\n",
      "112720/112720 [==============================] - 2s - loss: 1.2923 - acc: 0.0397 - label_accuracy: 0.0397 - val_loss: 1.9189 - val_acc: 0.0588 - val_label_accuracy: 0.0588\n",
      "Epoch 21/50\n",
      "112720/112720 [==============================] - 1s - loss: 0.8735 - acc: 0.1153 - label_accuracy: 0.1153 - val_loss: 1.8700 - val_acc: 0.0918 - val_label_accuracy: 0.0918\n",
      "Epoch 22/50\n",
      "112720/112720 [==============================] - 1s - loss: 0.8213 - acc: 0.3561 - label_accuracy: 0.3561 - val_loss: 1.8311 - val_acc: 0.4430 - val_label_accuracy: 0.4430\n",
      "Epoch 23/50\n",
      "112720/112720 [==============================] - 2s - loss: 0.7825 - acc: 0.4847 - label_accuracy: 0.4847 - val_loss: 1.7870 - val_acc: 0.4792 - val_label_accuracy: 0.4792\n",
      "Epoch 24/50\n",
      "112720/112720 [==============================] - 2s - loss: 0.7531 - acc: 0.4936 - label_accuracy: 0.4936 - val_loss: 1.7522 - val_acc: 0.5087 - val_label_accuracy: 0.5087\n",
      "Epoch 25/50\n",
      "112720/112720 [==============================] - 2s - loss: 0.7322 - acc: 0.5020 - label_accuracy: 0.5020 - val_loss: 1.7088 - val_acc: 0.4990 - val_label_accuracy: 0.4990\n",
      "Epoch 26/50\n",
      "112720/112720 [==============================] - 2s - loss: 0.7127 - acc: 0.5147 - label_accuracy: 0.5147 - val_loss: 1.6796 - val_acc: 0.5318 - val_label_accuracy: 0.5318\n",
      "Epoch 27/50\n",
      "112720/112720 [==============================] - 2s - loss: 0.6967 - acc: 0.5262 - label_accuracy: 0.5262 - val_loss: 1.6547 - val_acc: 0.5492 - val_label_accuracy: 0.5492\n",
      "Epoch 28/50\n",
      "112720/112720 [==============================] - 2s - loss: 0.6840 - acc: 0.5440 - label_accuracy: 0.5440 - val_loss: 1.6380 - val_acc: 0.5559 - val_label_accuracy: 0.5559\n",
      "Epoch 29/50\n",
      "112720/112720 [==============================] - 2s - loss: 0.6691 - acc: 0.5680 - label_accuracy: 0.5680 - val_loss: 1.6079 - val_acc: 0.5712 - val_label_accuracy: 0.5712\n",
      "Epoch 30/50\n",
      "112720/112720 [==============================] - 2s - loss: 0.6586 - acc: 0.5766 - label_accuracy: 0.5766 - val_loss: 1.5931 - val_acc: 0.5649 - val_label_accuracy: 0.5649\n",
      "Epoch 31/50\n",
      "112720/112720 [==============================] - 2s - loss: 0.6468 - acc: 0.5869 - label_accuracy: 0.5869 - val_loss: 1.5800 - val_acc: 0.6028 - val_label_accuracy: 0.6028\n",
      "Epoch 32/50\n",
      "112720/112720 [==============================] - 2s - loss: 0.6368 - acc: 0.5979 - label_accuracy: 0.5979 - val_loss: 1.5651 - val_acc: 0.5887 - val_label_accuracy: 0.5887\n",
      "Epoch 33/50\n",
      "112720/112720 [==============================] - 2s - loss: 0.6283 - acc: 0.6061 - label_accuracy: 0.6061 - val_loss: 1.5390 - val_acc: 0.6312 - val_label_accuracy: 0.6312\n",
      "Epoch 34/50\n",
      "112720/112720 [==============================] - 2s - loss: 0.6171 - acc: 0.6154 - label_accuracy: 0.6154 - val_loss: 1.5453 - val_acc: 0.5895 - val_label_accuracy: 0.5895\n",
      "Epoch 35/50\n",
      "112720/112720 [==============================] - 2s - loss: 0.6126 - acc: 0.6233 - label_accuracy: 0.6233 - val_loss: 1.5153 - val_acc: 0.6174 - val_label_accuracy: 0.6174\n",
      "Epoch 36/50\n",
      "112720/112720 [==============================] - 2s - loss: 0.6046 - acc: 0.6359 - label_accuracy: 0.6359 - val_loss: 1.4948 - val_acc: 0.6304 - val_label_accuracy: 0.6304\n",
      "Epoch 37/50\n",
      "112720/112720 [==============================] - 2s - loss: 0.5941 - acc: 0.6445 - label_accuracy: 0.6445 - val_loss: 1.4794 - val_acc: 0.6690 - val_label_accuracy: 0.6690\n",
      "Epoch 38/50\n",
      "112720/112720 [==============================] - 2s - loss: 0.5854 - acc: 0.6508 - label_accuracy: 0.6508 - val_loss: 1.4740 - val_acc: 0.6606 - val_label_accuracy: 0.6606\n",
      "Epoch 39/50\n",
      "112720/112720 [==============================] - 2s - loss: 0.5834 - acc: 0.6520 - label_accuracy: 0.6520 - val_loss: 1.4377 - val_acc: 0.6666 - val_label_accuracy: 0.6666\n",
      "Epoch 40/50\n",
      "112720/112720 [==============================] - 2s - loss: 0.5714 - acc: 0.6574 - label_accuracy: 0.6574 - val_loss: 1.4278 - val_acc: 0.6370 - val_label_accuracy: 0.6370\n",
      "Epoch 41/50\n",
      "112720/112720 [==============================] - 2s - loss: 0.5648 - acc: 0.6636 - label_accuracy: 0.6636 - val_loss: 1.4216 - val_acc: 0.7166 - val_label_accuracy: 0.7166\n",
      "Epoch 42/50\n",
      "112720/112720 [==============================] - 2s - loss: 0.5572 - acc: 0.6705 - label_accuracy: 0.6705 - val_loss: 1.3949 - val_acc: 0.6730 - val_label_accuracy: 0.6730\n",
      "Epoch 43/50\n",
      "112720/112720 [==============================] - 2s - loss: 0.5477 - acc: 0.6841 - label_accuracy: 0.6841 - val_loss: 1.3809 - val_acc: 0.7563 - val_label_accuracy: 0.7563\n",
      "Epoch 44/50\n",
      "112720/112720 [==============================] - 2s - loss: 0.5415 - acc: 0.6948 - label_accuracy: 0.6948 - val_loss: 1.3747 - val_acc: 0.7013 - val_label_accuracy: 0.7013\n",
      "Epoch 45/50\n",
      "112720/112720 [==============================] - 2s - loss: 0.5399 - acc: 0.6996 - label_accuracy: 0.6996 - val_loss: 1.3813 - val_acc: 0.5713 - val_label_accuracy: 0.5713\n",
      "Epoch 46/50\n",
      "112720/112720 [==============================] - 2s - loss: 0.5400 - acc: 0.7047 - label_accuracy: 0.7047 - val_loss: 1.3661 - val_acc: 0.7629 - val_label_accuracy: 0.7629\n",
      "Epoch 47/50\n",
      "112720/112720 [==============================] - 2s - loss: 0.5265 - acc: 0.7167 - label_accuracy: 0.7167 - val_loss: 1.3525 - val_acc: 0.7268 - val_label_accuracy: 0.7268\n",
      "Epoch 48/50\n",
      "112720/112720 [==============================] - 2s - loss: 0.5222 - acc: 0.7231 - label_accuracy: 0.7231 - val_loss: 1.3379 - val_acc: 0.7757 - val_label_accuracy: 0.7757\n",
      "Epoch 49/50\n",
      "112720/112720 [==============================] - 2s - loss: 0.5122 - acc: 0.7290 - label_accuracy: 0.7290 - val_loss: 1.3374 - val_acc: 0.7761 - val_label_accuracy: 0.7761\n",
      "Epoch 50/50\n",
      "112720/112720 [==============================] - 2s - loss: 0.5080 - acc: 0.7300 - label_accuracy: 0.7300 - val_loss: 1.3277 - val_acc: 0.7704 - val_label_accuracy: 0.7704\n",
      "18317/22544 [=======================>......] - ETA: 0s\n",
      " Train Acc: 0.7365152686834335, Test Acc: 0.7703601829707623, Label Acc: 0.8212828246983677\n",
      " \n",
      " Current Layer Attributes - epochs:50 hidden layers:10 features count:4\n",
      "Train on 112720 samples, validate on 22544 samples\n",
      "Epoch 1/50\n",
      "112720/112720 [==============================] - 5s - loss: 0.9149 - acc: 0.0078 - label_accuracy: 0.0078 - val_loss: 1.8391 - val_acc: 0.2092 - val_label_accuracy: 0.2092\n",
      "Epoch 2/50\n",
      "112720/112720 [==============================] - 3s - loss: 0.8132 - acc: 0.2116 - label_accuracy: 0.2116 - val_loss: 1.7922 - val_acc: 0.4025 - val_label_accuracy: 0.4025\n",
      "Epoch 3/50\n",
      "112720/112720 [==============================] - 3s - loss: 0.7466 - acc: 0.5097 - label_accuracy: 0.5097 - val_loss: 1.7252 - val_acc: 0.5991 - val_label_accuracy: 0.5991\n",
      "Epoch 4/50\n",
      "112720/112720 [==============================] - 3s - loss: 0.7020 - acc: 0.5722 - label_accuracy: 0.5722 - val_loss: 1.6957 - val_acc: 0.6262 - val_label_accuracy: 0.6262\n",
      "Epoch 5/50\n",
      "112720/112720 [==============================] - 3s - loss: 0.6684 - acc: 0.6545 - label_accuracy: 0.6545 - val_loss: 1.6174 - val_acc: 0.6869 - val_label_accuracy: 0.6869\n",
      "Epoch 6/50\n",
      "112720/112720 [==============================] - 3s - loss: 0.6555 - acc: 0.6230 - label_accuracy: 0.6230 - val_loss: 1.5214 - val_acc: 0.6735 - val_label_accuracy: 0.6735\n",
      "Epoch 7/50\n",
      "112720/112720 [==============================] - 3s - loss: 0.6049 - acc: 0.7205 - label_accuracy: 0.7205 - val_loss: 1.4105 - val_acc: 0.7408 - val_label_accuracy: 0.7408\n",
      "Epoch 8/50\n",
      "112720/112720 [==============================] - 3s - loss: 0.5828 - acc: 0.7279 - label_accuracy: 0.7279 - val_loss: 1.3517 - val_acc: 0.7726 - val_label_accuracy: 0.7726\n",
      "Epoch 9/50\n",
      "112720/112720 [==============================] - 3s - loss: 0.5671 - acc: 0.7371 - label_accuracy: 0.7371 - val_loss: 1.3721 - val_acc: 0.6954 - val_label_accuracy: 0.6954\n",
      "Epoch 10/50\n",
      "112720/112720 [==============================] - 3s - loss: 0.5793 - acc: 0.7254 - label_accuracy: 0.7254 - val_loss: 1.3313 - val_acc: 0.6892 - val_label_accuracy: 0.6892\n",
      "Epoch 11/50\n",
      "112720/112720 [==============================] - 3s - loss: 0.5409 - acc: 0.7367 - label_accuracy: 0.7367 - val_loss: 1.2796 - val_acc: 0.6464 - val_label_accuracy: 0.6464\n",
      "Epoch 12/50\n",
      "112720/112720 [==============================] - 3s - loss: 0.5199 - acc: 0.7560 - label_accuracy: 0.7560 - val_loss: 1.2722 - val_acc: 0.7981 - val_label_accuracy: 0.7981\n",
      "Epoch 13/50\n",
      "112720/112720 [==============================] - 3s - loss: 0.4739 - acc: 0.8063 - label_accuracy: 0.8063 - val_loss: 1.2083 - val_acc: 0.7958 - val_label_accuracy: 0.7958\n",
      "Epoch 14/50\n",
      "112720/112720 [==============================] - 3s - loss: 0.4466 - acc: 0.8069 - label_accuracy: 0.8069 - val_loss: 1.2110 - val_acc: 0.7272 - val_label_accuracy: 0.7272\n",
      "Epoch 15/50\n",
      "112720/112720 [==============================] - 3s - loss: 0.4141 - acc: 0.8333 - label_accuracy: 0.8333 - val_loss: 1.1283 - val_acc: 0.8116 - val_label_accuracy: 0.8116\n",
      "Epoch 16/50\n",
      "112720/112720 [==============================] - 3s - loss: 0.4337 - acc: 0.8004 - label_accuracy: 0.8004 - val_loss: 1.1307 - val_acc: 0.8227 - val_label_accuracy: 0.8227\n",
      "Epoch 17/50\n",
      "112720/112720 [==============================] - 3s - loss: 0.3794 - acc: 0.8321 - label_accuracy: 0.8321 - val_loss: 1.0545 - val_acc: 0.8274 - val_label_accuracy: 0.8274\n",
      "Epoch 18/50\n",
      "112720/112720 [==============================] - 3s - loss: 0.3474 - acc: 0.8412 - label_accuracy: 0.8412 - val_loss: 1.0134 - val_acc: 0.8264 - val_label_accuracy: 0.8264\n",
      "Epoch 19/50\n",
      "112720/112720 [==============================] - 3s - loss: 0.3348 - acc: 0.8451 - label_accuracy: 0.8451 - val_loss: 0.9739 - val_acc: 0.8344 - val_label_accuracy: 0.8344\n",
      "Epoch 20/50\n",
      "112720/112720 [==============================] - 3s - loss: 0.4421 - acc: 0.7686 - label_accuracy: 0.7686 - val_loss: 1.1167 - val_acc: 0.7900 - val_label_accuracy: 0.7900\n",
      "Epoch 21/50\n",
      "112720/112720 [==============================] - 3s - loss: 0.3583 - acc: 0.8383 - label_accuracy: 0.8383 - val_loss: 1.0852 - val_acc: 0.8231 - val_label_accuracy: 0.8231\n",
      "Epoch 22/50\n",
      "112720/112720 [==============================] - 3s - loss: 0.3265 - acc: 0.8495 - label_accuracy: 0.8495 - val_loss: 0.9455 - val_acc: 0.8200 - val_label_accuracy: 0.8200\n",
      "Epoch 23/50\n",
      "112720/112720 [==============================] - 3s - loss: 0.3060 - acc: 0.8547 - label_accuracy: 0.8547 - val_loss: 0.9675 - val_acc: 0.8307 - val_label_accuracy: 0.8307\n",
      "Epoch 24/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "112720/112720 [==============================] - 3s - loss: 0.2908 - acc: 0.8610 - label_accuracy: 0.8610 - val_loss: 0.8708 - val_acc: 0.8364 - val_label_accuracy: 0.8364\n",
      "Epoch 25/50\n",
      "112720/112720 [==============================] - 3s - loss: 0.3009 - acc: 0.8546 - label_accuracy: 0.8546 - val_loss: 0.8669 - val_acc: 0.8312 - val_label_accuracy: 0.8312\n",
      "Epoch 26/50\n",
      "112720/112720 [==============================] - 3s - loss: 0.3487 - acc: 0.8273 - label_accuracy: 0.8273 - val_loss: 1.1238 - val_acc: 0.7378 - val_label_accuracy: 0.7378\n",
      "Epoch 27/50\n",
      "112720/112720 [==============================] - 2s - loss: 0.3294 - acc: 0.8132 - label_accuracy: 0.8132 - val_loss: 1.1082 - val_acc: 0.7496 - val_label_accuracy: 0.7496\n",
      "Epoch 28/50\n",
      "112720/112720 [==============================] - 2s - loss: 0.3138 - acc: 0.7995 - label_accuracy: 0.7995 - val_loss: 0.9623 - val_acc: 0.7316 - val_label_accuracy: 0.7316\n",
      "Epoch 29/50\n",
      "112720/112720 [==============================] - 2s - loss: 0.2721 - acc: 0.8472 - label_accuracy: 0.8472 - val_loss: 0.9229 - val_acc: 0.8341 - val_label_accuracy: 0.8341\n",
      "Epoch 30/50\n",
      "112720/112720 [==============================] - 3s - loss: 0.2705 - acc: 0.8649 - label_accuracy: 0.8649 - val_loss: 0.9305 - val_acc: 0.8365 - val_label_accuracy: 0.8365\n",
      "Epoch 31/50\n",
      "112720/112720 [==============================] - 3s - loss: 0.2838 - acc: 0.8604 - label_accuracy: 0.8604 - val_loss: 0.9441 - val_acc: 0.8357 - val_label_accuracy: 0.8357\n",
      "Epoch 32/50\n",
      "112720/112720 [==============================] - 3s - loss: 0.2428 - acc: 0.8754 - label_accuracy: 0.8754 - val_loss: 0.8879 - val_acc: 0.8400 - val_label_accuracy: 0.8400\n",
      "Epoch 33/50\n",
      "112720/112720 [==============================] - 3s - loss: 0.2332 - acc: 0.8781 - label_accuracy: 0.8781 - val_loss: 0.8705 - val_acc: 0.8326 - val_label_accuracy: 0.8326\n",
      "Epoch 34/50\n",
      "112720/112720 [==============================] - 3s - loss: 0.2346 - acc: 0.8783 - label_accuracy: 0.8783 - val_loss: 0.9139 - val_acc: 0.8347 - val_label_accuracy: 0.8347\n",
      "Epoch 35/50\n",
      "112720/112720 [==============================] - 3s - loss: 0.2254 - acc: 0.8836 - label_accuracy: 0.8836 - val_loss: 0.8599 - val_acc: 0.8473 - val_label_accuracy: 0.8473\n",
      "Epoch 36/50\n",
      "112720/112720 [==============================] - 3s - loss: 0.2159 - acc: 0.8903 - label_accuracy: 0.8903 - val_loss: 0.8394 - val_acc: 0.8449 - val_label_accuracy: 0.8449\n",
      "Epoch 37/50\n",
      "112720/112720 [==============================] - 3s - loss: 0.2080 - acc: 0.8936 - label_accuracy: 0.8936 - val_loss: 0.8285 - val_acc: 0.8453 - val_label_accuracy: 0.8453\n",
      "Epoch 38/50\n",
      "112720/112720 [==============================] - 3s - loss: 0.2108 - acc: 0.8878 - label_accuracy: 0.8878 - val_loss: 0.8287 - val_acc: 0.8420 - val_label_accuracy: 0.8420\n",
      "Epoch 39/50\n",
      "112720/112720 [==============================] - 3s - loss: 0.2849 - acc: 0.8565 - label_accuracy: 0.8565 - val_loss: 0.9436 - val_acc: 0.8407 - val_label_accuracy: 0.8407\n",
      "Epoch 40/50\n",
      "112720/112720 [==============================] - 3s - loss: 0.2559 - acc: 0.8721 - label_accuracy: 0.8721 - val_loss: 0.9749 - val_acc: 0.8406 - val_label_accuracy: 0.8406\n",
      "Epoch 41/50\n",
      "112720/112720 [==============================] - 3s - loss: 0.2116 - acc: 0.8824 - label_accuracy: 0.8824 - val_loss: 0.7303 - val_acc: 0.8420 - val_label_accuracy: 0.8420\n",
      "Epoch 42/50\n",
      "112720/112720 [==============================] - 3s - loss: 0.2009 - acc: 0.8914 - label_accuracy: 0.8914 - val_loss: 0.6983 - val_acc: 0.8480 - val_label_accuracy: 0.8480\n",
      "Epoch 43/50\n",
      "112720/112720 [==============================] - 3s - loss: 0.1981 - acc: 0.8887 - label_accuracy: 0.8887 - val_loss: 0.7666 - val_acc: 0.8398 - val_label_accuracy: 0.8398\n",
      "Epoch 44/50\n",
      "112720/112720 [==============================] - 3s - loss: 0.2044 - acc: 0.8881 - label_accuracy: 0.8881 - val_loss: 0.8548 - val_acc: 0.8331 - val_label_accuracy: 0.8331\n",
      "Epoch 45/50\n",
      "112720/112720 [==============================] - 3s - loss: 0.2008 - acc: 0.8854 - label_accuracy: 0.8854 - val_loss: 0.8284 - val_acc: 0.8439 - val_label_accuracy: 0.8439\n",
      "Epoch 46/50\n",
      "112720/112720 [==============================] - 3s - loss: 0.1982 - acc: 0.8935 - label_accuracy: 0.8935 - val_loss: 0.8292 - val_acc: 0.8426 - val_label_accuracy: 0.8426\n",
      "Epoch 47/50\n",
      "112720/112720 [==============================] - 3s - loss: 0.1966 - acc: 0.8979 - label_accuracy: 0.8979 - val_loss: 0.8067 - val_acc: 0.8493 - val_label_accuracy: 0.8493\n",
      "Epoch 48/50\n",
      "112720/112720 [==============================] - 3s - loss: 0.1959 - acc: 0.8958 - label_accuracy: 0.8958 - val_loss: 0.7535 - val_acc: 0.8570 - val_label_accuracy: 0.8570\n",
      "Epoch 49/50\n",
      "112720/112720 [==============================] - 3s - loss: 0.2376 - acc: 0.8558 - label_accuracy: 0.8558 - val_loss: 0.7879 - val_acc: 0.8032 - val_label_accuracy: 0.8032\n",
      "Epoch 50/50\n",
      "112720/112720 [==============================] - 3s - loss: 0.2208 - acc: 0.8467 - label_accuracy: 0.8467 - val_loss: 0.7544 - val_acc: 0.8266 - val_label_accuracy: 0.8266\n",
      "19726/22544 [=========================>....] - ETA: 0s\n",
      " Train Acc: 0.8706529513001442, Test Acc: 0.8266057521104813, Label Acc: 0.7554559971611071\n",
      " \n",
      " Current Layer Attributes - epochs:50 hidden layers:10 features count:16\n",
      "Train on 112720 samples, validate on 22544 samples\n",
      "Epoch 1/50\n",
      "112720/112720 [==============================] - 5s - loss: 0.9123 - acc: 0.0087 - label_accuracy: 0.0087 - val_loss: 1580400.7412 - val_acc: 0.0105 - val_label_accuracy: 0.0105\n",
      "Epoch 2/50\n",
      "112720/112720 [==============================] - 3s - loss: 336.2488 - acc: 0.0402 - label_accuracy: 0.0402 - val_loss: 1.7922 - val_acc: 0.0963 - val_label_accuracy: 0.0963\n",
      "Epoch 3/50\n",
      "112720/112720 [==============================] - 3s - loss: 0.7589 - acc: 0.1659 - label_accuracy: 0.1659 - val_loss: 1.7094 - val_acc: 0.3550 - val_label_accuracy: 0.3550\n",
      "Epoch 4/50\n",
      "112720/112720 [==============================] - 3s - loss: 0.6986 - acc: 0.4883 - label_accuracy: 0.4883 - val_loss: 1.6388 - val_acc: 0.4689 - val_label_accuracy: 0.4689\n",
      "Epoch 5/50\n",
      "112720/112720 [==============================] - 3s - loss: 0.6522 - acc: 0.5805 - label_accuracy: 0.5805 - val_loss: 1.5114 - val_acc: 0.5630 - val_label_accuracy: 0.5630\n",
      "Epoch 6/50\n",
      "112720/112720 [==============================] - 3s - loss: 0.5997 - acc: 0.6515 - label_accuracy: 0.6515 - val_loss: 1.4272 - val_acc: 0.6097 - val_label_accuracy: 0.6097\n",
      "Epoch 7/50\n",
      "112720/112720 [==============================] - 3s - loss: 0.5566 - acc: 0.7309 - label_accuracy: 0.7309 - val_loss: 1.3966 - val_acc: 0.6653 - val_label_accuracy: 0.6653\n",
      "Epoch 8/50\n",
      "112720/112720 [==============================] - 3s - loss: 0.5335 - acc: 0.7373 - label_accuracy: 0.7373 - val_loss: 1.3688 - val_acc: 0.6646 - val_label_accuracy: 0.6646\n",
      "Epoch 9/50\n",
      "112720/112720 [==============================] - 3s - loss: 0.4968 - acc: 0.7441 - label_accuracy: 0.7441 - val_loss: 1.3052 - val_acc: 0.7136 - val_label_accuracy: 0.7136\n",
      "Epoch 10/50\n",
      "112720/112720 [==============================] - 3s - loss: 0.4693 - acc: 0.7661 - label_accuracy: 0.7661 - val_loss: 1.2879 - val_acc: 0.7052 - val_label_accuracy: 0.7052\n",
      "Epoch 11/50\n",
      "112720/112720 [==============================] - 3s - loss: 0.4563 - acc: 0.7705 - label_accuracy: 0.7705 - val_loss: 1.3329 - val_acc: 0.7308 - val_label_accuracy: 0.7308\n",
      "Epoch 12/50\n",
      "112720/112720 [==============================] - 3s - loss: 0.4299 - acc: 0.8135 - label_accuracy: 0.8135 - val_loss: 1.2801 - val_acc: 0.7549 - val_label_accuracy: 0.7549\n",
      "Epoch 13/50\n",
      "112720/112720 [==============================] - 3s - loss: 0.4083 - acc: 0.8206 - label_accuracy: 0.8206 - val_loss: 1.2530 - val_acc: 0.7476 - val_label_accuracy: 0.7476\n",
      "Epoch 14/50\n",
      "112720/112720 [==============================] - 3s - loss: 0.4455 - acc: 0.8147 - label_accuracy: 0.8147 - val_loss: 1.6134 - val_acc: 0.6297 - val_label_accuracy: 0.6297\n",
      "Epoch 15/50\n",
      "112720/112720 [==============================] - 3s - loss: 0.4687 - acc: 0.7864 - label_accuracy: 0.7864 - val_loss: 1.2590 - val_acc: 0.7590 - val_label_accuracy: 0.7590\n",
      "Epoch 16/50\n",
      "112720/112720 [==============================] - 3s - loss: 0.3921 - acc: 0.8458 - label_accuracy: 0.8458 - val_loss: 1.2651 - val_acc: 0.7628 - val_label_accuracy: 0.7628\n",
      "Epoch 17/50\n",
      "112720/112720 [==============================] - 3s - loss: 0.3944 - acc: 0.8372 - label_accuracy: 0.8372 - val_loss: 1.2185 - val_acc: 0.7851 - val_label_accuracy: 0.7851\n",
      "Epoch 18/50\n",
      "112720/112720 [==============================] - 3s - loss: 0.3594 - acc: 0.8452 - label_accuracy: 0.8452 - val_loss: 1.2127 - val_acc: 0.7861 - val_label_accuracy: 0.7861\n",
      "Epoch 19/50\n",
      "112720/112720 [==============================] - 3s - loss: 0.3476 - acc: 0.8553 - label_accuracy: 0.8553 - val_loss: 1.2103 - val_acc: 0.7802 - val_label_accuracy: 0.7802\n",
      "Epoch 20/50\n",
      "112720/112720 [==============================] - 3s - loss: 0.3348 - acc: 0.8584 - label_accuracy: 0.8584 - val_loss: 1.1855 - val_acc: 0.7765 - val_label_accuracy: 0.7765\n",
      "Epoch 21/50\n",
      "112720/112720 [==============================] - 3s - loss: 0.3365 - acc: 0.8510 - label_accuracy: 0.8510 - val_loss: 1.1814 - val_acc: 0.8065 - val_label_accuracy: 0.8065\n",
      "Epoch 22/50\n",
      "112720/112720 [==============================] - 3s - loss: 0.3318 - acc: 0.8515 - label_accuracy: 0.8515 - val_loss: 1.1950 - val_acc: 0.8222 - val_label_accuracy: 0.8222\n",
      "Epoch 23/50\n",
      "112720/112720 [==============================] - 3s - loss: 0.3378 - acc: 0.8449 - label_accuracy: 0.8449 - val_loss: 1.1542 - val_acc: 0.8196 - val_label_accuracy: 0.8196\n",
      "Epoch 24/50\n",
      "112720/112720 [==============================] - 3s - loss: 0.3054 - acc: 0.8636 - label_accuracy: 0.8636 - val_loss: 1.1321 - val_acc: 0.8231 - val_label_accuracy: 0.8231\n",
      "Epoch 25/50\n",
      "112720/112720 [==============================] - 3s - loss: 0.3015 - acc: 0.8646 - label_accuracy: 0.8646 - val_loss: 1.1293 - val_acc: 0.8235 - val_label_accuracy: 0.8235\n",
      "Epoch 26/50\n",
      "112720/112720 [==============================] - 3s - loss: 0.2983 - acc: 0.8653 - label_accuracy: 0.8653 - val_loss: 1.1296 - val_acc: 0.8246 - val_label_accuracy: 0.8246\n",
      "Epoch 27/50\n",
      "112720/112720 [==============================] - 2s - loss: 0.3025 - acc: 0.8650 - label_accuracy: 0.8650 - val_loss: 1.1125 - val_acc: 0.8253 - val_label_accuracy: 0.8253\n",
      "Epoch 28/50\n",
      "112720/112720 [==============================] - 2s - loss: 0.2914 - acc: 0.8660 - label_accuracy: 0.8660 - val_loss: 1.1379 - val_acc: 0.8321 - val_label_accuracy: 0.8321\n",
      "Epoch 29/50\n",
      "112720/112720 [==============================] - 2s - loss: 0.3097 - acc: 0.8551 - label_accuracy: 0.8551 - val_loss: 1.1688 - val_acc: 0.7836 - val_label_accuracy: 0.7836\n",
      "Epoch 30/50\n",
      "112720/112720 [==============================] - 2s - loss: 0.3180 - acc: 0.8450 - label_accuracy: 0.8450 - val_loss: 1.0968 - val_acc: 0.8090 - val_label_accuracy: 0.8090\n",
      "Epoch 31/50\n",
      "112720/112720 [==============================] - 2s - loss: 0.2884 - acc: 0.8656 - label_accuracy: 0.8656 - val_loss: 1.0594 - val_acc: 0.8254 - val_label_accuracy: 0.8254\n",
      "Epoch 32/50\n",
      "112720/112720 [==============================] - 2s - loss: 0.2852 - acc: 0.8657 - label_accuracy: 0.8657 - val_loss: 1.0697 - val_acc: 0.8086 - val_label_accuracy: 0.8086\n",
      "Epoch 33/50\n",
      "112720/112720 [==============================] - 2s - loss: 0.2787 - acc: 0.8663 - label_accuracy: 0.8663 - val_loss: 1.0576 - val_acc: 0.8374 - val_label_accuracy: 0.8374\n",
      "Epoch 34/50\n",
      "112720/112720 [==============================] - 2s - loss: 0.2835 - acc: 0.8639 - label_accuracy: 0.8639 - val_loss: 1.0460 - val_acc: 0.8361 - val_label_accuracy: 0.8361\n",
      "Epoch 35/50\n",
      "112720/112720 [==============================] - 2s - loss: 0.3003 - acc: 0.8571 - label_accuracy: 0.8571 - val_loss: 1.1622 - val_acc: 0.7317 - val_label_accuracy: 0.7317\n",
      "Epoch 36/50\n",
      "112720/112720 [==============================] - 2s - loss: 0.3014 - acc: 0.8602 - label_accuracy: 0.8602 - val_loss: 1.0573 - val_acc: 0.8264 - val_label_accuracy: 0.8264\n",
      "Epoch 37/50\n",
      "112720/112720 [==============================] - 2s - loss: 0.2871 - acc: 0.8671 - label_accuracy: 0.8671 - val_loss: 1.0312 - val_acc: 0.8249 - val_label_accuracy: 0.8249\n",
      "Epoch 38/50\n",
      "112720/112720 [==============================] - 2s - loss: 0.2804 - acc: 0.8689 - label_accuracy: 0.8689 - val_loss: 1.0823 - val_acc: 0.8274 - val_label_accuracy: 0.8274\n",
      "Epoch 39/50\n",
      "112720/112720 [==============================] - 2s - loss: 0.2773 - acc: 0.8704 - label_accuracy: 0.8704 - val_loss: 1.0203 - val_acc: 0.8325 - val_label_accuracy: 0.8325\n",
      "Epoch 40/50\n",
      "112720/112720 [==============================] - 2s - loss: 0.2756 - acc: 0.8723 - label_accuracy: 0.8723 - val_loss: 1.0209 - val_acc: 0.8352 - val_label_accuracy: 0.8352\n",
      "Epoch 41/50\n",
      "112720/112720 [==============================] - 2s - loss: 0.3168 - acc: 0.8455 - label_accuracy: 0.8455 - val_loss: 1.1151 - val_acc: 0.8290 - val_label_accuracy: 0.8290\n",
      "Epoch 42/50\n",
      "112720/112720 [==============================] - 2s - loss: 0.3325 - acc: 0.8485 - label_accuracy: 0.8485 - val_loss: 1.0273 - val_acc: 0.8264 - val_label_accuracy: 0.8264\n",
      "Epoch 43/50\n",
      "112720/112720 [==============================] - 2s - loss: 0.2880 - acc: 0.8707 - label_accuracy: 0.8707 - val_loss: 1.0037 - val_acc: 0.8260 - val_label_accuracy: 0.8260\n",
      "Epoch 44/50\n",
      "112720/112720 [==============================] - 2s - loss: 0.2697 - acc: 0.8739 - label_accuracy: 0.8739 - val_loss: 0.9768 - val_acc: 0.8320 - val_label_accuracy: 0.8320\n",
      "Epoch 45/50\n",
      "112720/112720 [==============================] - 2s - loss: 0.2650 - acc: 0.8761 - label_accuracy: 0.8761 - val_loss: 0.9768 - val_acc: 0.8340 - val_label_accuracy: 0.8340\n",
      "Epoch 46/50\n",
      "112720/112720 [==============================] - 2s - loss: 0.2646 - acc: 0.8776 - label_accuracy: 0.8776 - val_loss: 0.9716 - val_acc: 0.8518 - val_label_accuracy: 0.8518\n",
      "Epoch 47/50\n",
      "112720/112720 [==============================] - 2s - loss: 0.2637 - acc: 0.8792 - label_accuracy: 0.8792 - val_loss: 0.9630 - val_acc: 0.8310 - val_label_accuracy: 0.8310\n",
      "Epoch 48/50\n",
      "112720/112720 [==============================] - 2s - loss: 0.2535 - acc: 0.8802 - label_accuracy: 0.8802 - val_loss: 0.9611 - val_acc: 0.8350 - val_label_accuracy: 0.8350\n",
      "Epoch 49/50\n",
      "112720/112720 [==============================] - 2s - loss: 0.2526 - acc: 0.8814 - label_accuracy: 0.8814 - val_loss: 0.9516 - val_acc: 0.8384 - val_label_accuracy: 0.8384\n",
      "Epoch 50/50\n",
      "112720/112720 [==============================] - 2s - loss: 0.2622 - acc: 0.8782 - label_accuracy: 0.8782 - val_loss: 0.9490 - val_acc: 0.8384 - val_label_accuracy: 0.8384\n",
      "22544/22544 [==============================] - 0s     \n",
      "\n",
      " Train Acc: 0.8826295211911201, Test Acc: 0.838404905050993, Label Acc: 0.8022533711852378\n",
      " \n",
      " Current Layer Attributes - epochs:50 hidden layers:10 features count:32\n",
      "Train on 112720 samples, validate on 22544 samples\n",
      "Epoch 1/50\n",
      "112720/112720 [==============================] - 3s - loss: 359561.5811 - acc: 0.0035 - label_accuracy: 0.0035 - val_loss: 1.8876 - val_acc: 0.0076 - val_label_accuracy: 0.0076\n",
      "Epoch 2/50\n",
      "112720/112720 [==============================] - 2s - loss: 0.8332 - acc: 0.0155 - label_accuracy: 0.0155 - val_loss: 1.8027 - val_acc: 0.0582 - val_label_accuracy: 0.0582\n",
      "Epoch 3/50\n",
      "112720/112720 [==============================] - 2s - loss: 0.7555 - acc: 0.1369 - label_accuracy: 0.1369 - val_loss: 1.8965 - val_acc: 0.5314 - val_label_accuracy: 0.5314\n",
      "Epoch 4/50\n",
      "112720/112720 [==============================] - 2s - loss: 0.6964 - acc: 0.4930 - label_accuracy: 0.4930 - val_loss: 1.6932 - val_acc: 0.6154 - val_label_accuracy: 0.6154\n",
      "Epoch 5/50\n",
      "112720/112720 [==============================] - 2s - loss: 0.6447 - acc: 0.5818 - label_accuracy: 0.5818 - val_loss: 1.6403 - val_acc: 0.6556 - val_label_accuracy: 0.6556\n",
      "Epoch 6/50\n",
      "112720/112720 [==============================] - 2s - loss: 0.6127 - acc: 0.6263 - label_accuracy: 0.6263 - val_loss: 1.5652 - val_acc: 0.6807 - val_label_accuracy: 0.6807\n",
      "Epoch 7/50\n",
      "112720/112720 [==============================] - 2s - loss: 0.5822 - acc: 0.6759 - label_accuracy: 0.6759 - val_loss: 1.5355 - val_acc: 0.6813 - val_label_accuracy: 0.6813\n",
      "Epoch 8/50\n",
      "112720/112720 [==============================] - 2s - loss: 0.5880 - acc: 0.6699 - label_accuracy: 0.6699 - val_loss: 1.4848 - val_acc: 0.6905 - val_label_accuracy: 0.6905\n",
      "Epoch 9/50\n",
      "112720/112720 [==============================] - 2s - loss: 0.5390 - acc: 0.7368 - label_accuracy: 0.7368 - val_loss: 1.4549 - val_acc: 0.6887 - val_label_accuracy: 0.6887\n",
      "Epoch 10/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "112720/112720 [==============================] - 2s - loss: 0.5284 - acc: 0.7209 - label_accuracy: 0.7209 - val_loss: 1.4148 - val_acc: 0.7000 - val_label_accuracy: 0.7000\n",
      "Epoch 11/50\n",
      "112720/112720 [==============================] - 2s - loss: 0.5069 - acc: 0.7416 - label_accuracy: 0.7416 - val_loss: 1.3870 - val_acc: 0.7363 - val_label_accuracy: 0.7363\n",
      "Epoch 12/50\n",
      "112720/112720 [==============================] - 2s - loss: 0.5035 - acc: 0.7238 - label_accuracy: 0.7238 - val_loss: 1.3652 - val_acc: 0.6976 - val_label_accuracy: 0.6976\n",
      "Epoch 13/50\n",
      "112720/112720 [==============================] - 2s - loss: 0.4824 - acc: 0.7427 - label_accuracy: 0.7427 - val_loss: 1.4022 - val_acc: 0.7331 - val_label_accuracy: 0.7331\n",
      "Epoch 14/50\n",
      "112720/112720 [==============================] - 2s - loss: 0.4972 - acc: 0.7181 - label_accuracy: 0.7181 - val_loss: 1.3456 - val_acc: 0.6971 - val_label_accuracy: 0.6971\n",
      "Epoch 15/50\n",
      "112720/112720 [==============================] - 2s - loss: 0.4963 - acc: 0.7197 - label_accuracy: 0.7197 - val_loss: 1.3192 - val_acc: 0.7042 - val_label_accuracy: 0.7042\n",
      "Epoch 16/50\n",
      "112720/112720 [==============================] - 2s - loss: 0.4737 - acc: 0.7386 - label_accuracy: 0.7386 - val_loss: 1.3221 - val_acc: 0.7079 - val_label_accuracy: 0.7079\n",
      "Epoch 17/50\n",
      "112720/112720 [==============================] - 2s - loss: 0.4776 - acc: 0.7341 - label_accuracy: 0.7341 - val_loss: 1.3142 - val_acc: 0.7347 - val_label_accuracy: 0.7347\n",
      "Epoch 18/50\n",
      "112720/112720 [==============================] - 2s - loss: 0.4494 - acc: 0.7727 - label_accuracy: 0.7727 - val_loss: 1.2706 - val_acc: 0.7217 - val_label_accuracy: 0.7217\n",
      "Epoch 19/50\n",
      "112720/112720 [==============================] - 2s - loss: 0.4439 - acc: 0.7715 - label_accuracy: 0.7715 - val_loss: 1.2735 - val_acc: 0.6998 - val_label_accuracy: 0.6998\n",
      "Epoch 20/50\n",
      "112720/112720 [==============================] - 2s - loss: 0.4309 - acc: 0.7872 - label_accuracy: 0.7872 - val_loss: 1.2498 - val_acc: 0.7640 - val_label_accuracy: 0.7640\n",
      "Epoch 21/50\n",
      "112720/112720 [==============================] - 2s - loss: 0.4341 - acc: 0.7997 - label_accuracy: 0.7997 - val_loss: 1.3161 - val_acc: 0.7081 - val_label_accuracy: 0.7081\n",
      "Epoch 22/50\n",
      "112720/112720 [==============================] - 2s - loss: 0.4387 - acc: 0.7817 - label_accuracy: 0.7817 - val_loss: 1.2398 - val_acc: 0.7575 - val_label_accuracy: 0.7575\n",
      "Epoch 23/50\n",
      "112720/112720 [==============================] - 2s - loss: 0.4186 - acc: 0.8205 - label_accuracy: 0.8205 - val_loss: 1.2411 - val_acc: 0.7625 - val_label_accuracy: 0.7625\n",
      "Epoch 24/50\n",
      "112720/112720 [==============================] - 2s - loss: 0.4138 - acc: 0.8147 - label_accuracy: 0.8147 - val_loss: 1.2280 - val_acc: 0.7267 - val_label_accuracy: 0.7267\n",
      "Epoch 25/50\n",
      "112720/112720 [==============================] - 2s - loss: 0.4228 - acc: 0.8184 - label_accuracy: 0.8184 - val_loss: 1.2219 - val_acc: 0.7276 - val_label_accuracy: 0.7276\n",
      "Epoch 26/50\n",
      "112720/112720 [==============================] - 2s - loss: 0.4066 - acc: 0.8426 - label_accuracy: 0.8426 - val_loss: 1.2114 - val_acc: 0.7659 - val_label_accuracy: 0.7659\n",
      "Epoch 27/50\n",
      "112720/112720 [==============================] - 2s - loss: 0.4048 - acc: 0.8388 - label_accuracy: 0.8388 - val_loss: 1.1986 - val_acc: 0.7619 - val_label_accuracy: 0.7619\n",
      "Epoch 28/50\n",
      "112720/112720 [==============================] - 2s - loss: 0.4023 - acc: 0.8520 - label_accuracy: 0.8520 - val_loss: 1.1988 - val_acc: 0.7648 - val_label_accuracy: 0.7648\n",
      "Epoch 29/50\n",
      "112720/112720 [==============================] - 2s - loss: 0.4022 - acc: 0.8418 - label_accuracy: 0.8418 - val_loss: 1.1965 - val_acc: 0.7616 - val_label_accuracy: 0.7616\n",
      "Epoch 30/50\n",
      "112720/112720 [==============================] - 2s - loss: 0.3978 - acc: 0.8489 - label_accuracy: 0.8489 - val_loss: 1.1958 - val_acc: 0.7488 - val_label_accuracy: 0.7488\n",
      "Epoch 31/50\n",
      "112720/112720 [==============================] - 2s - loss: 0.3974 - acc: 0.8476 - label_accuracy: 0.8476 - val_loss: 1.1904 - val_acc: 0.7653 - val_label_accuracy: 0.7653\n",
      "Epoch 32/50\n",
      "112720/112720 [==============================] - 2s - loss: 0.3888 - acc: 0.8599 - label_accuracy: 0.8599 - val_loss: 1.2092 - val_acc: 0.7679 - val_label_accuracy: 0.7679\n",
      "Epoch 33/50\n",
      "112720/112720 [==============================] - 2s - loss: 0.3880 - acc: 0.8570 - label_accuracy: 0.8570 - val_loss: 1.1855 - val_acc: 0.7697 - val_label_accuracy: 0.7697\n",
      "Epoch 34/50\n",
      "112720/112720 [==============================] - 2s - loss: 0.3818 - acc: 0.8660 - label_accuracy: 0.8660 - val_loss: 1.1771 - val_acc: 0.7685 - val_label_accuracy: 0.7685\n",
      "Epoch 35/50\n",
      "112720/112720 [==============================] - 2s - loss: 0.3857 - acc: 0.8586 - label_accuracy: 0.8586 - val_loss: 1.1815 - val_acc: 0.7748 - val_label_accuracy: 0.7748\n",
      "Epoch 36/50\n",
      "112720/112720 [==============================] - 2s - loss: 0.3751 - acc: 0.8687 - label_accuracy: 0.8687 - val_loss: 1.1697 - val_acc: 0.7702 - val_label_accuracy: 0.7702\n",
      "Epoch 37/50\n",
      "112720/112720 [==============================] - 2s - loss: 0.3853 - acc: 0.8563 - label_accuracy: 0.8563 - val_loss: 1.1984 - val_acc: 0.7557 - val_label_accuracy: 0.7557\n",
      "Epoch 38/50\n",
      "112720/112720 [==============================] - 2s - loss: 0.3833 - acc: 0.8498 - label_accuracy: 0.8498 - val_loss: 1.1848 - val_acc: 0.7538 - val_label_accuracy: 0.7538\n",
      "Epoch 39/50\n",
      "112720/112720 [==============================] - 2s - loss: 0.3824 - acc: 0.8535 - label_accuracy: 0.8535 - val_loss: 1.1616 - val_acc: 0.7841 - val_label_accuracy: 0.7841\n",
      "Epoch 40/50\n",
      "112720/112720 [==============================] - 2s - loss: 0.3728 - acc: 0.8602 - label_accuracy: 0.8602 - val_loss: 1.1564 - val_acc: 0.7901 - val_label_accuracy: 0.7901\n",
      "Epoch 41/50\n",
      "112720/112720 [==============================] - 2s - loss: 0.3972 - acc: 0.8368 - label_accuracy: 0.8368 - val_loss: 1.1561 - val_acc: 0.7759 - val_label_accuracy: 0.7759\n",
      "Epoch 42/50\n",
      "112720/112720 [==============================] - 2s - loss: 0.4161 - acc: 0.8060 - label_accuracy: 0.8060 - val_loss: 1.2285 - val_acc: 0.7660 - val_label_accuracy: 0.7660\n",
      "Epoch 43/50\n",
      "112720/112720 [==============================] - 2s - loss: 0.4428 - acc: 0.7984 - label_accuracy: 0.7984 - val_loss: 1.2282 - val_acc: 0.7257 - val_label_accuracy: 0.7257\n",
      "Epoch 44/50\n",
      "112720/112720 [==============================] - 2s - loss: 0.4079 - acc: 0.8376 - label_accuracy: 0.8376 - val_loss: 1.1906 - val_acc: 0.7679 - val_label_accuracy: 0.7679\n",
      "Epoch 45/50\n",
      "112720/112720 [==============================] - 2s - loss: 0.3809 - acc: 0.8701 - label_accuracy: 0.8701 - val_loss: 1.1659 - val_acc: 0.7884 - val_label_accuracy: 0.7884\n",
      "Epoch 46/50\n",
      "112720/112720 [==============================] - 2s - loss: 0.3704 - acc: 0.8732 - label_accuracy: 0.8732 - val_loss: 1.1440 - val_acc: 0.7856 - val_label_accuracy: 0.7856\n",
      "Epoch 47/50\n",
      "112720/112720 [==============================] - 2s - loss: 0.3811 - acc: 0.8526 - label_accuracy: 0.8526 - val_loss: 1.1444 - val_acc: 0.7906 - val_label_accuracy: 0.7906\n",
      "Epoch 48/50\n",
      "112720/112720 [==============================] - 2s - loss: 0.3724 - acc: 0.8653 - label_accuracy: 0.8653 - val_loss: 1.1432 - val_acc: 0.7891 - val_label_accuracy: 0.7891\n",
      "Epoch 49/50\n",
      "112720/112720 [==============================] - 2s - loss: 0.3911 - acc: 0.8482 - label_accuracy: 0.8482 - val_loss: 1.2127 - val_acc: 0.7794 - val_label_accuracy: 0.7794\n",
      "Epoch 50/50\n",
      "112720/112720 [==============================] - 2s - loss: 0.3700 - acc: 0.8628 - label_accuracy: 0.8628 - val_loss: 1.1280 - val_acc: 0.7888 - val_label_accuracy: 0.7888\n",
      "22544/22544 [==============================] - 0s     \n",
      "\n",
      " Train Acc: 0.8787260502576828, Test Acc: 0.7887686342000961, Label Acc: 0.8222143364088006\n",
      " \n",
      " Current Layer Attributes - epochs:50 hidden layers:10 features count:122\n",
      "Train on 112720 samples, validate on 22544 samples\n",
      "Epoch 1/50\n",
      "112720/112720 [==============================] - 3s - loss: 0.8884 - acc: 0.0187 - label_accuracy: 0.0187 - val_loss: 1.7997 - val_acc: 0.1788 - val_label_accuracy: 0.1788\n",
      "Epoch 2/50\n",
      "112720/112720 [==============================] - 2s - loss: 0.7651 - acc: 0.3754 - label_accuracy: 0.3754 - val_loss: 1.7812 - val_acc: 0.4433 - val_label_accuracy: 0.4433\n",
      "Epoch 3/50\n",
      "112720/112720 [==============================] - 2s - loss: 0.7286 - acc: 0.4882 - label_accuracy: 0.4882 - val_loss: 1.7193 - val_acc: 0.5946 - val_label_accuracy: 0.5946\n",
      "Epoch 4/50\n",
      "112720/112720 [==============================] - 2s - loss: 0.6912 - acc: 0.5550 - label_accuracy: 0.5550 - val_loss: 1.6799 - val_acc: 0.6280 - val_label_accuracy: 0.6280\n",
      "Epoch 5/50\n",
      "112720/112720 [==============================] - 2s - loss: 0.6536 - acc: 0.6274 - label_accuracy: 0.6274 - val_loss: 1.6191 - val_acc: 0.6745 - val_label_accuracy: 0.6745\n",
      "Epoch 6/50\n",
      "112720/112720 [==============================] - 2s - loss: 0.6288 - acc: 0.6408 - label_accuracy: 0.6408 - val_loss: 1.5687 - val_acc: 0.6772 - val_label_accuracy: 0.6772\n",
      "Epoch 7/50\n",
      "112720/112720 [==============================] - 2s - loss: 0.5970 - acc: 0.6603 - label_accuracy: 0.6603 - val_loss: 1.5244 - val_acc: 0.7001 - val_label_accuracy: 0.7001\n",
      "Epoch 8/50\n",
      "112720/112720 [==============================] - 2s - loss: 0.5621 - acc: 0.6925 - label_accuracy: 0.6925 - val_loss: 1.4531 - val_acc: 0.7459 - val_label_accuracy: 0.7459\n",
      "Epoch 9/50\n",
      "112720/112720 [==============================] - 2s - loss: 0.5321 - acc: 0.7429 - label_accuracy: 0.7429 - val_loss: 1.3429 - val_acc: 0.7879 - val_label_accuracy: 0.7879\n",
      "Epoch 10/50\n",
      "112720/112720 [==============================] - 2s - loss: 0.5026 - acc: 0.7566 - label_accuracy: 0.7566 - val_loss: 1.2808 - val_acc: 0.7862 - val_label_accuracy: 0.7862\n",
      "Epoch 11/50\n",
      "112720/112720 [==============================] - 2s - loss: 0.4922 - acc: 0.7493 - label_accuracy: 0.7493 - val_loss: 1.3290 - val_acc: 0.7260 - val_label_accuracy: 0.7260\n",
      "Epoch 12/50\n",
      "112720/112720 [==============================] - 2s - loss: 0.4700 - acc: 0.7916 - label_accuracy: 0.7916 - val_loss: 1.1796 - val_acc: 0.7940 - val_label_accuracy: 0.7940\n",
      "Epoch 13/50\n",
      "112720/112720 [==============================] - 2s - loss: 0.4338 - acc: 0.8151 - label_accuracy: 0.8151 - val_loss: 1.1570 - val_acc: 0.7940 - val_label_accuracy: 0.7940\n",
      "Epoch 14/50\n",
      "112720/112720 [==============================] - 2s - loss: 0.4031 - acc: 0.8292 - label_accuracy: 0.8292 - val_loss: 1.1087 - val_acc: 0.7908 - val_label_accuracy: 0.7908\n",
      "Epoch 15/50\n",
      "112720/112720 [==============================] - 2s - loss: 0.4227 - acc: 0.7896 - label_accuracy: 0.7896 - val_loss: 1.0895 - val_acc: 0.7933 - val_label_accuracy: 0.7933\n",
      "Epoch 16/50\n",
      "112720/112720 [==============================] - 2s - loss: 0.3651 - acc: 0.8392 - label_accuracy: 0.8392 - val_loss: 1.0882 - val_acc: 0.7702 - val_label_accuracy: 0.7702\n",
      "Epoch 17/50\n",
      "112720/112720 [==============================] - 2s - loss: 0.3898 - acc: 0.8090 - label_accuracy: 0.8090 - val_loss: 1.0921 - val_acc: 0.8030 - val_label_accuracy: 0.8030\n",
      "Epoch 18/50\n",
      "112720/112720 [==============================] - 2s - loss: 0.3775 - acc: 0.8185 - label_accuracy: 0.8185 - val_loss: 1.1870 - val_acc: 0.7993 - val_label_accuracy: 0.7993\n",
      "Epoch 19/50\n",
      "112720/112720 [==============================] - 2s - loss: 0.3408 - acc: 0.8549 - label_accuracy: 0.8549 - val_loss: 1.0655 - val_acc: 0.7793 - val_label_accuracy: 0.7793\n",
      "Epoch 20/50\n",
      "112720/112720 [==============================] - 2s - loss: 0.3327 - acc: 0.8487 - label_accuracy: 0.8487 - val_loss: 1.0853 - val_acc: 0.8005 - val_label_accuracy: 0.8005\n",
      "Epoch 21/50\n",
      "112720/112720 [==============================] - 2s - loss: 0.3089 - acc: 0.8616 - label_accuracy: 0.8616 - val_loss: 1.0171 - val_acc: 0.7677 - val_label_accuracy: 0.7677\n",
      "Epoch 22/50\n",
      "112720/112720 [==============================] - 2s - loss: 0.3010 - acc: 0.8629 - label_accuracy: 0.8629 - val_loss: 1.0280 - val_acc: 0.7829 - val_label_accuracy: 0.7829\n",
      "Epoch 23/50\n",
      "112720/112720 [==============================] - 2s - loss: 0.3466 - acc: 0.8270 - label_accuracy: 0.8270 - val_loss: 1.0745 - val_acc: 0.7318 - val_label_accuracy: 0.7318\n",
      "Epoch 24/50\n",
      "112720/112720 [==============================] - 2s - loss: 0.2924 - acc: 0.8599 - label_accuracy: 0.8599 - val_loss: 0.9995 - val_acc: 0.8093 - val_label_accuracy: 0.8093\n",
      "Epoch 25/50\n",
      "112720/112720 [==============================] - 2s - loss: 0.2930 - acc: 0.8611 - label_accuracy: 0.8611 - val_loss: 0.9900 - val_acc: 0.7924 - val_label_accuracy: 0.7924\n",
      "Epoch 26/50\n",
      "112720/112720 [==============================] - 2s - loss: 0.2768 - acc: 0.8639 - label_accuracy: 0.8639 - val_loss: 0.9795 - val_acc: 0.7849 - val_label_accuracy: 0.7849\n",
      "Epoch 27/50\n",
      "112720/112720 [==============================] - 2s - loss: 0.2580 - acc: 0.8764 - label_accuracy: 0.8764 - val_loss: 1.0828 - val_acc: 0.7946 - val_label_accuracy: 0.7946\n",
      "Epoch 28/50\n",
      "112720/112720 [==============================] - 2s - loss: 0.3364 - acc: 0.8422 - label_accuracy: 0.8422 - val_loss: 1.0209 - val_acc: 0.7901 - val_label_accuracy: 0.7901\n",
      "Epoch 29/50\n",
      "112720/112720 [==============================] - 2s - loss: 0.2767 - acc: 0.8656 - label_accuracy: 0.8656 - val_loss: 0.9659 - val_acc: 0.7905 - val_label_accuracy: 0.7905\n",
      "Epoch 30/50\n",
      "112720/112720 [==============================] - 2s - loss: 0.2532 - acc: 0.8660 - label_accuracy: 0.8660 - val_loss: 0.9507 - val_acc: 0.7890 - val_label_accuracy: 0.7890\n",
      "Epoch 31/50\n",
      "112720/112720 [==============================] - 2s - loss: 0.2908 - acc: 0.8522 - label_accuracy: 0.8522 - val_loss: 0.9472 - val_acc: 0.8025 - val_label_accuracy: 0.8025\n",
      "Epoch 32/50\n",
      "112720/112720 [==============================] - 2s - loss: 0.2423 - acc: 0.8856 - label_accuracy: 0.8856 - val_loss: 0.9309 - val_acc: 0.7981 - val_label_accuracy: 0.7981\n",
      "Epoch 33/50\n",
      "112720/112720 [==============================] - 2s - loss: 0.2277 - acc: 0.8905 - label_accuracy: 0.8905 - val_loss: 0.9232 - val_acc: 0.7933 - val_label_accuracy: 0.7933\n",
      "Epoch 34/50\n",
      "112720/112720 [==============================] - 2s - loss: 0.2219 - acc: 0.8965 - label_accuracy: 0.8965 - val_loss: 0.9263 - val_acc: 0.8039 - val_label_accuracy: 0.8039\n",
      "Epoch 35/50\n",
      "112720/112720 [==============================] - 2s - loss: 0.2268 - acc: 0.8895 - label_accuracy: 0.8895 - val_loss: 0.9412 - val_acc: 0.7924 - val_label_accuracy: 0.7924\n",
      "Epoch 36/50\n",
      "112720/112720 [==============================] - 2s - loss: 0.2896 - acc: 0.8478 - label_accuracy: 0.8478 - val_loss: 1.0091 - val_acc: 0.7950 - val_label_accuracy: 0.7950\n",
      "Epoch 37/50\n",
      "112720/112720 [==============================] - 2s - loss: 0.2800 - acc: 0.8584 - label_accuracy: 0.8584 - val_loss: 1.4009 - val_acc: 0.6779 - val_label_accuracy: 0.6779\n",
      "Epoch 38/50\n",
      "112720/112720 [==============================] - 2s - loss: 0.3137 - acc: 0.7222 - label_accuracy: 0.7222 - val_loss: 0.9641 - val_acc: 0.7972 - val_label_accuracy: 0.7972\n",
      "Epoch 39/50\n",
      "112720/112720 [==============================] - 2s - loss: 0.2437 - acc: 0.8857 - label_accuracy: 0.8857 - val_loss: 0.9428 - val_acc: 0.8155 - val_label_accuracy: 0.8155\n",
      "Epoch 40/50\n",
      "112720/112720 [==============================] - 2s - loss: 0.2376 - acc: 0.8872 - label_accuracy: 0.8872 - val_loss: 0.9754 - val_acc: 0.8089 - val_label_accuracy: 0.8089\n",
      "Epoch 41/50\n",
      "112720/112720 [==============================] - 2s - loss: 0.2365 - acc: 0.8813 - label_accuracy: 0.8813 - val_loss: 0.9383 - val_acc: 0.8171 - val_label_accuracy: 0.8171\n",
      "Epoch 42/50\n",
      "112720/112720 [==============================] - 2s - loss: 0.2177 - acc: 0.8914 - label_accuracy: 0.8914 - val_loss: 0.9565 - val_acc: 0.8132 - val_label_accuracy: 0.8132\n",
      "Epoch 43/50\n",
      "112720/112720 [==============================] - 2s - loss: 0.2125 - acc: 0.8926 - label_accuracy: 0.8926 - val_loss: 0.9270 - val_acc: 0.8253 - val_label_accuracy: 0.8253\n",
      "Epoch 44/50\n",
      "112720/112720 [==============================] - 2s - loss: 0.1926 - acc: 0.9017 - label_accuracy: 0.9017 - val_loss: 0.9268 - val_acc: 0.8290 - val_label_accuracy: 0.8290\n",
      "Epoch 45/50\n",
      "112720/112720 [==============================] - 2s - loss: 0.2373 - acc: 0.8807 - label_accuracy: 0.8807 - val_loss: 1.0104 - val_acc: 0.8078 - val_label_accuracy: 0.8078\n",
      "Epoch 46/50\n",
      "112720/112720 [==============================] - 2s - loss: 0.2246 - acc: 0.8817 - label_accuracy: 0.8817 - val_loss: 0.9194 - val_acc: 0.8167 - val_label_accuracy: 0.8167\n",
      "Epoch 47/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "112720/112720 [==============================] - 2s - loss: 0.2104 - acc: 0.8905 - label_accuracy: 0.8905 - val_loss: 0.9553 - val_acc: 0.8129 - val_label_accuracy: 0.8129\n",
      "Epoch 48/50\n",
      "112720/112720 [==============================] - 2s - loss: 0.2330 - acc: 0.8943 - label_accuracy: 0.8943 - val_loss: 0.9992 - val_acc: 0.7960 - val_label_accuracy: 0.7960\n",
      "Epoch 49/50\n",
      "112720/112720 [==============================] - 2s - loss: 0.2216 - acc: 0.8942 - label_accuracy: 0.8942 - val_loss: 0.9202 - val_acc: 0.8104 - val_label_accuracy: 0.8104\n",
      "Epoch 50/50\n",
      "112720/112720 [==============================] - 2s - loss: 0.2157 - acc: 0.8992 - label_accuracy: 0.8992 - val_loss: 0.9379 - val_acc: 0.8163 - val_label_accuracy: 0.8163\n",
      "18317/22544 [=======================>......] - ETA: 0s\n",
      " Train Acc: 0.9054293930530548, Test Acc: 0.816270399838686, Label Acc: 0.7818488289567069\n"
     ]
    }
   ],
   "source": [
    "import itertools\n",
    "#features_arr = [4, 16, 32, 256, 1024]\n",
    "#hidden_layers_arr = [2, 6, 10, 100]\n",
    "\n",
    "features_arr = [4, 16, 32, 122]\n",
    "hidden_layers_arr = [2, 6, 10]\n",
    "\n",
    "epoch_arr = [50]\n",
    "\n",
    "def label_accuracy(y_true, y_pred):\n",
    "    return K.mean(K.equal(K.argmax(y_true, axis = 1), K.argmax(y_pred, axis = 1)))\n",
    "\n",
    "score = namedtuple(\"score\", ['epoch', 'no_of_features','hidden_layers','train_score', 'test_score'])\n",
    "scores = []\n",
    "predictions = pd.DataFrame()\n",
    "\n",
    "for e, h, f in itertools.product(epoch_arr, hidden_layers_arr, features_arr):\n",
    "    \n",
    "    print(\" \\n Current Layer Attributes - epochs:{} hidden layers:{} features count:{}\".format(e,h,f))\n",
    "    latent_dim = f\n",
    "    epochs = e\n",
    "    hidden_layers = h\n",
    "\n",
    "    Train.train()\n",
    "\n",
    "    vae_model = Model(inputs = Train.x, outputs = Train.x_ )\n",
    "    vae_model.compile(optimizer = \"adam\", loss = \"mean_squared_error\", metrics = ['accuracy', label_accuracy] )\n",
    "    #vae_model.compile(optimizer = \"adam\", loss = Lambda(get_loss)([Train.x, Train.x_]), metrics = ['accuracy', label_accuracy] )\n",
    "\n",
    "    train_size = x_train.shape[0] - x_train.shape[0]%batch_size\n",
    "    valid_size = x_valid.shape[0] - x_valid.shape[0]%batch_size\n",
    "\n",
    "    vae_model.fit(x = x_train[:train_size,:], y = x_train[:train_size,:], \n",
    "                  shuffle=True, epochs=epochs, \n",
    "                  batch_size = batch_size, \n",
    "                  #validation_data = (x_valid[:valid_size,:], x_valid[:valid_size,:]),\n",
    "                  validation_data = (x_test, x_test),\n",
    "                  verbose = 1)\n",
    "    \n",
    "    score_train = vae_model.evaluate(x_valid[:valid_size,:], y = x_valid[:valid_size,:],\n",
    "                               batch_size = batch_size,\n",
    "                               verbose = 1)\n",
    "    \n",
    "    score_test = vae_model.evaluate(x_test, y = x_test,\n",
    "                           batch_size = batch_size,\n",
    "                           verbose = 1)\n",
    "    y_test_pred = vae_model.predict(x_test, batch_size=batch_size)\n",
    "    \n",
    "    y_pred = np.argmax(y_test_pred[:,-2:], axis = 1)\n",
    "    y_test_1d = np.argmax(y_test.values, axis = 1)\n",
    "    \n",
    "    #y_pred[y_pred >= y_test_pred[:,-1].mean()] = 1\n",
    "    #y_pred[y_pred < y_test_pred[:,-1].mean()] = 0\n",
    "    \n",
    "    label_acc = np.mean(np.equal(y_test_1d, y_pred))\n",
    "    \n",
    "    scores.append(score(e,f,h,score_train[-1], label_acc)) #score_test[-1]))\n",
    "    \n",
    "    curr_pred = pd.DataFrame({\"{}_{}_{}\".format(e,f,h):y_pred},)\n",
    "    predictions = pd.concat([predictions, curr_pred], axis = 1)\n",
    "    \n",
    "    print(\"\\n Train Acc: {}, Test Acc: {}, Label Acc: {}\".format(score_train[-1], \n",
    "                                                                 score_test[-1], \n",
    "                                                                 label_acc)  )\n",
    "    \n",
    "scores = pd.DataFrame(scores)\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>epoch</th>\n",
       "      <th>no_of_features</th>\n",
       "      <th>hidden_layers</th>\n",
       "      <th>train_score</th>\n",
       "      <th>test_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>50</td>\n",
       "      <td>32</td>\n",
       "      <td>10</td>\n",
       "      <td>0.878726</td>\n",
       "      <td>0.822214</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>50</td>\n",
       "      <td>122</td>\n",
       "      <td>6</td>\n",
       "      <td>0.736515</td>\n",
       "      <td>0.821283</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>50</td>\n",
       "      <td>16</td>\n",
       "      <td>2</td>\n",
       "      <td>0.765703</td>\n",
       "      <td>0.812944</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>50</td>\n",
       "      <td>16</td>\n",
       "      <td>10</td>\n",
       "      <td>0.882630</td>\n",
       "      <td>0.802253</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>50</td>\n",
       "      <td>4</td>\n",
       "      <td>6</td>\n",
       "      <td>0.902147</td>\n",
       "      <td>0.792362</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>50</td>\n",
       "      <td>122</td>\n",
       "      <td>10</td>\n",
       "      <td>0.905429</td>\n",
       "      <td>0.781849</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>50</td>\n",
       "      <td>16</td>\n",
       "      <td>6</td>\n",
       "      <td>0.936125</td>\n",
       "      <td>0.781317</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>50</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>0.844571</td>\n",
       "      <td>0.775417</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>50</td>\n",
       "      <td>4</td>\n",
       "      <td>10</td>\n",
       "      <td>0.870653</td>\n",
       "      <td>0.755456</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>50</td>\n",
       "      <td>32</td>\n",
       "      <td>6</td>\n",
       "      <td>0.891945</td>\n",
       "      <td>0.753504</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>50</td>\n",
       "      <td>32</td>\n",
       "      <td>2</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.430758</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>50</td>\n",
       "      <td>122</td>\n",
       "      <td>2</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.430758</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    epoch  no_of_features  hidden_layers  train_score  test_score\n",
       "10     50              32             10     0.878726    0.822214\n",
       "7      50             122              6     0.736515    0.821283\n",
       "1      50              16              2     0.765703    0.812944\n",
       "9      50              16             10     0.882630    0.802253\n",
       "4      50               4              6     0.902147    0.792362\n",
       "11     50             122             10     0.905429    0.781849\n",
       "5      50              16              6     0.936125    0.781317\n",
       "0      50               4              2     0.844571    0.775417\n",
       "8      50               4             10     0.870653    0.755456\n",
       "6      50              32              6     0.891945    0.753504\n",
       "2      50              32              2     0.000000    0.430758\n",
       "3      50             122              2     0.000000    0.430758"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scores.sort_values(\"test_score\", ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "predictions.to_pickle(\"dataset/vae_only_predictions.pkl\")\n",
    "scores.to_pickle(\"dataset/vae_only_scores.pkl\")"
   ]
  }
 ],
 "metadata": {
  "_draft": {
   "nbviewer_url": "https://gist.github.com/33dcb1bcf3ca4a3461c4405a003a7591"
  },
  "anaconda-cloud": {},
  "gist": {
   "data": {
    "description": "Final Hyper parameter tuning",
    "public": false
   },
   "id": "33dcb1bcf3ca4a3461c4405a003a7591"
  },
  "kernelspec": {
   "display_name": "Python [conda env:p3]",
   "language": "python",
   "name": "conda-env-p3-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
