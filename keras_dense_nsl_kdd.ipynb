{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "pd.set_option(\"display.max_rows\",40)\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class dataset:\n",
    "    kdd_train_2labels = pd.read_pickle(\"dataset/kdd_train_2labels.pkl\")\n",
    "    kdd_train_2labels_y = pd.read_pickle(\"dataset/kdd_train_2labels_y.pkl\")\n",
    "    \n",
    "    kdd_test_2labels = pd.read_pickle(\"dataset/kdd_test_2labels.pkl\")\n",
    "    kdd_test_2labels_y = pd.read_pickle(\"dataset/kdd_test_2labels_y.pkl\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "le_2labels = LabelEncoder()\n",
    "dataset.y_train_2labels = le_2labels.fit_transform(dataset.kdd_train_2labels_y)\n",
    "dataset.y_test_2labels = le_2labels.transform(dataset.kdd_test_2labels_y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from itertools import product\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "class preprocessing:\n",
    "    x_train = dataset.kdd_train_2labels.iloc[:,:-2].values\n",
    "    y_train = np.array(dataset.y_train_2labels)\n",
    "\n",
    "    x_test, y_test = (dataset.kdd_test_2labels.iloc[:,:-2].values, \n",
    "                      np.array(dataset.y_test_2labels))\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from collections import namedtuple\n",
    "import numpy as np\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "from keras import optimizers\n",
    "from keras import regularizers\n",
    "\n",
    "class Train:\n",
    "    score = namedtuple(\"score\", ['epoch', 'no_of_features','hidden_layers','train_score', 'test_score'])\n",
    "    #model_detail = namedtuple(\"model_detail\", ['epoch', 'no_of_features','hidden_layers', 'model'])\n",
    "    scores = []\n",
    "    predictions = pd.DataFrame()\n",
    "    #models = []\n",
    "    def execute(x_train, x_test, \n",
    "                y_train, y_test, \n",
    "                input_dim, no_of_features, hidden_layers,\n",
    "                epochs = 5, keep_prob = 1):\n",
    "        \n",
    "        print(\"Training for no_of_features: {}, hidden_layer: {}\".format(no_of_features, hidden_layers\n",
    "                                                                        ))\n",
    "        model = Sequential()\n",
    "        model.add(Dense(no_of_features, input_dim=input_dim, activation='relu'))\n",
    "        model.add(Dropout(keep_prob))\n",
    "        #model.add(BatchNormalization())\n",
    "        \n",
    "        for i in range(hidden_layers - 1):\n",
    "            model.add(Dense(no_of_features, activation='relu'))\n",
    "            model.add(Dropout(keep_prob))\n",
    "            #model.add(BatchNormalization())\n",
    "\n",
    "        \n",
    "        model.add(Dense(1, activation=None))\n",
    "\n",
    "        model.compile(loss='mean_squared_error',\n",
    "                      optimizer=\"Adam\",\n",
    "                      metrics=['accuracy'])\n",
    "\n",
    "        x_train, x_valid, y_train, y_valid = train_test_split(x_train, y_train, test_size=.6)\n",
    "        \n",
    "        model.fit(x_train, y_train,\n",
    "                  validation_data=(x_test, y_test),\n",
    "                  epochs=epochs,\n",
    "                  batch_size=128,\n",
    "                  verbose = 1)\n",
    "        \n",
    "        curr_score_valid = model.evaluate(x_valid, y_valid) #, batch_size=128)\n",
    "        curr_score_test = model.evaluate(x_test, y_test) #, batch_size=128)\n",
    "        pred_value = model.predict(x_test)\n",
    "        \n",
    "        print(\"\\n Train Accuracy: {}, Test Accuracy: {}\".format(curr_score_valid[1], curr_score_test[1])  )\n",
    "        Train.scores.append(Train.score(epochs,no_of_features,hidden_layers,curr_score_valid[1], curr_score_test[1]))\n",
    "        #Train.models.append(Train.model_detail(epochs,no_of_features,hidden_layers,model))\n",
    "        y_pred = pred_value[:,-1]\n",
    "        y_pred[y_pred >= pred_value[:,-1].mean()] = 1\n",
    "        y_pred[y_pred < pred_value[:,-1].mean()] = 0\n",
    "        curr_pred = pd.DataFrame({\"{}_{}_{}\".format(epochs,f,h):y_pred},)\n",
    "        Train.predictions = pd.concat([Train.predictions, curr_pred], axis = 1)\n",
    "                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training for no_of_features: 2, hidden_layer: 2\n",
      "Train on 50389 samples, validate on 22544 samples\n",
      "Epoch 1/5\n",
      "50389/50389 [==============================] - 0s - loss: 0.3851 - acc: 0.4694 - val_loss: 0.2573 - val_acc: 0.5692\n",
      "Epoch 2/5\n",
      "50389/50389 [==============================] - 0s - loss: 0.2653 - acc: 0.4694 - val_loss: 0.2474 - val_acc: 0.5692\n",
      "Epoch 3/5\n",
      "50389/50389 [==============================] - 0s - loss: 0.2499 - acc: 0.5110 - val_loss: 0.2535 - val_acc: 0.4308\n",
      "Epoch 4/5\n",
      "50389/50389 [==============================] - 0s - loss: 0.2491 - acc: 0.5306 - val_loss: 0.2549 - val_acc: 0.4308\n",
      "Epoch 5/5\n",
      "50389/50389 [==============================] - 0s - loss: 0.2491 - acc: 0.5306 - val_loss: 0.2545 - val_acc: 0.4308\n",
      "20512/22544 [==========================>...] - ETA: 0s\n",
      " Train Accuracy: 0.5372565622353938, Test Accuracy: 0.43075762952448543\n",
      "Training for no_of_features: 2, hidden_layer: 6\n",
      "Train on 50389 samples, validate on 22544 samples\n",
      "Epoch 1/5\n",
      "50389/50389 [==============================] - 1s - loss: 0.6057 - acc: 0.6337 - val_loss: 0.1665 - val_acc: 0.8251\n",
      "Epoch 2/5\n",
      "50389/50389 [==============================] - 0s - loss: 0.1632 - acc: 0.8112 - val_loss: 0.1664 - val_acc: 0.7799\n",
      "Epoch 3/5\n",
      "50389/50389 [==============================] - 0s - loss: 0.1434 - acc: 0.8375 - val_loss: 0.1649 - val_acc: 0.7742\n",
      "Epoch 4/5\n",
      "50389/50389 [==============================] - 0s - loss: 0.1284 - acc: 0.8428 - val_loss: 0.1670 - val_acc: 0.7748\n",
      "Epoch 5/5\n",
      "50389/50389 [==============================] - 0s - loss: 0.1221 - acc: 0.8457 - val_loss: 0.1697 - val_acc: 0.7746\n",
      "20800/22544 [==========================>...] - ETA: 0s\n",
      " Train Accuracy: 0.8461711473327689, Test Accuracy: 0.7745741660752307\n",
      "Training for no_of_features: 2, hidden_layer: 10\n",
      "Train on 50389 samples, validate on 22544 samples\n",
      "Epoch 1/5\n",
      "50389/50389 [==============================] - 1s - loss: 0.3871 - acc: 0.4664 - val_loss: 0.2573 - val_acc: 0.5692\n",
      "Epoch 2/5\n",
      "50389/50389 [==============================] - 0s - loss: 0.2656 - acc: 0.4664 - val_loss: 0.2476 - val_acc: 0.5692\n",
      "Epoch 3/5\n",
      "50389/50389 [==============================] - 0s - loss: 0.2497 - acc: 0.5160 - val_loss: 0.2543 - val_acc: 0.4308\n",
      "Epoch 4/5\n",
      "50389/50389 [==============================] - 0s - loss: 0.2489 - acc: 0.5336 - val_loss: 0.2551 - val_acc: 0.4308\n",
      "Epoch 5/5\n",
      "50389/50389 [==============================] - 0s - loss: 0.2489 - acc: 0.5336 - val_loss: 0.2556 - val_acc: 0.4308\n",
      "20672/22544 [==========================>...] - ETA: 0s\n",
      " Train Accuracy: 0.5352587849280271, Test Accuracy: 0.43075762952448543\n",
      "Training for no_of_features: 4, hidden_layer: 2\n",
      "Train on 50389 samples, validate on 22544 samples\n",
      "Epoch 1/5\n",
      "50389/50389 [==============================] - 0s - loss: 109236209253.0577 - acc: 0.0179 - val_loss: 9780192.9211 - val_acc: 0.0089\n",
      "Epoch 2/5\n",
      "50389/50389 [==============================] - 0s - loss: 20078190790.1793 - acc: 0.0203 - val_loss: 3464099.3109 - val_acc: 0.0165\n",
      "Epoch 3/5\n",
      "50389/50389 [==============================] - 0s - loss: 222368334.4390 - acc: 0.0188 - val_loss: 1537222.5867 - val_acc: 0.0145\n",
      "Epoch 4/5\n",
      "50389/50389 [==============================] - 0s - loss: 65430775.9323 - acc: 0.0241 - val_loss: 281228.8375 - val_acc: 0.0208\n",
      "Epoch 5/5\n",
      "50389/50389 [==============================] - 0s - loss: 104780356.9934 - acc: 0.0278 - val_loss: 4747790.9112 - val_acc: 0.0232\n",
      "22240/22544 [============================>.] - ETA: 0s\n",
      " Train Accuracy: 0.030522332768839967, Test Accuracy: 0.023243435060326473\n",
      "Training for no_of_features: 4, hidden_layer: 6\n",
      "Train on 50389 samples, validate on 22544 samples\n",
      "Epoch 1/5\n",
      "50389/50389 [==============================] - 1s - loss: 5.5081 - acc: 0.4787 - val_loss: 0.1908 - val_acc: 0.7224\n",
      "Epoch 2/5\n",
      "50389/50389 [==============================] - 0s - loss: 0.0983 - acc: 0.9106 - val_loss: 0.2135 - val_acc: 0.7410\n",
      "Epoch 3/5\n",
      "50389/50389 [==============================] - 0s - loss: 0.0544 - acc: 0.9411 - val_loss: 0.2395 - val_acc: 0.7159\n",
      "Epoch 4/5\n",
      "50389/50389 [==============================] - 0s - loss: 0.0500 - acc: 0.9453 - val_loss: 0.2426 - val_acc: 0.7174\n",
      "Epoch 5/5\n",
      "50389/50389 [==============================] - 0s - loss: 0.0463 - acc: 0.9495 - val_loss: 0.2490 - val_acc: 0.7122\n",
      "20704/22544 [==========================>...] - ETA: 0s\n",
      " Train Accuracy: 0.9486928450465707, Test Accuracy: 0.7122072391767211\n",
      "Training for no_of_features: 4, hidden_layer: 10\n",
      "Train on 50389 samples, validate on 22544 samples\n",
      "Epoch 1/5\n",
      "50389/50389 [==============================] - 1s - loss: 96.5461 - acc: 0.4652 - val_loss: 0.3319 - val_acc: 0.5692\n",
      "Epoch 2/5\n",
      "50389/50389 [==============================] - 0s - loss: 0.3490 - acc: 0.4646 - val_loss: 0.2612 - val_acc: 0.5692\n",
      "Epoch 3/5\n",
      "50389/50389 [==============================] - 0s - loss: 0.2774 - acc: 0.4646 - val_loss: 0.2452 - val_acc: 0.5692\n",
      "Epoch 4/5\n",
      "50389/50389 [==============================] - 0s - loss: 0.2541 - acc: 0.4646 - val_loss: 0.2493 - val_acc: 0.5692\n",
      "Epoch 5/5\n",
      "50389/50389 [==============================] - 0s - loss: 0.2494 - acc: 0.5269 - val_loss: 0.2539 - val_acc: 0.4308\n",
      "20640/22544 [==========================>...] - ETA: 0s\n",
      " Train Accuracy: 0.5340415961049958, Test Accuracy: 0.43075762952448543\n",
      "Training for no_of_features: 8, hidden_layer: 2\n",
      "Train on 50389 samples, validate on 22544 samples\n",
      "Epoch 1/5\n",
      "50389/50389 [==============================] - 0s - loss: 1779567074.7647 - acc: 0.0677 - val_loss: 1279895.1435 - val_acc: 0.0660\n",
      "Epoch 2/5\n",
      "50389/50389 [==============================] - 0s - loss: 9603886388.9581 - acc: 0.0274 - val_loss: 11160045.7609 - val_acc: 0.0721\n",
      "Epoch 3/5\n",
      "50389/50389 [==============================] - 0s - loss: 52294702349.9706 - acc: 0.0294 - val_loss: 9846962.9607 - val_acc: 0.0035\n",
      "Epoch 4/5\n",
      "50389/50389 [==============================] - 0s - loss: 19521490324.9738 - acc: 0.0637 - val_loss: 44954078.5201 - val_acc: 0.1124\n",
      "Epoch 5/5\n",
      "50389/50389 [==============================] - 0s - loss: 14214565887.1409 - acc: 0.0388 - val_loss: 1442256.4333 - val_acc: 0.0094\n",
      "22048/22544 [============================>.] - ETA: 0s\n",
      " Train Accuracy: 0.017636007620660456, Test Accuracy: 0.009359474804826119\n",
      "Training for no_of_features: 8, hidden_layer: 6\n",
      "Train on 50389 samples, validate on 22544 samples\n",
      "Epoch 1/5\n",
      "50389/50389 [==============================] - 1s - loss: 103999.8811 - acc: 0.4357 - val_loss: 0.4006 - val_acc: 0.5692\n",
      "Epoch 2/5\n",
      "50389/50389 [==============================] - 0s - loss: 0.4934 - acc: 0.4640 - val_loss: 0.3935 - val_acc: 0.5692\n",
      "Epoch 3/5\n",
      "50389/50389 [==============================] - 0s - loss: 0.4744 - acc: 0.4649 - val_loss: 0.3933 - val_acc: 0.5396\n",
      "Epoch 4/5\n",
      "50389/50389 [==============================] - 0s - loss: 0.3610 - acc: 0.5659 - val_loss: 0.5504 - val_acc: 0.6403\n",
      "Epoch 5/5\n",
      "50389/50389 [==============================] - 0s - loss: 0.3685 - acc: 0.6188 - val_loss: 0.4196 - val_acc: 0.5517\n",
      "20768/22544 [==========================>...] - ETA: 0s\n",
      " Train Accuracy: 0.5570094199830652, Test Accuracy: 0.5517210787792761\n",
      "Training for no_of_features: 8, hidden_layer: 10\n",
      "Train on 50389 samples, validate on 22544 samples\n",
      "Epoch 1/5\n",
      "50389/50389 [==============================] - 1s - loss: 1397.5698 - acc: 0.6921 - val_loss: 0.3771 - val_acc: 0.6492\n",
      "Epoch 2/5\n",
      "50389/50389 [==============================] - 0s - loss: 482.7686 - acc: 0.9093 - val_loss: 0.2272 - val_acc: 0.7572\n",
      "Epoch 3/5\n",
      "50389/50389 [==============================] - 0s - loss: 0.2475 - acc: 0.9553 - val_loss: 0.2427 - val_acc: 0.7511\n",
      "Epoch 4/5\n",
      "50389/50389 [==============================] - 0s - loss: 128.5665 - acc: 0.9617 - val_loss: 0.2259 - val_acc: 0.7645\n",
      "Epoch 5/5\n",
      "50389/50389 [==============================] - 0s - loss: 48.4969 - acc: 0.9680 - val_loss: 0.2125 - val_acc: 0.7703\n",
      "21792/22544 [===========================>..] - ETA: 0s\n",
      " Train Accuracy: 0.9695835097375106, Test Accuracy: 0.7702714691270405\n",
      "Training for no_of_features: 16, hidden_layer: 2\n",
      "Train on 50389 samples, validate on 22544 samples\n",
      "Epoch 1/5\n",
      "50389/50389 [==============================] - 1s - loss: 7641302590.7336 - acc: 0.0281 - val_loss: 114084402.0460 - val_acc: 0.0202\n",
      "Epoch 2/5\n",
      "50389/50389 [==============================] - 0s - loss: 151708090812.3934 - acc: 0.0248 - val_loss: 170681.4890 - val_acc: 0.0768\n",
      "Epoch 3/5\n",
      "50389/50389 [==============================] - 0s - loss: 18749650899.8660 - acc: 0.0323 - val_loss: 270527171.0787 - val_acc: 0.0028\n",
      "Epoch 4/5\n",
      "50389/50389 [==============================] - 0s - loss: 85532551773.3839 - acc: 0.0169 - val_loss: 1665783428.7920 - val_acc: 8.8715e-05\n",
      "Epoch 5/5\n",
      "50389/50389 [==============================] - 0s - loss: 532651435721.0248 - acc: 0.0169 - val_loss: 674190919.7664 - val_acc: 6.2101e-04\n",
      "21920/22544 [============================>.] - ETA: 0s\n",
      " Train Accuracy: 0.0009128916172734971, Test Accuracy: 0.0006210078069552874\n",
      "Training for no_of_features: 16, hidden_layer: 6\n",
      "Train on 50389 samples, validate on 22544 samples\n",
      "Epoch 1/5\n",
      "50389/50389 [==============================] - 1s - loss: 5168446157.0460 - acc: 0.3390 - val_loss: 8256.0559 - val_acc: 0.4207\n",
      "Epoch 2/5\n",
      "50389/50389 [==============================] - 0s - loss: 1571833281.0345 - acc: 0.2740 - val_loss: 12247652.2164 - val_acc: 0.0762\n",
      "Epoch 3/5\n",
      "50389/50389 [==============================] - 0s - loss: 3453150358.3369 - acc: 0.2384 - val_loss: 85663914.1742 - val_acc: 0.0115\n",
      "Epoch 4/5\n",
      "50389/50389 [==============================] - 0s - loss: 2070730739.3516 - acc: 0.3477 - val_loss: 795162.7842 - val_acc: 0.5220\n",
      "Epoch 5/5\n",
      "50389/50389 [==============================] - 0s - loss: 47499278.9866 - acc: 0.4553 - val_loss: 3221702.8423 - val_acc: 0.4019\n",
      "21440/22544 [===========================>..] - ETA: 0s\n",
      " Train Accuracy: 0.43015717612193055, Test Accuracy: 0.4018807665010646\n",
      "Training for no_of_features: 16, hidden_layer: 10\n",
      "Train on 50389 samples, validate on 22544 samples\n",
      "Epoch 1/5\n",
      "50389/50389 [==============================] - 1s - loss: 381803.8452 - acc: 0.5225 - val_loss: 0.3142 - val_acc: 0.5379\n",
      "Epoch 2/5\n",
      "50389/50389 [==============================] - 0s - loss: 1000.6729 - acc: 0.7379 - val_loss: 4.6165 - val_acc: 0.7046\n",
      "Epoch 3/5\n",
      "50389/50389 [==============================] - 0s - loss: 2642.7059 - acc: 0.7674 - val_loss: 332.2388 - val_acc: 0.5850\n",
      "Epoch 4/5\n",
      "50389/50389 [==============================] - 0s - loss: 4573733.4392 - acc: 0.7822 - val_loss: 2507.1979 - val_acc: 0.6713\n",
      "Epoch 5/5\n",
      "50389/50389 [==============================] - 0s - loss: 17831.5552 - acc: 0.8544 - val_loss: 378.6064 - val_acc: 0.6065\n",
      "22400/22544 [============================>.] - ETA: 0s\n",
      " Train Accuracy: 0.8044956604572396, Test Accuracy: 0.6065471965933286\n",
      "Training for no_of_features: 32, hidden_layer: 2\n",
      "Train on 50389 samples, validate on 22544 samples\n",
      "Epoch 1/5\n",
      "50389/50389 [==============================] - 1s - loss: 50134493031.6800 - acc: 0.1209 - val_loss: 11537.9566 - val_acc: 0.0802\n",
      "Epoch 2/5\n",
      "50389/50389 [==============================] - 0s - loss: 8702106506.5101 - acc: 0.1345 - val_loss: 364608.6801 - val_acc: 0.0540\n",
      "Epoch 3/5\n",
      "50389/50389 [==============================] - 0s - loss: 34396454772.0510 - acc: 0.0369 - val_loss: 11643711.0154 - val_acc: 0.0019\n",
      "Epoch 4/5\n",
      "50389/50389 [==============================] - 0s - loss: 191945858261.7367 - acc: 0.0227 - val_loss: 728854404.0927 - val_acc: 0.0311\n",
      "Epoch 5/5\n",
      "50389/50389 [==============================] - 0s - loss: 259731719290.1291 - acc: 0.0217 - val_loss: 5398660030.2204 - val_acc: 0.0012\n",
      "22432/22544 [============================>.] - ETA: 0s\n",
      " Train Accuracy: 0.0020771591871295513, Test Accuracy: 0.001242015613910575\n",
      "Training for no_of_features: 32, hidden_layer: 6\n",
      "Train on 50389 samples, validate on 22544 samples\n",
      "Epoch 1/5\n",
      "50389/50389 [==============================] - 1s - loss: 38172233.0332 - acc: 0.4713 - val_loss: 17658.7034 - val_acc: 0.5291\n",
      "Epoch 2/5\n",
      "50389/50389 [==============================] - 0s - loss: 5056286325.8513 - acc: 0.4688 - val_loss: 599009.4284 - val_acc: 0.4367\n",
      "Epoch 3/5\n",
      "50389/50389 [==============================] - 0s - loss: 1565042883.9215 - acc: 0.2603 - val_loss: 239890006.2928 - val_acc: 0.0771\n",
      "Epoch 4/5\n",
      "50389/50389 [==============================] - 0s - loss: 5987094842.6505 - acc: 0.1765 - val_loss: 6851286.5142 - val_acc: 0.0225\n",
      "Epoch 5/5\n",
      "50389/50389 [==============================] - 0s - loss: 58044621.2688 - acc: 0.1333 - val_loss: 33506585.5978 - val_acc: 0.0516\n",
      "20832/22544 [==========================>...] - ETA: 0s\n",
      " Train Accuracy: 0.04442739204064352, Test Accuracy: 0.05158800567778566\n",
      "Training for no_of_features: 32, hidden_layer: 10\n",
      "Train on 50389 samples, validate on 22544 samples\n",
      "Epoch 1/5\n",
      "50389/50389 [==============================] - 1s - loss: 460162063.1649 - acc: 0.4969 - val_loss: 33.2694 - val_acc: 0.5858\n",
      "Epoch 2/5\n",
      "50389/50389 [==============================] - 1s - loss: 6657125.7498 - acc: 0.6234 - val_loss: 32183.2972 - val_acc: 0.5360\n",
      "Epoch 3/5\n",
      "50389/50389 [==============================] - 1s - loss: 3848231.1441 - acc: 0.6860 - val_loss: 82.9144 - val_acc: 0.5839\n",
      "Epoch 4/5\n",
      "50389/50389 [==============================] - 1s - loss: 7166092.4267 - acc: 0.7034 - val_loss: 8357.6023 - val_acc: 0.6325\n",
      "Epoch 5/5\n",
      "50389/50389 [==============================] - 1s - loss: 32474549.7150 - acc: 0.6993 - val_loss: 19634.2435 - val_acc: 0.0850\n",
      "22272/22544 [============================>.] - ETA: 0s\n",
      " Train Accuracy: 0.08529582980524979, Test Accuracy: 0.08498935415188076\n"
     ]
    }
   ],
   "source": [
    "#features_arr = [4, 8, 16, 32, 64, 128, 256, 1024]\n",
    "#hidden_layers_arr = [2, 4, 6, 50, 100]\n",
    "\n",
    "features_arr = [2, 4, 8, 16, 32]\n",
    "hidden_layers_arr = [2, 6, 10]\n",
    "\n",
    "\n",
    "for f, h in product(features_arr, hidden_layers_arr):\n",
    "    Train.execute(preprocessing.x_train, preprocessing.x_test, \n",
    "                  preprocessing.y_train, preprocessing.y_test, \n",
    "                 122, f, h)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>epoch</th>\n",
       "      <th>no_of_features</th>\n",
       "      <th>hidden_layers</th>\n",
       "      <th>train_score</th>\n",
       "      <th>test_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0.537257</td>\n",
       "      <td>0.430758</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "      <td>0.846171</td>\n",
       "      <td>0.774574</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "      <td>0.535259</td>\n",
       "      <td>0.430758</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>0.030522</td>\n",
       "      <td>0.023243</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>6</td>\n",
       "      <td>0.948693</td>\n",
       "      <td>0.712207</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>10</td>\n",
       "      <td>0.534042</td>\n",
       "      <td>0.430758</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>5</td>\n",
       "      <td>8</td>\n",
       "      <td>2</td>\n",
       "      <td>0.017636</td>\n",
       "      <td>0.009359</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>5</td>\n",
       "      <td>8</td>\n",
       "      <td>6</td>\n",
       "      <td>0.557009</td>\n",
       "      <td>0.551721</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>5</td>\n",
       "      <td>8</td>\n",
       "      <td>10</td>\n",
       "      <td>0.969584</td>\n",
       "      <td>0.770271</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>5</td>\n",
       "      <td>16</td>\n",
       "      <td>2</td>\n",
       "      <td>0.000913</td>\n",
       "      <td>0.000621</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>5</td>\n",
       "      <td>16</td>\n",
       "      <td>6</td>\n",
       "      <td>0.430157</td>\n",
       "      <td>0.401881</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>5</td>\n",
       "      <td>16</td>\n",
       "      <td>10</td>\n",
       "      <td>0.804496</td>\n",
       "      <td>0.606547</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>5</td>\n",
       "      <td>32</td>\n",
       "      <td>2</td>\n",
       "      <td>0.002077</td>\n",
       "      <td>0.001242</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>5</td>\n",
       "      <td>32</td>\n",
       "      <td>6</td>\n",
       "      <td>0.044427</td>\n",
       "      <td>0.051588</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>5</td>\n",
       "      <td>32</td>\n",
       "      <td>10</td>\n",
       "      <td>0.085296</td>\n",
       "      <td>0.084989</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    epoch  no_of_features  hidden_layers  train_score  test_score\n",
       "0       5               2              2     0.537257    0.430758\n",
       "1       5               2              6     0.846171    0.774574\n",
       "2       5               2             10     0.535259    0.430758\n",
       "3       5               4              2     0.030522    0.023243\n",
       "4       5               4              6     0.948693    0.712207\n",
       "5       5               4             10     0.534042    0.430758\n",
       "6       5               8              2     0.017636    0.009359\n",
       "7       5               8              6     0.557009    0.551721\n",
       "8       5               8             10     0.969584    0.770271\n",
       "9       5              16              2     0.000913    0.000621\n",
       "10      5              16              6     0.430157    0.401881\n",
       "11      5              16             10     0.804496    0.606547\n",
       "12      5              32              2     0.002077    0.001242\n",
       "13      5              32              6     0.044427    0.051588\n",
       "14      5              32             10     0.085296    0.084989"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(Train.scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#for m in Train.models:\n",
    "#    m.model.save(\"dataset/keras_model_epoch_{}_no_of_features_{}_hidden_layers_{}\".format(m.epoch,\n",
    "#                                                                                         m.no_of_features,\n",
    "#                                                                                         m.hidden_layers))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Train.predictions.to_pickle(\"dataset/keras_dense_nsl_kdd.pkl\")\n",
    "pd.DataFrame(Train.scores).to_pickle(\"dataset/keras_dense_nsl_kdd.pkl\")"
   ]
  }
 ],
 "metadata": {
  "_draft": {
   "nbviewer_url": "https://gist.github.com/0f6c9677d5f316c57d9d8bd6e0fe8850"
  },
  "anaconda-cloud": {},
  "gist": {
   "data": {
    "description": "Final Hyper parameter tuning",
    "public": false
   },
   "id": "0f6c9677d5f316c57d9d8bd6e0fe8850"
  },
  "kernelspec": {
   "display_name": "Python [conda env:p3]",
   "language": "python",
   "name": "conda-env-p3-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
