{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "pd.set_option(\"display.max_rows\",40)\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class dataset:\n",
    "    kdd_train_2labels = pd.read_pickle(\"dataset/kdd_train_2labels.pkl\")\n",
    "    kdd_train_2labels_y = pd.read_pickle(\"dataset/kdd_train_2labels_y.pkl\")\n",
    "    \n",
    "    kdd_test_2labels = pd.read_pickle(\"dataset/kdd_test_2labels.pkl\")\n",
    "    kdd_test_2labels_y = pd.read_pickle(\"dataset/kdd_test_2labels_y.pkl\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "le_2labels = LabelEncoder()\n",
    "dataset.y_train_2labels = le_2labels.fit_transform(dataset.kdd_train_2labels_y)\n",
    "dataset.y_test_2labels = le_2labels.transform(dataset.kdd_test_2labels_y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from itertools import product\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "class preprocessing:\n",
    "    x_train = dataset.kdd_train_2labels.iloc[:,:-2].values\n",
    "    y_train = np.array(dataset.y_train_2labels)\n",
    "\n",
    "    x_test, y_test = (dataset.kdd_test_2labels.iloc[:,:-2].values, \n",
    "                      np.array(dataset.y_test_2labels))\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from collections import namedtuple\n",
    "import numpy as np\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "from keras import optimizers\n",
    "from keras import regularizers\n",
    "\n",
    "class Train:\n",
    "    score = namedtuple(\"score\", ['epoch', 'no_of_features','hidden_layers','train_score', 'test_score'])\n",
    "    #model_detail = namedtuple(\"model_detail\", ['epoch', 'no_of_features','hidden_layers', 'model'])\n",
    "    scores = []\n",
    "    predictions = pd.DataFrame()\n",
    "    #models = []\n",
    "    def execute(x_train, x_test, \n",
    "                y_train, y_test, \n",
    "                input_dim, no_of_features, hidden_layers,\n",
    "                epochs = 5, keep_prob = 1):\n",
    "        \n",
    "        print(\"Training for no_of_features: {}, hidden_layer: {}\".format(no_of_features, hidden_layers\n",
    "                                                                        ))\n",
    "        model = Sequential()\n",
    "        model.add(Dense(no_of_features, input_dim=input_dim, activation='relu'))\n",
    "        model.add(Dropout(keep_prob))\n",
    "        #model.add(BatchNormalization())\n",
    "        \n",
    "        for i in range(hidden_layers - 1):\n",
    "            model.add(Dense(no_of_features, activation='relu'))\n",
    "            model.add(Dropout(keep_prob))\n",
    "            #model.add(BatchNormalization())\n",
    "\n",
    "        \n",
    "        model.add(Dense(1, activation=None))\n",
    "\n",
    "        model.compile(loss='mean_squared_error',\n",
    "                      optimizer=\"Adam\",\n",
    "                      metrics=['accuracy'])\n",
    "\n",
    "        x_train, x_valid, y_train, y_valid = train_test_split(x_train, y_train, test_size=.6)\n",
    "        \n",
    "        model.fit(x_train, y_train,\n",
    "                  validation_data=(x_valid, y_valid),\n",
    "                  epochs=epochs,\n",
    "                  batch_size=128,\n",
    "                  verbose = 0)\n",
    "        \n",
    "        curr_score_valid = model.evaluate(x_valid, y_valid) #, batch_size=128)\n",
    "        curr_score_test = model.evaluate(x_test, y_test) #, batch_size=128)\n",
    "        pred_value = model.predict(x_test)\n",
    "        \n",
    "        print(\"\\n Train Accuracy: {}, Test Accuracy: {}\".format(curr_score_valid[1], curr_score_test[1])  )\n",
    "        Train.scores.append(Train.score(epochs,no_of_features,hidden_layers,curr_score_valid[1], curr_score_test[1]))\n",
    "        #Train.models.append(Train.model_detail(epochs,no_of_features,hidden_layers,model))\n",
    "        y_pred = pred_value[:,-1]\n",
    "        y_pred[y_pred >= pred_value[:,-1].mean()] = 1\n",
    "        y_pred[y_pred < pred_value[:,-1].mean()] = 0\n",
    "        curr_pred = pd.DataFrame({\"{}_{}_{}\".format(epochs,f,h):y_pred},)\n",
    "        Train.predictions = pd.concat([Train.predictions, curr_pred], axis = 1)\n",
    "                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training for no_of_features: 4, hidden_layer: 2\n",
      "22304/22544 [============================>.] - ETA: 0s\n",
      " Train Accuracy: 0.015360393734123625, Test Accuracy: 0.010778921220723917\n",
      "Training for no_of_features: 4, hidden_layer: 4\n",
      "21792/22544 [===========================>..] - ETA: 0s\n",
      " Train Accuracy: 0.5586896697713802, Test Accuracy: 0.5328246983676366\n",
      "Training for no_of_features: 4, hidden_layer: 6\n",
      "22304/22544 [============================>.] - ETA: 0s\n",
      " Train Accuracy: 0.46153947925486877, Test Accuracy: 0.5685770049680624\n",
      "Training for no_of_features: 4, hidden_layer: 50\n",
      "21824/22544 [============================>.] - ETA: 0s\n",
      " Train Accuracy: 0.5347824936494496, Test Accuracy: 0.43075762952448543\n",
      "Training for no_of_features: 4, hidden_layer: 100\n",
      "22464/22544 [============================>.] - ETA: 0s\n",
      " Train Accuracy: 0.5348618755292125, Test Accuracy: 0.43075762952448543\n",
      "Training for no_of_features: 8, hidden_layer: 2\n",
      "22272/22544 [============================>.] - ETA: 0s\n",
      " Train Accuracy: 0.0066416172734970365, Test Accuracy: 0.004746273953158268\n",
      "Training for no_of_features: 8, hidden_layer: 4\n",
      "21728/22544 [===========================>..] - ETA: 0s\n",
      " Train Accuracy: 0.4497115791701948, Test Accuracy: 0.4264105748757984\n",
      "Training for no_of_features: 8, hidden_layer: 6\n",
      "22368/22544 [============================>.] - ETA: 0s\n",
      " Train Accuracy: 0.49567368755292124, Test Accuracy: 0.544402058197303\n",
      "Training for no_of_features: 8, hidden_layer: 50\n",
      "22240/22544 [============================>.] - ETA: 0s\n",
      " Train Accuracy: 0.9770850973751058, Test Accuracy: 0.7410397444996452\n",
      "Training for no_of_features: 8, hidden_layer: 100\n",
      "22208/22544 [============================>.] - ETA: 0s\n",
      " Train Accuracy: 0.5365024343776461, Test Accuracy: 0.43075762952448543\n",
      "Training for no_of_features: 16, hidden_layer: 2\n",
      "21984/22544 [============================>.] - ETA: 0s\n",
      " Train Accuracy: 0.2233144580863675, Test Accuracy: 0.15733676366217175\n",
      "Training for no_of_features: 16, hidden_layer: 4\n",
      "22496/22544 [============================>.] - ETA: 0s\n",
      " Train Accuracy: 0.29811864944961897, Test Accuracy: 0.22529276082327893\n",
      "Training for no_of_features: 16, hidden_layer: 6\n",
      "22336/22544 [============================>.] - ETA: 0s\n",
      " Train Accuracy: 0.5995713378492803, Test Accuracy: 0.5599272533711852\n",
      "Training for no_of_features: 16, hidden_layer: 50\n",
      "22272/22544 [============================>.] - ETA: 0s\n",
      " Train Accuracy: 0.9410324936494496, Test Accuracy: 0.7050212916962385\n",
      "Training for no_of_features: 16, hidden_layer: 100\n",
      "22240/22544 [============================>.] - ETA: 0s\n",
      " Train Accuracy: 0.5354572396274344, Test Accuracy: 0.43075762952448543\n",
      "Training for no_of_features: 32, hidden_layer: 2\n",
      "22304/22544 [============================>.] - ETA: 0s\n",
      " Train Accuracy: 0.001111346316680779, Test Accuracy: 0.0012863733144073811\n",
      "Training for no_of_features: 32, hidden_layer: 4\n",
      "21952/22544 [============================>.] - ETA: 0s\n",
      " Train Accuracy: 0.10905747248094835, Test Accuracy: 0.09772001419446416\n",
      "Training for no_of_features: 32, hidden_layer: 6\n",
      "22528/22544 [============================>.] - ETA: 0s\n",
      " Train Accuracy: 0.01969993649449619, Test Accuracy: 0.025904897090134847\n",
      "Training for no_of_features: 32, hidden_layer: 50\n",
      "22304/22544 [============================>.] - ETA: 0s\n",
      " Train Accuracy: 0.9522650296359018, Test Accuracy: 0.7480039034776437\n",
      "Training for no_of_features: 32, hidden_layer: 100\n",
      "22464/22544 [============================>.] - ETA: 0s\n",
      " Train Accuracy: 0.5353646274343776, Test Accuracy: 0.43075762952448543\n",
      "Training for no_of_features: 64, hidden_layer: 2\n",
      "22304/22544 [============================>.] - ETA: 0s\n",
      " Train Accuracy: 0.025666807790008468, Test Accuracy: 0.019118168914123494\n",
      "Training for no_of_features: 64, hidden_layer: 4\n",
      "22176/22544 [============================>.] - ETA: 0s\n",
      " Train Accuracy: 0.05560700677392041, Test Accuracy: 0.04435770049680625\n",
      "Training for no_of_features: 64, hidden_layer: 6\n",
      "22368/22544 [============================>.] - ETA: 0s\n",
      " Train Accuracy: 0.021393416596104997, Test Accuracy: 0.005766501064584812\n",
      "Training for no_of_features: 64, hidden_layer: 50\n",
      "22496/22544 [============================>.] - ETA: 0s\n",
      " Train Accuracy: 0.9609838060965283, Test Accuracy: 0.7175745209368346\n",
      "Training for no_of_features: 64, hidden_layer: 100\n",
      "22400/22544 [============================>.] - ETA: 0s\n",
      " Train Accuracy: 0.5338431414055885, Test Accuracy: 0.43075762952448543\n",
      "Training for no_of_features: 128, hidden_layer: 2\n",
      "22016/22544 [============================>.] - ETA: 0s\n",
      " Train Accuracy: 0.0003572184589331075, Test Accuracy: 0.00022178850248403122\n",
      "Training for no_of_features: 128, hidden_layer: 4\n",
      "22304/22544 [============================>.] - ETA: 0s\n",
      " Train Accuracy: 0.06355842506350551, Test Accuracy: 0.07070617459190916\n",
      "Training for no_of_features: 128, hidden_layer: 6\n",
      "22544/22544 [==============================] - 2s     \n",
      "\n",
      " Train Accuracy: 0.017662468247248094, Test Accuracy: 0.01641234918381831\n",
      "Training for no_of_features: 128, hidden_layer: 50\n",
      "22544/22544 [==============================] - 5s     \n",
      "\n",
      " Train Accuracy: 0.5338431414055885, Test Accuracy: 0.43075762952448543\n",
      "Training for no_of_features: 128, hidden_layer: 100\n",
      "22400/22544 [============================>.] - ETA: 0s\n",
      " Train Accuracy: 0.5344120448772227, Test Accuracy: 0.43075762952448543\n",
      "Training for no_of_features: 256, hidden_layer: 2\n",
      "22080/22544 [============================>.] - ETA: 0s\n",
      " Train Accuracy: 0.00209038950042337, Test Accuracy: 0.0031050390347764373\n",
      "Training for no_of_features: 256, hidden_layer: 4\n",
      "22464/22544 [============================>.] - ETA: 0s\n",
      " Train Accuracy: 0.006707768839966131, Test Accuracy: 0.0041696238466997874\n",
      "Training for no_of_features: 256, hidden_layer: 6\n",
      "22464/22544 [============================>.] - ETA: 0s\n",
      " Train Accuracy: 0.02078482218458933, Test Accuracy: 0.017033356990773598\n",
      "Training for no_of_features: 256, hidden_layer: 50\n",
      "75584/75584 [==============================] - 24s    \n",
      "22496/22544 [============================>.] - ETA: 0s\n",
      " Train Accuracy: 0.5348883361558001, Test Accuracy: 0.43075762952448543\n",
      "Training for no_of_features: 256, hidden_layer: 100\n",
      "75584/75584 [==============================] - 49s    \n",
      "22496/22544 [============================>.] - ETA: 0s\n",
      " Train Accuracy: 0.5344517358171041, Test Accuracy: 0.43075762952448543\n",
      "Training for no_of_features: 1024, hidden_layer: 2\n",
      "22496/22544 [============================>.] - ETA: 0s\n",
      " Train Accuracy: 0.00010584250635055038, Test Accuracy: 8.87154009936125e-05\n",
      "Training for no_of_features: 1024, hidden_layer: 4\n",
      "22544/22544 [==============================] - 4s     \n",
      "\n",
      " Train Accuracy: 0.001045194750211685, Test Accuracy: 0.001596877217885025\n",
      "Training for no_of_features: 1024, hidden_layer: 6\n",
      "22432/22544 [============================>.] - ETA: 0s\n",
      " Train Accuracy: 0.004260160880609653, Test Accuracy: 0.008117459190915543\n",
      "Training for no_of_features: 1024, hidden_layer: 50\n",
      "22544/22544 [==============================] - 25s    \n",
      "\n",
      " Train Accuracy: 0.5346501905165114, Test Accuracy: 0.43075762952448543\n",
      "Training for no_of_features: 1024, hidden_layer: 100\n"
     ]
    }
   ],
   "source": [
    "features_arr = [4, 8, 16, 32, 64, 128, 256, 1024]\n",
    "hidden_layers_arr = [2, 4, 6, 50, 100]\n",
    "\n",
    "\n",
    "for f, h in product(features_arr, hidden_layers_arr):\n",
    "    Train.execute(preprocessing.x_train, preprocessing.x_test, \n",
    "                  preprocessing.y_train, preprocessing.y_test, \n",
    "                 122, f, h)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pd.DataFrame(Train.scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#for m in Train.models:\n",
    "#    m.model.save(\"dataset/keras_model_epoch_{}_no_of_features_{}_hidden_layers_{}\".format(m.epoch,\n",
    "#                                                                                         m.no_of_features,\n",
    "#                                                                                         m.hidden_layers))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Train.predictions.to_pickle(\"dataset/dense_only_predictions.pkl\")\n",
    "pd.DataFrame(Train.scores).to_pickle(\"dataset/dense_only_scores.pkl\")"
   ]
  }
 ],
 "metadata": {
  "_draft": {
   "nbviewer_url": "https://gist.github.com/0f6c9677d5f316c57d9d8bd6e0fe8850"
  },
  "anaconda-cloud": {},
  "gist": {
   "data": {
    "description": "Final Hyper parameter tuning",
    "public": false
   },
   "id": "0f6c9677d5f316c57d9d8bd6e0fe8850"
  },
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
