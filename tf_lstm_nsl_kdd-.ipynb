{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Read Data Sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-06-01T17:23:30.525219Z",
     "start_time": "2017-06-01T17:23:30.121532Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import time\n",
    "from collections import namedtuple\n",
    "pd.set_option(\"display.max_rows\",35)\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-06-01T17:23:30.585521Z",
     "start_time": "2017-06-01T17:23:30.526848Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class dataset:\n",
    "    kdd_train_2labels = pd.read_pickle(\"dataset/kdd_train_2labels_20percent.pkl\")\n",
    "    kdd_test_2labels = pd.read_pickle(\"dataset/kdd_test_2labels_20percent.pkl\")\n",
    "    \n",
    "    kdd_train_5labels = pd.read_pickle(\"dataset/kdd_train_5labels.pkl\")\n",
    "    kdd_test_5labels = pd.read_pickle(\"dataset/kdd_test_5labels.pkl\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-06-01T17:23:30.591918Z",
     "start_time": "2017-06-01T17:23:30.587152Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(25192, 120)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.kdd_train_2labels.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-06-01T17:23:30.602901Z",
     "start_time": "2017-06-01T17:23:30.593452Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(11850, 120)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.kdd_test_2labels.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-06-01T17:23:30.963779Z",
     "start_time": "2017-06-01T17:23:30.604391Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.99148920692946862"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn import model_selection as ms\n",
    "from sklearn import preprocessing as pp\n",
    "\n",
    "class preprocess:\n",
    "    \n",
    "    output_columns_2labels = ['is_Attack','is_Normal']\n",
    "    \n",
    "    x_input = dataset.kdd_train_2labels.drop(output_columns_2labels, axis = 1)\n",
    "    y_output = dataset.kdd_train_2labels.loc[:,output_columns_2labels]\n",
    "\n",
    "    x_test_input = dataset.kdd_test_2labels.drop(output_columns_2labels, axis = 1)\n",
    "    y_test = dataset.kdd_test_2labels.loc[:,output_columns_2labels]\n",
    "\n",
    "    ss = pp.StandardScaler()\n",
    "\n",
    "    x_train = ss.fit_transform(x_input)\n",
    "    x_test = ss.transform(x_test_input)\n",
    "\n",
    "    y_train = y_output.values\n",
    "    y_test = y_test.values\n",
    "\n",
    "preprocess.x_train.std()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-06-01T17:23:32.728911Z",
     "start_time": "2017-06-01T17:23:30.965282Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.contrib.legacy_seq2seq.python.ops.seq2seq import basic_rnn_seq2seq\n",
    "from tensorflow.contrib.rnn import RNNCell, LSTMCell, MultiRNNCell\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-06-01T17:23:32.906823Z",
     "start_time": "2017-06-01T17:23:32.730589Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class network(object):\n",
    "    \n",
    "    input_dim = 118\n",
    "    classes = 2\n",
    "    hidden_encoder_dim = 118\n",
    "    hidden_layers = 1\n",
    "    latent_dim = 10\n",
    "\n",
    "    hidden_decoder_dim = 118\n",
    "    lam = 0.01\n",
    "    \n",
    "    def __init__(self, classes, hidden_layers, num_of_features):\n",
    "        self.classes = classes\n",
    "        self.hidden_layers = hidden_layers\n",
    "        self.latent_dim = num_of_features\n",
    "            \n",
    "    def build_layers(self):\n",
    "        tf.reset_default_graph()\n",
    "        #learning_rate = tf.Variable(initial_value=0.001)\n",
    "\n",
    "        input_dim = self.input_dim\n",
    "        classes = self.classes\n",
    "        hidden_encoder_dim = self.hidden_encoder_dim\n",
    "        hidden_layers = self.hidden_layers\n",
    "        latent_dim = self.latent_dim\n",
    "        hidden_decoder_dim = self.hidden_decoder_dim\n",
    "        lam = self.lam\n",
    "        \n",
    "        with tf.variable_scope(\"Input\"):\n",
    "            self.x_input = tf.placeholder(\"float\", shape=[None, 1, input_dim])\n",
    "            self.y_input_ = tf.placeholder(\"float\", shape=[None, 1, classes])\n",
    "            self.keep_prob = tf.placeholder(\"float\")\n",
    "            self.lr = tf.placeholder(\"float\")\n",
    "            self.x_list = tf.unstack(self.x_input, axis= 1)\n",
    "            self.y_list_ = tf.unstack(self.y_input_, axis = 1)\n",
    "            self.y_ = self.y_list_[0]\n",
    "            \n",
    "            #GO = tf.fill((tf.shape(self.x)[0], 1), 0.5)\n",
    "            \n",
    "            #y_with_GO = tf.stack([self.y_, GO])\n",
    "            \n",
    "        with tf.variable_scope(\"lstm\"):\n",
    "            multi_cell = MultiRNNCell([LSTMCell(input_dim) for i in range(hidden_layers)] )\n",
    "            \n",
    "            self.y, states = basic_rnn_seq2seq(self.x_list, self.y_list_, multi_cell)\n",
    "            #self.y = tf.slice(self.y, [0, 0], [-1,2])\n",
    "            \n",
    "            #self.out = tf.squeeze(self.y)\n",
    "            \n",
    "            self.y = tf.layers.dense(self.y[0], classes, activation = tf.nn.softmax)\n",
    "        with tf.variable_scope(\"Loss\"):\n",
    "            \n",
    "            self.regularized_loss = tf.losses.mean_squared_error(self.y_, self.y)\n",
    "            correct_prediction = tf.equal(tf.argmax(self.y_, 1), tf.argmax(self.y, 1))\n",
    "            self.tf_accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32), name = \"Accuracy\")\n",
    "\n",
    "        with tf.variable_scope(\"Optimizer\"):\n",
    "            learning_rate=self.lr\n",
    "            optimizer = tf.train.AdamOptimizer(learning_rate)\n",
    "            gradients, variables = zip(*optimizer.compute_gradients(self.regularized_loss))\n",
    "            gradients = [\n",
    "                None if gradient is None else tf.clip_by_value(gradient, -1, 1)\n",
    "                for gradient in gradients]\n",
    "            self.train_op = optimizer.apply_gradients(zip(gradients, variables))\n",
    "            #self.train_op = optimizer.minimize(self.regularized_loss)\n",
    "            \n",
    "        # add op for merging summary\n",
    "        #self.summary_op = tf.summary.merge_all()\n",
    "        self.pred = tf.argmax(self.y, axis = 1)\n",
    "        self.actual = tf.argmax(self.y_, axis = 1)\n",
    "\n",
    "        # add Saver ops\n",
    "        self.saver = tf.train.Saver()\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-06-01T00:59:00.684124Z",
     "start_time": "2017-06-01T00:58:59.843181Z"
    }
   },
   "source": [
    "batch_iterations = 200\n",
    "\n",
    "x_train, x_valid, y_train, y_valid, = ms.train_test_split(preprocess.x_train, \n",
    "                                                                          preprocess.y_train, \n",
    "                                                                          test_size=0.1)\n",
    "batch_indices = np.array_split(np.arange(x_train.shape[0]), \n",
    "                                           batch_iterations)\n",
    "                                                                          \n",
    "for i in batch_indices:\n",
    "    print(x_train[i,np.newaxis,:])\n",
    "    print(y_train[i,np.newaxis,:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-06-01T17:23:33.111756Z",
     "start_time": "2017-06-01T17:23:32.908453Z"
    },
    "collapsed": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import collections\n",
    "\n",
    "class Train:    \n",
    "    \n",
    "    result = namedtuple(\"score\", ['epoch', 'no_of_features','hidden_layers','train_score', 'test_score', 'time_taken'])\n",
    "\n",
    "    predictions = {}\n",
    "\n",
    "    results = []\n",
    "    best_acc = 0\n",
    "    best_acc_global = 0\n",
    "\n",
    "    def train(epochs, net, h,f, lrs):\n",
    "        batch_iterations = 200\n",
    "        train_loss = None\n",
    "        Train.best_acc = 0\n",
    "        os.makedirs(\"dataset/tf_lstm_nsl_kdd-/hidden layers_{}_features count_{}\".format(h,f),\n",
    "                    exist_ok = True)\n",
    "        with tf.Session() as sess:\n",
    "            #summary_writer_train = tf.summary.FileWriter('./logs/kdd/VAE/training', graph=sess.graph)\n",
    "            #summary_writer_valid = tf.summary.FileWriter('./logs/kdd/VAE/validation')\n",
    "\n",
    "            sess.run(tf.global_variables_initializer())\n",
    "            start_time = time.perf_counter()\n",
    "            for lr in lrs:\n",
    "                for epoch in range(1, (epochs+1)):\n",
    "                    x_train, x_valid, y_train, y_valid, = ms.train_test_split(preprocess.x_train, \n",
    "                                                                              preprocess.y_train, \n",
    "                                                                              test_size=0.1)\n",
    "                    batch_indices = np.array_split(np.arange(x_train.shape[0]), \n",
    "                                               batch_iterations)\n",
    "\n",
    "                    for i in batch_indices:\n",
    "\n",
    "                        _, train_loss = sess.run([net.train_op, net.regularized_loss], #net.summary_op\n",
    "                                                              feed_dict={net.x_input: x_train[i,np.newaxis,:], \n",
    "                                                                         net.y_input_: y_train[i,np.newaxis,:], \n",
    "                                                                         net.keep_prob:1, net.lr:lr})\n",
    "                        #summary_writer_train.add_summary(summary_str, epoch)\n",
    "                        if(train_loss > 1e9):\n",
    "                            print(\"Step {} | Training Loss: {:.6f}\".format(epoch, train_loss))\n",
    "\n",
    "\n",
    "                    valid_accuracy,valid_loss = sess.run([net.tf_accuracy, net.regularized_loss], #net.summary_op \n",
    "                                                          feed_dict={net.x_input: x_valid[:,np.newaxis,:], \n",
    "                                                                     net.y_input_: y_valid[:,np.newaxis,:], \n",
    "                                                                     net.keep_prob:1, net.lr:lr})\n",
    "                    #summary_writer_valid.add_summary(summary_str, epoch)\n",
    "\n",
    "\n",
    "\n",
    "                    accuracy, pred_value, actual_value, y_pred = sess.run([net.tf_accuracy, \n",
    "                                                                   net.pred, \n",
    "                                                                   net.actual, net.y], \n",
    "                                                                  feed_dict={net.x_input: preprocess.x_test[:,np.newaxis,:], \n",
    "                                                                             net.y_input_: preprocess.y_test[:,np.newaxis,:], \n",
    "                                                                             net.keep_prob:1, net.lr:lr})\n",
    "\n",
    "                    print(\"Step {} | Training Loss: {:.6f} | Train Accuracy: {:.6f} | Test Accuracy: {:.6f}\".format(epoch, train_loss, valid_accuracy, accuracy))\n",
    "\n",
    "                    if accuracy > Train.best_acc_global:\n",
    "                                Train.best_acc_global = accuracy\n",
    "                                Train.pred_value = pred_value\n",
    "                                Train.actual_value = actual_value\n",
    "                                Train.best_parameters = \"Hidden Layers:{}, Features Count:{}\".format(h, f)\n",
    "\n",
    "                    if accuracy > Train.best_acc:\n",
    "\n",
    "                        #net.saver.save(sess, \"dataset/tf_vae_only_nsl_kdd_hidden layers_{}_features count_{}\".format(epochs,h,f))\n",
    "                        #Train.results.append(Train.result(epochs, f, h,valid_accuracy, accuracy))\n",
    "                        #curr_pred = pd.DataFrame({\"Attack_prob\":y_pred[:,-2], \"Normal_prob\":y_pred[:, -1]})\n",
    "                        #Train.predictions.update({\"{}_{}_{}\".format(epochs,f,h):curr_pred})\n",
    "\n",
    "                        Train.best_acc = accuracy\n",
    "                        if not (np.isnan(train_loss)):\n",
    "                            net.saver.save(sess, \n",
    "                                       \"dataset/tf_lstm_nsl_kdd-/hidden layers_{}_features count_{}/model\"\n",
    "                                       .format(h,f), \n",
    "                                       global_step = epoch, \n",
    "                                       write_meta_graph=False)\n",
    "\n",
    "                        curr_pred = pd.DataFrame({\"Attack_prob\":y_pred[:,-2], \"Normal_prob\":y_pred[:, -1], \"Prediction\":pred_value})\n",
    "                        Train.predictions.update({\"{}_{}_{}\".format(epochs*len(lrs),f,h):\n",
    "                                                  (curr_pred, \n",
    "                                                   Train.result(epochs*len(lrs), f, h,valid_accuracy, accuracy, time.perf_counter() - start_time))})\n",
    "\n",
    "\n",
    "\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-06-01T17:26:15.350458Z",
     "start_time": "2017-06-01T17:23:33.113444Z"
    },
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current Layer Attributes - epochs:5 hidden layers:2 features count:122\n",
      "Step 1 | Training Loss: 0.000026 | Train Accuracy: 0.995635 | Test Accuracy: 0.955781\n",
      "Step 2 | Training Loss: 0.000005 | Train Accuracy: 0.999206 | Test Accuracy: 0.995106\n",
      "Step 3 | Training Loss: 0.000003 | Train Accuracy: 0.998810 | Test Accuracy: 0.973502\n",
      "Step 4 | Training Loss: 0.000002 | Train Accuracy: 0.999206 | Test Accuracy: 0.960675\n",
      "Step 5 | Training Loss: 0.000002 | Train Accuracy: 0.999206 | Test Accuracy: 0.955527\n",
      "Step 1 | Training Loss: 0.000005 | Train Accuracy: 1.000000 | Test Accuracy: 0.955527\n",
      "Step 2 | Training Loss: 0.000001 | Train Accuracy: 0.998810 | Test Accuracy: 0.955527\n",
      "Step 3 | Training Loss: 0.000000 | Train Accuracy: 0.999603 | Test Accuracy: 0.955527\n",
      "Step 4 | Training Loss: 0.000002 | Train Accuracy: 0.998810 | Test Accuracy: 0.955527\n",
      "Step 5 | Training Loss: 0.008831 | Train Accuracy: 0.998810 | Test Accuracy: 0.955443\n",
      "Current Layer Attributes - epochs:5 hidden layers:4 features count:122\n",
      "Step 1 | Training Loss: 0.061947 | Train Accuracy: 0.919444 | Test Accuracy: 0.542616\n",
      "Step 2 | Training Loss: 0.094787 | Train Accuracy: 0.955159 | Test Accuracy: 0.520169\n",
      "Step 3 | Training Loss: 0.034702 | Train Accuracy: 0.966270 | Test Accuracy: 0.589367\n",
      "Step 4 | Training Loss: 0.025856 | Train Accuracy: 0.967857 | Test Accuracy: 0.588692\n",
      "Step 5 | Training Loss: 0.044329 | Train Accuracy: 0.976190 | Test Accuracy: 0.591561\n",
      "Step 1 | Training Loss: 0.041175 | Train Accuracy: 0.974206 | Test Accuracy: 0.598481\n",
      "Step 2 | Training Loss: 0.034792 | Train Accuracy: 0.977778 | Test Accuracy: 0.598987\n",
      "Step 3 | Training Loss: 0.018192 | Train Accuracy: 0.972222 | Test Accuracy: 0.599494\n",
      "Step 4 | Training Loss: 0.035937 | Train Accuracy: 0.971825 | Test Accuracy: 0.600169\n",
      "Step 5 | Training Loss: 0.026774 | Train Accuracy: 0.974206 | Test Accuracy: 0.601266\n",
      "Current Layer Attributes - epochs:5 hidden layers:6 features count:122\n",
      "Step 1 | Training Loss: 0.051273 | Train Accuracy: 0.953175 | Test Accuracy: 0.569620\n",
      "Step 2 | Training Loss: 0.012012 | Train Accuracy: 0.969444 | Test Accuracy: 0.566160\n",
      "Step 3 | Training Loss: 0.020637 | Train Accuracy: 0.975794 | Test Accuracy: 0.639916\n",
      "Step 4 | Training Loss: 0.022362 | Train Accuracy: 0.975794 | Test Accuracy: 0.648354\n",
      "Step 5 | Training Loss: 0.023881 | Train Accuracy: 0.971825 | Test Accuracy: 0.615527\n",
      "Step 1 | Training Loss: 0.035004 | Train Accuracy: 0.973413 | Test Accuracy: 0.616118\n",
      "Step 2 | Training Loss: 0.003735 | Train Accuracy: 0.975397 | Test Accuracy: 0.616287\n",
      "Step 3 | Training Loss: 0.002391 | Train Accuracy: 0.976190 | Test Accuracy: 0.616540\n",
      "Step 4 | Training Loss: 0.024492 | Train Accuracy: 0.968651 | Test Accuracy: 0.616624\n",
      "Step 5 | Training Loss: 0.007351 | Train Accuracy: 0.975000 | Test Accuracy: 0.616540\n"
     ]
    }
   ],
   "source": [
    "import itertools\n",
    "class Hyperparameters:\n",
    "#    features_arr = [2, 4, 8, 16, 32, 64, 128, 256]\n",
    "#    hidden_layers_arr = [2, 4, 6, 10]\n",
    "    features_arr = [122] #[4, 8, 16, 32]\n",
    "    hidden_layers_arr = [2, 4, 6]\n",
    "\n",
    "    epochs = [5]\n",
    "    lrs = [1e-2, 1e-4]\n",
    "    \n",
    "    for e, h, f in itertools.product(epochs, hidden_layers_arr, features_arr):\n",
    "        print(\"Current Layer Attributes - epochs:{} hidden layers:{} features count:{}\".format(e,h,f))\n",
    "        n = network(2,h,f)\n",
    "        n.build_layers()\n",
    "        Train.train(e, n, h,f, lrs)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-06-01T17:26:15.357149Z",
     "start_time": "2017-06-01T17:26:15.352273Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dict1 = {}\n",
    "dict2 = []\n",
    "for k, (v1, v2) in Train.predictions.items():\n",
    "    dict1.update({k: v1})\n",
    "    dict2.append(v2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-06-01T17:26:15.367709Z",
     "start_time": "2017-06-01T17:26:15.358800Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Train.predictions = dict1\n",
    "Train.results = dict2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-06-01T17:26:15.375519Z",
     "start_time": "2017-06-01T17:26:15.369512Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_results = pd.DataFrame(Train.results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-06-01T17:26:15.391875Z",
     "start_time": "2017-06-01T17:26:15.377417Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>epoch</th>\n",
       "      <th>no_of_features</th>\n",
       "      <th>hidden_layers</th>\n",
       "      <th>train_score</th>\n",
       "      <th>test_score</th>\n",
       "      <th>time_taken</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10</td>\n",
       "      <td>122</td>\n",
       "      <td>2</td>\n",
       "      <td>0.999206</td>\n",
       "      <td>0.995106</td>\n",
       "      <td>4.875151</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>10</td>\n",
       "      <td>122</td>\n",
       "      <td>6</td>\n",
       "      <td>0.975794</td>\n",
       "      <td>0.648354</td>\n",
       "      <td>30.417004</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10</td>\n",
       "      <td>122</td>\n",
       "      <td>4</td>\n",
       "      <td>0.974206</td>\n",
       "      <td>0.601266</td>\n",
       "      <td>52.221337</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   epoch  no_of_features  hidden_layers  train_score  test_score  time_taken\n",
       "0     10             122              2     0.999206    0.995106    4.875151\n",
       "2     10             122              6     0.975794    0.648354   30.417004\n",
       "1     10             122              4     0.974206    0.601266   52.221337"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_results.sort_values(by = 'test_score', ascending = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-06-01T17:26:15.404283Z",
     "start_time": "2017-06-01T17:26:15.393614Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pd.Panel(Train.predictions).to_pickle(\"dataset/tf_lstm_nsl_kdd_predictions-.pkl\")\n",
    "df_results.to_pickle(\"dataset/tf_lstm_nsl_kdd_scores-.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-06-01T17:46:57.605437Z",
     "start_time": "2017-06-01T17:46:57.544230Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import itertools\n",
    "\n",
    "def plot_confusion_matrix(cm, classes,\n",
    "                          normalize=False,\n",
    "                          title='Confusion matrix',\n",
    "                          cmap=plt.cm.Blues):\n",
    "    \"\"\"\n",
    "    This function prints and plots the confusion matrix.\n",
    "    Normalization can be applied by setting `normalize=True`.\n",
    "    \"\"\"\n",
    "    np.set_printoptions(precision=4)\n",
    "\n",
    "    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n",
    "    plt.title(title)\n",
    "    plt.colorbar()\n",
    "    tick_marks = np.arange(len(classes))\n",
    "    plt.xticks(tick_marks, classes, rotation=45)\n",
    "    plt.yticks(tick_marks, classes)\n",
    "\n",
    "    if normalize:\n",
    "        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "        print(\"Normalized confusion matrix\")\n",
    "    else:\n",
    "        print('Confusion matrix, without normalization')\n",
    "\n",
    "    print(cm)\n",
    "\n",
    "    thresh = cm.max() / 2.\n",
    "    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
    "        plt.text(j, i, cm[i, j].round(4),\n",
    "                 horizontalalignment=\"center\",\n",
    "                 color=\"white\" if cm[i, j] > thresh else \"black\")\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.ylabel('True label')\n",
    "    plt.xlabel('Predicted label')\n",
    "\n",
    "def plot(actual_value, pred_value):\n",
    "    from sklearn.metrics import confusion_matrix\n",
    "    cm_2labels = confusion_matrix(y_pred = pred_value, y_true = actual_value)\n",
    "    plt.figure(figsize=[6,6])\n",
    "    plot_confusion_matrix(cm_2labels, preprocess.output_columns_2labels, normalize = True,\n",
    "                         title = Train.best_parameters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-06-01T17:46:58.292309Z",
     "start_time": "2017-06-01T17:46:58.021876Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Normalized confusion matrix\n",
      "[[ 1.     0.   ]\n",
      " [ 0.027  0.973]]\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAbUAAAGgCAYAAAAtsfn1AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\namZmlhsOamZmlhv/H3JiD+y9JBB9AAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f35325385c0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot(actual_value = Train.actual_value, pred_value = Train.pred_value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-06-01T17:46:59.567338Z",
     "start_time": "2017-06-01T17:46:59.538824Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#4.5 GB\n",
    "pd.Series(Train.pred_value).to_csv('LSTM_prediction_values-.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "_draft": {
   "nbviewer_url": "https://gist.github.com/7d1ace18a82178e15ece8fc5252fce88"
  },
  "anaconda-cloud": {},
  "gist": {
   "data": {
    "description": "Hyper parameter tuning",
    "public": false
   },
   "id": "7d1ace18a82178e15ece8fc5252fce88"
  },
  "kernelspec": {
   "display_name": "Python [conda env:p3]",
   "language": "python",
   "name": "conda-env-p3-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
